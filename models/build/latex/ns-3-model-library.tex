%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}

\usepackage{amssymb}
 \definecolor{VerbatimBorderColor}{rgb}{1,1,1}
 \renewcommand{\sphinxcode}[1]{\texttt{\small{#1}}}


\title{ns-3 Model Library}
\date{Apr 29, 2020}
\release{ns-3-dev}
\author{ns-3 project}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{ns-3.png}\par}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


This is the \sphinxstyleemphasis{ns\sphinxhyphen{}3 Model Library} documentation. Primary documentation for the ns\sphinxhyphen{}3 project is
available in five forms:
\begin{itemize}
\item {} 
\sphinxhref{https://www.nsnam.org/doxygen/index.html}{ns\sphinxhyphen{}3 Doxygen}: Documentation of the public APIs of the simulator

\item {} 
Tutorial, Manual, and Model Library \sphinxstyleemphasis{(this document)} for the \sphinxhref{https://www.nsnam.org/documentation/latest/}{latest release} and \sphinxhref{https://www.nsnam.org/documentation/development-tree/}{development tree}

\item {} 
\sphinxhref{https://www.nsnam.org/wiki}{ns\sphinxhyphen{}3 wiki}

\end{itemize}

This document is written in \sphinxhref{http://docutils.sourceforge.net/rst.html}{reStructuredText} for \sphinxhref{http://sphinx.pocoo.org/}{Sphinx} and is maintained in the
\sphinxcode{\sphinxupquote{doc/models}} directory of ns\sphinxhyphen{}3’s source code.


\chapter{Organization}
\label{\detokenize{organization:organization}}\label{\detokenize{organization::doc}}
This manual compiles documentation for \sphinxstyleemphasis{ns\sphinxhyphen{}3} models and supporting
software that enable users to construct network simulations.
It is important to distinguish between \sphinxstylestrong{modules} and \sphinxstylestrong{models}:
\begin{itemize}
\item {} 
\sphinxstyleemphasis{ns\sphinxhyphen{}3} software is organized into separate \sphinxstyleemphasis{modules} that are each
built as a separate software library.  Individual ns\sphinxhyphen{}3 programs can link
the modules (libraries) they need to conduct their simulation.

\item {} 
\sphinxstyleemphasis{ns\sphinxhyphen{}3} \sphinxstyleemphasis{models} are abstract representations of real\sphinxhyphen{}world objects,
protocols, devices, etc.

\end{itemize}

An \sphinxstyleemphasis{ns\sphinxhyphen{}3} module may consist of more than one model (for instance, the
\sphinxcode{\sphinxupquote{internet}} module contains models for both TCP and UDP).  In general,
ns\sphinxhyphen{}3 models do not span multiple software modules, however.

This manual provides documentation about the models of \sphinxstyleemphasis{ns\sphinxhyphen{}3}.  It
complements two other sources of documentation concerning models:
\begin{itemize}
\item {} 
the model APIs are documented, from a programming perspective, using
\sphinxhref{http://www.doxygen.org}{Doxygen}.  Doxygen for ns\sphinxhyphen{}3 models is available
\sphinxhref{http://www.nsnam.org/docs/doxygen/index.html}{on the project web server}.

\item {} 
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} core is documented in the developer’s manual.  \sphinxstyleemphasis{ns\sphinxhyphen{}3} models make
use of the facilities of the core, such as attributes, default values,
random numbers, test frameworks, etc.  Consult the
\sphinxhref{http://www.nsnam.org}{main web site} to find copies of the manual.

\end{itemize}

Finally, additional documentation about various aspects of \sphinxstyleemphasis{ns\sphinxhyphen{}3} may
exist on the \sphinxhref{http://www.nsnam.org/wiki}{project wiki}.

A sample outline of how to write model library documentation can be
found by executing the \sphinxcode{\sphinxupquote{create\sphinxhyphen{}module.py}} program and looking at the
template created in the file \sphinxcode{\sphinxupquote{new\sphinxhyphen{}module/doc/new\sphinxhyphen{}module.rst}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{cd} src
\PYGZdl{} ./create\PYGZhy{}module.py new\PYGZhy{}module
\end{sphinxVerbatim}

The remainder of this document is organized alphabetically by module name.

If you are new to \sphinxstyleemphasis{ns\sphinxhyphen{}3}, you might first want to read below about the network
module, which contains some fundamental models for the simulator.
The packet model, models for different address formats, and abstract
base classes for objects such as nodes, net devices, channels, sockets, and
applications are discussed there.


\chapter{Animation}
\label{\detokenize{animation:animation}}\label{\detokenize{animation::doc}}
Animation is an important tool for network simulation. While \sphinxstyleemphasis{ns\sphinxhyphen{}3} does not
contain a default graphical animation tool, we currently have two ways to provide
animation, namely using the PyViz method or the NetAnim method.
The PyViz method is described in \sphinxurl{http://www.nsnam.org/wiki/PyViz}.

We will describe the NetAnim method briefly here.


\section{NetAnim}
\label{\detokenize{animation:netanim}}
NetAnim is a standalone, Qt4\sphinxhyphen{}based software executable that uses a trace file generated during
an \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation to display the topology and animate the packet flow between nodes.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen,height=400\sphinxpxdimen]{{NetAnim_3_105}.pdf}
\caption{An example of packet animation on wired\sphinxhyphen{}links}\label{\detokenize{animation:id1}}\end{figure}

In addition, NetAnim also provides useful features such as tables to display meta\sphinxhyphen{}data of packets like the image below

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{PacketStatistics}.pdf}
\caption{An example of tables for packet meta\sphinxhyphen{}data with protocol filters}\label{\detokenize{animation:id2}}\end{figure}

A way to visualize the trajectory of a mobile node

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{Trajectory}.pdf}
\caption{An example of the trajectory of a mobile node}\label{\detokenize{animation:id3}}\end{figure}

A way to display the routing\sphinxhyphen{}tables of multiple nodes at various points in time

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{RoutingTables}.pdf}
\end{figure}

A way to display counters associated with multiple nodes as a chart or a table

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{NodeCountersChart}.pdf}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{NodeCountersTable}.pdf}
\end{figure}

A way to view the timeline of packet transmit and receive events

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{PacketTimeline}.pdf}
\end{figure}


\subsection{Methodology}
\label{\detokenize{animation:methodology}}
The class ns3::AnimationInterface is responsible for the creation the trace XML file.
AnimationInterface uses the tracing infrastructure to track packet flows between nodes.
AnimationInterface registers itself as a trace hook for tx and rx events before the simulation
begins. When a packet is scheduled for transmission or reception, the corresponding tx and rx
trace hooks in AnimationInterface are called. When the rx hooks are called, AnimationInterface will be aware of the two endpoints between which a packet has flowed, and adds this information
to the trace file, in XML format along with the corresponding tx and rx timestamps. The XML format
will be discussed in a later section. It is important to note that AnimationInterface records a
packet only if the rx trace hooks are called. Every tx event must be matched by an rx event.


\subsection{Downloading NetAnim}
\label{\detokenize{animation:downloading-netanim}}
If NetAnim is not already available in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} package you downloaded, you can do the following:

Please ensure that you have installed mercurial.
The latest version of NetAnim can be downloaded using mercurial with the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} hg clone http://code.nsnam.org/netanim
\end{sphinxVerbatim}


\subsection{Building NetAnim}
\label{\detokenize{animation:building-netanim}}

\subsubsection{Prerequisites}
\label{\detokenize{animation:prerequisites}}
Qt5 (5.4 and over) is required to build NetAnim. This can be obtained using the following ways:

For Ubuntu Linux distributions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} apt\PYGZhy{}get install qt5\PYGZhy{}default
\end{sphinxVerbatim}

For Red Hat/Fedora based distribution:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} yum install qt5
\PYGZdl{} yum install qt5\PYGZhy{}devel
\end{sphinxVerbatim}

For Mac/OSX, see \sphinxurl{http://qt.nokia.com/downloads/}


\subsubsection{Build steps}
\label{\detokenize{animation:build-steps}}
To build NetAnim use the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{cd} netanim
\PYGZdl{} make clean
\PYGZdl{} qmake NetAnim.pro
\PYGZdl{} make
\end{sphinxVerbatim}

Note: qmake could be “qmake\sphinxhyphen{}qt5” in some systems

This should create an executable named “NetAnim” in the same directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYGZdl{} ls \PYGZhy{}l NetAnim
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x \PYG{l+m}{1} john john \PYG{l+m}{390395} \PYG{l+m}{2012}\PYGZhy{}05\PYGZhy{}22 \PYG{l+m}{08}:32 NetAnim
\end{sphinxVerbatim}


\subsection{Usage}
\label{\detokenize{animation:usage}}
Using NetAnim is a two\sphinxhyphen{}step process

Step 1:Generate the animation XML trace file during simulation using “ns3::AnimationInterface” in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} code base.

Step 2:Load the XML trace file generated in Step 1 with the offline Qt4\sphinxhyphen{}based animator named NetAnim.


\subsubsection{Step 1: Generate XML animation trace file}
\label{\detokenize{animation:step-1-generate-xml-animation-trace-file}}
The class “AnimationInterface” under “src/netanim” uses underlying \sphinxstyleemphasis{ns\sphinxhyphen{}3} trace sources
to construct a timestamped ASCII file in XML format.

Examples are found under src/netanim/examples
Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}d debug configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}dumbbell\PYGZhy{}animation\PYGZdq{}}
\end{sphinxVerbatim}

The above will create an XML file dumbbell\sphinxhyphen{}animation.xml


\paragraph{Mandatory}
\label{\detokenize{animation:mandatory}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Ensure that your program’s wscript includes the “netanim” module. An example of such a wscript is at src/netanim/examples/wscript.

\item {} 
Include the header {[}\#include “ns3/netanim\sphinxhyphen{}module.h”{]} in your test program

\item {} 
Add the statement

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{AnimationInterface} \PYG{n+nf}{anim} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{animation.xml}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}  \PYG{c+c1}{// where \PYGZdq{}animation.xml\PYGZdq{} is any arbitrary filename}
\end{sphinxVerbatim}

{[}for versions before ns\sphinxhyphen{}3.13 you also have to use the line “anim.SetXMLOutput() to set the XML mode and also use anim.StartAnimation();{]}


\paragraph{Optional}
\label{\detokenize{animation:optional}}
The following are optional but useful steps:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 1}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{SetMobilityPollInterval} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

AnimationInterface records the position of all nodes every 250 ms by default. The statement above sets
the periodic interval at which AnimationInterface records the position of all nodes. If the nodes are
expected to move very little, it is useful to set a high mobility poll interval to avoid large XML files.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 2}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{SetConstantPosition} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}} \PYG{n}{Node} \PYG{o}{\PYGZgt{}} \PYG{n}{n}\PYG{p}{,} \PYG{k+kt}{double} \PYG{n}{x}\PYG{p}{,} \PYG{k+kt}{double} \PYG{n}{y}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

AnimationInterface requires that the position of all nodes be set. In \sphinxstyleemphasis{ns\sphinxhyphen{}3} this is done by setting an associated MobilityModel. “SetConstantPosition” is a quick way to set the x\sphinxhyphen{}y coordinates of a node which is stationary.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 3}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{SetStartTime} \PYG{p}{(}\PYG{n}{Seconds}\PYG{p}{(}\PYG{l+m+mi}{150}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;} \PYG{n}{and} \PYG{n}{anim}\PYG{p}{.}\PYG{n}{SetStopTime} \PYG{p}{(}\PYG{n}{Seconds}\PYG{p}{(}\PYG{l+m+mi}{150}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

AnimationInterface can generate large XML files. The above statements restricts the window between which AnimationInterface does tracing. Restricting the window serves to focus only on relevant portions of the simulation and creating manageably small XML files

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 4}
\PYG{n}{AnimationInterface} \PYG{n+nf}{anim} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{animation.xml}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{50000}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Using the above constructor ensures that each animation XML trace file has only 50000 packets. For example, if AnimationInterface captures 150000 packets, using the above constructor splits the capture into 3 files
\begin{itemize}
\item {} 
animation.xml \sphinxhyphen{} containing the packet range 1\sphinxhyphen{}50000

\item {} 
animation.xml\sphinxhyphen{}1 \sphinxhyphen{} containing the packet range 50001\sphinxhyphen{}100000

\item {} 
animation.xml\sphinxhyphen{}2 \sphinxhyphen{} containing the packet range 100001\sphinxhyphen{}150000

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 5}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{EnablePacketMetadata} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

With the above statement, AnimationInterface records the meta\sphinxhyphen{}data of each packet in the xml trace file. Metadata can be used by NetAnim to provide better statistics and filter, along with providing some brief information about the packet such as TCP sequence number or source \& destination IP address during packet animation.

CAUTION: Enabling this feature will result in larger XML trace files.
Please do NOT enable this feature when using Wimax links.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 6}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{UpdateNodeDescription} \PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Access\PYGZhy{}point}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

With the above statement, AnimationInterface assigns the text “Access\sphinxhyphen{}point” to node 5.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 7}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{UpdateNodeSize} \PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

With the above statement, AnimationInterface sets the node size to scale by 1.5. NetAnim automatically scales the graphics view to fit the oboundaries of the topology. This means that NetAnim, can abnormally scale a node’s size too high or too low. Using AnimationInterface::UpdateNodeSize allows you to overwrite the default scaling in NetAnim and use your own custom scale.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Step 8}
\PYG{n}{anim}\PYG{p}{.}\PYG{n}{UpdateNodeCounter} \PYG{p}{(}\PYG{l+m+mi}{89}\PYG{p}{,} \PYG{l+m+mi}{7}\PYG{p}{,} \PYG{l+m+mf}{3.4}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

With the above statement, AnimationInterface sets the counter with Id == 89, associated with Node 7 with the value 3.4.
The counter with Id 89 is obtained using AnimationInterface::AddNodeCounter. An example usage for this is in src/netanim/examples/resource\sphinxhyphen{}counters.cc.


\subsubsection{Step 2: Loading the XML in NetAnim}
\label{\detokenize{animation:step-2-loading-the-xml-in-netanim}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Assuming NetAnim was built, use the command “./NetAnim” to launch NetAnim. Please review the section “Building NetAnim” if NetAnim is not available.

\item {} 
When NetAnim is opened, click on the File open button at the top\sphinxhyphen{}left corner, select the XML file generated during Step 1.

\item {} 
Hit the green play button to begin animation.

\end{enumerate}

Here is a video illustrating this
\sphinxurl{http://www.youtube.com/watch?v=tz\_hUuNwFDs}


\subsection{Wiki}
\label{\detokenize{animation:wiki}}
For detailed instructions on installing “NetAnim”, F.A.Qs and loading the XML trace file
(mentioned earlier) using NetAnim please refer:
\sphinxurl{http://www.nsnam.org/wiki/NetAnim}


\chapter{Antenna Module}
\label{\detokenize{antenna:antenna-module}}\label{\detokenize{antenna::doc}}

\section{Design documentation}
\label{\detokenize{antenna-design:design-documentation}}\label{\detokenize{antenna-design::doc}}

\subsection{Overview}
\label{\detokenize{antenna-design:overview}}
The Antenna module provides:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
a new base class (AntennaModel) that provides an interface for the modeling of the radiation pattern of an antenna;

\item {} 
a set of classes derived from this base class that each models the radiation pattern of different types of antennas;

\item {} 
the class ThreeGppAntennaArrayModel, which implements the antenna model described in 3GPP TR 38.901

\end{enumerate}


\subsection{AntennaModel}
\label{\detokenize{antenna-design:antennamodel}}
The AntennaModel uses the coordinate system adopted in \sphinxcite{antenna-design:balanis} and
depicted in Figure {\hyperref[\detokenize{antenna-design:fig-antenna-coordinate-system}]{\sphinxcrossref{\DUrole{std,std-ref}{Coordinate system of the AntennaModel}}}}. This system
is obtained by translating the Cartesian coordinate system used by the
ns\sphinxhyphen{}3 MobilityModel into the new origin \(o\) which is the location
of the antenna, and then transforming the coordinates of every generic
point \(p\) of the space from Cartesian coordinates
\((x,y,z)\) into spherical coordinates
\((r, \theta,\phi)\).
The antenna model neglects the radial component \(r\), and
only considers the angle components \((\theta, \phi)\). An antenna
radiation pattern is then expressed as a mathematical function
\(g(\theta, \phi) \longrightarrow \mathcal{R}\) that returns the
gain (in dB) for each possible direction of
transmission/reception. All angles are expressed in radians.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{antenna-coordinate-system}.pdf}
\caption{Coordinate system of the AntennaModel}\label{\detokenize{antenna-design:id10}}\label{\detokenize{antenna-design:fig-antenna-coordinate-system}}\end{figure}


\subsection{Single antenna models}
\label{\detokenize{antenna-design:single-antenna-models}}
In this section we describe the antenna radiation pattern models that
are included within the antenna module.


\subsubsection{IsotropicAntennaModel}
\label{\detokenize{antenna-design:isotropicantennamodel}}
This antenna radiation pattern model provides a unitary gain (0 dB)
for all direction.


\subsubsection{CosineAntennaModel}
\label{\detokenize{antenna-design:cosineantennamodel}}
This is the cosine model described in \sphinxcite{antenna-design:chunjian}: the antenna gain is
determined as:
\begin{equation*}
\begin{split}g(\phi, \theta) = \cos^{n} \left(\frac{\phi - \phi_{0}}{2}  \right)\end{split}
\end{equation*}
where \(\phi_{0}\) is the azimuthal orientation of the antenna
(i.e., its direction of maximum gain) and the exponential
\begin{equation*}
\begin{split}n = -\frac{3}{20 \log_{10} \left( \cos \frac{\phi_{3dB}}{4} \right)}\end{split}
\end{equation*}
determines the desired 3dB beamwidth \(\phi_{3dB}\). Note that
this radiation pattern is independent of the inclination angle
\(\theta\).

A major difference between the model of \sphinxcite{antenna-design:chunjian} and the one
implemented in the class CosineAntennaModel is that only the element
factor (i.e., what described by the above formulas) is considered. In
fact, \sphinxcite{antenna-design:chunjian} also considered an additional antenna array
factor. The reason why the latter is excluded is that we expect that
the average user would desire to specify a given beamwidth exactly,
without adding an array factor at a latter stage which would in
practice alter the effective beamwidth of the resulting radiation
pattern.


\subsubsection{ParabolicAntennaModel}
\label{\detokenize{antenna-design:parabolicantennamodel}}
This model is based on the parabolic approximation of the main lobe radiation pattern. It is often used in the context of cellular system to model the radiation pattern of a cell sector, see for instance \sphinxcite{antenna-design:r4-092042a} and \sphinxcite{antenna-design:calcev}. The antenna gain in dB is determined as:
\begin{equation*}
\begin{split}g_{dB}(\phi, \theta) = -\min \left( 12 \left(\frac{\phi  - \phi_{0}}{\phi_{3dB}} \right)^2, A_{max} \right)\end{split}
\end{equation*}
where \(\phi_{0}\) is the azimuthal orientation of the antenna
(i.e., its direction of maximum gain), \(\phi_{3dB}\) is its 3 dB
beamwidth, and \(A_{max}\) is the maximum attenuation in dB of the
antenna. Note that this radiation pattern is independent of the inclination angle
\(\theta\).


\subsection{ThreeGppAntennaArrayModel}
\label{\detokenize{antenna-design:threegppantennaarraymodel}}
The class ThreeGppAntennaArrayModel implements the antenna model described in
3GPP TR 38.901 %
\begin{footnote}[38901]\sphinxAtStartFootnote
3GPP. 2018. TR 38.901, Study on channel model for frequencies from 0.5 to 100 GHz, V15.0.0. (2018\sphinxhyphen{}06).
%
\end{footnote}, which is used by the classes ThreeGppSpectrumPropagationLossModel
and ThreeGppChannelModel.
Each instance of this class models an isotropic rectangular antenna array composed
of a single panel with NxM elements, where N is the number of rows and M is the
number of columns, configurable through the attributes “NumRows” and “NumColumns”.
The radiation pattern of the antenna elements follows the model specified in
Sec. 7.3 of 3GPP TR 38.901; only vertical polarization is considered (i.e.,
\({\zeta = 0}\)).
The directional gain of the antenna elements can be configured through the
attribute “ElementGain” (see formula 2.34 in \sphinxcite{antenna-design:mailloux} to choose a proper value).
By default, the array is orthogonal to the x\sphinxhyphen{}axis, pointing towards the positive
direction, but the orientation can be changed through the attributes “BearingAngle”,
which adjusts the azimuth angle, and “DowntiltAngle”, which adjusts the elevation angle.
The spacing between the horizontal and vertical elements can be configured through
the attributes “AntennaHorizontalSpacing” and “AntennaVerticalSpacing”.

\sphinxstylestrong{Note:}
\begin{itemize}
\item {} 
Currently, the model does not support multi\sphinxhyphen{}panel antennas, i.e.,
\(N_{g} = M_{g} = 1\).

\item {} 
Currently, the model supports only single polarized (i.e., P = 1) antenna
panels with vertical polarization (i.e., \({\zeta = 0}\))

\end{itemize}


\section{User Documentation}
\label{\detokenize{antenna-user:user-documentation}}\label{\detokenize{antenna-user::doc}}
The antenna modeled can be used with all the wireless technologies and
physical layer models that support it. Currently, this includes
the physical layer models based on the SpectrumPhy. Please refer to
the documentation of each of these models for details.


\section{Testing Documentation}
\label{\detokenize{antenna-testing:testing-documentation}}\label{\detokenize{antenna-testing::doc}}
In this section we describe the test suites included with the antenna
module that verify its correct functionality.


\subsection{Angles}
\label{\detokenize{antenna-testing:angles}}
The unit test suite \sphinxcode{\sphinxupquote{angles}} verifies that the Angles class is
constructed properly by correct conversion from 3D Cartesian
coordinates according to the available methods (construction from a
single vector and from a pair of vectors). For each method, several
test cases are provided that compare the values \((\phi, \theta)\)
determined by the constructor to known reference values. The test
passes if for each case the values are equal to the reference up to a
tolerance of \(10^{-10}\) which accounts for numerical errors.


\subsection{DegreesToRadians}
\label{\detokenize{antenna-testing:degreestoradians}}
The unit test suite \sphinxcode{\sphinxupquote{degrees\sphinxhyphen{}radians}} verifies that the methods
\sphinxcode{\sphinxupquote{DegreesToRadians}} and \sphinxcode{\sphinxupquote{RadiansToDegrees}} work properly by
comparing with known reference values in a number of test
cases. Each test case passes if the comparison is equal up to a
tolerance of \(10^{-10}\) which accounts for numerical errors.


\subsection{IsotropicAntennaModel}
\label{\detokenize{antenna-testing:isotropicantennamodel}}
The unit test suite \sphinxcode{\sphinxupquote{isotropic\sphinxhyphen{}antenna\sphinxhyphen{}model}} checks that the
\sphinxcode{\sphinxupquote{IsotropicAntennaModel}} class works properly, i.e., returns always a
0dB gain regardless of the direction.


\subsection{CosineAntennaModel}
\label{\detokenize{antenna-testing:cosineantennamodel}}
The unit test suite \sphinxcode{\sphinxupquote{cosine\sphinxhyphen{}antenna\sphinxhyphen{}model}} checks that the
\sphinxcode{\sphinxupquote{CosineAntennaModel}} class works properly. Several test cases are
provided that check for the antenna gain value calculated at different
directions and for different values of the orientation, the reference
gain and the beamwidth. The reference gain is calculated by hand. Each
test case passes if the reference gain in dB is equal to the value returned
by \sphinxcode{\sphinxupquote{CosineAntennaModel}} within a tolerance of 0.001, which accounts
for the approximation done for the calculation of the reference
values.


\subsection{ParabolicAntennaModel}
\label{\detokenize{antenna-testing:parabolicantennamodel}}
The unit test suite \sphinxcode{\sphinxupquote{parabolic\sphinxhyphen{}antenna\sphinxhyphen{}model}} checks that the
\sphinxcode{\sphinxupquote{ParabolicAntennaModel}} class works properly. Several test cases are
provided that check for the antenna gain value calculated at different
directions and for different values of the orientation, the maximum attenuation
and the beamwidth. The reference gain is calculated by hand. Each
test case passes if the reference gain in dB is equal to the value returned
by \sphinxcode{\sphinxupquote{ParabolicAntennaModel}} within a tolerance of 0.001, which accounts
for the approximation done for the calculation of the reference
values.


\chapter{Ad Hoc On\sphinxhyphen{}Demand Distance Vector (AODV)}
\label{\detokenize{aodv:ad-hoc-on-demand-distance-vector-aodv}}\label{\detokenize{aodv::doc}}
This model implements the base specification of the Ad Hoc On\sphinxhyphen{}Demand
Distance Vector (AODV) protocol. The implementation is based on
\index{RFC@\spxentry{RFC}!RFC 3561@\spxentry{RFC 3561}}\sphinxhref{https://tools.ietf.org/html/rfc3561.html}{\sphinxstylestrong{RFC 3561}}.

The model was written by Elena Buchatskaia and Pavel Boyko of ITTP RAS,
and is based on the ns\sphinxhyphen{}2 AODV model developed by the CMU/MONARCH group
and optimized and tuned by Samir Das and Mahesh Marina, University of
Cincinnati, and also on the AODV\sphinxhyphen{}UU implementation by Erik Nordström of
Uppsala University.


\section{Model Description}
\label{\detokenize{aodv:model-description}}
The source code for the AODV model lives in the directory \sphinxtitleref{src/aodv}.


\subsection{Design}
\label{\detokenize{aodv:design}}
Class \sphinxcode{\sphinxupquote{ns3::aodv::RoutingProtocol}} implements all functionality of
service packet exchange and inherits from \sphinxcode{\sphinxupquote{ns3::Ipv4RoutingProtocol}}.
The base class defines two virtual functions for packet routing and
forwarding.  The first one, \sphinxcode{\sphinxupquote{ns3::aodv::RouteOutput}}, is used for
locally originated packets, and the second one, \sphinxcode{\sphinxupquote{ns3::aodv::RouteInput}},
is used for forwarding and/or delivering received packets.

Protocol operation depends on many adjustable parameters. Parameters for
this functionality are attributes of \sphinxcode{\sphinxupquote{ns3::aodv::RoutingProtocol}}.
Parameter default values are drawn from the RFC and allow the
enabling/disabling protocol features, such as broadcasting HELLO messages,
broadcasting data packets and so on.

AODV discovers routes on demand.  Therefore, the AODV model buffers all
packets while a route request packet (RREQ) is disseminated.
A packet queue is implemented in aodv\sphinxhyphen{}rqueue.cc. A smart pointer to
the packet, \sphinxcode{\sphinxupquote{ns3::Ipv4RoutingProtocol::ErrorCallback}},
\sphinxcode{\sphinxupquote{ns3::Ipv4RoutingProtocol::UnicastForwardCallback}}, and the IP header
are stored in this queue. The packet queue implements garbage collection
of old packets and a queue size limit.

The routing table implementation supports garbage collection of
old entries and state machine, defined in the standard.
It is implemented as a STL map container. The key is a destination IP address.

Some elements of protocol operation aren’t described in the RFC. These
elements generally concern cooperation of different OSI model layers.
The model uses the following heuristics:
\begin{itemize}
\item {} 
This AODV implementation can detect the presence of unidirectional
links and avoid them if necessary.  If the node the model receives an
RREQ for is a neighbor, the cause may be a unidirectional link.
This heuristic is taken from AODV\sphinxhyphen{}UU implementation and can be disabled.

\item {} 
Protocol operation strongly depends on broken link detection mechanism.
The model implements two such heuristics.  First, this implementation
support HELLO messages. However HELLO messages are not a good way to
perform neighbor sensing in a wireless environment (at least not over
802.11). Therefore, one may experience bad performance when running over
wireless.  There are several reasons for this: 1) HELLO messages are
broadcasted. In 802.11, broadcasting is often done at a
lower bit rate than unicasting, thus HELLO messages can travel further
than unicast data. 2) HELLO messages are small, thus less prone to
bit errors than data transmissions, and 3) Broadcast transmissions are
not guaranteed to be bidirectional, unlike unicast transmissions.
Second, we use layer 2 feedback when possible. Link are considered to be
broken if frame transmission results in a transmission failure for all
retries. This mechanism is meant for active links and works faster than
the first method.

\end{itemize}

The layer 2 feedback implementation relies on the \sphinxcode{\sphinxupquote{TxErrHeader}} trace source,
currently supported in AdhocWifiMac only.


\subsection{Scope and Limitations}
\label{\detokenize{aodv:scope-and-limitations}}
The model is for IPv4 only.  The following optional protocol optimizations
are not implemented:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Local link repair.

\item {} 
RREP, RREQ and HELLO message extensions.

\end{enumerate}

These techniques require direct access to IP header, which contradicts
the assertion from the AODV RFC that AODV works over UDP.  This model uses
UDP for simplicity, hindering the ability to implement certain protocol
optimizations. The model doesn’t use low layer raw sockets because they
are not portable.


\subsection{Future Work}
\label{\detokenize{aodv:future-work}}
No announced plans.


\chapter{3GPP HTTP applications}
\label{\detokenize{applications:gpp-http-applications}}\label{\detokenize{applications::doc}}

\section{Model Description}
\label{\detokenize{applications:model-description}}
The model is a part of the applications library. The HTTP model is based on a commonly
used 3GPP model in standardization {\hyperref[\detokenize{applications:id4}]{\sphinxcrossref{{[}4{]}}}}.


\subsection{Design}
\label{\detokenize{applications:design}}
This traffic generator simulates web browsing traffic using the Hypertext
Transfer Protocol (HTTP). It consists of one or more \sphinxcode{\sphinxupquote{ThreeGppHttpClient}}
applications which connect to a \sphinxcode{\sphinxupquote{ThreeGppHttpServer}} application. The client
models a web browser which requests web pages to the server. The server
is then responsible to serve the web pages as requested. Please refer to
\sphinxcode{\sphinxupquote{ThreeGppHttpClientHelper}} and \sphinxcode{\sphinxupquote{ThreeGppHttpServerHelper}} for usage instructions.

Technically speaking, the client transmits \sphinxstyleemphasis{request objects} to demand a
service from the server. Depending on the type of request received, the
server transmits either:
\begin{itemize}
\item {} 
a \sphinxstyleemphasis{main object}, i.e., the HTML file of the web page; or

\item {} 
an \sphinxstyleemphasis{embedded object}, e.g., an image referenced by the HTML file.

\end{itemize}

The main and embedded object sizes are illustrated in figures {\hyperref[\detokenize{applications:fig-http-main-object-size}]{\sphinxcrossref{\DUrole{std,std-ref}{3GPP HTTP main object size histogram}}}}
and {\hyperref[\detokenize{applications:fig-http-embedded-object-size}]{\sphinxcrossref{\DUrole{std,std-ref}{3GPP HTTP embedded object size histogram}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{http-main-object-size}.png}
\caption{3GPP HTTP main object size histogram}\label{\detokenize{applications:id5}}\label{\detokenize{applications:fig-http-main-object-size}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{http-embedded-object-size}.png}
\caption{3GPP HTTP embedded object size histogram}\label{\detokenize{applications:id6}}\label{\detokenize{applications:fig-http-embedded-object-size}}\end{figure}



A major portion of the traffic pattern is \sphinxstyleemphasis{reading time}, which does not
generate any traffic. Because of this, one may need to simulate a good
number of clients and/or sufficiently long simulation duration in order to
generate any significant traffic in the system. Reading time is illustrated in
{\hyperref[\detokenize{applications:fig-http-reading-time}]{\sphinxcrossref{\DUrole{std,std-ref}{3GPP HTTP reading time histogram}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{http-reading-time}.png}
\caption{3GPP HTTP reading time histogram}\label{\detokenize{applications:id7}}\label{\detokenize{applications:fig-http-reading-time}}\end{figure}


\subsubsection{3GPP HTTP server description}
\label{\detokenize{applications:gpp-http-server-description}}
3GPP HTTP server is a model application which simulates the traffic of a web server. This
application works in conjunction with \sphinxcode{\sphinxupquote{ThreeGppHttpClient}} applications.

The application works by responding to requests. Each request is a small
packet of data which contains \sphinxcode{\sphinxupquote{ThreeGppHttpHeader}}. The value of the \sphinxstyleemphasis{content type}
field of the header determines the type of object that the client is
requesting. The possible type is either a \sphinxstyleemphasis{main object} or an \sphinxstyleemphasis{embedded object}.

The application is responsible to generate the right type of object and send
it back to the client. The size of each object to be sent is randomly
determined (see \sphinxcode{\sphinxupquote{ThreeGppHttpVariables}}). Each object may be sent as multiple packets
due to limited socket buffer space.

To assist with the transmission, the application maintains several instances
of \sphinxcode{\sphinxupquote{ThreeGppHttpServerTxBuffer}}. Each instance keeps track of the object type to be
served and the number of bytes left to be sent.

The application accepts connection request from clients. Every connection is
kept open until the client disconnects.

Maximum transmission unit (MTU) size is configurable in \sphinxcode{\sphinxupquote{ThreeGppHttpServer}} or in
\sphinxcode{\sphinxupquote{ThreeGppHttpVariables}}. By default, the low variant is 536 bytes and high variant is 1460 bytes.
The default values are set with the intention of having a TCP header (size of which is 40 bytes) added
in the packet in such way that lower layers can avoid splitting packets. The change of MTU sizes
affects all TCP sockets after the server application has started. It is mainly visible in sizes of
packets received by \sphinxcode{\sphinxupquote{ThreeGppHttpClient}} applications.


\subsubsection{3GPP HTTP client description}
\label{\detokenize{applications:gpp-http-client-description}}
3GPP HTTP client is a model application which simulates the traffic of a web browser. This
application works in conjunction with an ThreeGppHttpServer application.

In summary, the application works as follows.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Upon start, it opens a connection to the destination web server
(ThreeGppHttpServer).

\item {} 
After the connection is established, the application immediately requests
a \sphinxstyleemphasis{main object} from the server by sending a request packet.

\item {} 
After receiving a main object (which can take some time if it consists of
several packets), the application “parses” the main object. Parsing time
is illustrated in figure {\hyperref[\detokenize{applications:fig-http-parsing-time}]{\sphinxcrossref{\DUrole{std,std-ref}{3GPP HTTP parsing time histogram}}}}.

\item {} 
The parsing takes a short time (randomly determined) to determine the
number of \sphinxstyleemphasis{embedded objects} (also randomly determined) in the web page.
Number of embedded object is illustrated in {\hyperref[\detokenize{applications:fig-http-num-of-embedded-objects}]{\sphinxcrossref{\DUrole{std,std-ref}{3GPP HTTP number of embedded objects histogram}}}}.
\begin{itemize}
\item {} \begin{description}
\item[{If at least one embedded object is determined, the application requests}] \leavevmode
the first embedded object from the server. The request for the next
embedded object follows after the previous embedded object has been
completely received.

\end{description}

\item {} \begin{description}
\item[{If there is no more embedded object to request, the application enters}] \leavevmode
the \sphinxstyleemphasis{reading time}.

\end{description}

\end{itemize}

\item {} 
Reading time is a long delay (again, randomly determined) where the
application does not induce any network traffic, thus simulating the user
reading the downloaded web page.

\item {} 
After the reading time is finished, the process repeats to step \#2.

\end{enumerate}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{http-parsing-time}.png}
\caption{3GPP HTTP parsing time histogram}\label{\detokenize{applications:id8}}\label{\detokenize{applications:fig-http-parsing-time}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{http-num-of-embedded-objects}.png}
\caption{3GPP HTTP number of embedded objects histogram}\label{\detokenize{applications:id9}}\label{\detokenize{applications:fig-http-num-of-embedded-objects}}\end{figure}

The client models HTTP \sphinxstyleemphasis{persistent connection}, i.e., HTTP 1.1, where the
connection to the server is maintained and used for transmitting and receiving
all objects.

Each request by default has a constant size of 350 bytes. A \sphinxcode{\sphinxupquote{ThreeGppHttpHeader}}
is attached to each request packet. The header contains information
such as the content type requested (either main object or embedded object)
and the timestamp when the packet is transmitted (which will be used to
compute the delay and RTT of the packet).


\subsection{References}
\label{\detokenize{applications:references}}
Many aspects of the traffic are randomly determined by \sphinxcode{\sphinxupquote{ThreeGppHttpVariables}}.
A separate instance of this object is used by the HTTP server and client applications.
These characteristics are based on a legacy 3GPP specification. The description
can be found in the following references:



\phantomsection\label{\detokenize{applications:id1}}
{[}1{]} 3GPP TR 25.892, “Feasibility Study for Orthogonal Frequency Division Multiplexing (OFDM) for UTRAN enhancement”



\phantomsection\label{\detokenize{applications:id2}}
{[}2{]} IEEE 802.16m, “Evaluation Methodology Document (EMD)”, IEEE 802.16m\sphinxhyphen{}08/004r5, July 2008.



\phantomsection\label{\detokenize{applications:id3}}
{[}3{]} NGMN Alliance, “NGMN Radio Access Performance Evaluation Methodology”, v1.0, January 2008.



\phantomsection\label{\detokenize{applications:id4}}
{[}4{]} 3GPP2\sphinxhyphen{}TSGC5, “HTTP, FTP and TCP models for 1xEV\sphinxhyphen{}DV simulations”, 2001.




\section{Usage}
\label{\detokenize{applications:usage}}
The three\sphinxhyphen{}gpp\sphinxhyphen{}http\sphinxhyphen{}example can be referenced to see basic usage of the HTTP applications.
In summary, using the \sphinxcode{\sphinxupquote{ThreeGppHttpServerHelper}} and \sphinxcode{\sphinxupquote{ThreeGppHttpClientHelper}} allow the
user to easily install \sphinxcode{\sphinxupquote{ThreeGppHttpServer}} and \sphinxcode{\sphinxupquote{ThreeGppHttpClient}} applications to nodes.
The helper objects can be used to configure attribute values for the client
and server objects, but not for the \sphinxcode{\sphinxupquote{ThreeGppHttpVariables}} object. Configuration of variables
is done by modifying attributes of \sphinxcode{\sphinxupquote{ThreeGppHttpVariables}}, which should be done prior to helpers
installing applications to nodes.

The client and server provide a number of ns\sphinxhyphen{}3 trace sources such as
“Tx”, “Rx”, “RxDelay”, and “StateTransition” on the server side, and a large
number on the client side (“ConnectionEstablished”,
“ConnectionClosed”,”TxMainObjectRequest”, “TxEmbeddedObjectRequest”,
“RxMainObjectPacket”, “RxMainObject”, “RxEmbeddedObjectPacket”,
“RxEmbeddedObject”, “Rx”, “RxDelay”, “RxRtt”, “StateTransition”).


\subsection{Building the 3GPP HTTP applications}
\label{\detokenize{applications:building-the-3gpp-http-applications}}
Building the applications does not require any special steps to be taken. It suffices to enable
the applications module.


\subsection{Examples}
\label{\detokenize{applications:examples}}
For an example demonstrating HTTP applications
run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYGZsq{}three\PYGZhy{}gpp\PYGZhy{}http\PYGZhy{}example\PYGZsq{}
\end{sphinxVerbatim}

By default, the example will print out the web page requests of the client and responses of the
server and client receiving content packets by using LOG\_INFO of \sphinxcode{\sphinxupquote{ThreeGppHttpServer}} and \sphinxcode{\sphinxupquote{ThreeGppHttpClient}}.


\subsection{Tests}
\label{\detokenize{applications:tests}}
For testing HTTP applications, three\sphinxhyphen{}gpp\sphinxhyphen{}http\sphinxhyphen{}client\sphinxhyphen{}server\sphinxhyphen{}test is provided. Run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}s three\PYGZhy{}gpp\PYGZhy{}http\PYGZhy{}client\PYGZhy{}server\PYGZhy{}test
\end{sphinxVerbatim}

The test consists of simple Internet nodes having HTTP server and client applications installed.
Multiple variant scenarios are tested: delay is 3ms, 30ms or 300ms, bit error rate 0 or 5.0*10\textasciicircum{}(\sphinxhyphen{}6),
MTU size 536 or 1460 bytes and either IPV4 or IPV6 is used. A simulation with each combination of
these parameters is run multiple times to verify functionality with different random variables.

Test cases themselves are rather simple: test verifies that HTTP object packet bytes sent match
total bytes received by the client, and that \sphinxcode{\sphinxupquote{ThreeGppHttpHeader}} matches the expected packet.


\chapter{Bridge NetDevice}
\label{\detokenize{bridge:bridge-netdevice}}\label{\detokenize{bridge::doc}}
\sphinxstyleemphasis{Placeholder chapter}

Some examples of the use of Bridge NetDevice can be found in \sphinxcode{\sphinxupquote{examples/csma/}}
directory.


\chapter{BRITE Integration}
\label{\detokenize{brite:brite-integration}}\label{\detokenize{brite::doc}}
This model implements an interface to BRITE, the Boston university
Representative Internet Topology gEnerator %
\begin{footnote}[1]\sphinxAtStartFootnote
Alberto Medina, Anukool Lakhina, Ibrahim Matta, and John Byers. BRITE: An Approach to Universal Topology Generation. In Proceedings of the International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunications Systems\sphinxhyphen{} MASCOTS ‘01, Cincinnati, Ohio, August 2001.
%
\end{footnote}. BRITE is a standard tool for
generating realistic internet topologies. The ns\sphinxhyphen{}3 model, described herein,
provides a helper class to facilitate generating ns\sphinxhyphen{}3 specific topologies
using BRITE configuration files. BRITE builds the original graph which is
stored as nodes and edges in the ns\sphinxhyphen{}3 BriteTopolgyHelper class. In the ns\sphinxhyphen{}3
integration of BRITE, the generator generates a topology and then provides
access to leaf nodes for each AS generated.  ns\sphinxhyphen{}3 users can than attach
custom topologies to these leaf nodes either by creating them manually or
using topology generators provided in ns\sphinxhyphen{}3.

There are three major types of topologies available in BRITE:  Router,
AS, and Hierarchical which is a combination of AS and Router.   For the
purposes of ns\sphinxhyphen{}3 simulation, the most useful are likely to be Router and
Hierarchical.  Router level topologies be generated using either the Waxman
model or the Barabasi\sphinxhyphen{}Albert model.  Each model has different parameters that
effect topology creation.  For flat router topologies, all nodes are considered
to be in the same AS.

BRITE Hierarchical topologies contain two levels.  The first is the AS level.
This level can be also be created by using either the Waxman model or the
Barabasi\sphinxhyphen{}Albert model.  Then for each node in the AS topology, a router level
topology is constructed.  These router level topologies can again either use
the Waxman model or the Barbasi\sphinxhyphen{}Albert model.  BRITE interconnects these separate
router topologies as specified by the AS level topology.  Once the hierarchical
topology is constructed, it is flattened into a large router level topology.

Further information can be found in the BRITE user manual: \sphinxurl{http://www.cs.bu.edu/brite/publications/usermanual.pdf}


\section{Model Description}
\label{\detokenize{brite:model-description}}
The model relies on building an external BRITE library,
and then building some ns\sphinxhyphen{}3 helpers that call out to the library.
The source code for the ns\sphinxhyphen{}3 helpers lives in the directory
\sphinxcode{\sphinxupquote{src/brite/helper}}.


\subsection{Design}
\label{\detokenize{brite:design}}
To generate the BRITE topology, ns\sphinxhyphen{}3 helpers call out to the external BRITE library,
and using a standard BRITE configuration file, the BRITE code builds a graph with nodes
and edges according to this configuration file. Please see the BRITE documentation
or the example configuration files in src/brite/examples/conf\_files to get a better
grasp of BRITE configuration options. The graph built by BRITE is returned to ns\sphinxhyphen{}3,
and a ns\sphinxhyphen{}3 implementation of the graph is built.  Leaf nodes for each AS are available
for the user to either attach custom topologies or install ns\sphinxhyphen{}3 applications directly.


\subsection{References}
\label{\detokenize{brite:references}}

\section{Usage}
\label{\detokenize{brite:usage}}
The brite\sphinxhyphen{}generic\sphinxhyphen{}example can be referenced to see basic usage of the BRITE
interface. In summary, the BriteTopologyHelper is used as the interface point
by passing in a BRITE configuration file. Along with the configuration file a
BRITE formatted random seed file can also be passed in.  If a seed file is not
passed in, the helper will create a seed file using ns\sphinxhyphen{}3’s UniformRandomVariable.
Once the topology has been generated by BRITE, BuildBriteTopology() is called to
create the ns\sphinxhyphen{}3 representation.  Next IP Address can be assigned to the topology
using either AssignIpv4Addresses() or AssignIpv6Addresses().  It should be noted
that each point\sphinxhyphen{}to\sphinxhyphen{}point link in the topology will be treated as a new network
therefore for IPV4 a /30 subnet should be used to avoid wasting a large amount of
the available address space.

Example BRITE configuration files can be found in /src/brite/examples/conf\_files/.
ASBarbasi and ASWaxman are examples of AS only topologies.  The RTBarabasi and
RTWaxman files are examples of router only topologies.  Finally the
TD\_ASBarabasi\_RTWaxman configuration file is an example of a Hierarchical topology
that uses the Barabasi\sphinxhyphen{}Albert model for the AS level and the Waxman model for each
of the router level topologies.   Information on the BRITE parameters used in these files
can be found in the BRITE user manual.


\subsection{Building BRITE Integration}
\label{\detokenize{brite:building-brite-integration}}
The first step is to download and build the ns\sphinxhyphen{}3 specific BRITE repository:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} hg clone http://code.nsnam.org/BRITE
\PYGZdl{} \PYG{n+nb}{cd} BRITE
\PYGZdl{} make
\end{sphinxVerbatim}

This will build BRITE and create a library, libbrite.so, within the BRITE
directory.

Once BRITE has been built successfully, we proceed to configure ns\sphinxhyphen{}3 with
BRITE support. Change to your ns\sphinxhyphen{}3 directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}with\PYGZhy{}brite\PYG{o}{=}/your/path/to/brite/source \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples
\end{sphinxVerbatim}

Make sure it says ‘enabled’ beside ‘BRITE Integration’. If it does not, then
something has gone wrong. Either you have forgotten to build BRITE first
following the steps above, or ns\sphinxhyphen{}3 could not find your BRITE directory.

Next, build ns\sphinxhyphen{}3:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf
\end{sphinxVerbatim}


\subsection{Examples}
\label{\detokenize{brite:examples}}
For an example demonstrating BRITE integration
run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s1}{\PYGZsq{}brite\PYGZhy{}generic\PYGZhy{}example\PYGZsq{}}
\end{sphinxVerbatim}

By enabling the verbose parameter, the example will print out the node and
edge information in a similar format to standard BRITE output. There are
many other command\sphinxhyphen{}line parameters including confFile, tracing, and nix, described below:
\begin{quote}
\begin{description}
\item[{confFile}] \leavevmode
A BRITE configuration file. Many different BRITE configuration
file examples exist in the src/brite/examples/conf\_files directory, for
example, RTBarabasi20.conf and RTWaxman.conf. Please refer to
the conf\_files directory for more examples.

\item[{tracing}] \leavevmode
Enables ascii tracing.

\item[{nix}] \leavevmode
Enables nix\sphinxhyphen{}vector routing. Global routing is used by default.

\end{description}
\end{quote}

The generic BRITE example also support visualization using pyviz, assuming
python bindings in ns\sphinxhyphen{}3 are enabled:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run brite\PYGZhy{}generic\PYGZhy{}example \PYGZhy{}\PYGZhy{}vis
\end{sphinxVerbatim}

Simulations involving BRITE can also be used with MPI.  The total number of MPI instances is
passed to the BRITE topology helper where a modulo divide is used to assign the nodes for each
AS to a MPI instance.  An example can be found in src/brite/examples:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mpirun \PYGZhy{}np \PYG{l+m}{2} ./waf \PYGZhy{}\PYGZhy{}run brite\PYGZhy{}MPI\PYGZhy{}example
\end{sphinxVerbatim}

Please see the ns\sphinxhyphen{}3 MPI documentation for information on setting up MPI with ns\sphinxhyphen{}3.


\chapter{Buildings Module}
\label{\detokenize{buildings:buildings-module}}\label{\detokenize{buildings::doc}}
cd .. include:: replace.txt


\section{Design documentation}
\label{\detokenize{buildings-design:design-documentation}}\label{\detokenize{buildings-design::doc}}

\subsection{Overview}
\label{\detokenize{buildings-design:overview}}
The Buildings module provides:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
a new class (\sphinxcode{\sphinxupquote{Building}}) that models the presence of a building in a simulation scenario;

\item {} 
a new class (\sphinxcode{\sphinxupquote{MobilityBuildingInfo}}) that allows to specify the location, size and characteristics of buildings present in the simulated area, and allows the placement of nodes inside those buildings;

\item {} 
a container class with the definition of the most useful pathloss models and the correspondent variables called \sphinxcode{\sphinxupquote{BuildingsPropagationLossModel}}.

\item {} 
a new propagation model (\sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}}) working with the mobility model just introduced, that allows to model the phenomenon of indoor/outdoor propagation in the presence of buildings.

\item {} 
a simplified model working only with Okumura Hata (\sphinxcode{\sphinxupquote{OhBuildingsPropagationLossModel}}) considering the phenomenon of indoor/outdoor propagation in the presence of buildings.

\end{enumerate}

The models have been designed with LTE in mind, though their implementation is in fact independent from any LTE\sphinxhyphen{}specific code, and can be used with other ns\sphinxhyphen{}3 wireless technologies as well (e.g., wifi, wimax).

The \sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}} pathloss model included is obtained through a combination of several well known pathloss models in order to mimic different environmental scenarios such as urban, suburban and open areas. Moreover, the model considers both outdoor and indoor indoor and outdoor communication has to be included since HeNB might be installed either within building and either outside. In case of indoor communication, the model has to consider also the type of building in outdoor \textless{}\sphinxhyphen{}\textgreater{} indoor communication according to some general criteria such as the wall penetration losses of the common materials; moreover it includes some general configuration for the internal walls in indoor communications.

The \sphinxcode{\sphinxupquote{OhBuildingsPropagationLossModel}} pathloss model has been created for simplifying the previous one removing the thresholds for switching from one model to other. For doing this it has been used only one propagation model from the one available (i.e., the Okumura Hata). The presence of building is still considered in the model; therefore all the considerations of above regarding the building type are still valid. The same consideration can be done for what concern the environmental scenario and frequency since both of them are parameters of the model considered.


\subsection{The Building class}
\label{\detokenize{buildings-design:the-building-class}}
The model includes a specific class called \sphinxcode{\sphinxupquote{Building}} which contains a ns3 \sphinxcode{\sphinxupquote{Box}} class for defining the dimension of the building. In order to implements the characteristics of the pathloss models included, the \sphinxcode{\sphinxupquote{Building}} class supports the following attributes:
\begin{itemize}
\item {} 
building type:
\begin{itemize}
\item {} 
Residential (default value)

\item {} 
Office

\item {} 
Commercial

\end{itemize}

\item {} 
external walls type
\begin{itemize}
\item {} 
Wood

\item {} 
ConcreteWithWindows (default value)

\item {} 
ConcreteWithoutWindows

\item {} 
StoneBlocks

\end{itemize}

\item {} 
number of floors (default value 1, which means only ground\sphinxhyphen{}floor)

\item {} 
number of rooms in x\sphinxhyphen{}axis (default value 1)

\item {} 
number of rooms in y\sphinxhyphen{}axis (default value 1)

\end{itemize}

The Building class is based on the following assumptions:
\begin{itemize}
\item {} 
a buildings is represented as a rectangular parallelepiped (i.e., a box)

\item {} 
the walls are parallel to the x, y, and z axis

\item {} 
a building is divided into a grid of rooms, identified by the following parameters:
\begin{itemize}
\item {} 
number of floors

\item {} 
number of rooms along the x\sphinxhyphen{}axis

\item {} 
number of rooms along the y\sphinxhyphen{}axis

\end{itemize}

\item {} 
the z axis is the vertical axis, i.e., floor numbers increase for increasing z axis values

\item {} 
the x and y room indices start from 1 and increase along the x and y axis respectively

\item {} 
all rooms in a building have equal size

\end{itemize}


\subsection{The MobilityBuildingInfo class}
\label{\detokenize{buildings-design:the-mobilitybuildinginfo-class}}
The \sphinxcode{\sphinxupquote{MobilityBuildingInfo}} class, which inherits from the ns3 class \sphinxcode{\sphinxupquote{Object}}, is in charge of maintaining information about the position of a node with respect to building. The information managed by \sphinxcode{\sphinxupquote{MobilityBuildingInfo}} is:
\begin{itemize}
\item {} 
whether the node is indoor or outdoor

\item {} 
if indoor:
\begin{itemize}
\item {} 
in which building the node is

\item {} 
in which room the node is positioned (x, y and floor room indices)

\end{itemize}

\end{itemize}

The class \sphinxcode{\sphinxupquote{MobilityBuildingInfo}} is used by \sphinxcode{\sphinxupquote{BuildingsPropagationLossModel}} class, which inherits from the ns3 class \sphinxcode{\sphinxupquote{PropagationLossModel}} and manages the pathloss computation of the single components and their composition according to the nodes’ positions. Moreover, it implements also the shadowing, that is the loss due to obstacles in the main path (i.e., vegetation, buildings, etc.).

It is to be noted that, \sphinxcode{\sphinxupquote{MobilityBuildingInfo}} can be used by any other propagation model. However, based on the information at the time of this writing, only the ones defined in the building module are designed for considering the constraints introduced by the buildings.


\subsection{ItuR1238PropagationLossModel}
\label{\detokenize{buildings-design:itur1238propagationlossmodel}}
This class implements a building\sphinxhyphen{}dependent indoor propagation loss model based on the ITU P.1238 model, which includes losses due to type of building (i.e., residential, office and commercial).
The analytical expression is given in the following.
\begin{equation*}
\begin{split}L_\mathrm{total} = 20\log f + N\log d + L_f(n)- 28 [dB]\end{split}
\end{equation*}
where:
\begin{quote}

\(N = \left\{ \begin{array}{lll} 28 & residential \\ 30 & office \\ 22 & commercial\end{array} \right.\) : power loss coefficient {[}dB{]}

\(L_f = \left\{ \begin{array}{lll} 4n & residential \\ 15+4(n-1) & office \\ 6+3(n-1) & commercial\end{array} \right.\)

\(n\) : number of floors between base station and mobile (\(n\ge 1\))

\(f\) : frequency {[}MHz{]}

\(d\) : distance (where \(d > 1\)) {[}m{]}
\end{quote}


\subsection{BuildingsPropagationLossModel}
\label{\detokenize{buildings-design:buildingspropagationlossmodel}}
The BuildingsPropagationLossModel provides an additional set of building\sphinxhyphen{}dependent pathloss model elements that are used to implement different pathloss logics. These pathloss model elements are described in the following subsections.


\subsubsection{External Wall Loss (EWL)}
\label{\detokenize{buildings-design:external-wall-loss-ewl}}
This component models the penetration loss through walls for indoor to outdoor communications and vice\sphinxhyphen{}versa. The values are taken from the \sphinxcite{propagation:cost231} model.
\begin{itemize}
\item {} 
Wood \textasciitilde{} 4 dB

\item {} 
Concrete with windows (not metallized) \textasciitilde{} 7 dB

\item {} 
Concrete without windows \textasciitilde{} 15 dB (spans between 10 and 20 in COST231)

\item {} 
Stone blocks \textasciitilde{} 12 dB

\end{itemize}


\subsubsection{Internal Walls Loss (IWL)}
\label{\detokenize{buildings-design:internal-walls-loss-iwl}}
This component models the penetration loss occurring in indoor\sphinxhyphen{}to\sphinxhyphen{}indoor communications within the same building. The total loss is calculated assuming that each single internal wall has a constant penetration loss \(L_{siw}\), and approximating the number of walls that are penetrated with the manhattan distance (in number of rooms) between the transmitter and the receiver. In detail, let \(x_1\), \(y_1\), \(x_2\), \(y_2\) denote the room number along the \(x\) and \(y\) axis respectively for user 1 and 2; the total loss \(L_{IWL}\) is calculated as
\begin{equation*}
\begin{split}L_{IWL} = L_{siw} (|x_1 -x_2| + |y_1 - y_2|)\end{split}
\end{equation*}

\subsubsection{Height Gain Model (HG)}
\label{\detokenize{buildings-design:height-gain-model-hg}}
This component model the gain due to the fact that the transmitting device is on a floor above the ground. In the literature \sphinxcite{buildings-references:turkmani} this gain has been evaluated as about 2 dB per floor. This gain can be applied to all the indoor to outdoor communications and vice\sphinxhyphen{}versa.


\subsubsection{Shadowing Model}
\label{\detokenize{buildings-design:shadowing-model}}
The shadowing is modeled according to a log\sphinxhyphen{}normal distribution with variable standard deviation as function of the relative position (indoor or outdoor) of the MobilityModel instances involved. One random value is drawn for each pair of MobilityModels, and stays constant for that pair during the whole simulation. Thus, the model is appropriate for static nodes only.

The model considers that the mean of the shadowing loss in dB is always 0. For the variance, the model considers three possible values of standard deviation, in detail:
\begin{itemize}
\item {} 
outdoor (\sphinxcode{\sphinxupquote{m\_shadowingSigmaOutdoor}}, defaul value of 7 dB) \(\rightarrow X_\mathrm{O} \sim N(\mu_\mathrm{O}, \sigma_\mathrm{O}^2)\).

\item {} 
indoor (\sphinxcode{\sphinxupquote{m\_shadowingSigmaIndoor}}, defaul value of 10 dB) \(\rightarrow X_\mathrm{I} \sim N(\mu_\mathrm{I}, \sigma_\mathrm{I}^2)\).

\item {} 
external walls penetration (\sphinxcode{\sphinxupquote{m\_shadowingSigmaExtWalls}}, default value 5 dB) \(\rightarrow X_\mathrm{W} \sim N(\mu_\mathrm{W}, \sigma_\mathrm{W}^2)\)

\end{itemize}

The simulator generates a shadowing value per each active link according to nodes’ position the first time the link is used for transmitting. In case of transmissions from outdoor nodes to indoor ones, and vice\sphinxhyphen{}versa, the standard deviation (\(\sigma_\mathrm{IO}\)) has to be calculated as the square root of the sum of the quadratic values of the standard deviatio in case of outdoor nodes and the one for the external walls penetration. This is due to the fact that that the components producing the shadowing are independent of each other; therefore, the variance of a distribution resulting from the sum of two independent normal ones is the sum of the variances.
\begin{align*}\!\begin{aligned}
X \sim N(\mu,\sigma^2) \mbox{ and } Y \sim N(\nu,\tau^2)\\
Z = X + Y \sim Z (\mu + \nu, \sigma^2 + \tau^2)\\
\Rightarrow \sigma_\mathrm{IO} = \sqrt{\sigma_\mathrm{O}^2 + \sigma_\mathrm{W}^2}\\
\end{aligned}\end{align*}

\subsection{Pathloss logics}
\label{\detokenize{buildings-design:pathloss-logics}}
In the following we describe the different pathloss logic that are implemented by inheriting from BuildingsPropagationLossModel.


\subsubsection{HybridBuildingsPropagationLossModel}
\label{\detokenize{buildings-design:hybridbuildingspropagationlossmodel}}
The \sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}} pathloss model included is obtained through a combination of several well known pathloss models in order to mimic different outdoor and indoor scenarios, as well as indoor\sphinxhyphen{}to\sphinxhyphen{}outdoor and outdoor\sphinxhyphen{}to\sphinxhyphen{}indoor scenarios. In detail, the class \sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}} integrates the following pathloss models:
\begin{itemize}
\item {} 
OkumuraHataPropagationLossModel (OH) (at frequencies \textgreater{} 2.3 GHz substituted by Kun2600MhzPropagationLossModel)

\item {} 
ItuR1411LosPropagationLossModel and ItuR1411NlosOverRooftopPropagationLossModel (I1411)

\item {} 
ItuR1238PropagationLossModel (I1238)

\item {} 
the pathloss elements of the BuildingsPropagationLossModel (EWL, HG, IWL)

\end{itemize}

The following pseudo\sphinxhyphen{}code illustrates how the different pathloss model elements described above are integrated in  \sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
  \PYG{n}{then}
    \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
      \PYG{n}{then}
        \PYG{k}{if} \PYG{p}{(}\PYG{n}{distance} \PYG{o}{\PYGZgt{}} \PYG{l+m+mi}{1} \PYG{n}{km}\PYG{p}{)}
          \PYG{n}{then}
            \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{or} \PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{below} \PYG{n}{the} \PYG{n}{rooftop}\PYG{p}{)}
              \PYG{n}{then}
                \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411}
              \PYG{k}{else}
                \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH}
          \PYG{k}{else}
            \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411}
      \PYG{k}{else} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
        \PYG{k}{if} \PYG{p}{(}\PYG{n}{distance} \PYG{o}{\PYGZgt{}} \PYG{l+m+mi}{1} \PYG{n}{km}\PYG{p}{)}
          \PYG{n}{then}
            \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{or} \PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{below} \PYG{n}{the} \PYG{n}{rooftop}\PYG{p}{)}
              \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411} \PYG{o}{+} \PYG{n}{EWL} \PYG{o}{+} \PYG{n}{HG}
            \PYG{k}{else}
              \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{n}{EWL} \PYG{o}{+} \PYG{n}{HG}
          \PYG{k}{else}
            \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411} \PYG{o}{+} \PYG{n}{EWL} \PYG{o}{+} \PYG{n}{HG}
\PYG{k}{else} \PYG{p}{(}\PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
    \PYG{n}{then}
     \PYG{k}{if} \PYG{p}{(}\PYG{n}{same} \PYG{n}{building}\PYG{p}{)}
        \PYG{n}{then}
          \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1238} \PYG{o}{+} \PYG{n}{IWL}
        \PYG{k}{else}
          \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411} \PYG{o}{+} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{EWL}
   \PYG{k}{else} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
    \PYG{k}{if} \PYG{p}{(}\PYG{n}{distance} \PYG{o}{\PYGZgt{}} \PYG{l+m+mi}{1} \PYG{n}{km}\PYG{p}{)}
      \PYG{n}{then}
        \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{or} \PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{below} \PYG{n}{the} \PYG{n}{rooftop}\PYG{p}{)}
              \PYG{n}{then}
                \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411} \PYG{o}{+} \PYG{n}{EWL} \PYG{o}{+} \PYG{n}{HG}
              \PYG{k}{else}
                \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{n}{EWL} \PYG{o}{+} \PYG{n}{HG}
      \PYG{k}{else}
        \PYG{n}{L} \PYG{o}{=} \PYG{n}{I1411} \PYG{o}{+} \PYG{n}{EWL}
\end{sphinxVerbatim}

We note that, for the case of communication between two nodes below rooftop level with distance is greater then 1 km, we still consider the I1411 model, since OH is specifically designed for macro cells and therefore for antennas above the roof\sphinxhyphen{}top level.

For the ITU\sphinxhyphen{}R P.1411 model we consider both the LOS and NLoS versions. In particular, we considers the LoS propagation for distances that are shorted than a tunable threshold (\sphinxcode{\sphinxupquote{m\_itu1411NlosThreshold}}). In case on NLoS propagation, the over the roof\sphinxhyphen{}top model is taken in consideration for modeling both macro BS and SC. In case on NLoS several parameters scenario dependent have been included, such as average street width, orientation, etc. The values of such parameters have to be properly set according to the scenario implemented, the model does not calculate natively their values. In case any values is provided, the standard ones are used, apart for the height of the mobile and BS, which instead their integrity is tested directly in the code (i.e., they have to be greater then zero).  In the following we give the expressions of the components of the model.

We also note that the use of different propagation models (OH, I1411, I1238 with their variants) in HybridBuildingsPropagationLossModel can result in discontinuities of the pathloss with respect to distance. A proper tuning of the attributes (especially the distance threshold attributes) can avoid these discontinuities. However, since the behavior of each model depends on several other parameters (frequency, node height, etc), there is no default value of these thresholds that can avoid the discontinuities in all possible configurations. Hence, an appropriate tuning of these parameters is left to the user.


\subsubsection{OhBuildingsPropagationLossModel}
\label{\detokenize{buildings-design:ohbuildingspropagationlossmodel}}
The \sphinxcode{\sphinxupquote{OhBuildingsPropagationLossModel}} class has been created as a simple means to solve the discontinuity problems of \sphinxcode{\sphinxupquote{HybridBuildingsPropagationLossModel}} without doing scenario\sphinxhyphen{}specific  parameter tuning. The solution is to use only one propagation loss model (i.e., Okumura Hata), while retaining the structure of the pathloss logic for the calculation of other path loss components (such as wall penetration losses). The result is a model that is free of discontinuities (except those due to walls), but that is less realistic overall for a generic scenario with buildings and outdoor/indoor users, e.g., because Okumura Hata is not suitable neither for indoor communications nor for outdoor communications below rooftop level.

In detail, the class \sphinxcode{\sphinxupquote{OhBuildingsPropagationLossModel}} integrates the following pathloss models:
\begin{itemize}
\item {} 
OkumuraHataPropagationLossModel (OH)

\item {} 
the pathloss elements of the BuildingsPropagationLossModel (EWL, HG, IWL)

\end{itemize}

The following pseudo\sphinxhyphen{}code illustrates how the different pathloss model elements described above are integrated in \sphinxcode{\sphinxupquote{OhBuildingsPropagationLossModel}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
  \PYG{n}{then}
    \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
      \PYG{n}{then}
        \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH}
      \PYG{k}{else} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
        \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{n}{EWL}
\PYG{k}{else} \PYG{p}{(}\PYG{n}{txNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{indoor}\PYG{p}{)}
    \PYG{n}{then}
     \PYG{k}{if} \PYG{p}{(}\PYG{n}{same} \PYG{n}{building}\PYG{p}{)}
        \PYG{n}{then}
          \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{n}{IWL}
        \PYG{k}{else}
          \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{EWL}
   \PYG{k}{else} \PYG{p}{(}\PYG{n}{rxNode} \PYG{o+ow}{is} \PYG{n}{outdoor}\PYG{p}{)}
      \PYG{n}{L} \PYG{o}{=} \PYG{n}{OH} \PYG{o}{+} \PYG{n}{EWL}
\end{sphinxVerbatim}

We note that OhBuildingsPropagationLossModel is a significant simplification with respect to HybridBuildingsPropagationLossModel, due to the fact that OH is used always. While this gives a less accurate model in some scenarios (especially below rooftop and indoor), it effectively avoids the issue of pathloss discontinuities that affects HybridBuildingsPropagationLossModel.


\section{User Documentation}
\label{\detokenize{buildings-user:user-documentation}}\label{\detokenize{buildings-user::doc}}

\subsection{How to use buildings in a simulation}
\label{\detokenize{buildings-user:how-to-use-buildings-in-a-simulation}}
In this section we explain the basic usage of the buildings model within a
simulation program.


\subsubsection{Include the headers}
\label{\detokenize{buildings-user:include-the-headers}}
Add this at the beginning of your simulation program:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}include \PYGZlt{}ns3/buildings\PYGZhy{}module.h\PYGZgt{}}
\end{sphinxVerbatim}


\subsubsection{Create a building}
\label{\detokenize{buildings-user:create-a-building}}
As an example, let’s create a residential 10 x 20 x 10 building:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{double} \PYG{n}{x\PYGZus{}min} \PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{;}
\PYG{n}{double} \PYG{n}{x\PYGZus{}max} \PYG{o}{=} \PYG{l+m+mf}{10.0}\PYG{p}{;}
\PYG{n}{double} \PYG{n}{y\PYGZus{}min} \PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{;}
\PYG{n}{double} \PYG{n}{y\PYGZus{}max} \PYG{o}{=} \PYG{l+m+mf}{20.0}\PYG{p}{;}
\PYG{n}{double} \PYG{n}{z\PYGZus{}min} \PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{;}
\PYG{n}{double} \PYG{n}{z\PYGZus{}max} \PYG{o}{=} \PYG{l+m+mf}{10.0}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Building}\PYG{o}{\PYGZgt{}} \PYG{n}{b} \PYG{o}{=} \PYG{n}{CreateObject} \PYG{o}{\PYGZlt{}}\PYG{n}{Building}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetBoundaries} \PYG{p}{(}\PYG{n}{Box} \PYG{p}{(}\PYG{n}{x\PYGZus{}min}\PYG{p}{,} \PYG{n}{x\PYGZus{}max}\PYG{p}{,} \PYG{n}{y\PYGZus{}min}\PYG{p}{,} \PYG{n}{y\PYGZus{}max}\PYG{p}{,} \PYG{n}{z\PYGZus{}min}\PYG{p}{,} \PYG{n}{z\PYGZus{}max}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetBuildingType} \PYG{p}{(}\PYG{n}{Building}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Residential}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetExtWallsType} \PYG{p}{(}\PYG{n}{Building}\PYG{p}{:}\PYG{p}{:}\PYG{n}{ConcreteWithWindows}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetNFloors} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetNRoomsX} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{b}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetNRoomsY} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This building has three floors and an internal 3 x 2  grid of rooms of equal size.

The helper class GridBuildingAllocator is also available to easily
create a set of buildings with identical characteristics placed on a
rectangular grid. Here’s an example of how to use it:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{GridBuildingAllocator}\PYG{o}{\PYGZgt{}}  \PYG{n}{gridBuildingAllocator}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{GridBuildingAllocator}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{GridWidth}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LengthX}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LengthY}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{13}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{DeltaX}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{DeltaY}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Height}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetBuildingAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NRoomsX}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetBuildingAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NRoomsY}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetBuildingAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{NFloors}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{MinX}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{MinY}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gridBuildingAllocator}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This will create a 3x2 grid of 6 buildings, each 7 x 13 x 6 m with 2 x
4 rooms inside and 2 foors; the buildings are spaced by 3 m on both
the x and the y axis.


\subsubsection{Setup nodes and mobility models}
\label{\detokenize{buildings-user:setup-nodes-and-mobility-models}}
Nodes and mobility models are configured as usual, however in order to
use them with the buildings model you need an additional call to
\sphinxcode{\sphinxupquote{BuildingsHelper::Install()}}, so as to let the mobility model include
the information on their position w.r.t. the buildings. Here is an example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}
\PYG{n}{mobility}\PYG{o}{.}\PYG{n}{SetMobilityModel} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ns3::ConstantPositionMobilityModel}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ueNodes}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{o}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ueNodes}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{BuildingsHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ueNodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is to be noted that any mobility model can be used. However, the
user is advised to make sure that the behavior of the mobility model
being used is consistent with the presence of Buildings. For example,
using a simple random mobility over the whole simulation area in
presence of buildings might easily results in node moving in and out
of buildings, regardless of the presence of walls.


\subsubsection{Place some nodes}
\label{\detokenize{buildings-user:place-some-nodes}}
You can place nodes in your simulation using several methods, which
are described in the following.


\paragraph{Legacy positioning methods}
\label{\detokenize{buildings-user:legacy-positioning-methods}}
Any legacy ns\sphinxhyphen{}3 positioning method can be used to place node in the
simulation. The important additional step is to For example, you can
place nodes manually like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{ConstantPositionMobilityModel}\PYG{o}{\PYGZgt{}} \PYG{n}{mm0} \PYG{o}{=} \PYG{n}{enbNodes}\PYG{o}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{ConstantPositionMobilityModel}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{ConstantPositionMobilityModel}\PYG{o}{\PYGZgt{}} \PYG{n}{mm1} \PYG{o}{=} \PYG{n}{enbNodes}\PYG{o}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{ConstantPositionMobilityModel}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mm0}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetPosition} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mm1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetPosition} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{30.0}\PYG{p}{,} \PYG{l+m+mf}{40.0}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}
\PYG{n}{mobility}\PYG{o}{.}\PYG{n}{SetMobilityModel} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ns3::ConstantPositionMobilityModel}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ueNodes}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{o}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ueNodes}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{BuildingsHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ueNodes}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mm0}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetPosition} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mm1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetPosition} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{30.0}\PYG{p}{,} \PYG{l+m+mf}{40.0}\PYG{p}{,} \PYG{l+m+mf}{1.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Alternatively, you could use any existing PositionAllocator
class. The coordinates of the node will determine whether it is placed
outdoor or indoor and, if indoor, in which building and room it is placed.


\paragraph{Building\sphinxhyphen{}specific positioning methods}
\label{\detokenize{buildings-user:building-specific-positioning-methods}}
The following position allocator classes are available to place node
in special positions with respect to buildings:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{RandomBuildingPositionAllocator}}: Allocate each position by
randomly choosing a building from the list of all buildings, and
then randomly choosing a position inside the building.

\item {} 
\sphinxcode{\sphinxupquote{RandomRoomPositionAllocator}}: Allocate each position by randomly
choosing a room from the list of rooms in all buildings, and then
randomly choosing a position inside the room.

\item {} 
\sphinxcode{\sphinxupquote{SameRoomPositionAllocator}}: Walks a given NodeContainer
sequentially, and for each node allocate a new position randomly in
the same room of that node.

\item {} 
\sphinxcode{\sphinxupquote{FixedRoomPositionAllocator}}: Generate a random position
uniformly distributed in the volume of a chosen room inside a
chosen building.

\end{itemize}


\subsubsection{Making the Mobility Model Consistent for a node}
\label{\detokenize{buildings-user:making-the-mobility-model-consistent-for-a-node}}
Initially, a mobility model of a node is made consistent when a node is
initialized, which eventually triggers a call to the \sphinxcode{\sphinxupquote{DoInitialize}}
method of the \sphinxtitleref{MobilityBuildingInfo\textasciigrave{}} class. In particular, it calls the
\sphinxcode{\sphinxupquote{MakeMobilityModelConsistent}} method, which goes through the lists of
all buildings, determine if the node is indoor or outdoor, and if indoor
it also determines the building in which the node is located and the
corresponding floor number inside the building. Moreover, this method also
caches the position of the node, which is used to make the mobility model
consistent for a moving node whenever the \sphinxcode{\sphinxupquote{IsInside}} method of
\sphinxcode{\sphinxupquote{MobilityBuildingInfo}} class is called.


\subsubsection{Building\sphinxhyphen{}aware pathloss model}
\label{\detokenize{buildings-user:building-aware-pathloss-model}}
After you placed buildings and nodes in a simulation, you can use a
building\sphinxhyphen{}aware pathloss model in a simulation exactly in the same way
you would use any regular path loss model. How to do this is specific
for the wireless module that you are considering (lte, wifi, wimax,
etc.), so please refer to the documentation of that model for specific
instructions.


\subsubsection{Building\sphinxhyphen{}aware channel condition model}
\label{\detokenize{buildings-user:building-aware-channel-condition-model}}
The class BuildingsChannelConditionModel implements a \sphinxhref{propagation.html\#channelconditionmodel}{channel condition model}
which determines the LOS/NLOS channel state based on the buildings deployed in
the scenario.


\subsection{Main configurable attributes}
\label{\detokenize{buildings-user:main-configurable-attributes}}
The \sphinxcode{\sphinxupquote{Building}} class has the following configurable parameters:
\begin{itemize}
\item {} 
building type: Residential, Office and Commercial.

\item {} 
external walls type: Wood, ConcreteWithWindows, ConcreteWithoutWindows and StoneBlocks.

\item {} 
building bounds: a \sphinxcode{\sphinxupquote{Box}} class with the building bounds.

\item {} 
number of floors.

\item {} 
number of rooms in x\sphinxhyphen{}axis and y\sphinxhyphen{}axis (rooms can be placed only in a grid way).

\end{itemize}

The \sphinxcode{\sphinxupquote{BuildingMobilityLossModel}} parameter configurable with the ns3 attribute system is represented by the bound (string \sphinxcode{\sphinxupquote{Bounds}}) of the simulation area by providing a \sphinxcode{\sphinxupquote{Box}} class with the area bounds. Moreover, by means of its methods the following parameters can be configured:
\begin{itemize}
\item {} 
the number of floor the node is placed (default 0).

\item {} 
the position in the rooms grid.

\end{itemize}

The \sphinxcode{\sphinxupquote{BuildingPropagationLossModel}} class has the following configurable parameters configurable with the attribute system:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Frequency}}: reference frequency (default 2160 MHz), note that by setting the frequency the wavelength is set accordingly automatically and viceversa).

\item {} 
\sphinxcode{\sphinxupquote{Lambda}}: the wavelength (0.139 meters, considering the above frequency).

\item {} 
\sphinxcode{\sphinxupquote{ShadowSigmaOutdoor}}: the standard deviation of the shadowing for outdoor nodes (defaul 7.0).

\item {} 
\sphinxcode{\sphinxupquote{ShadowSigmaIndoor}}: the standard deviation of the shadowing for indoor nodes (default 8.0).

\item {} 
\sphinxcode{\sphinxupquote{ShadowSigmaExtWalls}}: the standard deviation of the shadowing due to external walls penetration for outdoor to indoor communications (default 5.0).

\item {} 
\sphinxcode{\sphinxupquote{RooftopLevel}}: the level of the rooftop of the building in meters (default 20 meters).

\item {} 
\sphinxcode{\sphinxupquote{Los2NlosThr}}: the value of distance of the switching point between line\sphinxhyphen{}of\sphinxhyphen{}sigth and non\sphinxhyphen{}line\sphinxhyphen{}of\sphinxhyphen{}sight propagation model in meters (default 200 meters).

\item {} 
\sphinxcode{\sphinxupquote{ITU1411DistanceThr}}: the value of distance of the switching point between short range (ITU 1211) communications and long range (Okumura Hata) in meters (default 200 meters).

\item {} 
\sphinxcode{\sphinxupquote{MinDistance}}: the minimum distance in meters between two nodes for evaluating the pathloss (considered neglictible before this threshold) (default 0.5 meters).

\item {} 
\sphinxcode{\sphinxupquote{Environment}}: the environment scenario among Urban, SubUrban and OpenAreas (default Urban).

\item {} 
\sphinxcode{\sphinxupquote{CitySize}}: the dimension of the city among Small, Medium, Large (default Large).

\end{itemize}

In order to use the hybrid mode, the class to be used is the \sphinxcode{\sphinxupquote{HybridBuildingMobilityLossModel}}, which allows the selection of the proper pathloss model according to the pathloss logic presented in the design chapter. However, this solution has the problem that the pathloss model switching points might present discontinuities due to the different characteristics of the model. This implies that according to the specific scenario, the threshold used for switching have to be properly tuned.
The simple \sphinxcode{\sphinxupquote{OhBuildingMobilityLossModel}} overcome this problem by using only the Okumura Hata model and the wall penetration losses.


\section{Testing Documentation}
\label{\detokenize{buildings-testing:testing-documentation}}\label{\detokenize{buildings-testing::doc}}

\subsection{Overview}
\label{\detokenize{buildings-testing:overview}}
To test and validate the ns\sphinxhyphen{}3 Building Pathloss module, some test suites is provided which are integrated with the ns\sphinxhyphen{}3 test framework. To run them, you need to have configured the build of the simulator in this way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}enable\PYGZhy{}modules\PYG{o}{=}buildings
\PYGZdl{} ./test.py
\end{sphinxVerbatim}

The above will run not only the test suites belonging to the buildings module, but also those belonging to all the other ns\sphinxhyphen{}3 modules on which the buildings module depends. See the ns\sphinxhyphen{}3 manual for generic information on the testing framework.

You can get a more detailed report in HTML format in this way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}w results.html
\end{sphinxVerbatim}

After the above command has run, you can view the detailed result for each test by opening the file \sphinxcode{\sphinxupquote{results.html}} with a web browser.

You can run each test suite separately using this command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}s test\PYGZhy{}suite\PYGZhy{}name
\end{sphinxVerbatim}

For more details about \sphinxcode{\sphinxupquote{test.py}} and the ns\sphinxhyphen{}3 testing framework, please refer to the ns\sphinxhyphen{}3 manual.


\subsection{Description of the test suites}
\label{\detokenize{buildings-testing:description-of-the-test-suites}}

\subsubsection{BuildingsHelper test}
\label{\detokenize{buildings-testing:buildingshelper-test}}
The test suite \sphinxcode{\sphinxupquote{buildings\sphinxhyphen{}helper}} checks that the method \sphinxcode{\sphinxupquote{BuildingsHelper::MakeAllInstancesConsistent ()}} works properly, i.e., that the BuildingsHelper is successful in locating if nodes are outdoor or indoor, and if indoor that they are located in the correct building, room and floor. Several test cases are provided with different buildings (having different size, position, rooms and floors) and different node positions. The test passes if each every node is located correctly.


\subsubsection{BuildingPositionAllocator test}
\label{\detokenize{buildings-testing:buildingpositionallocator-test}}
The test suite \sphinxcode{\sphinxupquote{building\sphinxhyphen{}position\sphinxhyphen{}allocator}} feature two test cases that check that respectively RandomRoomPositionAllocator and SameRoomPositionAllocator work properly. Each test cases involves a single 2x3x2 room building (total 12 rooms) at known coordinates and respectively 24 and 48 nodes. Both tests check that the number of nodes allocated in each room is the expected one and that the position of the nodes is also correct.


\subsubsection{Buildings Pathloss tests}
\label{\detokenize{buildings-testing:buildings-pathloss-tests}}
The test suite \sphinxcode{\sphinxupquote{buildings\sphinxhyphen{}pathloss\sphinxhyphen{}model}} provides different unit tests that compare the expected results of the buildings pathloss module in specific scenarios with pre calculated values obtained offline with an Octave script (test/reference/buildings\sphinxhyphen{}pathloss.m). The tests are considered passed if the two values are equal up to a tolerance of 0.1, which is deemed appropriate for the typical usage of pathloss values (which are in dB).

In the following we detailed the scenarios considered, their selection has been done for covering the wide set of possible pathloss logic combinations. The pathloss logic results therefore implicitly tested.


\paragraph{Test \#1 Okumura Hata}
\label{\detokenize{buildings-testing:test-1-okumura-hata}}
In this test we test the standard Okumura Hata model; therefore both eNB and UE are placed outside at a distance of 2000 m. The frequency used is the E\sphinxhyphen{}UTRA band \#5, which correspond to 869 MHz (see table 5.5\sphinxhyphen{}1 of 36.101). The test includes also the validation of the areas extensions (i.e., urban, suburban and open\sphinxhyphen{}areas) and of the city size (small, medium and large).


\paragraph{Test \#2 COST231 Model}
\label{\detokenize{buildings-testing:test-2-cost231-model}}
This test is aimed at validating the COST231 model. The test is similar to the Okumura Hata one, except that the frequency used is the EUTRA band \#1 (2140 MHz) and that the test can be performed only for large and small cities in urban scenarios due to model limitations.


\paragraph{Test \#3 2.6 GHz model}
\label{\detokenize{buildings-testing:test-3-2-6-ghz-model}}
This test validates the 2.6 GHz Kun model. The test is similar to Okumura Hata one except that the frequency is the EUTRA band \#7 (2620 MHz) and the test can be performed only in urban scenario.


\paragraph{Test \#4 ITU1411 LoS model}
\label{\detokenize{buildings-testing:test-4-itu1411-los-model}}
This test is aimed at validating the ITU1411 model in case of line of sight within street canyons transmissions. In this case the UE is placed at 100 meters far from the eNB, since the threshold for switching between LoS and NLoS is left to default one (i.e., 200 m.).


\paragraph{Test \#5 ITU1411 NLoS model}
\label{\detokenize{buildings-testing:test-5-itu1411-nlos-model}}
This test is aimed at validating the ITU1411 model in case of non line of sight over the rooftop transmissions. In this case the UE is placed at 900 meters far from the eNB, in order to be above the threshold for switching between LoS and NLoS is left to default one (i.e., 200 m.).


\paragraph{Test \#6 ITUP1238 model}
\label{\detokenize{buildings-testing:test-6-itup1238-model}}
This test is aimed at validating the ITUP1238 model in case of indoor transmissions. In this case both the UE and the eNB are placed in a residential building with walls made of concrete with windows. Ue is placed at the second floor and distances 30 meters far from the eNB, which is placed at the first floor.


\paragraph{Test \#7 Outdoor \sphinxhyphen{}\textgreater{} Indoor with Okumura Hata model}
\label{\detokenize{buildings-testing:test-7-outdoor-indoor-with-okumura-hata-model}}
This test validates the outdoor to indoor transmissions for large distances. In this case the UE is placed in a residential building with wall made of concrete with windows and distances 2000 meters from the outdoor eNB.


\paragraph{Test \#8 Outdoor \sphinxhyphen{}\textgreater{} Indoor with ITU1411 model}
\label{\detokenize{buildings-testing:test-8-outdoor-indoor-with-itu1411-model}}
This test validates the outdoor to indoor transmissions for short distances. In this case the UE is placed in a residential building with walls made of concrete with windows and distances 100 meters from the outdoor eNB.


\paragraph{Test \#9 Indoor \sphinxhyphen{}\textgreater{} Outdoor with ITU1411 model}
\label{\detokenize{buildings-testing:test-9-indoor-outdoor-with-itu1411-model}}
This test validates the outdoor to indoor transmissions for very short distances. In this case the eNB is placed in the second floor of a residential building with walls made of concrete with windows and distances 100 meters from the outdoor UE (i.e., LoS communication). Therefore the height gain has to be included in the pathloss evaluation.


\paragraph{Test \#10 Indoor \sphinxhyphen{}\textgreater{} Outdoor with ITU1411 model}
\label{\detokenize{buildings-testing:test-10-indoor-outdoor-with-itu1411-model}}
This test validates the outdoor to indoor transmissions for short distances. In this case the eNB is placed in the second floor of a residential building with walls made of concrete with windows and distances 500 meters from the outdoor UE (i.e., NLoS communication). Therefore the height gain has to be included in the pathloss evaluation.


\subsubsection{Buildings Shadowing Test}
\label{\detokenize{buildings-testing:buildings-shadowing-test}}
The test suite \sphinxcode{\sphinxupquote{buildings\sphinxhyphen{}shadowing\sphinxhyphen{}test}} is a unit test intended to verify the statistical distribution of the shadowing model implemented by \sphinxcode{\sphinxupquote{BuildingsPathlossModel}}. The shadowing is modeled according to a normal distribution with mean \(\mu = 0\) and variable standard deviation \(\sigma\), according to models commonly used in literature. Three test cases are provided, which cover the cases of indoor, outdoor and indoor\sphinxhyphen{}to\sphinxhyphen{}outdoor communications.
Each test case generates 1000 different samples of shadowing for different pairs of MobilityModel instances in a given scenario. Shadowing values are obtained by subtracting from the total loss value returned by \sphinxcode{\sphinxupquote{HybridBuildingsPathlossModel}} the path loss component which is constant and pre\sphinxhyphen{}determined for each test case. The test verifies that the sample mean and sample variance of the shadowing values fall within the 99\% confidence interval of the sample mean and sample variance. The test also verifies that the shadowing values returned at successive times for the same pair of MobilityModel instances is constant.


\subsubsection{Buildings Channel Condition Model Test}
\label{\detokenize{buildings-testing:buildings-channel-condition-model-test}}
The BuildingsChannelConditionModelTestSuite tests the class BuildingsChannelConditionModel.
It checks if the channel condition between two nodes is correctly determined when a
building is deployed.


\section{References}
\label{\detokenize{buildings-references:references}}\label{\detokenize{buildings-references::doc}}

\chapter{Click Modular Router Integration}
\label{\detokenize{click:click-modular-router-integration}}\label{\detokenize{click::doc}}
Click is a software architecture for building configurable routers.
By using different combinations of packet processing units called elements,
a Click router can be made to perform a specific kind of functionality.
This flexibility provides a good platform for testing and experimenting with
different protocols.


\section{Model Description}
\label{\detokenize{click:model-description}}
The source code for the Click model lives in the directory \sphinxcode{\sphinxupquote{src/click}}.


\subsection{Design}
\label{\detokenize{click:design}}
ns\sphinxhyphen{}3’s design is well suited for an integration with Click due to the following reasons:
\begin{itemize}
\item {} 
Packets in ns\sphinxhyphen{}3 are serialised/deserialised as they move up/down the stack. This allows ns\sphinxhyphen{}3 packets to be passed to and from Click as they are.

\item {} 
This also means that any kind of ns\sphinxhyphen{}3 traffic generator and transport should work easily on top of Click.

\item {} 
By striving to implement click as an Ipv4RoutingProtocol instance, we can avoid significant changes to the LL and MAC layer of the ns\sphinxhyphen{}3 code.

\end{itemize}

The design goal was to make the ns\sphinxhyphen{}3\sphinxhyphen{}click public API simple enough such that the user needs to merely add an Ipv4ClickRouting instance to the node, and inform each Click node of the Click configuration file (.click file) that it is to use.

This model implements the interface to the Click Modular Router and
provides the Ipv4ClickRouting class to allow a node to use Click
for external routing. Unlike normal Ipv4RoutingProtocol sub types,
Ipv4ClickRouting doesn’t use a RouteInput() method, but instead,
receives a packet on the appropriate interface and processes it
accordingly. Note that you need to have a routing table type element
in your Click graph to use Click for external routing. This is needed
by the RouteOutput() function inherited from Ipv4RoutingProtocol.
Furthermore, a Click based node uses a different kind of L3 in the
form of Ipv4L3ClickProtocol, which is a trimmed down version of
Ipv4L3Protocol. Ipv4L3ClickProtocol passes on packets passing through
the stack to Ipv4ClickRouting for processing.


\subsubsection{Developing a Simulator API to allow ns\sphinxhyphen{}3 to interact with Click}
\label{\detokenize{click:developing-a-simulator-api-to-allow-ns-3-to-interact-with-click}}
Much of the API is already well defined, which allows Click to probe for information from the simulator (like a Node’s ID, an Interface ID and so forth). By retaining most of the methods, it should be possible to write new implementations specific to ns\sphinxhyphen{}3 for the same functionality.

Hence, for the Click integration with ns\sphinxhyphen{}3, a class named Ipv4ClickRouting will handle the interaction with Click. The code for the same can be found in \sphinxcode{\sphinxupquote{src/click/model/ipv4\sphinxhyphen{}click\sphinxhyphen{}routing.\{cc,h\}}}.


\subsubsection{Packet hand off between ns\sphinxhyphen{}3 and Click}
\label{\detokenize{click:packet-hand-off-between-ns-3-and-click}}
There are four kinds of packet hand\sphinxhyphen{}offs that can occur between ns\sphinxhyphen{}3 and Click.
\begin{itemize}
\item {} 
L4 to L3

\item {} 
L3 to L4

\item {} 
L3 to L2

\item {} 
L2 to L3

\end{itemize}

To overcome this, we implement Ipv4L3ClickProtocol, a stripped down version of Ipv4L3Protocol. Ipv4L3ClickProtocol passes packets to and from Ipv4ClickRouting appropriately to perform routing.


\subsection{Scope and Limitations}
\label{\detokenize{click:scope-and-limitations}}\begin{itemize}
\item {} 
In its current state, the NS\sphinxhyphen{}3 Click Integration is limited to use only with L3, leaving NS\sphinxhyphen{}3 to handle L2. We are currently working on adding Click MAC support as well. See the usage section to make sure that you design your Click graphs accordingly.

\item {} 
Furthermore, ns\sphinxhyphen{}3\sphinxhyphen{}click will work only with userlevel elements. The complete list of elements are available at \sphinxurl{http://read.cs.ucla.edu/click/elements}. Elements that have ‘all’, ‘userlevel’ or ‘ns’ mentioned beside them may be used.

\item {} 
As of now, the ns\sphinxhyphen{}3 interface to Click is Ipv4 only. We will be adding Ipv6 support in the future.

\end{itemize}


\subsection{References}
\label{\detokenize{click:references}}\begin{itemize}
\item {} 
Eddie Kohler, Robert Morris, Benjie Chen, John Jannotti, and M. Frans Kaashoek. The click modular router. ACM Transactions on Computer Systems 18(3), August 2000, pages 263\sphinxhyphen{}297.

\item {} 
Lalith Suresh P., and Ruben Merz. Ns\sphinxhyphen{}3\sphinxhyphen{}click: click modular router integration for ns\sphinxhyphen{}3. In Proc. of 3rd International ICST Workshop on NS\sphinxhyphen{}3 (WNS3), Barcelona, Spain. March, 2011.

\item {} 
Michael Neufeld, Ashish Jain, and Dirk Grunwald. Nsclick: bridging network simulation and deployment. MSWiM ‘02: Proceedings of the 5th ACM international workshop on Modeling analysis and simulation of wireless and mobile systems, 2002, Atlanta, Georgia, USA. \sphinxurl{http://doi.acm.org/10.1145/570758.570772}

\end{itemize}


\section{Usage}
\label{\detokenize{click:usage}}

\subsection{Building Click}
\label{\detokenize{click:building-click}}
The first step is to clone Click from the github repository and build it:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} git clone https://github.com/kohler/click
\PYGZdl{} \PYG{n+nb}{cd} click/
\PYGZdl{} ./configure \PYGZhy{}\PYGZhy{}disable\PYGZhy{}linuxmodule \PYGZhy{}\PYGZhy{}enable\PYGZhy{}nsclick \PYGZhy{}\PYGZhy{}enable\PYGZhy{}wifi
\PYGZdl{} make
\end{sphinxVerbatim}

The \textendash{}enable\sphinxhyphen{}wifi flag may be skipped if you don’t intend on using Click with Wifi.
* Note: You don’t need to do a ‘make install’.

Once Click has been built successfully, change into the ns\sphinxhyphen{}3 directory and
configure ns\sphinxhyphen{}3 with Click Integration support:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}with\PYGZhy{}nsclick\PYG{o}{=}/path/to/click/source
\end{sphinxVerbatim}

Hint:  If you have click installed one directory above ns\sphinxhyphen{}3 (such as in the
ns\sphinxhyphen{}3\sphinxhyphen{}allinone directory), and the name of the directory is ‘click’ (or
a symbolic link to the directory is named ‘click’), then the \textendash{}with\sphinxhyphen{}nsclick
specifier is not necessary; the ns\sphinxhyphen{}3 build system will successfully find
the directory.

If it says ‘enabled’ beside ‘NS\sphinxhyphen{}3 Click Integration Support’, then you’re good to go. Note: If running modular ns\sphinxhyphen{}3, the minimum set of modules required to run all ns\sphinxhyphen{}3\sphinxhyphen{}click examples is wifi, csma and config\sphinxhyphen{}store.

Next, try running one of the examples:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run nsclick\PYGZhy{}simple\PYGZhy{}lan
\end{sphinxVerbatim}

You may then view the resulting .pcap traces, which are named nsclick\sphinxhyphen{}simple\sphinxhyphen{}lan\sphinxhyphen{}0\sphinxhyphen{}0.pcap and nsclick\sphinxhyphen{}simple\sphinxhyphen{}lan\sphinxhyphen{}0\sphinxhyphen{}1.pcap.


\subsection{Click Graph Instructions}
\label{\detokenize{click:click-graph-instructions}}
The following should be kept in mind when making your Click graph:
\begin{itemize}
\item {} 
Only userlevel elements can be used.

\item {} 
You will need to replace FromDevice and ToDevice elements with FromSimDevice and ToSimDevice elements.

\item {} 
Packets to the kernel are sent up using ToSimDevice(tap0,IP).

\item {} 
For any node, the device which sends/receives packets to/from the kernel, is named ‘tap0’. The remaining interfaces should be named eth0, eth1 and so forth (even if you’re using wifi). Please note that the device numbering should begin from 0. In future, this will be made flexible so that users can name devices in their Click file as they wish.

\item {} 
A routing table element is a mandatory. The OUTports of the routing table element should correspond to the interface number of the device through which the packet will ultimately be sent out. Violating this rule will lead to really weird packet traces. This routing table element’s name should then be passed to the Ipv4ClickRouting protocol object as a simulation parameter. See the Click examples for details.

\item {} 
The current implementation leaves Click with mainly L3 functionality, with ns\sphinxhyphen{}3 handling L2. We will soon begin working to support the use of MAC protocols on Click as well. This means that as of now, Click’s Wifi specific elements cannot be used with ns\sphinxhyphen{}3.

\end{itemize}


\subsection{Debugging Packet Flows from Click}
\label{\detokenize{click:debugging-packet-flows-from-click}}
From any point within a Click graph, you may use the Print (\sphinxurl{http://read.cs.ucla.edu/click/elements/print}) element and its variants for pretty printing of packet contents. Furthermore, you may generate pcap traces of packets flowing through a Click graph by using the ToDump (\sphinxurl{http://read.cs.ucla.edu/click/elements/todump}) element as well. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{myarpquerier}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Print}\PYG{p}{(}\PYG{n}{fromarpquery}\PYG{p}{,}\PYG{l+m+mi}{64}\PYG{p}{)}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{ToDump}\PYG{p}{(}\PYG{n}{out\PYGZus{}arpquery}\PYG{p}{,}\PYG{n}{PER\PYGZus{}NODE} \PYG{l+m+mi}{1}\PYG{p}{)}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{ethout}\PYG{p}{;}
\end{sphinxVerbatim}

and …will print the contents of packets that flow out of the ArpQuerier, then generate a pcap trace file which will have a suffix ‘out\_arpquery’, for each node using the Click file, before pushing packets onto ‘ethout’.


\subsection{Helper}
\label{\detokenize{click:helper}}
To have a node run Click, the easiest way would be to use the ClickInternetStackHelper
class in your simulation script. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ClickInternetStackHelper} \PYG{n}{click}\PYG{p}{;}
\PYG{n}{click}\PYG{p}{.}\PYG{n}{SetClickFile} \PYG{p}{(}\PYG{n}{myNodeContainer}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{nsclick\PYGZhy{}simple\PYGZhy{}lan.click}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{click}\PYG{p}{.}\PYG{n}{SetRoutingTableElement} \PYG{p}{(}\PYG{n}{myNodeContainer}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u/rt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{click}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{myNodeContainer}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The example scripts inside \sphinxcode{\sphinxupquote{src/click/examples/}} demonstrate the use of Click based nodes
in different scenarios. The helper source can be found inside \sphinxcode{\sphinxupquote{src/click/helper/click\sphinxhyphen{}internet\sphinxhyphen{}stack\sphinxhyphen{}helper.\{h,cc\}}}


\subsection{Examples}
\label{\detokenize{click:examples}}
The following examples have been written, which can be found in \sphinxcode{\sphinxupquote{src/click/examples/}}:
\begin{itemize}
\item {} 
nsclick\sphinxhyphen{}simple\sphinxhyphen{}lan.cc and nsclick\sphinxhyphen{}raw\sphinxhyphen{}wlan.cc: A Click based node communicating with a normal ns\sphinxhyphen{}3 node without Click, using Csma and Wifi respectively. It also demonstrates the use of TCP on top of Click, something which the original nsclick implementation for NS\sphinxhyphen{}2 couldn’t achieve.

\item {} 
nsclick\sphinxhyphen{}udp\sphinxhyphen{}client\sphinxhyphen{}server\sphinxhyphen{}csma.cc and nsclick\sphinxhyphen{}udp\sphinxhyphen{}client\sphinxhyphen{}server\sphinxhyphen{}wifi.cc: A 3 node LAN (Csma and Wifi respectively) wherein 2 Click based nodes run a UDP client, that sends packets to a third Click based node running a UDP server.

\item {} 
nsclick\sphinxhyphen{}routing.cc: One Click based node communicates to another via a third node that acts as an IP router (using the IP router Click configuration). This demonstrates routing using Click.

\end{itemize}

Scripts are available within \sphinxcode{\sphinxupquote{\textless{}click\sphinxhyphen{}dir\textgreater{}/conf/}} that allow you to generate Click files for some common scenarios. The IP Router used in \sphinxcode{\sphinxupquote{nsclick\sphinxhyphen{}routing.cc}} was generated from the make\sphinxhyphen{}ip\sphinxhyphen{}conf.pl file and slightly adapted to work with ns\sphinxhyphen{}3\sphinxhyphen{}click.


\section{Validation}
\label{\detokenize{click:validation}}
This model has been tested as follows:
\begin{itemize}
\item {} 
Unit tests have been written to verify the internals of Ipv4ClickRouting. This can be found in \sphinxcode{\sphinxupquote{src/click/ipv4\sphinxhyphen{}click\sphinxhyphen{}routing\sphinxhyphen{}test.cc}}. These tests verify whether the methods inside Ipv4ClickRouting which deal with Device name to ID, IP Address from device name and Mac Address from device name bindings work as expected.

\item {} 
The examples have been used to test Click with actual simulation scenarios. These can be found in \sphinxcode{\sphinxupquote{src/click/examples/}}. These tests cover the following: the use of different kinds of transports on top of Click, TCP/UDP, whether Click nodes can communicate with non\sphinxhyphen{}Click based nodes, whether Click nodes can communicate with each other, using Click to route packets using static routing.

\item {} 
Click has been tested with Csma, Wifi and Point\sphinxhyphen{}to\sphinxhyphen{}Point devices. Usage instructions are available in the preceding section.

\end{itemize}


\chapter{CSMA NetDevice}
\label{\detokenize{csma:csma-netdevice}}\label{\detokenize{csma::doc}}
This is the introduction to CSMA NetDevice chapter, to complement the CSMA model
doxygen.


\section{Overview of the CSMA model}
\label{\detokenize{csma:overview-of-the-csma-model}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} CSMA device models a simple bus network in the spirit of Ethernet.
Although it does not model any real physical network you could ever build or
buy, it does provide some very useful functionality.

Typically when one thinks of a bus network Ethernet or IEEE 802.3 comes to mind.
Ethernet uses CSMA/CD (Carrier Sense Multiple Access with Collision Detection
with exponentially increasing backoff to contend for the shared transmission
medium. The \sphinxstyleemphasis{ns\sphinxhyphen{}3} CSMA device models only a portion of this process, using the
nature of the globally available channel to provide instantaneous (faster than
light) carrier sense and priority\sphinxhyphen{}based collision “avoidance.” Collisions in the
sense of Ethernet never happen and so the \sphinxstyleemphasis{ns\sphinxhyphen{}3} CSMA device does not model
collision detection, nor will any transmission in progress be “jammed.”


\subsection{CSMA Layer Model}
\label{\detokenize{csma:csma-layer-model}}
There are a number of conventions in use for describing layered communications
architectures in the literature and in textbooks. The most common layering model
is the ISO seven layer reference model. In this view the CsmaNetDevice and
CsmaChannel pair occupies the lowest two layers \textendash{} at the physical (layer one),
and data link (layer two) positions. Another important reference model is that
specified by RFC 1122, “Requirements for Internet Hosts \textendash{} Communication
Layers.” In this view the CsmaNetDevice and CsmaChannel pair occupies the lowest
layer \textendash{} the link layer. There is also a seemingly endless litany of alternative
descriptions found in textbooks and in the literature. We adopt the naming
conventions used in the IEEE 802 standards which speak of LLC, MAC, MII and PHY
layering. These acronyms are defined as:
\begin{itemize}
\item {} 
LLC:  Logical Link Control;

\item {} 
MAC:  Media Access Control;

\item {} 
MII:  Media Independent Interface;

\item {} 
PHY:  Physical Layer.

\end{itemize}

In this case the \sphinxstyleemphasis{LLC} and \sphinxstyleemphasis{MAC} are sublayers of the OSI data link layer and
the \sphinxstyleemphasis{MII} and \sphinxstyleemphasis{PHY} are sublayers of the OSI physical layer.

The “top” of the CSMA device defines the transition from the network layer to
the data link layer. This transition is performed by higher layers by calling
either CsmaNetDevice::Send or CsmaNetDevice::SendFrom.

In contrast to the IEEE 802.3 standards, there is no precisely specified PHY in
the CSMA model in the sense of wire types, signals or pinouts. The “bottom”
interface of the CsmaNetDevice can be thought of as as a kind of Media
Independent Interface (MII) as seen in the “Fast Ethernet” (IEEE 802.3u)
specifications. This MII interface fits into a corresponding media independent
interface on the CsmaChannel. You will not find the equivalent of a 10BASE\sphinxhyphen{}T or
a 1000BASE\sphinxhyphen{}LX PHY.

The CsmaNetDevice calls the CsmaChannel through a media independent interface.
There is a method defined to tell the channel when to start “wiggling the wires”
using the method CsmaChannel::TransmitStart, and a method to tell the channel
when the transmission process is done and the channel should begin propagating
the last bit across the “wire”: CsmaChannel::TransmitEnd.

When the TransmitEnd method is executed, the channel will model a single uniform
signal propagation delay in the medium and deliver copes of the packet to each
of the devices attached to the packet via the CsmaNetDevice::Receive method.

There is a “pin” in the device media independent interface corresponding to
“COL” (collision). The state of the channel may be sensed by calling
CsmaChannel::GetState. Each device will look at this “pin” before starting a
send and will perform appropriate backoff operations if required.

Properly received packets are forwarded up to higher levels from the
CsmaNetDevice via a callback mechanism. The callback function is initialized by
the higher layer (when the net device is attached) using
CsmaNetDevice::SetReceiveCallback and is invoked upon “proper” reception of a
packet by the net device in order to forward the packet up
the protocol stack.


\section{CSMA Channel Model}
\label{\detokenize{csma:csma-channel-model}}
The class CsmaChannel models the actual transmission medium. There is no fixed
limit for the number of devices connected to the channel. The CsmaChannel models
a data rate and a speed\sphinxhyphen{}of\sphinxhyphen{}light delay which can be accessed via the attributes
“DataRate” and “Delay” respectively. The data rate provided to the channel is
used to set the data rates used by the transmitter sections of the CSMA devices
connected to the channel. There is no way to independently set data rates in the
devices. Since the data rate is only used to calculate a delay time, there is no
limitation (other than by the data type holding the value) on the speed at which
CSMA channels and devices can operate; and no restriction based on any kind of
PHY characteristics.

The CsmaChannel has three states, \sphinxcode{\sphinxupquote{IDLE}}, \sphinxcode{\sphinxupquote{TRANSMITTING}} and
\sphinxcode{\sphinxupquote{PROPAGATING}}. These three states are “seen” instantaneously by all devices on
the channel. By this we mean that if one device begins or ends a simulated
transmission, all devices on the channel are \sphinxstyleemphasis{immediately} aware of the
change in state. There is no time during which one device may see an \sphinxcode{\sphinxupquote{IDLE}}
channel while another device physically further away in the collision domain may
have begun transmitting with the associated signals not propagated down the
channel to other devices. Thus there is no need for collision detection in the
CsmaChannel model and it is not implemented in any way.

We do, as the name indicates, have a Carrier Sense aspect to the model.  Since
the simulator is single threaded, access to the common channel will be
serialized by the simulator. This provides a deterministic mechanism for
contending for the channel. The channel is allocated (transitioned from state
\sphinxcode{\sphinxupquote{IDLE}} to state \sphinxcode{\sphinxupquote{TRANSMITTING}}) on a first\sphinxhyphen{}come first\sphinxhyphen{}served basis.
The channel always goes through a three state process:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{IDLE} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TRANSMITTING} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{PROPAGATING} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{IDLE}
\end{sphinxVerbatim}

The \sphinxcode{\sphinxupquote{TRANSMITTING}} state models the time during which the source net device is
actually wiggling the signals on the wire. The \sphinxcode{\sphinxupquote{PROPAGATING}} state models the
time after the last bit was sent, when the signal is propagating down the wire
to the “far end.”

The transition to the \sphinxcode{\sphinxupquote{TRANSMITTING}} state is  driven by a call to
CsmaChannel::TransmitStart which is called by the net device that transmits the
packet. It is the responsibility of that device to end the transmission with a
call to CsmaChannel::TransmitEnd at the appropriate simulation time that
reflects the time elapsed to put all of the packet bits on the wire. When
TransmitEnd is called, the channel schedules an event corresponding to a single
speed\sphinxhyphen{}of\sphinxhyphen{}light delay. This delay applies to all net devices on the channel
identically. You can think of a symmetrical hub in which the packet bits
propagate to a central location and then back out equal length cables to the
other devices on the channel. The single “speed of light” delay then corresponds
to the time it takes for: 1) a signal to propagate from one CsmaNetDevice
through its cable to the hub; plus 2) the time it takes for the hub to forward
the packet out a port; plus 3) the time it takes for the signal in question to
propagate to the destination net device.

The CsmaChannel models a broadcast medium so the packet is delivered to all of
the devices on the channel (including the source) at the end of the propagation
time. It is the responsibility of the sending device to determine whether or not
it receives a packet broadcast over the channel.

The CsmaChannel provides following Attributes:
\begin{itemize}
\item {} 
DataRate:  The bitrate for packet transmission on connected devices;

\item {} 
Delay: The speed of light transmission delay for the channel.

\end{itemize}


\section{CSMA Net Device Model}
\label{\detokenize{csma:csma-net-device-model}}
The CSMA network device appears somewhat like an Ethernet device. The
CsmaNetDevice provides following Attributes:
\begin{itemize}
\item {} 
Address:  The Mac48Address of the device;

\item {} 
SendEnable:  Enable packet transmission if true;

\item {} 
ReceiveEnable:  Enable packet reception if true;

\item {} 
EncapsulationMode:  Type of link layer encapsulation to use;

\item {} 
RxErrorModel:  The receive error model;

\item {} 
TxQueue:  The transmit queue used by the device;

\item {} 
InterframeGap:  The optional time to wait between “frames”;

\item {} 
Rx:  A trace source for received packets;

\item {} 
Drop:  A trace source for dropped packets.

\end{itemize}

The CsmaNetDevice supports the assignment of a “receive error model.” This is an
ErrorModel object that is used to simulate data corruption on the link.

Packets sent over the CsmaNetDevice are always routed through the transmit queue
to provide a trace hook for packets sent out over the network. This transmit
queue can be set (via attribute) to model different queuing strategies.

Also configurable by attribute is the encapsulation method used by the device.
Every packet gets an EthernetHeader that includes the destination and source MAC
addresses, and a length/type field. Every packet also gets an EthernetTrailer
which includes the FCS. Data in the packet may be encapsulated in different
ways.

By default, or by setting the “EncapsulationMode” attribute to “Dix”, the
encapsulation is according to the DEC, Intel, Xerox standard. This is sometimes
called EthernetII framing and is the familiar destination MAC, source MAC,
EtherType, Data, CRC format.

If the “EncapsulationMode” attribute is set to “Llc”, the encapsulation is by
LLC SNAP. In this case, a SNAP header is added that contains the EtherType (IP
or ARP).

The other implemented encapsulation modes are IP\_ARP (set “EncapsulationMode” to
“IpArp”) in which the length type of the Ethernet header receives the protocol
number of the packet; or ETHERNET\_V1 (set “EncapsulationMode” to “EthernetV1”)
in which the length type of the Ethernet header receives the length of the
packet.  A “Raw” encapsulation mode is defined but not implemented \textendash{} use of the
RAW mode results in an assertion.

Note that all net devices on a channel must be set to the same encapsulation
mode for correct results. The encapsulation mode is not sensed at the receiver.

The CsmaNetDevice implements a random exponential backoff algorithm that is
executed if the channel is determined to be busy (\sphinxcode{\sphinxupquote{TRANSMITTING}} or
\sphinxcode{\sphinxupquote{PPROPAGATING}}) when the device wants to start propagating. This results in a
random delay of up to pow (2, retries) \sphinxhyphen{} 1 microseconds before a retry is
attempted. The default maximum number of retries is 1000.


\section{Using the CsmaNetDevice}
\label{\detokenize{csma:using-the-csmanetdevice}}
The CSMA net devices and channels are typically created and configured using the
associated \sphinxcode{\sphinxupquote{CsmaHelper}} object.  The various \sphinxstyleemphasis{ns\sphinxhyphen{}3} device helpers generally
work in a similar way, and their use is seen in many of our example programs.

The conceptual model of interest is that of a bare computer “husk” into which
you plug net devices. The bare computers are created using a \sphinxcode{\sphinxupquote{NodeContainer}}
helper. You just ask this helper to create as many computers (we call them
\sphinxcode{\sphinxupquote{Nodes}}) as you need on your network:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{csmaNodes}\PYG{p}{;}
\PYG{n}{csmaNodes}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{n}{nCsmaNodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once you have your nodes, you need to instantiate a \sphinxcode{\sphinxupquote{CsmaHelper}} and set any
attributes you may want to change.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{csma}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataRate}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{100Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{csma}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Delay}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{NanoSeconds} \PYG{p}{(}\PYG{l+m+mi}{6560}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{csma}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{EncapsulationMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dix}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{csma}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{FrameSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2000}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once the attributes are set, all that remains is to create the devices and
install them on the required nodes, and to connect the devices together using a
CSMA channel. When we create the net devices, we add them to a container to
allow you to use them in the future. This all takes just one line of code.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NetDeviceContainer} \PYG{n}{csmaDevices} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{csmaNodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

We recommend thinking carefully about changing these Attributes, since
it can result in behavior that surprises users.  We allow this because
we believe flexibility is important.  As an example of a possibly
surprising effect of changing Attributes, consider the following:

The Mtu Attribute indicates the Maximum Transmission Unit to the device.
This is the size of the largest Protocol Data Unit (PDU) that the
device can send.  This Attribute defaults to 1500 bytes and corresponds
to a number found in RFC 894, “A Standard for the Transmission of IP
Datagrams over Ethernet Networks.”  The number is actually derived
from the maximum packet size for 10Base5 (full\sphinxhyphen{}spec Ethernet) networks \textendash{}
1518 bytes.  If you subtract DIX encapsulation overhead for Ethernet
packets (18 bytes) you will end up with a maximum possible data size (MTU)
of 1500 bytes.  One can also find that the MTU for IEEE 802.3 networks
is 1492 bytes.  This is because LLC/SNAP encapsulation adds an extra eight
bytes of overhead to the packet.  In both cases, the underlying network
hardware is limited to 1518 bytes, but the MTU is different because the
encapsulation is different.

If one leaves the Mtu Attribute at 1500 bytes and changes the encapsulation
mode Attribute to Llc, the result will be a network that encapsulates 1500
byte PDUs with LLC/SNAP framing resulting in packets of 1526 bytes.  This
would be illegal in many networks, but we allow you do do this.  This
results in a simulation that quite subtly does not reflect what you might
be expecting since a real device would balk at sending a 1526 byte packet.

There also exist jumbo frames (1500 \textless{} MTU \textless{}= 9000 bytes) and super\sphinxhyphen{}jumbo
(MTU \textgreater{} 9000 bytes) frames that are not officially sanctioned by IEEE but
are available in some high\sphinxhyphen{}speed (Gigabit) networks and NICs.  In the
CSMA model, one could leave the encapsulation mode set to Dix, and set the
Mtu to 64000 bytes \textendash{} even though an associated CsmaChannel DataRate was
left at 10 megabits per second (certainly not Gigabit Ethernet).  This
would essentially model an Ethernet switch made out of vampire\sphinxhyphen{}tapped
1980s\sphinxhyphen{}style 10Base5 networks that support super\sphinxhyphen{}jumbo datagrams, which is
certainly not something that was ever made, nor is likely to ever be made;
however it is quite easy for you to configure.

Be careful about assumptions regarding what CSMA is actually modelling and
how configuration (Attributes) may allow you to swerve considerably away
from reality.


\section{CSMA Tracing}
\label{\detokenize{csma:csma-tracing}}
Like all \sphinxstyleemphasis{ns\sphinxhyphen{}3} devices, the CSMA Model provides a number of trace sources.
These trace sources can be hooked using your own custom trace code, or you can
use our helper functions to arrange for tracing to be enabled on devices you
specify.


\subsection{Upper\sphinxhyphen{}Level (MAC) Hooks}
\label{\detokenize{csma:upper-level-mac-hooks}}
From the point of view of tracing in the net device, there are several
interesting points to insert trace hooks. A convention inherited from other
simulators is that packets destined for transmission onto attached networks pass
through a single “transmit queue” in the net device. We provide trace hooks at
this point in packet flow, which corresponds (abstractly) only to a transition
from the network to data link layer, and call them collectively the device MAC
hooks.

When a packet is sent to the CSMA net device for transmission it always passes
through the transmit queue. The transmit queue in the CsmaNetDevice inherits
from Queue, and therefore inherits three trace sources:
\begin{itemize}
\item {} 
An Enqueue operation source (see Queue::m\_traceEnqueue);

\item {} 
A Dequeue operation source (see Queue::m\_traceDequeue);

\item {} 
A Drop operation source (see Queue::m\_traceDrop).

\end{itemize}

The upper\sphinxhyphen{}level (MAC) trace hooks for the CsmaNetDevice are, in fact, exactly
these three trace sources on the single transmit queue of the device.

The m\_traceEnqueue event is triggered when a packet is placed on the transmit
queue. This happens at the time that CsmaNetDevice::Send or
CsmaNetDevice::SendFrom is called by a higher layer to queue a packet for
transmission.

The m\_traceDequeue event is triggered when a packet is removed from the transmit
queue. Dequeues from the transmit queue can happen in three situations:  1) If
the underlying channel is idle when the CsmaNetDevice::Send or
CsmaNetDevice::SendFrom is called, a packet is dequeued from the transmit queue
and immediately transmitted;  2) If the underlying channel is idle, a packet may
be dequeued and immediately transmitted in an internal TransmitCompleteEvent
that functions much like a transmit complete interrupt service routine; or 3)
from the random exponential backoff handler if a timeout is detected.

Case (3) implies that a packet is dequeued from the transmit queue if it is
unable to be transmitted according to the backoff rules. It is important to
understand that this will appear as a Dequeued packet and it is easy to
incorrectly assume that the packet was transmitted since it passed through the
transmit queue. In fact, a packet is actually dropped by the net device in this
case. The reason for this behavior is due to the definition of the Queue Drop
event. The m\_traceDrop event is, by definition, fired when a packet cannot be
enqueued on the transmit queue because it is full. This event only fires if the
queue is full and we do not overload this event to indicate that the CsmaChannel
is “full.”


\subsection{Lower\sphinxhyphen{}Level (PHY) Hooks}
\label{\detokenize{csma:lower-level-phy-hooks}}
Similar to the upper level trace hooks, there are trace hooks available at the
lower levels of the net device. We call these the PHY hooks. These events fire
from the device methods that talk directly to the CsmaChannel.

The trace source m\_dropTrace is called to indicate a packet that is dropped by
the device. This happens in two cases: First, if the receive side of the net
device is not enabled (see CsmaNetDevice::m\_receiveEnable and the associated
attribute “ReceiveEnable”).

The m\_dropTrace is also used to indicate that a packet was discarded as corrupt
if a receive error model is used (see CsmaNetDevice::m\_receiveErrorModel and the
associated attribute “ReceiveErrorModel”).

The other low\sphinxhyphen{}level trace source fires on reception of an accepted packet (see
CsmaNetDevice::m\_rxTrace). A packet is accepted if it is destined for the
broadcast address, a multicast address, or to the MAC address assigned to the
net device.


\section{Summary}
\label{\detokenize{csma:summary}}
The ns3 CSMA model is a simplistic model of an Ethernet\sphinxhyphen{}like network.  It
supports a Carrier\sphinxhyphen{}Sense function and allows for Multiple Access to a
shared medium.  It is not physical in the sense that the state of the
medium is instantaneously shared among all devices.  This means that there
is no collision detection required in this model and none is implemented.
There will never be a “jam” of a packet already on the medium.  Access to
the shared channel is on a first\sphinxhyphen{}come first\sphinxhyphen{}served basis as determined by
the simulator scheduler.  If the channel is determined to be busy by looking
at the global state, a random exponential backoff is performed and a retry
is attempted.

Ns\sphinxhyphen{}3 Attributes provide a mechanism for setting various parameters in the
device and channel such as addresses, encapsulation modes and error model
selection.  Trace hooks are provided in the usual manner with a set of
upper level hooks corresponding to a transmit queue and used in ASCII
tracing; and also a set of lower level hooks used in pcap tracing.

Although the ns\sphinxhyphen{}3 CsmaChannel and CsmaNetDevice does not model any kind of
network you could build or buy, it does provide us with some useful
functionality.  You should, however, understand that it is explicitly not
Ethernet or any flavor of IEEE 802.3 but an interesting subset.


\chapter{DSDV Routing}
\label{\detokenize{dsdv:dsdv-routing}}\label{\detokenize{dsdv::doc}}
Destination\sphinxhyphen{}Sequenced Distance Vector (DSDV) routing protocol is a pro\sphinxhyphen{}active, table\sphinxhyphen{}driven routing protocol
for MANETs developed by Charles E. Perkins and Pravin Bhagwat in 1994. It uses the hop count as metric in route
selection.

This model was developed by
\sphinxhref{http://www.ittc.ku.edu/resilinets}{the ResiliNets research group}
at the University of Kansas.  A paper on this model exists at
\sphinxhref{https://wiki.ittc.ku.edu/resilinets/ResiliNets\_Publications\#.E2.80.9CDestination-Sequenced\_Distance\_Vector\_.28DSDV.29\_Routing\_Protocol\_Implementation\_in\_ns-3.E2.80.9D}{this URL}.


\section{DSDV Routing Overview}
\label{\detokenize{dsdv:dsdv-routing-overview}}
DSDV Routing Table: Every node will maintain a table listing all the other nodes it has known either directly
or through some neighbors. Every node has a single entry in the routing table. The entry will have information
about the node’s IP address, last known sequence number and the hop count to reach that node. Along with these
details the table also keeps track of the nexthop neighbor to reach the destination node, the timestamp of the last
update received for that node.

The DSDV update message consists of three fields, Destination Address, Sequence Number and Hop Count.

Each node uses 2 mechanisms to send out the DSDV updates. They are,
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} \begin{description}
\item[{Periodic Updates}] \leavevmode
Periodic updates are sent out after every m\_periodicUpdateInterval(default:15s). In this update the node broadcasts
out its entire routing table.

\end{description}

\item {} \begin{description}
\item[{Trigger Updates}] \leavevmode
Trigger Updates are small updates in\sphinxhyphen{}between the periodic updates. These updates are sent out whenever a node
receives a DSDV packet that caused a change in its routing table. The original paper did not clearly mention
when for what change in the table should a DSDV update be sent out. The current implementation sends out an update
irrespective of the change in the routing table.

\end{description}

\end{enumerate}

The updates are accepted based on the metric for a particular node. The first factor determining the acceptance of
an update is the sequence number. It has to accept the update if the sequence number of the update message is higher
irrespective of the metric. If the update with same sequence number is received, then the update with least metric
(hopCount) is given precedence.

In highly mobile scenarios, there is a high chance of route fluctuations, thus we have the concept of weighted
settling time where an update with change in metric will not be advertised to neighbors. The node waits for
the settling time to make sure that it did not receive the update from its old neighbor before sending out
that update.

The current implementation covers all the above features of DSDV. The current implementation also has a request queue
to buffer packets that have no routes to destination. The default is set to buffer up to 5 packets per destination.


\section{References}
\label{\detokenize{dsdv:references}}
Link to the Paper: \sphinxurl{http://portal.acm.org/citation.cfm?doid=190314.190336}


\chapter{DSR Routing}
\label{\detokenize{dsr:dsr-routing}}\label{\detokenize{dsr::doc}}
Dynamic Source Routing (DSR) protocol is a reactive routing protocol designed specifically
for use in multi\sphinxhyphen{}hop wireless ad hoc networks of mobile nodes.

This model was developed by
\sphinxhref{http://www.ittc.ku.edu/resilinets}{the ResiliNets research group}
at the University of Kansas.


\section{DSR Routing Overview}
\label{\detokenize{dsr:dsr-routing-overview}}
This model implements the base specification of the Dynamic Source Routing
(DSR) protocol. Implementation is based on \index{RFC@\spxentry{RFC}!RFC 4728@\spxentry{RFC 4728}}\sphinxhref{https://tools.ietf.org/html/rfc4728.html}{\sphinxstylestrong{RFC 4728}}, with some extensions
and modifications to the RFC specifications.

DSR operates on a on\sphinxhyphen{}demand behavior. Therefore, our DSR model buffers all
packets while a route request packet (RREQ) is disseminated. We implement
a packet buffer in dsr\sphinxhyphen{}rsendbuff.cc. The packet queue implements
garbage collection of old packets and a queue size limit. When the packet
is sent out from the send buffer, it will be queued in maintenance buffer
for next hop acknowledgment.

The maintenance buffer then buffers the already sent out packets and waits
for the notification of packet delivery.  Protocol operation strongly
depends on broken link detection mechanism. We implement the three heuristics
recommended based the RFC as follows:

First, we use link layer feedback when possible, which is also the fastest
mechanism of these three to detect link errors. A link is considered to be
broken if frame transmission results in a transmission failure for all
retries. This mechanism is meant for active links and works much faster
than in its absence.  DSR is able to
detect the link layer transmission failure and notify that as broken.
Recalculation of routes will be triggered
when needed.  If user does not want to use link layer acknowledgment,
it can be tuned by setting “LinkAcknowledgment” attribute to false in
“dsr\sphinxhyphen{}routing.cc”.

Second, passive acknowledgment should be used whenever possible. The node
turns on “promiscuous” receive mode, in which it can receive packets not
destined for itself, and when the node assures the delivery of that data
packet to its destination, it cancels the passive acknowledgment timer.

Last, we use a network layer acknowledge scheme to notify the receipt of
a packet. Route request packet will not be acknowledged or retransmitted.

The Route Cache implementation support garbage collection of old entries
and state machine, as defined in the
standard.  It implements as a STL map container. The key is the
destination IP address.

DSR operates with direct access to IP header, and operates between network
and transport layer.  When packet is sent out from transport layer, it
passes itself to DSR and DSR header is appended.

We have two caching mechanisms: path cache and link cache.  The path cache
saves the whole path in the cache.  The paths are sorted based on the
hop count, and whenever one path is not able to be used, we change to the
next path.  The link cache is a slightly better design in the sense that it
uses different subpaths and uses Implemented Link Cache using
Dijkstra algorithm, and this part is implemented by
Song Luan \textless{}\sphinxhref{mailto:lsuper@mail.ustc.edu.cn}{lsuper@mail.ustc.edu.cn}\textgreater{}.

The following optional protocol optimizations aren’t implemented:
\begin{itemize}
\item {} 
Flow state

\item {} 
First Hop External (F), Last Hop External (L) flags

\item {} 
Handling unknown DSR options

\item {} \begin{description}
\item[{Two types of error headers:}] \leavevmode\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
flow state not supported option

\item {} 
unsupported option (not going to happen in simulation)

\end{enumerate}

\end{description}

\end{itemize}


\subsection{DSR update in ns\sphinxhyphen{}3.17}
\label{\detokenize{dsr:dsr-update-in-ns-3-17}}
We originally used “TxErrHeader” in Ptr\textless{}WifiMac\textgreater{} to indicate the transmission
error of a specific packet in link layer, however, it was not working
quite correctly since even when the packet was dropped, this header was
not recorded in the trace file.  We used to a different path on implementing
the link layer notification mechanism.  We look into the trace file by
finding packet receive event.  If we find one receive event for the
data packet, we count that as the indicator for successful data delivery.


\subsection{Useful parameters}
\label{\detokenize{dsr:useful-parameters}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{Parameter}                \PYG{o}{|} \PYG{n}{Description}                        \PYG{o}{|} \PYG{n}{Default}     \PYG{o}{|}
\PYG{o}{+}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{+}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{+}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{=}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{MaxSendBuffLen}           \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{number} \PYG{n}{of} \PYG{n}{packets} \PYG{n}{that} \PYG{n}{can} \PYG{o}{|} \PYG{l+m+mi}{64}          \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{n}{be} \PYG{n}{stored} \PYG{o+ow}{in} \PYG{n}{send} \PYG{n}{buffer}           \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{MaxSendBuffTime}          \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{time} \PYG{n}{packets} \PYG{n}{can} \PYG{n}{be} \PYG{n}{queued} \PYG{o}{|} \PYG{n}{Seconds}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)} \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{o+ow}{in} \PYG{n}{the} \PYG{n}{send} \PYG{n}{buffer}                 \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{MaxMaintLen}              \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{number} \PYG{n}{of} \PYG{n}{packets} \PYG{n}{that} \PYG{n}{can} \PYG{o}{|} \PYG{l+m+mi}{50}          \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{n}{be} \PYG{n}{stored} \PYG{o+ow}{in} \PYG{n}{maintenance} \PYG{n}{buffer}    \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{MaxMaintTime}             \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{time} \PYG{n}{packets} \PYG{n}{can} \PYG{n}{be} \PYG{n}{queued} \PYG{o}{|} \PYG{n}{Seconds}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)} \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{o+ow}{in} \PYG{n}{maintenance} \PYG{n}{buffer}              \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{MaxCacheLen}              \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{number} \PYG{n}{of} \PYG{n}{route} \PYG{n}{entries}    \PYG{o}{|} \PYG{l+m+mi}{64}          \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{n}{that} \PYG{n}{can} \PYG{n}{be} \PYG{n}{stored} \PYG{o+ow}{in} \PYG{n}{route} \PYG{n}{cache}  \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{RouteCacheTimeout}        \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{time} \PYG{n}{the} \PYG{n}{route} \PYG{n}{cache} \PYG{n}{can}   \PYG{o}{|} \PYG{n}{Seconds}\PYG{p}{(}\PYG{l+m+mi}{300}\PYG{p}{)}\PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{n}{be} \PYG{n}{queued} \PYG{o+ow}{in} \PYG{n}{route} \PYG{n}{cache}           \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{RreqRetries}              \PYG{o}{|} \PYG{n}{Maximum} \PYG{n}{number} \PYG{n}{of} \PYG{n}{retransmissions}  \PYG{o}{|} \PYG{l+m+mi}{16}          \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{k}{for} \PYG{n}{request} \PYG{n}{discovery} \PYG{n}{of} \PYG{n}{a} \PYG{n}{route}   \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{CacheType}                \PYG{o}{|} \PYG{n}{Use} \PYG{n}{Link} \PYG{n}{Cache} \PYG{o+ow}{or} \PYG{n}{use} \PYG{n}{Path} \PYG{n}{Cache}   \PYG{o}{|} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LinkCache}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|}                                    \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{|} \PYG{n}{LinkAcknowledgment}       \PYG{o}{|} \PYG{n}{Enable} \PYG{n}{Link} \PYG{n}{layer} \PYG{n}{acknowledgment}   \PYG{o}{|} \PYG{k+kc}{True}        \PYG{o}{|}
\PYG{o}{|}                          \PYG{o}{|} \PYG{n}{mechanism}                          \PYG{o}{|}             \PYG{o}{|}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\end{sphinxVerbatim}


\subsection{Implementation modification}
\label{\detokenize{dsr:implementation-modification}}\begin{itemize}
\item {} \begin{description}
\item[{The DsrFsHeader has added 3 fields: message type, source id, destination id, and these changes only for post\sphinxhyphen{}processing}] \leavevmode\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Message type is used to identify the data packet from control packet

\item {} 
source id is used to identify the real source of the data packet since we have to deliver the packet hop\sphinxhyphen{}by\sphinxhyphen{}hop and the Ipv4Header is not carrying the real source and destination ip address as needed

\item {} 
destination id is for same reason of above

\end{enumerate}

\end{description}

\item {} 
Route Reply header is not word\sphinxhyphen{}aligned in DSR RFC, change it to word\sphinxhyphen{}aligned in implementation

\item {} 
DSR works as a shim header between transport and network protocol, it needs its own forwarding mechanism, we are changing the packet transmission to hop\sphinxhyphen{}by\sphinxhyphen{}hop delivery, so we added two fields in dsr fixed header to notify packet delivery

\end{itemize}


\subsection{Current Route Cache implementation}
\label{\detokenize{dsr:current-route-cache-implementation}}
This implementation used “path cache”, which is simple to implement and ensures loop\sphinxhyphen{}free paths:
\begin{itemize}
\item {} 
the path cache has automatic expire policy

\item {} 
the cache saves multiple route entries for a certain destination and sort the entries based on hop counts

\item {} 
the MaxEntriesEachDst can be tuned to change the maximum entries saved for a single destination

\item {} 
when adding multiple routes for one destination, the route is compared based on hop\sphinxhyphen{}count and expire time, the one with less hop count or relatively new route is favored

\item {} 
Future implementation may include “link cache” as another possibility

\end{itemize}


\section{DSR Instructions}
\label{\detokenize{dsr:dsr-instructions}}
The following should be kept in mind when running DSR as routing protocol:
\begin{itemize}
\item {} 
NodeTraversalTime is the time it takes to traverse two neighboring nodes and should be chosen to fit the transmission range

\item {} 
PassiveAckTimeout is the time a packet in maintenance buffer wait for passive acknowledgment, normally set as two times of NodeTraversalTime

\item {} 
RouteCacheTimeout should be set smaller value when the nodes’ velocity become higher. The default value is 300s.

\end{itemize}


\section{Helper}
\label{\detokenize{dsr:helper}}
To have a node run DSR, the easiest way would be to use the DsrHelper
and DsrMainHelpers in your simulation script. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{DsrHelper} \PYG{n}{dsr}\PYG{p}{;}
\PYG{n}{DsrMainHelper} \PYG{n}{dsrMain}\PYG{p}{;}
\PYG{n}{dsrMain}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{dsr}\PYG{p}{,} \PYG{n}{adhocNodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The example scripts inside \sphinxcode{\sphinxupquote{src/dsr/examples/}} demonstrate the use of DSR based nodes in different scenarios.
The helper source can be found inside \sphinxcode{\sphinxupquote{src/dsr/helper/dsr\sphinxhyphen{}main\sphinxhyphen{}helper.\{h,cc\}}}
and \sphinxcode{\sphinxupquote{src/dsr/helper/dsr\sphinxhyphen{}helper.\{h,cc\}}}


\section{Examples}
\label{\detokenize{dsr:examples}}
The example can be found in \sphinxcode{\sphinxupquote{src/dsr/examples/}}:
\begin{itemize}
\item {} 
dsr.cc use DSR as routing protocol within a traditional MANETs environment{[}3{]}.

\end{itemize}

DSR is also built in the routing comparison case in \sphinxcode{\sphinxupquote{examples/routing/}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{manet\sphinxhyphen{}routing\sphinxhyphen{}compare.cc}} is a comparison case with built in MANET routing protocols and can generate its own results.

\end{itemize}


\section{Validation}
\label{\detokenize{dsr:validation}}
This model has been tested as follows:
\begin{itemize}
\item {} 
Unit tests have been written to verify the internals of DSR. This can be found in \sphinxcode{\sphinxupquote{src/dsr/test/dsr\sphinxhyphen{}test\sphinxhyphen{}suite.cc}}. These tests verify whether the methods inside DSR module which deal with packet buffer, headers work correctly.

\item {} 
Simulation cases similar to {[}3{]} have been tested and have comparable results.

\item {} 
manet\sphinxhyphen{}routing\sphinxhyphen{}compare.cc has been used to compare DSR with three of other routing protocols.

\end{itemize}

A paper was presented on these results at the Workshop on ns\sphinxhyphen{}3 in 2011.


\section{Limitations}
\label{\detokenize{dsr:limitations}}
The model is not fully compliant with \index{RFC@\spxentry{RFC}!RFC 4728@\spxentry{RFC 4728}}\sphinxhref{https://tools.ietf.org/html/rfc4728.html}{\sphinxstylestrong{RFC 4728}}. As an example, Dsr fixed size header
has been extended and it is four octets longer then the RFC specification.
As a consequence, the DSR headers can not be correctly decoded by Wireshark.

The model full compliance with the RFC is planned for the future.


\section{References}
\label{\detokenize{dsr:references}}
{[}1{]} Original paper: \sphinxurl{http://www.monarch.cs.rice.edu/monarch-papers/dsr-chapter00.pdf}

{[}2{]} RFC 4728 \sphinxurl{http://www6.ietf.org/rfc/rfc4728.txt}

{[}3{]} Broch’s comparison paper: \sphinxurl{http://www.monarch.cs.rice.edu/monarch-papers/mobicom98.ps}


\chapter{Emulation Overview}
\label{\detokenize{emulation-overview:emulation-overview}}\label{\detokenize{emulation-overview::doc}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} has been designed for integration into testbed and virtual machine
environments. We have addressed this need by providing two kinds of net devices.
The first kind of device is a file descriptor net device (\sphinxcode{\sphinxupquote{FdNetDevice}}),
which is a generic device type that can read and write from a file descriptor.
By associating this file descriptor with different things on the host
system, different capabilities can be provided.  For instance, the
FdNetDevice can be associated with an underlying packet socket to provide
emulation capabilities.  This allows \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulations
to send data on a “real” network. The second kind, called a \sphinxcode{\sphinxupquote{TapBridge}}
\sphinxcode{\sphinxupquote{NetDevice}} allows a “real” host to participate in an \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation as if
it were one of the simulated nodes. An \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation may be constructed with
any combination of simulated or emulated devices.

\sphinxstylestrong{Note:} Prior to ns\sphinxhyphen{}3.17, the emulation capability was provided by a
special device called an \sphinxcode{\sphinxupquote{Emu}} NetDevice; the \sphinxcode{\sphinxupquote{Emu}} NetDevice has
been replaced by the \sphinxcode{\sphinxupquote{FdNetDevice}}.

One of the use\sphinxhyphen{}cases we want to support is that of a testbed. A concrete example
of an environment of this kind is the ORBIT testbed. ORBIT is a laboratory
emulator/field trial network arranged as a two dimensional grid of 400 802.11
radio nodes. We integrate with ORBIT by using their “imaging” process to load
and run \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulations on the ORBIT array. We can use our
\sphinxcode{\sphinxupquote{EmuFdNetDevice}}
to drive the hardware in the testbed and we can accumulate results either using
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} tracing and logging functions, or the native ORBIT data gathering
techniques. See \sphinxurl{http://www.orbit-lab.org/} for details on the ORBIT
testbed.

A simulation of this kind is shown in the following figure:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{testbed}.pdf}
\caption{Example Implementation of Testbed Emulation.}\label{\detokenize{emulation-overview:id1}}\label{\detokenize{emulation-overview:testbed}}\end{figure}

You can see that there are separate hosts, each running a subset of a “global”
simulation. Instead of an \sphinxstyleemphasis{ns\sphinxhyphen{}3} channel connecting the hosts, we use real
hardware provided by the testbed. This allows \sphinxstyleemphasis{ns\sphinxhyphen{}3} applications and protocol
stacks attached to a simulation node to communicate over real hardware.

We expect the primary use for this configuration will be to generate repeatable
experimental results in a real\sphinxhyphen{}world network environment that includes all of
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} tracing, logging, visualization and statistics gathering tools.

In what can be viewed as essentially an inverse configuration, we allow “real”
machines running native applications and protocol stacks to integrate with an
\sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation. This allows for the simulation of large networks connected to
a real machine, and also enables virtualization. A simulation of this kind is
shown in the following figure:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{emulated-channel}.pdf}
\caption{Implementation overview of emulated channel.}\label{\detokenize{emulation-overview:id2}}\label{\detokenize{emulation-overview:emulated-channel}}\end{figure}

Here, you will see that there is a single host with a number of virtual machines
running on it. An \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation is shown running in the virtual machine shown
in the center of the figure. This simulation has a number of nodes with
associated \sphinxstyleemphasis{ns\sphinxhyphen{}3} applications and protocol stacks that are talking to an \sphinxstyleemphasis{ns\sphinxhyphen{}3}
channel through native simulated \sphinxstyleemphasis{ns\sphinxhyphen{}3} net devices.

There are also two virtual machines shown at the far left and far right of the
figure. These VMs are running native (Linux) applications and protocol stacks.
The VM is connected into the simulation by a Linux Tap net device. The user\sphinxhyphen{}mode
handler for the Tap device is instantiated in the simulation and attached to a
proxy node that represents the native VM in the simulation. These handlers allow
the Tap devices on the native VMs to behave as if they were \sphinxstyleemphasis{ns\sphinxhyphen{}3} net devices in
the simulation VM. This, in turn, allows the native software and protocol suites
in the native VMs to believe that they are connected to the simulated \sphinxstyleemphasis{ns\sphinxhyphen{}3}
channel.

We expect the typical use case for this environment will be to analyze the
behavior of native applications and protocol suites in the presence of large
simulated \sphinxstyleemphasis{ns\sphinxhyphen{}3} networks.

For more details:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{fd-net-device::doc}]{\sphinxcrossref{\DUrole{doc}{FdNetDevice}}}} chapter.

\item {} 
{\hyperref[\detokenize{tap::doc}]{\sphinxcrossref{\DUrole{doc}{TapBridge}}}} chapter.

\end{itemize}


\chapter{Energy Framework}
\label{\detokenize{energy:energy-framework}}\label{\detokenize{energy::doc}}
Energy consumption is a key issue for wireless devices, and wireless
network researchers often need to investigate the energy consumption
at a node or in the overall network while running network simulations
in ns\sphinxhyphen{}3. This requires ns\sphinxhyphen{}3 to support energy consumption
modeling. Further, as concepts such as fuel cells and energy
scavenging are becoming viable for low power wireless devices,
incorporating the effect of these emerging technologies into
simulations requires support for modeling diverse energy sources in
ns\sphinxhyphen{}3. The ns\sphinxhyphen{}3 Energy Framework provides the basis for energy
consumption, energy source and energy harvesting modeling.


\section{Model Description}
\label{\detokenize{energy:model-description}}
The source code for the Energy Framework is currently at: \sphinxcode{\sphinxupquote{src/energy}}.


\subsection{Design}
\label{\detokenize{energy:design}}
The ns\sphinxhyphen{}3 Energy Framework is composed of 3 parts: Energy Source,
Device Energy Model and Energy Harvester.  The framework is
implemented into the \sphinxcode{\sphinxupquote{src/energy/models}} folder.


\subsubsection{Energy Source}
\label{\detokenize{energy:energy-source}}
The Energy Source represents the power supply on each node. A node can
have one or more energy sources, and each energy source can be
connected to multiple device energy models. Connecting an energy
source to a device energy model implies that the corresponding device
draws power from the source. The basic functionality of the Energy
Source is to provide energy for devices on the node. When energy is
completely drained from the Energy Source, it notifies the devices on
node such that each device can react to this event. Further, each node
can access the Energy Source Objects for information such as remaining
energy or energy fraction (battery level). This enables the
implementation of energy aware protocols in ns\sphinxhyphen{}3.

In order to model a wide range of power supplies such as batteries,
the Energy Source must be able to capture characteristics of these
supplies. There are 2 important characteristics or effects related to
practical batteries:
\begin{description}
\item[{Rate Capacity Effect}] \leavevmode
Decrease of battery lifetime when the current draw is higher
than the rated value of the battery.

\item[{Recovery Effect}] \leavevmode
Increase of battery lifetime when the battery is alternating
between discharge and idle states.

\end{description}

In order to incorporate the Rate Capacity Effect, the Energy Source
uses current draw from all the devices on the same node to calculate
energy consumption. Moreover, multiple Energy Harvesters can be
connected to the Energy Source in order to replenish its energy. The
Energy Source periodically polls all the devices and energy harvesters
on the same node to calculate the total current drain and hence the
energy consumption. When a device changes state, its corresponding
Device Energy Model will notify the Energy Source of this change and
new total current draw will be calculated. Similarly, every Energy
Harvester update triggers an update to the connected Energy Source.

The Energy Source base class keeps a list of devices (Device Energy
Model objects) and energy harvesters (Energy Harvester objects) that
are using the particular Energy Source as power supply. When energy is
completely drained, the Energy Source will notify all devices on this
list. Each device can then handle this event independently, based on
the desired behavior that should be followed in case of power outage.


\subsubsection{Device Energy Model}
\label{\detokenize{energy:device-energy-model}}
The Device Energy Model is the energy consumption model of a device
installed on the node. It is designed to be a state based model where
each device is assumed to have a number of states, and each state is
associated with a power consumption value. Whenever the state of the
device changes, the corresponding Device Energy Model will notify the
Energy Source of the new current draw of the device. The Energy Source
will then calculate the new total current draw and update the
remaining energy.

The Device Energy Model can also be used for devices that do not have
finite number of states. For example, in an electric vehicle, the
current draw of the motor is determined by its speed. Since the
vehicle’s speed can take continuous values within a certain range, it
is infeasible to define a set of discrete states of
operation. However, by converting the speed value into current
directly, the same set of Device Energy Model APIs can still be used.


\subsubsection{Energy Harvester}
\label{\detokenize{energy:energy-harvester}}
The energy harvester represents the elements that harvest energy from
the environment and recharge the Energy Source to which it is
connected. The energy harvester includes the complete implementation
of the actual energy harvesting device (e.g., a solar panel) and the
environment (e.g., the solar radiation). This means that in
implementing an energy harvester, the energy contribution of the
environment and the additional energy requirements of the energy
harvesting device such as the conversion efficiency and the internal
power consumption of the device needs to be jointly modeled.


\subsubsection{WiFi Radio Energy Model}
\label{\detokenize{energy:wifi-radio-energy-model}}
The WiFi Radio Energy Model is the energy consumption model of a Wifi
net device. It provides a state for each of the available states of
the PHY layer: Idle, CcaBusy, Tx, Rx, ChannelSwitch, Sleep, Off. Each of
such states is associated with a value (in Ampere) of the current draw
(see below for the corresponding attribute names). A Wifi Radio Energy
Model PHY Listener is registered to the Wifi PHY in order to be
notified of every Wifi PHY state transition. At every transition, the
energy consumed in the previous state is computed and the energy
source is notified in order to update its remaining energy.

The Wifi Tx Current Model gives the possibility to compute the current
draw in the transmit state as a function of the nominal tx power (in
dBm), as observed in several experimental measurements. To this
purpose, the Wifi Radio Energy Model PHY Listener is notified of the
nominal tx power used to transmit the current frame and passes such a
value to the Wifi Tx Current Model which takes care of updating the
current draw in the Tx state. Hence, the energy consumption is
correctly computed even if the Wifi Remote Station Manager performs
per\sphinxhyphen{}frame power control. Currently, a Linear Wifi Tx Current Model is
implemented which computes the tx current as a linear function
(according to parameters that can be specified by the user) of the
nominal tx power in dBm.

The Wifi Radio Energy Model offers the possibility to specify a
callback that is invoked when the energy source is depleted. If such a
callback is not specified when the Wifi Radio Energy Model Helper is
used to install the model on a device, a callback is implicitly made
so that the Wifi PHY is put in the OFF mode (hence no frame is
transmitted nor received afterwards) when the energy source is
depleted. Likewise, it is possible to specify a callback that is
invoked when the energy source is recharged (which might occur in case
an energy harvester is connected to the energy source). If such a
callback is not specified when the Wifi Radio Energy Model Helper is
used to install the model on a device, a callback is implicitly made
so that the Wifi PHY is resumed from the OFF mode when the energy
source is recharged.


\subsection{Future Work}
\label{\detokenize{energy:future-work}}
For Device Energy Models, we are planning to include support for other
PHY layer models provided in ns\sphinxhyphen{}3 such as WiMAX, and to model the
energy consumptions of other non communicating devices, like a generic
sensor and a CPU. For Energy Sources, we are planning to included new
types of Energy Sources such as Supercapacitor and Nickel\sphinxhyphen{}Metal
Hydride (Ni\sphinxhyphen{}MH) battery. For the Energy Harvesters, we are planning to
implement an energy harvester that recharges the energy sources
according to the power levels defined in a user customizable dataset
of real measurements.


\subsection{References}
\label{\detokenize{energy:references}}

\section{Usage}
\label{\detokenize{energy:usage}}
The main way that ns\sphinxhyphen{}3 users will typically interact with the Energy
Framework is through the helper API and through the publicly visible
attributes of the framework. The helper API is defined in
\sphinxcode{\sphinxupquote{src/energy/helper/*.h}}.

In order to use the energy framework, the user must install an Energy
Source for the node of interest, the corresponding Device Energy Model
for the network devices and, if necessary, the one or more Energy
Harvester. Energy Source (objects) are aggregated onto each node by
the Energy Source Helper. In order to allow multiple energy sources
per node, we aggregate an Energy Source Container rather than directly
aggregating a source object.

The Energy Source object keeps a list of Device Energy Model and
Energy Harvester objects using the source as power supply. Device
Energy Model objects are installed onto the Energy Source by the
Device Energy Model Helper, while Energy Harvester object are
installed by the Energy Harvester Helper. User can access the Device
Energy Model objects through the Energy Source object to obtain energy
consumption information of individual devices. Moreover, the user can
access to the Energy Harvester objects in order to gather information
regarding the current harvestable power and the total energy harvested
by the harvester.


\subsection{Examples}
\label{\detokenize{energy:examples}}
The example directories, \sphinxcode{\sphinxupquote{src/examples/energy}} and
\sphinxcode{\sphinxupquote{examples/energy}}, contain some basic code that shows how to set up
the framework.


\subsection{Helpers}
\label{\detokenize{energy:helpers}}

\subsubsection{Energy Source Helper}
\label{\detokenize{energy:energy-source-helper}}
Base helper class for Energy Source objects, this helper Aggregates
Energy Source object onto a node. Child implementation of this class
creates the actual Energy Source object.


\subsubsection{Device Energy Model Helper}
\label{\detokenize{energy:device-energy-model-helper}}
Base helper class for Device Energy Model objects, this helper
attaches Device Energy Model objects onto Energy Source objects. Child
implementation of this class creates the actual Device Energy Model
object.


\subsubsection{Energy Harvesting Helper}
\label{\detokenize{energy:energy-harvesting-helper}}
Base helper class for Energy Harvester objects, this helper attaches
Energy Harvester objects onto Energy Source objects. Child
implementation of this class creates the actual Energy Harvester
object.


\subsection{Attributes}
\label{\detokenize{energy:attributes}}
Attributes differ between Energy Sources, Devices Energy Models and
Energy Harvesters implementations, please look at the specific child
class for details.


\subsubsection{Basic Energy Source}
\label{\detokenize{energy:basic-energy-source}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{BasicEnergySourceInitialEnergyJ}}: Initial energy stored in
basic energy source.

\item {} 
\sphinxcode{\sphinxupquote{BasicEnergySupplyVoltageV}}: Initial supply voltage for basic energy source.

\item {} 
\sphinxcode{\sphinxupquote{PeriodicEnergyUpdateInterval}}: Time between two consecutive periodic
energy updates.

\end{itemize}


\subsubsection{RV Battery Model}
\label{\detokenize{energy:rv-battery-model}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelPeriodicEnergyUpdateInterval}}: RV battery model sampling
interval.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelOpenCircuitVoltage}}: RV battery model open circuit voltage.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelCutoffVoltage}}: RV battery model cutoff voltage.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelAlphaValue}}: RV battery model alpha value.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelBetaValue}}: RV battery model beta value.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelNumOfTerms}}: The number of terms of the infinite sum for estimating battery level.

\end{itemize}


\subsubsection{WiFi Radio Energy Model}
\label{\detokenize{energy:id8}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{IdleCurrentA}}: The default radio Idle current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{CcaBusyCurrentA}}: The default radio CCA Busy State current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{TxCurrentA}}: The radio Tx current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{RxCurrentA}}: The radio Rx current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{SwitchingCurrentA}}: The default radio Channel Switch current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{SleepCurrentA}}: The radio Sleep current in Ampere.

\item {} 
\sphinxcode{\sphinxupquote{TxCurrentModel}}: A pointer to the attached tx current model.

\end{itemize}


\subsubsection{Basic Energy Harvester}
\label{\detokenize{energy:basic-energy-harvester}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{PeriodicHarvestedPowerUpdateInterval}}: Time between two consecutive
periodic updates of the harvested power.

\item {} 
\sphinxcode{\sphinxupquote{HarvestablePower}}: Random variables that represents the amount of power
that is provided by the energy harvester.

\end{itemize}


\subsection{Tracing}
\label{\detokenize{energy:tracing}}
Traced values differ between Energy Sources, Devices Energy Models and
Energy Harvesters implementations, please look at the specific child
class for details.


\subsubsection{Basic Energy Source}
\label{\detokenize{energy:id9}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{RemainingEnergy}}: Remaining energy at BasicEnergySource.

\end{itemize}


\subsubsection{RV Battery Model}
\label{\detokenize{energy:id10}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelBatteryLevel}}: RV battery model battery level.

\item {} 
\sphinxcode{\sphinxupquote{RvBatteryModelBatteryLifetime}}: RV battery model battery lifetime.

\end{itemize}


\subsubsection{WiFi Radio Energy Model}
\label{\detokenize{energy:id11}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{TotalEnergyConsumption}}: Total energy consumption of the radio device.

\end{itemize}


\subsubsection{Basic Energy Harvester}
\label{\detokenize{energy:id12}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{HarvestedPower}}: Current power provided by the BasicEnergyHarvester.

\item {} 
\sphinxcode{\sphinxupquote{TotalEnergyHarvested}}: Total energy harvested by the BasicEnergyHarvester.

\end{itemize}


\subsection{Validation}
\label{\detokenize{energy:validation}}
Comparison of the Energy Framework against actual devices have not
been performed. Current implementation of the Energy Framework is
checked numerically for computation errors. The RV battery model is
validated by comparing results with what was presented in the original
RV battery model paper.


\chapter{File Descriptor NetDevice}
\label{\detokenize{fd-net-device:file-descriptor-netdevice}}\label{\detokenize{fd-net-device::doc}}
The \sphinxcode{\sphinxupquote{src/fd\sphinxhyphen{}net\sphinxhyphen{}device}} module provides the \sphinxcode{\sphinxupquote{FdNetDevice}} class,
which is able to read and write traffic using a file descriptor
provided by the user.  This file descriptor can be associated to a TAP
device, to a raw socket, to a user space process generating/consuming
traffic, etc.
The user has full freedom to define how external traffic is generated
and \sphinxstyleemphasis{ns\sphinxhyphen{}3} traffic is consumed.

Different mechanisms to associate a simulation to external traffic can
be provided through helper classes.  Three specific helpers are provided:
\begin{itemize}
\item {} 
EmuFdNetDeviceHelper (to associate the \sphinxstyleemphasis{ns\sphinxhyphen{}3} device with a physical device
in the host machine)

\item {} 
TapFdNetDeviceHelper (to associate the ns\sphinxhyphen{}3 device with the file descriptor
from a tap device in the host machine)

\item {} 
PlanteLabFdNetDeviceHelper (to automate the creation of tap devices in
PlanetLab nodes, enabling \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulations that can send and receive
traffic though the Internet using PlanetLab resource.

\end{itemize}


\section{Model Description}
\label{\detokenize{fd-net-device:model-description}}
The source code for this module lives in the directory \sphinxcode{\sphinxupquote{src/fd\sphinxhyphen{}net\sphinxhyphen{}device}}.

The FdNetDevice is a special type of \sphinxstyleemphasis{ns\sphinxhyphen{}3} NetDevice that reads traffic
to and from a file descriptor.  That is, unlike pure simulation NetDevice
objects that write frames to and from a simulated channel, this FdNetDevice
directs frames out of the simulation to a file descriptor.  The file
descriptor may be associated to a Linux TUN/TAP device, to a socket, or
to a user\sphinxhyphen{}space process.

It is up to the user of this device to provide a file descriptor.  The
type of file descriptor being provided determines what is being
modelled.  For instance, if the file descriptor provides a raw socket
to a WiFi card on the host machine, the device being modelled is a
WiFi device.

From the conceptual “top” of the device looking down, it looks to the
simulated node like a device supporting a 48\sphinxhyphen{}bit IEEE MAC address that
can be bridged, supports broadcast, and uses IPv4 ARP or IPv6 Neighbor
Discovery, although these attributes can be tuned on a per\sphinxhyphen{}use\sphinxhyphen{}case basis.


\subsection{Design}
\label{\detokenize{fd-net-device:design}}
The FdNetDevice implementation makes use of a reader object,
extended from the \sphinxcode{\sphinxupquote{FdReader}} class in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} \sphinxcode{\sphinxupquote{src/core}} module,
which manages a separate thread from the main \sphinxstyleemphasis{ns\sphinxhyphen{}3} execution thread, in order
to read traffic from the file descriptor.

Upon invocation of the \sphinxcode{\sphinxupquote{StartDevice}} method, the reader object is initialized
and starts the reading thread.
Before device start, a file descriptor must be previously associated to the
FdNetDevice with the \sphinxcode{\sphinxupquote{SetFileDescriptor}} invocation.

The creation and configuration of the file descriptor can be left to a
number of helpers, described in more detail below. When this is done, the
invocation of \sphinxcode{\sphinxupquote{SetFileDescriptor}} is responsibility of
the helper and must not be directly invoked by the user.

Upon reading an incoming frame from the file descriptor, the reader
will pass the frame to the \sphinxcode{\sphinxupquote{ReceiveCallback}} method, whose
task it is to schedule the reception of the frame by the device as a
\sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation event. Since the new frame is passed from the reader
thread to the main \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation thread, thread\sphinxhyphen{}safety issues
are avoided by using the \sphinxcode{\sphinxupquote{ScheduleWithContext}} call instead of the
regular \sphinxcode{\sphinxupquote{Schedule}} call.

In order to avoid overwhelming the scheduler when the incoming data rate
is too high, a counter is kept with the number of frames that are currently
scheduled to be received by the device. If this counter reaches the value
given by the \sphinxcode{\sphinxupquote{RxQueueSize}} attribute in the device, then the new frame will
be dropped silently.

The actual reception of the new frame by the device occurs when the
scheduled \sphinxcode{\sphinxupquote{FordwarUp}} method is invoked by the simulator.
This method acts as if a new frame had arrived from a channel attached
to the device. The device then decapsulates the frame, removing any layer 2
headers, and forwards it to upper network stack layers of the node.
The \sphinxcode{\sphinxupquote{ForwardUp}} method will remove the frame headers,
according to the frame encapsulation type defined by the \sphinxcode{\sphinxupquote{EncapsulationMode}}
attribute, and invoke the receive callback passing an IP packet.

An extra header, the PI header, can be present when the file descriptor is
associated to a TAP device that was created without setting the IFF\_NO\_PI flag.
This extra header is removed if \sphinxcode{\sphinxupquote{EncapsulationMode}} is set to DIXPI value.

In the opposite direction, packets generated inside the simulation that are
sent out through the device, will be passed to the \sphinxcode{\sphinxupquote{Send}} method, which
will in turn invoke the \sphinxcode{\sphinxupquote{SendFrom}} method. The latter method will add the
necessary layer 2 headers, and simply write the newly created frame to the
file descriptor.


\subsection{Scope and Limitations}
\label{\detokenize{fd-net-device:scope-and-limitations}}
Users of this device are cautioned that there is no flow control
across the file descriptor boundary, when using in emulation mode.
That is, in a Linux system, if the speed of writing network packets
exceeds the ability of the underlying physical device to buffer the
packets, backpressure up to the writing application will be applied
to avoid local packet loss.  No such flow control is provided across
the file descriptor interface, so users must be aware of this limitation.

As explained before, the RxQueueSize attribute limits the number of packets
that can be pending to be received by the device.
Frames read from the file descriptor while the number of pending packets is
in its maximum will be silently dropped.

The mtu of the device defaults to the Ethernet II MTU value. However, helpers
are supposed to set the mtu to the right value to reflect the characteristics
of the network interface associated to the file descriptor.
If no helper is used, then the responsibility of setting the correct mtu value
for the device falls back to the user.
The size of the read buffer on the file descriptor reader is set to the
mtu value in the \sphinxcode{\sphinxupquote{StartDevice}} method.

The FdNetDevice class currently supports three encapsulation modes,
DIX for Ethernet II frames, LLC for 802.2 LLC/SNAP frames,
and DIXPI for Ethernet II frames with an additional TAP PI header.
This means that traffic traversing the file descriptor is expected to be
Ethernet II compatible.  IEEE 802.1q (VLAN) tagging is not supported.
Attaching an FdNetDevice to a wireless interface is possible as long as the
driver provides Ethernet II frames to the socket API.
Note that to associate a FdNetDevice to a wireless card in ad\sphinxhyphen{}hoc mode,
the MAC address of the device must be set to the real card MAC address, else
any incoming traffic a fake MAC address will be discarded by the driver.

As mentioned before, three helpers are provided with the fd\sphinxhyphen{}net\sphinxhyphen{}device module.
Each individual helper (file descriptor type) may have platform
limitations.  For instance, threading, real\sphinxhyphen{}time simulation mode, and the
ability to create TUN/TAP devices are prerequisites to using the
provided helpers.  Support for these modes can be found in the output
of the \sphinxcode{\sphinxupquote{waf configure}} step, e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Threading Primitives          : enabled
Real Time Simulator           : enabled
Emulated Net Device           : enabled
Tap Bridge                    : enabled
\end{sphinxVerbatim}

It is important to mention that while testing the \sphinxcode{\sphinxupquote{FdNetDevice}} we have found
an upper bound limit for TCP throughput when using 1Gb Ethernet links of 60Mbps.
This limit is most likely due to the processing power of the computers involved
in the tests.


\section{Usage}
\label{\detokenize{fd-net-device:usage}}
The usage pattern for this type of device is similar to other net devices
with helpers that install to node pointers or node containers.
When using the base \sphinxcode{\sphinxupquote{FdNetDeviceHelper}} the user is responsible for
creating and setting the file descriptor by himself.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{FdNetDeviceHelper} \PYG{n}{fd}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices} \PYG{o}{=} \PYG{n}{fd}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{nodes}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// file descriptor generation}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}

\PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetFileDescriptor} \PYG{p}{(}\PYG{n}{fd}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Most commonly a FdNetDevice will be used to interact with the host system.
In these cases it is almost certain that the user will want to run in real\sphinxhyphen{}time
emulation mode, and to enable checksum computations.
The typical program statements are as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GlobalValue}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Bind} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{SimulatorImplementationType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RealtimeSimulatorImpl}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{GlobalValue}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Bind} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ChecksumEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The easiest way to set up an experiment that interacts with a Linux host
system is to user the \sphinxcode{\sphinxupquote{Emu}} and \sphinxcode{\sphinxupquote{Tap}} helpers.
Perhaps the most unusual part of these helper implementations
relates to the requirement for executing some of the code with super\sphinxhyphen{}user
permissions. Rather than force the user to execute the entire simulation as
root, we provide a small “creator” program that runs as root and does any
required high\sphinxhyphen{}permission sockets work. The easiest way to set the right
privileges for the “creator” programs, is by enabling the \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}sudo}}
flag when performing \sphinxcode{\sphinxupquote{waf configure}}.

We do a similar thing for both the \sphinxcode{\sphinxupquote{Emu}} and the \sphinxcode{\sphinxupquote{Tap}} devices.  The
high\sphinxhyphen{}level view is that the \sphinxcode{\sphinxupquote{CreateFileDescriptor}} method creates a local interprocess
(Unix) socket, forks, and executes the small creation program. The small
program, which runs as suid root, creates a raw socket and sends back the raw
socket file descriptor over the Unix socket that is passed to it as a parameter.
The raw socket is passed as a control message (sometimes called ancillary data)
of type SCM\_RIGHTS.


\subsection{Helpers}
\label{\detokenize{fd-net-device:helpers}}

\subsubsection{EmuFdNetDeviceHelper}
\label{\detokenize{fd-net-device:emufdnetdevicehelper}}
The EmuFdNetDeviceHelper creates a raw socket to an underlying physical
device, and provides the socket descriptor to the FdNetDevice.  This
allows the \sphinxstyleemphasis{ns\sphinxhyphen{}3} simulation to read frames from and write frames to
a network device on the host.

The emulation helper permits to transparently integrate a simulated
\sphinxstyleemphasis{ns\sphinxhyphen{}3} node into a network composed of real nodes.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|         host 1       |     |         host 2        |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|    ns\PYGZhy{}3 simulation   |     |                       |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     |         Linux         |
|       ns\PYGZhy{}3 Node      |     |     Network Stack     |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |     |   +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|  |    ns\PYGZhy{}3 TCP    |  |     |   |       TCP      |  |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |     |   +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|  |    ns\PYGZhy{}3 IP     |  |     |   |       IP       |  |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |     |   +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|  |   FdNetDevice  |  |     |   |                |  |
|  |    10.1.1.1    |  |     |   |                |  |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |     |   +    ETHERNET    +  |
|  |   raw socket   |  |     |   |                |  |
|\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}|     |   +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|       | eth0 |       |     |        | eth0 |       |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+

        10.1.1.11                     10.1.1.12

            |                            |
            +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
\end{sphinxVerbatim}

This helper replaces the functionality of the \sphinxcode{\sphinxupquote{EmuNetDevice}} found in
\sphinxstyleemphasis{ns\sphinxhyphen{}3} prior to ns\sphinxhyphen{}3.17, by bringing this type of device into the common
framework of the FdNetDevice.  The \sphinxcode{\sphinxupquote{EmuNetDevice}} was deprecated
in favor of this new helper.

The device is configured to perform
MAC spoofing to separate simulation network traffic from other
network traffic that may be flowing to and from the host.

One can use this helper in a testbed situation where the host on
which the simulation is running has a specific interface of interest which
drives the testbed hardware. You would also need to set this specific interface
into promiscuous mode and provide an appropriate device name to the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
simulation.  Additionally, hardware offloading of segmentation and checksums
should be disabled.

The helper only works if the underlying interface is up and in
promiscuous mode. Packets will be sent out over the device, but we use MAC
spoofing. The MAC addresses will be generated (by default) using the
Organizationally Unique Identifier (OUI) 00:00:00 as a base. This vendor code
is not assigned to any organization and so should not conflict with any real
hardware.

It is always up to the user to determine that using these MAC addresses is okay
on your network and won’t conflict with anything else (including another
simulation using such devices) on your network. If you are using the emulated
FdNetDevice configuration in separate simulations,
you must consider global MAC address
assignment issues and ensure that MAC addresses are unique across all
simulations. The emulated net device respects the MAC address provided in the
\sphinxcode{\sphinxupquote{Address}} attribute so you can do this manually. For larger simulations, you
may want to set the OUI in the MAC address allocation function.

Before invoking the \sphinxcode{\sphinxupquote{Install}} method, the correct device name must be configured
on the helper using the \sphinxcode{\sphinxupquote{SetDeviceName}} method. The device name is required to
identify which physical device should be used to open the raw socket.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EmuFdNetDeviceHelper} \PYG{n}{emu}\PYG{p}{;}
\PYG{n}{emu}\PYG{p}{.}\PYG{n}{SetDeviceName} \PYG{p}{(}\PYG{n}{deviceName}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices} \PYG{o}{=} \PYG{n}{emu}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{device} \PYG{o}{=} \PYG{n}{devices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Address}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Mac48AddressValue} \PYG{p}{(}\PYG{n}{Mac48Address}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Allocate} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{TapFdNetDeviceHelper}
\label{\detokenize{fd-net-device:tapfdnetdevicehelper}}
A Tap device is a special type of Linux device for which one end of the
device appears to the kernel as a virtual net\_device, and the other
end is provided as a file descriptor to user\sphinxhyphen{}space.  This file descriptor
can be passed to the FdNetDevice.  Packets forwarded to the TAP device
by the kernel will show up in the FdNetDevice in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

Users should note that this usage of TAP devices is different than that
provided by the TapBridge NetDevice found in \sphinxcode{\sphinxupquote{src/tap\sphinxhyphen{}bridge}}.
The model in this helper is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|                host                 |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|    ns\PYGZhy{}3 simulation   |              |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+              |
|      ns\PYGZhy{}3 Node       |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |    ns\PYGZhy{}3 TCP    |  |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |    ns\PYGZhy{}3 IP     |  |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |   FdNetDevice  |  |              |
|\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}+    +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|       | TAP  |            | eth0 |  |
|       +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+            +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|     192.168.0.1               |     |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                |
                                |
                                \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} (Internet) \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}

In the above, the configuration requires that the host be able to forward
traffic generated by the simulation to the Internet.

The model in TapBridge (in another module) is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|  Linux |
|  host  |                    +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   ghost  |
|  apps  |                    |   node   |
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
|  stack |                    |    IP    |     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   stack  |     |   node   |
|  TAP   |                    |==========|     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
| device | \PYGZlt{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} IPC \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} |   tap    |     |    IP    |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                    |  bridge  |     |   stack  |
                              | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
                              |   ns\PYGZhy{}3   |     |   ns\PYGZhy{}3   |
                              |   net    |     |   net    |
                              |  device  |     |  device  |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                   ||               ||
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                              |        ns\PYGZhy{}3 channel       |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
\end{sphinxVerbatim}

In the above, packets instead traverse \sphinxstyleemphasis{ns\sphinxhyphen{}3} NetDevices and Channels.

The usage pattern for this example is that the user sets the
MAC address and either (or both) the IPv4 and IPv6 addresses and masks
on the device, and the PI header if needed.  For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TapFdNetDeviceHelper} \PYG{n}{helper}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetDeviceName} \PYG{p}{(}\PYG{n}{deviceName}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetModePi} \PYG{p}{(}\PYG{n}{modePi}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetTapIpv4Address} \PYG{p}{(}\PYG{n}{tapIp}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetTapIpv4Mask} \PYG{p}{(}\PYG{n}{tapMask}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{PlanetLabFdNetDeviceHelper}
\label{\detokenize{fd-net-device:planetlabfdnetdevicehelper}}
PlanetLab is a world wide distributed network testbed composed of
nodes connected to the Internet.
Running ns\sphinxhyphen{}3 simulations in PlanetLab nodes using the
PlanetLabFdNetDeviceHelper allows to send simulated traffic generated by
ns\sphinxhyphen{}3 directly to the Internet. This setup can be useful to validate
ns\sphinxhyphen{}3 Internet protocols or other future protocols implemented in ns\sphinxhyphen{}3.

To run experiments using PlanetLab nodes it is required to have a
PlanetLab account.
Only members of PlanetLab partner institutions can obtain such accounts
( for more information visit \sphinxurl{http://www.planet-lab.org/} or
\sphinxurl{http://www.planet-lab.eu} ).
Once the account is obtained, a PlanetLab \sphinxtitleref{slice} must be requested in
order to conduct experiments.
A slice represents an experiment unit related to a group of PlanetLab users,
and can be associated to virtual machines in different PlanetLab nodes.
Slices can also be customized by adding configuration tags to it
(this is done by PlanetLab administrators).

The PlanetLabFdNetDeviceHelper creates TAP devices on PlanetLab nodes
using specific PlanetLab mechanisms (i.e. the vsys system), and
associates the TAP device to a FdNetDevice in ns\sphinxhyphen{}3.
The functionality provided by this helper is similar to that provided
by the FdTapNetDeviceHelper, except that the underlying mechanisms
to create the TAP device are different.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|         PlanetLab  host             |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|    ns\PYGZhy{}3 simulation   |              |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+              |
|       ns\PYGZhy{}3 Node      |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |    ns\PYGZhy{}3 TCP    |  |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |    ns\PYGZhy{}3 IP     |  |              |
|  +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |              |
|  |   FdNetDevice  |  |              |
|\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}+    +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|       | TAP  |            | eth0 |  |
|       +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+            +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+  |
|     192.168.0.1               |     |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                |
                                |
                                \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} (Internet) \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}

In order to be able to assign private IPv4 addresses to the TAP devices,
account holders must request the \sphinxtitleref{vsys\_vnet} tag to be added to their slice
by PlanetLab administrators.
The vsys\_vnet tag is associated to private network segment and only addresses
from this segment can be used in experiments.

The syntax used to create a TAP device with this helper is similar to that
used for the previously described helpers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{PlanetLabFdNetDeviceHelper} \PYG{n}{helper}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetTapIpAddress} \PYG{p}{(}\PYG{n}{tapIp}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{SetTapMask} \PYG{p}{(}\PYG{n}{tapMask}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\PYG{n}{helper}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

PlanetLab nodes have a Fedora based distribution, so ns\sphinxhyphen{}3 can be installed
following the instructions for ns\sphinxhyphen{}3 Linux installation.


\subsection{Attributes}
\label{\detokenize{fd-net-device:attributes}}
The \sphinxcode{\sphinxupquote{FdNetDevice}} provides a number of attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Address}}:  The MAC address of the device

\item {} 
\sphinxcode{\sphinxupquote{Start}}:  The simulation start time to spin up the device thread

\item {} 
\sphinxcode{\sphinxupquote{Stop}}:  The simulation start time to stop the device thread

\item {} 
\sphinxcode{\sphinxupquote{EncapsulationMode}}:  Link\sphinxhyphen{}layer encapsulation format

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{RxQueueSize}}:  The buffer size of the read queue on the file descriptor}] \leavevmode
thread (default of 1000 packets)

\end{description}

\end{itemize}

\sphinxcode{\sphinxupquote{Start}} and \sphinxcode{\sphinxupquote{Stop}} do not normally need to be specified unless the
user wants to limit the time during which this device is active.
\sphinxcode{\sphinxupquote{Address}} needs to be set to some kind of unique MAC address if the
simulation will be interacting with other real devices somehow using
real MAC addresses.  Typical code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Address}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Mac48AddressValue} \PYG{p}{(}\PYG{n}{Mac48Address}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Allocate} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Output}
\label{\detokenize{fd-net-device:output}}
Ascii and PCAP tracing is provided similar to the other \sphinxstyleemphasis{ns\sphinxhyphen{}3} NetDevice
types, through the helpers, such as (e.g.):
\begin{description}
\item[{::}] \leavevmode
EmuFdNetDeviceHelper emu;
NetDeviceContainer devices = emu.Install (node);
…
emu.EnablePcap (“emu\sphinxhyphen{}ping”, device, true);

\end{description}

The standard set of Mac\sphinxhyphen{}level NetDevice trace sources is provided.
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxTx}}:  Trace source triggered when \sphinxstyleemphasis{ns\sphinxhyphen{}3} provides the device with a
new frame to send

\item {} 
\sphinxcode{\sphinxupquote{MaxTxDrop}}:  Trace source if write to file descriptor fails

\item {} 
\sphinxcode{\sphinxupquote{MaxPromiscRx}}:  Whenever any valid Mac frame is received

\item {} 
\sphinxcode{\sphinxupquote{MaxRx}}:  Whenever a valid Mac frame is received for this device

\item {} 
\sphinxcode{\sphinxupquote{Sniffer}}:  Non\sphinxhyphen{}promiscuous packet sniffer

\item {} 
\sphinxcode{\sphinxupquote{PromiscSniffer}}:  Promiscuous packet sniffer (for tcpdump\sphinxhyphen{}like traces)

\end{itemize}


\subsection{Examples}
\label{\detokenize{fd-net-device:examples}}
Several examples are provided:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{dummy\sphinxhyphen{}network.cc}}:  This simple example creates two nodes and
interconnects them with a Unix pipe by passing the file descriptors
from the socketpair into the FdNetDevice objects of the respective nodes.

\item {} 
\sphinxcode{\sphinxupquote{realtime\sphinxhyphen{}dummy\sphinxhyphen{}network.cc}}:  Same as dummy\sphinxhyphen{}network.cc but uses the real time
simulator implementnation instead of the default one.

\item {} 
\sphinxcode{\sphinxupquote{fd2fd\sphinxhyphen{}onoff.cc}}: This example is aimed at measuring the throughput of the
FdNetDevice in a pure simulation. For this purpose two FdNetDevices, attached to
different nodes but in a same simulation, are connected using a socket pair.
TCP traffic is sent at a saturating data rate.

\item {} 
\sphinxcode{\sphinxupquote{fd\sphinxhyphen{}emu\sphinxhyphen{}onoff.cc}}: This example is aimed at measuring the throughput of the
FdNetDevice  when using the EmuFdNetDeviceHelper to attach the simulated
device to a real device in the host machine. This is achieved by saturating
the channel with TCP traffic.

\item {} 
\sphinxcode{\sphinxupquote{fd\sphinxhyphen{}emu\sphinxhyphen{}ping.cc}}: This example uses the EmuFdNetDeviceHelper to send ICMP
traffic over a real channel.

\item {} 
\sphinxcode{\sphinxupquote{fd\sphinxhyphen{}emu\sphinxhyphen{}udp\sphinxhyphen{}echo.cc}}: This example uses the EmuFdNetDeviceHelper to send UDP
traffic over a real channel.

\item {} 
\sphinxcode{\sphinxupquote{fd\sphinxhyphen{}planetlab\sphinxhyphen{}ping.cc}}: This example shows how to set up an experiment to send
ICMP traffic from a PlanetLab node to the Internet.

\item {} 
\sphinxcode{\sphinxupquote{fd\sphinxhyphen{}tap\sphinxhyphen{}ping.cc}}: This example uses the TapFdNetDeviceHelper to send ICMP
traffic over a real channel.

\end{itemize}


\chapter{Flow Monitor}
\label{\detokenize{flow-monitor:flow-monitor}}\label{\detokenize{flow-monitor::doc}}

\section{Model Description}
\label{\detokenize{flow-monitor:model-description}}
The source code for the new module lives in the directory \sphinxcode{\sphinxupquote{src/flow\sphinxhyphen{}monitor}}.

The Flow Monitor module goal is to provide a flexible system to measure the
performance of network protocols. The module uses probes, installed in network
nodes, to track the packets exchanged by the nodes, and it will measure
a number of parameters. Packets are divided according to the flow they belong
to, where each flow is defined according to the probe’s characteristics (e.g.,
for IP, a flow is defined as the packets with the same \{protocol, source (IP, port),
destination (IP, port)\} tuple.

The statistics are collected for each flow can be exported in XML format. Moreover,
the user can access the probes directly to request specific stats about each flow.


\subsection{Design}
\label{\detokenize{flow-monitor:design}}
Flow Monitor module is designed in a modular way. It can be extended by subclassing
\sphinxcode{\sphinxupquote{ns3::FlowProbe}} and \sphinxcode{\sphinxupquote{ns3::FlowClassifier}}.
Typically, a subclass of \sphinxcode{\sphinxupquote{ns3::FlowProbe}} works by listening to the appropriate
class Traces, and then uses its own \sphinxcode{\sphinxupquote{ns3::FlowClassifier}} subclass to classify
the packets passing though each node.

Each Probe can try to listen to other classes traces (e.g., \sphinxcode{\sphinxupquote{ns3::Ipv4FlowProbe}}
will try to use any \sphinxcode{\sphinxupquote{ns3::NetDevice}} trace named \sphinxcode{\sphinxupquote{TxQueue/Drop}}) but this
is something that the user should not rely into blindly, because the trace is not
guaranteed to be in every type of \sphinxcode{\sphinxupquote{ns3::NetDevice}}. As an example,
\sphinxcode{\sphinxupquote{CsmaNetDevice}} and \sphinxcode{\sphinxupquote{PointToPointNetDevice}} have a \sphinxcode{\sphinxupquote{TxQueue/Drop}} trace, while
\sphinxcode{\sphinxupquote{WiFiNetDevice}} does not.

The full module design is described in \sphinxcite{flow-monitor:flowmonitor}


\subsection{Scope and Limitations}
\label{\detokenize{flow-monitor:scope-and-limitations}}
At the moment, probes and classifiers are available only for IPv4 and IPv6.

IPv4 and IPv6 probes will classify packets in four points:
\begin{itemize}
\item {} 
When a packet is sent (SendOutgoing IPv{[}4,6{]} traces)

\item {} 
When a packet is forwarded (UnicastForward IPv{[}4,6{]} traces)

\item {} 
When a packet is received (LocalDeliver IPv{[}4,6{]} traces)

\item {} 
When a packet is dropped (Drop IPv{[}4,6{]} traces)

\end{itemize}

Since the packets are tracked at IP level, any retransmission caused by L4 protocols (e.g., TCP)
will be seen by the probe as a new packet.

A Tag will be added to the packet (\sphinxcode{\sphinxupquote{ns3::Ipv{[}4,6{]}FlowProbeTag}}). The tag will carry
basic packet’s data, useful for the packet’s classification.

It must be underlined that only L4 (TCP, UDP) packets are, so far, classified.
Moreover, only unicast packets will be classified.
These limitations may be removed in the future.

The data collected for each flow are:
\begin{itemize}
\item {} 
timeFirstTxPacket: when the first packet in the flow was transmitted;

\item {} 
timeLastTxPacket: when the last packet in the flow was transmitted;

\item {} 
timeFirstRxPacket: when the first packet in the flow was received by an end node;

\item {} 
timeLastRxPacket: when the last packet in the flow was received;

\item {} 
delaySum: the sum of all end\sphinxhyphen{}to\sphinxhyphen{}end delays for all received packets of the flow;

\item {} 
jitterSum: the sum of all end\sphinxhyphen{}to\sphinxhyphen{}end delay jitter (delay variation) values for all received packets of the flow, as defined in \index{RFC@\spxentry{RFC}!RFC 3393@\spxentry{RFC 3393}}\sphinxhref{https://tools.ietf.org/html/rfc3393.html}{\sphinxstylestrong{RFC 3393}};

\item {} 
txBytes, txPackets: total number of transmitted bytes / packets for the flow;

\item {} 
rxBytes, rxPackets: total number of received bytes / packets for the flow;

\item {} 
lostPackets: total number of packets that are assumed to be lost (not reported over 10 seconds);

\item {} 
timesForwarded: the number of times a packet has been reportedly forwarded;

\item {} 
delayHistogram, jitterHistogram, packetSizeHistogram: histogram versions for the delay, jitter, and packet sizes, respectively;

\item {} 
packetsDropped, bytesDropped: the number of lost packets and bytes, divided according to the loss reason code (defined in the probe).

\end{itemize}

It is worth pointing out that the probes measure the packet bytes including IP headers.
The L2 headers are not included in the measure.

These stats will be written in XML form upon request (see the Usage section).


\subsubsection{The “lost” packets problem}
\label{\detokenize{flow-monitor:the-lost-packets-problem}}
At the end of a simulation, Flow Monitor could report about “lost” packets, i.e.,
packets that Flow Monitor have lost track of.

It is important to keep in mind that Flow Monitor records the packets statistics by
intercepting them at a given network level \sphinxhyphen{} let’s say at IP level. When the simulation
ends, any packet queued for transmission below the IP level will be considered as lost.

It is strongly suggested to consider this point when using Flow Monitor. The user can choose to:
\begin{itemize}
\item {} 
Ignore the lost packets (if their number is a statistically irrelevant quantity), or

\item {} 
Stop the Applications before the actual Simulation End time, leaving enough time between the two for the queued packets to be processed.

\end{itemize}

The second method is the suggested one. Usually a few seconds are enough (the
exact value depends on the network type).

It is important to stress that “lost” packets could be anywhere in the network, and could count
toward the received packets or the dropped ones. Ideally, their number should be zero or a minimal
fraction of the other ones, i.e., they should be “statistically irrelevant”.


\subsection{References}
\label{\detokenize{flow-monitor:references}}

\section{Usage}
\label{\detokenize{flow-monitor:usage}}
The module usage is extremely simple. The helper will take care of about everything.

The typical use is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Flow monitor}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{FlowMonitor}\PYG{o}{\PYGZgt{}} \PYG{n}{flowMonitor}\PYG{p}{;}
\PYG{n}{FlowMonitorHelper} \PYG{n}{flowHelper}\PYG{p}{;}
\PYG{n}{flowMonitor} \PYG{o}{=} \PYG{n}{flowHelper}\PYG{p}{.}\PYG{n}{InstallAll}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}

\PYG{o}{\PYGZhy{}}\PYG{n}{yourApplicationsContainer}\PYG{o}{\PYGZhy{}}\PYG{p}{.}\PYG{n}{Stop} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{n}{stop\PYGZus{}time}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Stop} \PYG{p}{(}\PYG{n}{Seconds}\PYG{p}{(}\PYG{n}{stop\PYGZus{}time}\PYG{o}{+}\PYG{n}{cleanup\PYGZus{}time}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Run} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{flowMonitor}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SerializeToXmlFile}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{NameOfFile.xml}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

the \sphinxcode{\sphinxupquote{SerializeToXmlFile ()}} function 2nd and 3rd parameters are used respectively to
activate/deactivate the histograms and the per\sphinxhyphen{}probe detailed stats.
Other possible alternatives can be found in the Doxygen documentation, while
\sphinxcode{\sphinxupquote{cleanup\_time}} is the time needed by in\sphinxhyphen{}flight packets to reach their destinations.


\subsection{Helpers}
\label{\detokenize{flow-monitor:helpers}}
The helper API follows the pattern usage of normal helpers.
Through the helper you can install the monitor in the nodes, set the monitor attributes, and
print the statistics.

One important thing is: the \sphinxcode{\sphinxupquote{ns3::FlowMonitorHelper}} must be instantiated only
once in the main.


\subsection{Attributes}
\label{\detokenize{flow-monitor:attributes}}
The module provides the following attributes in \sphinxcode{\sphinxupquote{ns3::FlowMonitor}}:
\begin{itemize}
\item {} 
MaxPerHopDelay (Time, default 10s): The maximum per\sphinxhyphen{}hop delay that should be considered;

\item {} 
StartTime (Time, default 0s): The time when the monitoring starts;

\item {} 
DelayBinWidth (double, default 0.001): The width used in the delay histogram;

\item {} 
JitterBinWidth (double, default 0.001): The width used in the jitter histogram;

\item {} 
PacketSizeBinWidth (double, default 20.0): The width used in the packetSize histogram;

\item {} 
FlowInterruptionsBinWidth (double, default 0.25): The width used in the flowInterruptions histogram;

\item {} 
FlowInterruptionsMinTime (double, default 0.5): The minimum inter\sphinxhyphen{}arrival time that is considered a flow interruption.

\end{itemize}


\subsection{Output}
\label{\detokenize{flow-monitor:output}}
The main model output is an XML formatted report about flow statistics. An example is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZlt{}}\PYG{o}{?}\PYG{n}{xml} \PYG{n}{version}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1.0}\PYG{l+s}{\PYGZdq{}} \PYG{o}{?}\PYG{o}{\PYGZgt{}}
\PYG{o}{\PYGZlt{}}\PYG{n}{FlowMonitor}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{FlowStats}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{Flow} \PYG{n}{flowId}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{timeFirstTxPacket}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+0.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{timeFirstRxPacket}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+20067198.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{timeLastTxPacket}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+2235764408.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{timeLastRxPacket}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+2255831606.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{delaySum}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+138731526300.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{jitterSum}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+1849692150.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{lastDelay}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+20067198.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{n}{txBytes}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2149400}\PYG{l+s}{\PYGZdq{}} \PYG{n}{rxBytes}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2149400}\PYG{l+s}{\PYGZdq{}} \PYG{n}{txPackets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3735}\PYG{l+s}{\PYGZdq{}} \PYG{n}{rxPackets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3735}\PYG{l+s}{\PYGZdq{}} \PYG{n}{lostPackets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}} \PYG{n}{timesForwarded}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7466}\PYG{l+s}{\PYGZdq{}}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{Flow}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowStats}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4FlowClassifier}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{Flow} \PYG{n}{flowId}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{sourceAddress}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10.1.3.1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{destinationAddress}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10.1.2.2}\PYG{l+s}{\PYGZdq{}} \PYG{n}{protocol}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6}\PYG{l+s}{\PYGZdq{}} \PYG{n}{sourcePort}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{49153}\PYG{l+s}{\PYGZdq{}} \PYG{n}{destinationPort}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{50000}\PYG{l+s}{\PYGZdq{}} \PYG{o}{/}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{Ipv4FlowClassifier}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6FlowClassifier}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{Ipv6FlowClassifier}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{FlowProbes}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{FlowProbe} \PYG{n}{index}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}}\PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{n}{FlowStats}  \PYG{n}{flowId}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{packets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3735}\PYG{l+s}{\PYGZdq{}} \PYG{n}{bytes}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2149400}\PYG{l+s}{\PYGZdq{}} \PYG{n}{delayFromFirstProbeSum}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+0.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowStats}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowProbe}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{FlowProbe} \PYG{n}{index}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2}\PYG{l+s}{\PYGZdq{}}\PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{n}{FlowStats}  \PYG{n}{flowId}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{packets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7466}\PYG{l+s}{\PYGZdq{}} \PYG{n}{bytes}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2224020}\PYG{l+s}{\PYGZdq{}} \PYG{n}{delayFromFirstProbeSum}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+199415389258.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowStats}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowProbe}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{n}{FlowProbe} \PYG{n}{index}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4}\PYG{l+s}{\PYGZdq{}}\PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{n}{FlowStats}  \PYG{n}{flowId}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}} \PYG{n}{packets}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3735}\PYG{l+s}{\PYGZdq{}} \PYG{n}{bytes}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2149400}\PYG{l+s}{\PYGZdq{}} \PYG{n}{delayFromFirstProbeSum}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{+138731526300.0ns}\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZgt{}}
    \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowStats}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowProbe}\PYG{o}{\PYGZgt{}}
  \PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowProbes}\PYG{o}{\PYGZgt{}}
\PYG{o}{\PYGZlt{}}\PYG{o}{/}\PYG{n}{FlowMonitor}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

The output was generated by a TCP flow from 10.1.3.1 to 10.1.2.2.

It is worth noticing that the index 2 probe is reporting more packets and more bytes than the other probes.
That’s a perfectly normal behaviour, as packets are fragmented at IP level in that node.

It should also be observed that the receiving node’s probe (index 4) doesn’t count the fragments, as the
reassembly is done before the probing point.


\subsection{Examples}
\label{\detokenize{flow-monitor:examples}}
The examples are located in \sphinxtitleref{src/flow\sphinxhyphen{}monitor/examples}.

Moreover, the following examples use the flow\sphinxhyphen{}monitor module:
\begin{itemize}
\item {} 
examples/matrix\sphinxhyphen{}topology/matrix\sphinxhyphen{}topology.cc

\item {} 
examples/routing/manet\sphinxhyphen{}routing\sphinxhyphen{}compare.cc

\item {} 
examples/routing/simple\sphinxhyphen{}global\sphinxhyphen{}routing.cc

\item {} 
examples/tcp/tcp\sphinxhyphen{}variants\sphinxhyphen{}comparison.cc

\item {} 
examples/wireless/multirate.cc

\item {} 
examples/wireless/wifi\sphinxhyphen{}hidden\sphinxhyphen{}terminal.cc

\end{itemize}


\subsection{Troubleshooting}
\label{\detokenize{flow-monitor:troubleshooting}}
Do not define more than one \sphinxcode{\sphinxupquote{ns3::FlowMonitorHelper}} in the simulation.


\section{Validation}
\label{\detokenize{flow-monitor:validation}}
The paper in the references contains a full description of the module validation against
a test network.

Tests are provided to ensure the Histogram correct functionality.


\chapter{Internet Models (IP, TCP, Routing, UDP, Internet Applications)}
\label{\detokenize{internet-models:internet-models-ip-tcp-routing-udp-internet-applications}}\label{\detokenize{internet-models::doc}}

\section{Internet Stack}
\label{\detokenize{internet-stack:internet-stack}}\label{\detokenize{internet-stack::doc}}

\subsection{Internet stack aggregation}
\label{\detokenize{internet-stack:internet-stack-aggregation}}
A bare class \sphinxcode{\sphinxupquote{Node}} is not very useful as\sphinxhyphen{}is; other objects must be
aggregated to it to provide useful node functionality.

The \sphinxstyleemphasis{ns\sphinxhyphen{}3} source code directory \sphinxcode{\sphinxupquote{src/internet}} provides implementation
of TCP/IPv4\sphinxhyphen{} and IPv6\sphinxhyphen{}related components. These include IPv4, ARP, UDP, TCP,
IPv6, Neighbor Discovery, and other related protocols.

Internet Nodes are not subclasses of class Node; they are simply Nodes that have
had a bunch of IP\sphinxhyphen{}related objects aggregated to them. They can be put together
by hand, or via a helper function \sphinxcode{\sphinxupquote{InternetStackHelper::Install ()}}
which does the following to all nodes passed in as arguments:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{InternetStackHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node}\PYG{p}{)} \PYG{k}{const}
\PYG{p}{\PYGZob{}}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}ipv4Enabled}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{c+cm}{/* IPv4 stack */}
      \PYG{k}{if} \PYG{p}{(}\PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)} \PYG{o}{!}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}
        \PYG{p}{\PYGZob{}}
          \PYG{n}{NS\PYGZus{}FATAL\PYGZus{}ERROR} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{InternetStackHelper::Install (): Aggregating }\PYG{l+s}{\PYGZdq{}}
                          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{an InternetStack to a node with an existing Ipv4 object}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
          \PYG{k}{return}\PYG{p}{;}
        \PYG{p}{\PYGZcb{}}

      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ArpL3Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::Ipv4L3Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::Icmpv4L4Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{c+c1}{// Set routing}
      \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv4} \PYG{o}{=} \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4RoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv4Routing} \PYG{o}{=} \PYG{n}{m\PYGZus{}routing}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Create} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{ipv4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetRoutingProtocol} \PYG{p}{(}\PYG{n}{ipv4Routing}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}

  \PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}ipv6Enabled}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{c+cm}{/* IPv6 stack */}
      \PYG{k}{if} \PYG{p}{(}\PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)} \PYG{o}{!}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}
        \PYG{p}{\PYGZob{}}
          \PYG{n}{NS\PYGZus{}FATAL\PYGZus{}ERROR} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{InternetStackHelper::Install (): Aggregating }\PYG{l+s}{\PYGZdq{}}
                          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{an InternetStack to a node with an existing Ipv6 object}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
          \PYG{k}{return}\PYG{p}{;}
        \PYG{p}{\PYGZcb{}}

      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::Ipv6L3Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::Icmpv6L4Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{c+c1}{// Set routing}
      \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv6} \PYG{o}{=} \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6RoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv6Routing} \PYG{o}{=} \PYG{n}{m\PYGZus{}routingv6}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Create} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{ipv6}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetRoutingProtocol} \PYG{p}{(}\PYG{n}{ipv6Routing}\PYG{p}{)}\PYG{p}{;}

      \PYG{c+cm}{/* register IPv6 extensions and options */}
      \PYG{n}{ipv6}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{RegisterExtensions} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{ipv6}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{RegisterOptions} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}

  \PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}ipv4Enabled} \PYG{o}{|}\PYG{o}{|} \PYG{n}{m\PYGZus{}ipv6Enabled}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{c+cm}{/* UDP and TCP stacks */}
      \PYG{n}{CreateAndAggregateObjectFromTypeId} \PYG{p}{(}\PYG{n}{node}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::UdpL4Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AggregateObject} \PYG{p}{(}\PYG{n}{m\PYGZus{}tcpFactory}\PYG{p}{.}\PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Object}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{PacketSocketFactory}\PYG{o}{\PYGZgt{}} \PYG{n}{factory} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{PacketSocketFactory}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AggregateObject} \PYG{p}{(}\PYG{n}{factory}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Where multiple implementations exist in \sphinxstyleemphasis{ns\sphinxhyphen{}3} (TCP, IP routing), these objects
are added by a factory object (TCP) or by a routing helper (m\_routing).

Note that the routing protocol is configured and set outside this
function. By default, the following protocols are added:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{InternetStackHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Initialize} \PYG{p}{(}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{SetTcp} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpL4Protocol}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{Ipv4StaticRoutingHelper} \PYG{n}{staticRouting}\PYG{p}{;}
  \PYG{n}{Ipv4GlobalRoutingHelper} \PYG{n}{globalRouting}\PYG{p}{;}
  \PYG{n}{Ipv4ListRoutingHelper} \PYG{n}{listRouting}\PYG{p}{;}
  \PYG{n}{Ipv6ListRoutingHelper} \PYG{n}{listRoutingv6}\PYG{p}{;}
  \PYG{n}{Ipv6StaticRoutingHelper} \PYG{n}{staticRoutingv6}\PYG{p}{;}
  \PYG{n}{listRouting}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{staticRouting}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{listRouting}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{globalRouting}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{listRoutingv6}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{staticRoutingv6}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetRoutingHelper} \PYG{p}{(}\PYG{n}{listRouting}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetRoutingHelper} \PYG{p}{(}\PYG{n}{listRoutingv6}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

By default, IPv4 and IPv6 are enabled.


\subsubsection{Internet Node structure}
\label{\detokenize{internet-stack:internet-node-structure}}
An IP\sphinxhyphen{}capable Node (an \sphinxstyleemphasis{ns\sphinxhyphen{}3} Node augmented by aggregation to have one or more
IP stacks) has the following internal structure.


\paragraph{Layer\sphinxhyphen{}3 protocols}
\label{\detokenize{internet-stack:layer-3-protocols}}
At the lowest layer, sitting above the NetDevices, are the “layer 3” protocols,
including IPv4, IPv6, ARP and so on. The class
\sphinxcode{\sphinxupquote{Ipv4L3Protocol}} is an implementation class whose public interface is
typically class \sphinxcode{\sphinxupquote{Ipv4}}, but the
Ipv4L3Protocol public API is also used internally at present.

In class Ipv4L3Protocol, one method described below is \sphinxcode{\sphinxupquote{Receive ()}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{  * Lower layer calls this method after calling L3Demux::Lookup}
\PYG{c+cm}{  * The ARP subclass needs to know from which NetDevice this}
\PYG{c+cm}{  * packet is coming to:}
\PYG{c+cm}{  *    \PYGZhy{} implement a per\PYGZhy{}NetDevice ARP cache}
\PYG{c+cm}{  *    \PYGZhy{} send back arp replies on the right device}
\PYG{c+cm}{  */}
\PYG{k+kt}{void} \PYG{n+nf}{Receive}\PYG{p}{(} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{device}\PYG{p}{,} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{p}\PYG{p}{,} \PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{protocol}\PYG{p}{,}
\PYG{k}{const} \PYG{n}{Address} \PYG{o}{\PYGZam{}}\PYG{n}{from}\PYG{p}{,} \PYG{k}{const} \PYG{n}{Address} \PYG{o}{\PYGZam{}}\PYG{n}{to}\PYG{p}{,} \PYG{n}{NetDevice}\PYG{o}{:}\PYG{o}{:}\PYG{n}{PacketType} \PYG{n}{packetType}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

First, note that the \sphinxcode{\sphinxupquote{Receive ()}} function has a matching signature to the
ReceiveCallback in the class \sphinxcode{\sphinxupquote{Node}}. This function pointer is
inserted into the Node’s protocol handler when \sphinxcode{\sphinxupquote{AddInterface ()}} is called.
The actual registration is done
with a statement such as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{RegisterProtocolHandler} \PYG{p}{(} \PYG{n}{MakeCallback} \PYG{p}{(}\PYG{o}{\PYGZam{}}\PYG{n}{Ipv4Protocol}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Receive}\PYG{p}{,} \PYG{n}{ipv4}\PYG{p}{)}\PYG{p}{,}
                          \PYG{n}{Ipv4L3Protocol}\PYG{o}{:}\PYG{o}{:}\PYG{n}{PROT\PYGZus{}NUMBER}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The Ipv4L3Protocol object is aggregated to the Node; there is only one such
Ipv4L3Protocol object. Higher\sphinxhyphen{}layer protocols that have a packet to send down to
the Ipv4L3Protocol object can call \sphinxcode{\sphinxupquote{GetObject\textless{}Ipv4L3Protocol\textgreater{} ()}} to obtain a
pointer, as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4L3Protocol}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv4} \PYG{o}{=} \PYG{n}{m\PYGZus{}node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4L3Protocol}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{if} \PYG{p}{(}\PYG{n}{ipv4} \PYG{o}{!}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{ipv4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Send} \PYG{p}{(}\PYG{n}{packet}\PYG{p}{,} \PYG{n}{saddr}\PYG{p}{,} \PYG{n}{daddr}\PYG{p}{,} \PYG{n}{PROT\PYGZus{}NUMBER}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

This class nicely demonstrates two techniques we exploit in \sphinxstyleemphasis{ns\sphinxhyphen{}3} to bind
objects together:  callbacks, and object aggregation.

Once IPv4 routing has determined that a packet is for the local node, it
forwards it up the stack.  This is done with the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{Ipv4L3Protocol}\PYG{o}{:}\PYG{o}{:}\PYG{n}{LocalDeliver} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{packet}\PYG{p}{,} \PYG{n}{Ipv4Header} \PYG{k}{const}\PYG{o}{\PYGZam{}}\PYG{n}{ip}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{iif}\PYG{p}{)}
\end{sphinxVerbatim}

The first step is to find the right Ipv4L4Protocol object, based on IP protocol
number. For instance, TCP is registered in the demux as protocol number 6.
Finally, the \sphinxcode{\sphinxupquote{Receive()}} function on the Ipv4L4Protocol (such as
\sphinxcode{\sphinxupquote{TcpL4Protocol::Receive}} is called.

We have not yet introduced the class Ipv4Interface. Basically, each NetDevice is
paired with an IPv4 representation of such device. In Linux, this class
\sphinxcode{\sphinxupquote{Ipv4Interface}} roughly corresponds to the \sphinxcode{\sphinxupquote{struct in\_device}}; the
main purpose is to provide address\sphinxhyphen{}family specific information (addresses) about
an interface.

All the classes have appropriate traces in order to track sent, received and lost packets.
The users is encouraged to use them so to find out if (and where) a packet is dropped. A
common mistake is to forget the effects of local queues when sending packets, e.g., the ARP
queue. This can be particularly puzzling when sending jumbo packets or packet bursts using UDP.
The ARP cache pending queue is limited (3 datagrams) and IP packets might be fragmented, easily
overfilling the ARP cache queue size. In those cases it is useful to increase the ARP cache
pending size to a proper value, e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ArpCache::PendingQueueSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{n}{MAX\PYGZus{}BURST\PYGZus{}SIZE}\PYG{o}{/}\PYG{n}{L2MTU}\PYG{o}{*}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The IPv6 implementation follows a similar architecture.  Dual\sphinxhyphen{}stacked nodes (one with
support for both IPv4 and IPv6) will allow an IPv6 socket to receive IPv4 connections
as a standard dual\sphinxhyphen{}stacked system does.  A socket bound and listening to an IPv6 endpoint
can receive an IPv4 connection and will return the remote address as an IPv4\sphinxhyphen{}mapped address.
Support for the IPV6\_V6ONLY socket option does not currently exist.


\paragraph{Layer\sphinxhyphen{}4 protocols and sockets}
\label{\detokenize{internet-stack:layer-4-protocols-and-sockets}}
We next describe how the transport protocols, sockets, and applications tie
together. In summary, each transport protocol implementation is a socket
factory. An application that needs a new socket

For instance, to create a UDP socket, an application would use a code snippet
such as the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{n}{udpSocketFactory} \PYG{o}{=} \PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{m\PYGZus{}socket} \PYG{o}{=} \PYG{n}{socketFactory}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Bind} \PYG{p}{(}\PYG{n}{m\PYGZus{}local\PYGZus{}address}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\end{sphinxVerbatim}

The above will query the node to get a pointer to its UDP socket factory, will
create one such socket, and will use the socket with an API similar to the
C\sphinxhyphen{}based sockets API, such as \sphinxcode{\sphinxupquote{Connect ()}} and \sphinxcode{\sphinxupquote{Send ()}}.  The address passed
to the \sphinxcode{\sphinxupquote{Bind ()}}, \sphinxcode{\sphinxupquote{Connect ()}}, or \sphinxcode{\sphinxupquote{Send ()}} functions may be a
\sphinxcode{\sphinxupquote{Ipv4Address}}, \sphinxcode{\sphinxupquote{Ipv6Address}}, or \sphinxcode{\sphinxupquote{Address}}.
If a \sphinxcode{\sphinxupquote{Address}} is passed in and contains anything other than
a \sphinxcode{\sphinxupquote{Ipv4Address}} or \sphinxcode{\sphinxupquote{Ipv6Address}}, these functions will
return an error.  The \sphinxcode{\sphinxupquote{Bind (void)}} and \sphinxcode{\sphinxupquote{Bind6 (void)}} functions bind to
“0.0.0.0” and “::” respectively.

The socket can also be bound to a specific NetDevice though the
\sphinxcode{\sphinxupquote{BindToNetDevice (Ptr\textless{}NetDevice\textgreater{} netdevice)}} function.
\sphinxcode{\sphinxupquote{BindToNetDevice (Ptr\textless{}NetDevice\textgreater{} netdevice)}} will bind the socket
to “0.0.0.0” and “::” (equivalent to calling \sphinxcode{\sphinxupquote{Bind ()}} and \sphinxcode{\sphinxupquote{Bind6 ()}},
unless the socket has been already bound to a specific address.
Summarizing, the correct sequence is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{n}{udpSocketFactory} \PYG{o}{=} \PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
 \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{m\PYGZus{}socket} \PYG{o}{=} \PYG{n}{socketFactory}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
 \PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{BindToNetDevice} \PYG{p}{(}\PYG{n}{n\PYGZus{}netDevice}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\end{sphinxVerbatim}

or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{n}{udpSocketFactory} \PYG{o}{=} \PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{m\PYGZus{}socket} \PYG{o}{=} \PYG{n}{socketFactory}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Bind} \PYG{p}{(}\PYG{n}{m\PYGZus{}local\PYGZus{}address}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{BindToNetDevice} \PYG{p}{(}\PYG{n}{n\PYGZus{}netDevice}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\end{sphinxVerbatim}

The following raises an error:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{n}{udpSocketFactory} \PYG{o}{=} \PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Udp}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{m\PYGZus{}socket} \PYG{o}{=} \PYG{n}{socketFactory}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{BindToNetDevice} \PYG{p}{(}\PYG{n}{n\PYGZus{}netDevice}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Bind} \PYG{p}{(}\PYG{n}{m\PYGZus{}local\PYGZus{}address}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\end{sphinxVerbatim}

See the chapter on \sphinxstyleemphasis{ns\sphinxhyphen{}3} sockets for more information.

We have described so far a socket factory (e.g. \sphinxcode{\sphinxupquote{class Udp}}) and a socket,
which may be specialized (e.g., class \sphinxcode{\sphinxupquote{UdpSocket}}).  There are a few
more key objects that relate to the specialized task of demultiplexing a packet
to one or more receiving sockets.  The key object in this task is class
\sphinxcode{\sphinxupquote{Ipv4EndPointDemux}}.  This demultiplexer stores objects of class
\sphinxcode{\sphinxupquote{Ipv4EndPoint}}.  This class holds the addressing/port tuple (local
port, local address, destination port, destination address) associated with the
socket, and a receive callback. This receive callback has a receive function
registered by the socket. The \sphinxcode{\sphinxupquote{Lookup ()}} function to Ipv4EndPointDemux
returns a list of Ipv4EndPoint objects (there may be a list since more than one
socket may match the packet). The layer\sphinxhyphen{}4 protocol copies the packet to each
Ipv4EndPoint and calls its \sphinxcode{\sphinxupquote{ForwardUp ()}} method, which then calls the
\sphinxcode{\sphinxupquote{Receive ()}} function registered by the socket.

An issue that arises when working with the sockets API on real
systems is the need to manage the reading from a socket, using
some type of I/O (e.g., blocking, non\sphinxhyphen{}blocking, asynchronous, …).
\sphinxstyleemphasis{ns\sphinxhyphen{}3} implements an asynchronous model for socket I/O; the application
sets a callback to be notified of received data ready to be read, and the
callback is invoked by the transport protocol when data is available.
This callback is specified as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{Socket}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetRecvCallback} \PYG{p}{(}\PYG{n}{Callback}\PYG{o}{\PYGZlt{}}\PYG{k+kt}{void}\PYG{p}{,} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}}\PYG{p}{,}
                              \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{Address}\PYG{o}{\PYGZam{}}\PYG{o}{\PYGZgt{}} \PYG{n}{receivedData}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The data being received is conveyed in the Packet data buffer.  An example
usage is in class \sphinxcode{\sphinxupquote{PacketSink}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m\PYGZus{}socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetRecvCallback} \PYG{p}{(}\PYG{n}{MakeCallback}\PYG{p}{(}\PYG{o}{\PYGZam{}}\PYG{n}{PacketSink}\PYG{o}{:}\PYG{o}{:}\PYG{n}{HandleRead}\PYG{p}{,} \PYG{k}{this}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

To summarize, internally, the UDP implementation is organized as follows:
\begin{itemize}
\item {} 
a \sphinxcode{\sphinxupquote{UdpImpl}} class that implements the UDP socket factory functionality

\item {} 
a \sphinxcode{\sphinxupquote{UdpL4Protocol}} class that implements the protocol logic that is
socket\sphinxhyphen{}independent

\item {} 
a \sphinxcode{\sphinxupquote{UdpSocketImpl}} class that implements socket\sphinxhyphen{}specific aspects of UDP

\item {} 
a class called \sphinxcode{\sphinxupquote{Ipv4EndPoint}} that stores the addressing tuple (local port,
local address, destination port, destination address) associated with the
socket, and a receive callback for the socket.

\end{itemize}


\subsubsection{IP\sphinxhyphen{}capable node interfaces}
\label{\detokenize{internet-stack:ip-capable-node-interfaces}}
Many of the implementation details, or internal objects themselves, of
IP\sphinxhyphen{}capable Node objects are not exposed at the simulator public API. This
allows for different implementations; for instance, replacing the native \sphinxstyleemphasis{ns\sphinxhyphen{}3}
models with ported TCP/IP stack code.

The C++ public APIs of all of these objects is found in the \sphinxcode{\sphinxupquote{src/network}}
directory, including principally:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{address.h}}

\item {} 
\sphinxcode{\sphinxupquote{socket.h}}

\item {} 
\sphinxcode{\sphinxupquote{node.h}}

\item {} 
\sphinxcode{\sphinxupquote{packet.h}}

\end{itemize}

These are typically base class objects that implement the default values used in
the implementation, implement access methods to get/set state variables, host
attributes, and implement publicly\sphinxhyphen{}available methods exposed to clients such as
\sphinxcode{\sphinxupquote{CreateSocket}}.


\subsubsection{Example path of a packet}
\label{\detokenize{internet-stack:example-path-of-a-packet}}
These two figures show an example stack trace of how packets flow through the
Internet Node objects.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{internet-node-send}.pdf}
\caption{Send path of a packet.}\label{\detokenize{internet-stack:id1}}\label{\detokenize{internet-stack:internet-node-send}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{internet-node-recv}.pdf}
\caption{Receive path of a packet.}\label{\detokenize{internet-stack:id2}}\label{\detokenize{internet-stack:internet-node-recv}}\end{figure}


\section{IPv4}
\label{\detokenize{ipv4:ipv4}}\label{\detokenize{ipv4::doc}}
This chapter describes the \sphinxstyleemphasis{ns\sphinxhyphen{}3} IPv4 address assignment and basic components tracking.


\subsection{IPv4 addresses assignment}
\label{\detokenize{ipv4:ipv4-addresses-assignment}}
In order to use IPv4 on a network, the first thing to do is assigning IPv4 addresses.

Any IPv4\sphinxhyphen{}enabled \sphinxstyleemphasis{ns\sphinxhyphen{}3} node will have at least one NetDevice: the \sphinxcode{\sphinxupquote{ns3::LoopbackNetDevice}}.
The loopback device address is \sphinxcode{\sphinxupquote{127.0.0.1}}.
All the other NetDevices will have one (or more) IPv4 addresses.

Note that, as today, \sphinxstyleemphasis{ns\sphinxhyphen{}3} does not have a NAT module, and it does not follows the rules about
filtering private addresses (\index{RFC@\spxentry{RFC}!RFC 1918@\spxentry{RFC 1918}}\sphinxhref{https://tools.ietf.org/html/rfc1918.html}{\sphinxstylestrong{RFC 1918}}): 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16.
These addresses are routed as any other address. This behaviour could change in the future.

IPv4 global addresses can be:
\begin{itemize}
\item {} 
manually assigned

\item {} 
assigned though DHCP

\end{itemize}

\sphinxstyleemphasis{ns\sphinxhyphen{}3} can use both methods, and it’s quite important to understand the implications of both.


\subsubsection{Manually assigned IPv4 addresses}
\label{\detokenize{ipv4:manually-assigned-ipv4-addresses}}
This is probably the easiest and most used method. As an example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n0} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n1} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n+nf}{net} \PYG{p}{(}\PYG{n}{n0}\PYG{p}{,} \PYG{n}{n1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{ndc} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{net}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Assign IPv4 Addresses.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv4AddressHelper} \PYG{n}{ipv4}\PYG{p}{;}
\PYG{n}{ipv4}\PYG{p}{.}\PYG{n}{SetBase} \PYG{p}{(}\PYG{n}{Ipv4Address} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{192.168.1.0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{NetMask} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/24}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv4InterfaceContainer} \PYG{n}{ic} \PYG{o}{=} \PYG{n}{ipv4}\PYG{p}{.}\PYG{n}{Assign} \PYG{p}{(}\PYG{n}{ndc}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This method will add two global IPv4 addresses to the nodes.

Note that the addresses are assigned in sequence. As a consequence, the first Node / NetDevice
will have “192.168.1.1”, the second “192.168.1.2” and so on.

It is possible to repeat the above to assign more than one address to a node.
However, due to the \sphinxcode{\sphinxupquote{Ipv4AddressHelper}} singleton nature, one should first assign all the
addresses of a network, then change the network base (\sphinxcode{\sphinxupquote{SetBase}}), then do a new assignment.

Alternatively, it is possible to assign a specific address to a node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n0} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n+nf}{net} \PYG{p}{(}\PYG{n}{n0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{ndc} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{net}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Specifically Assign an IPv4 Address.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv4AddressHelper} \PYG{n}{ipv4}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{device} \PYG{o}{=} \PYG{n}{ndc}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node} \PYG{o}{=} \PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv4proto} \PYG{o}{=} \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{int32\PYGZus{}t} \PYG{n}{ifIndex} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;}
\PYG{n}{ifIndex} \PYG{o}{=} \PYG{n}{ipv4proto}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetInterfaceForDevice} \PYG{p}{(}\PYG{n}{device}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv4InterfaceAddress} \PYG{n}{ipv4Addr} \PYG{o}{=} \PYG{n}{Ipv4InterfaceAddress} \PYG{p}{(}\PYG{n}{Ipv4Address} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{192.168.1.42}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{NetMask} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/24}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ipv4proto}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddAddress} \PYG{p}{(}\PYG{n}{ifIndex}\PYG{p}{,} \PYG{n}{ipv4Addr}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{DHCP assigned IPv4 addresses}
\label{\detokenize{ipv4:dhcp-assigned-ipv4-addresses}}
DHCP is available in the internet\sphinxhyphen{}apps module. In order to use DHCP you have to have a
\sphinxcode{\sphinxupquote{DhcpServer}} application in a node (the DHC server node) and a \sphinxcode{\sphinxupquote{DhcpClient}} application in
each of the nodes. Note that it not necessary that all the nodes in a subnet use DHCP. Some
nodes can have static addresses.

All the DHCP setup is performed though the \sphinxcode{\sphinxupquote{DhcpHelper}}  class. A complete example is in
\sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps/examples/dhcp\sphinxhyphen{}example.cc}}.

Further info about the DHCP functionalities can be found in the \sphinxcode{\sphinxupquote{internet\sphinxhyphen{}apps}} model documentation.


\subsection{Tracing in the IPv4 Stack}
\label{\detokenize{ipv4:tracing-in-the-ipv4-stack}}
The internet stack provides a number of trace sources in its various
protocol implementations.  These trace sources can be hooked using your own
custom trace code, or you can use our helper functions in some cases to
arrange for tracing to be enabled.


\subsubsection{Tracing in ARP}
\label{\detokenize{ipv4:tracing-in-arp}}
ARP provides two trace hooks, one in the cache, and one in the layer three
protocol.  The trace accessor in the cache is given the name “Drop.”  When
a packet is transmitted over an interface that requires ARP, it is first
queued for transmission in the ARP cache until the required MAC address is
resolved.  There are a number of retries that may be done trying to get the
address, and if the maximum retry count is exceeded the packet in question
is dropped by ARP.  The single trace hook in the ARP cache is called,
\begin{itemize}
\item {} 
If an outbound packet is placed in the ARP cache pending address resolution
and no resolution can be made within the maximum retry count, the outbound
packet is dropped and this trace is fired;

\end{itemize}

A second trace hook lives in the ARP L3 protocol (also named “Drop”) and may
be called for a  number of reasons.
\begin{itemize}
\item {} 
If an ARP reply is received for an entry that is not waiting for a reply,
the ARP reply packet is dropped and this trace is fired;

\item {} 
If an ARP reply is received for a non\sphinxhyphen{}existent entry, the ARP reply packet
is dropped and this trace is fired;

\item {} 
If an ARP cache entry is in the DEAD state (has timed out) and an ARP reply
packet is received, the reply packet is dropped and this trace is fired.

\item {} 
Each ARP cache entry has a queue of pending packets.  If the size of the
queue is exceeded, the outbound packet is dropped and this trace is fired.

\end{itemize}


\subsubsection{Tracing in IPv4}
\label{\detokenize{ipv4:tracing-in-ipv4}}
The IPv4 layer three protocol provides three trace hooks.  These are the
“Tx” (ns3::Ipv4L3Protocol::m\_txTrace), “Rx” (ns3::Ipv4L3Protocol::m\_rxTrace)
and “Drop” (ns3::Ipv4L3Protocol::m\_dropTrace) trace sources.

The “Tx” trace is fired in a number of situations, all of which indicate that
a given packet is about to be sent down to a given ns3::Ipv4Interface.
\begin{itemize}
\item {} 
In the case of a packet destined for the broadcast address, the
Ipv4InterfaceList is iterated and for every interface that is up and can
fragment the packet or has a large enough MTU to transmit the packet,
the trace is hit.  See ns3::Ipv4L3Protocol::Send.

\item {} 
In the case of a packet that needs routing, the “Tx” trace may be fired
just before a packet is sent to the interface appropriate to the default
gateway.  See ns3::Ipv4L3Protocol::SendRealOut.

\item {} 
Also in the case of a packet that needs routing, the “Tx” trace may be
fired just before a packet is sent to the outgoing interface appropriate
to the discovered route.  See ns3::Ipv4L3Protocol::SendRealOut.

\end{itemize}

The “Rx” trace is fired when a packet is passed from the device up to the
ns3::Ipv4L3Protocol::Receive function.
\begin{itemize}
\item {} 
In the receive function, the Ipv4InterfaceList is iterated, and if the
Ipv4Interface corresponding to the receiving device is fount to be in the
UP state, the trace is fired.

\end{itemize}

The “Drop” trace is fired in any case where the packet is dropped (in both
the transmit and receive paths).
\begin{itemize}
\item {} 
In the ns3::Ipv4Interface::Receive function, the packet is dropped and the
drop trace is hit if the interface corresponding to the receiving device
is in the DOWN state.

\item {} 
Also in the ns3::Ipv4Interface::Receive function, the packet is dropped and
the drop trace is hit if the checksum is found to be bad.

\item {} 
In ns3::Ipv4L3Protocol::Send, an outgoing packet bound for the broadcast
address is dropped and the “Drop” trace is fired if the “don’t fragment”
bit is set and fragmentation is available and required.

\item {} 
Also in ns3::Ipv4L3Protocol::Send, an outgoing packet destined for the
broadcast address is dropped and the “Drop” trace is hit if fragmentation
is not available and is required (MTU \textless{} packet size).

\item {} 
In the case of a broadcast address, an outgoing packet is cloned for each
outgoing interface.  If any of the interfaces is in the DOWN state, the
“Drop” trace event fires with a reference to the copied packet.

\item {} 
In the case of a packet requiring a route, an outgoing packet is dropped
and the “Drop” trace event fires if no route to the remote host is found.

\item {} 
In ns3::Ipv4L3Protocol::SendRealOut, an outgoing packet being routed
is dropped and the “Drop” trace is fired if the “don’t fragment” bit is
set and fragmentation is available and required.

\item {} 
Also in ns3::Ipv4L3Protocol::SendRealOut, an outgoing packet being routed
is dropped and the “Drop” trace is hit if fragmentation is not available
and is required (MTU \textless{} packet size).

\item {} 
An outgoing packet being routed is dropped and the “Drop” trace event fires
if the required Ipv4Interface is in the DOWN state.

\item {} 
If a packet is being forwarded, and the TTL is exceeded (see
ns3::Ipv4L3Protocol::DoForward), the packet is dropped and the “Drop” trace
event is fired.

\end{itemize}


\subsection{Explicit Congestion Notification (ECN) bits}
\label{\detokenize{ipv4:explicit-congestion-notification-ecn-bits}}\begin{itemize}
\item {} 
In IPv4, ECN bits are the last 2 bits in TOS field and occupy 14th and 15th
bits in the header.

\item {} 
The IPv4 header class defines an EcnType enum with all four ECN codepoints
(ECN\_NotECT, ECN\_ECT1, ECN\_ECT0, ECN\_CE) mentioned
in RFC 3168, and also a setter and getter method to handle ECN values in
the TOS field.

\end{itemize}


\subsection{Ipv4QueueDiscItem}
\label{\detokenize{ipv4:ipv4queuediscitem}}
The traffic control sublayer in \sphinxstyleemphasis{ns\sphinxhyphen{}3} handles objects of class
\sphinxcode{\sphinxupquote{QueueDiscItem}} which are used to hold an ns3::Packet and an ns3::Header.
This is done to facilitate the marking of packets for Explicit
Congestion Notification.  The \sphinxcode{\sphinxupquote{Mark ()}} method is implemented in
Ipv4QueueDiscItem. It returns true if marking the packet is successful, i.e.,
it successfully sets the CE bit in the IPv4 header. The \sphinxcode{\sphinxupquote{Mark ()}} method
will return false, however, if the IPv4 header indicates the \sphinxcode{\sphinxupquote{ECN\_NotECT}}
codepoint.


\subsection{RFC 6621 duplicate packet detection}
\label{\detokenize{ipv4:rfc-6621-duplicate-packet-detection}}
To support mesh network protocols over broadcast\sphinxhyphen{}capable networks (e.g. Wi\sphinxhyphen{}Fi),
it is useful to have support for duplicate packet detection and filtering,
since nodes in a network may receive multiple copies of flooded multicast
packets arriving on different paths.  The \sphinxcode{\sphinxupquote{Ipv4L3Protocol}} model in \sphinxstyleemphasis{ns\sphinxhyphen{}3}
has a model for hash\sphinxhyphen{}based duplicate packet detection (DPD) based on
Section 6.2.2 of (\index{RFC@\spxentry{RFC}!RFC 6621@\spxentry{RFC 6621}}\sphinxhref{https://tools.ietf.org/html/rfc6621.html}{\sphinxstylestrong{RFC 6621}}).  The model, disabled by default, must be
enabled by setting \sphinxcode{\sphinxupquote{EnableRFC6621}} to true.  A second attribute,
\sphinxcode{\sphinxupquote{DuplicateExpire}}, sets the expiration delay for erasing the cache entry
of a packet in the duplicate cache; the delay value defaults to 1ms.


\section{IPv6}
\label{\detokenize{ipv6:ipv6}}\label{\detokenize{ipv6::doc}}
This chapter describes the \sphinxstyleemphasis{ns\sphinxhyphen{}3} IPv6 model capabilities and limitations along with its
usage and examples.


\subsection{IPv6 model description}
\label{\detokenize{ipv6:ipv6-model-description}}
The IPv6 model is loosely patterned after the Linux implementation;
the implementation is not complete as some features of IPv6 are not of
much interest to simulation studies, and some features of IPv6 are simply
not modeled yet in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

The base class \sphinxcode{\sphinxupquote{Ipv6}}
defines a generic API, while the class \sphinxcode{\sphinxupquote{Ipv6L3Protocol}} is the actual class
implementing the protocol. The actual classes used by the IPv6 stack are located mainly
in the directory \sphinxcode{\sphinxupquote{src/internet}}.

The implementation of IPv6 is contained in the following files:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
src/internet/model/icmpv6\PYGZhy{}header.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/icmpv6\PYGZhy{}l4\PYGZhy{}protocol.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}address\PYGZhy{}generator.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}autoconfigured\PYGZhy{}prefix.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}end\PYGZhy{}point.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}end\PYGZhy{}point\PYGZhy{}demux.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}extension.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}extension\PYGZhy{}demux.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}extension\PYGZhy{}header.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}header.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}interface.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}interface\PYGZhy{}address.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}l3\PYGZhy{}protocol.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}list\PYGZhy{}routing.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}option.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}option\PYGZhy{}demux.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}option\PYGZhy{}header.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}packet\PYGZhy{}info\PYGZhy{}tag.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}pmtu\PYGZhy{}cache.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}raw\PYGZhy{}socket\PYGZhy{}factory.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}raw\PYGZhy{}socket\PYGZhy{}factory\PYGZhy{}impl.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}raw\PYGZhy{}socket\PYGZhy{}impl.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}route.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}routing\PYGZhy{}protocol.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}routing\PYGZhy{}table\PYGZhy{}entry.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ipv6\PYGZhy{}static\PYGZhy{}routing.\PYGZob{}cc,h\PYGZcb{}
src/internet/model/ndisc\PYGZhy{}cache.\PYGZob{}cc,h\PYGZcb{}
src/network/utils/inet6\PYGZhy{}socket\PYGZhy{}address.\PYGZob{}cc,h\PYGZcb{}
src/network/utils/ipv6\PYGZhy{}address.\PYGZob{}cc,h\PYGZcb{}
\end{sphinxVerbatim}

Also some helpers are involved with IPv6:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
src/internet/helper/internet\PYGZhy{}stack\PYGZhy{}helper.\PYGZob{}cc,h\PYGZcb{}
src/internet/helper/ipv6\PYGZhy{}address\PYGZhy{}helper.\PYGZob{}cc,h\PYGZcb{}
src/internet/helper/ipv6\PYGZhy{}interface\PYGZhy{}container.\PYGZob{}cc,h\PYGZcb{}
src/internet/helper/ipv6\PYGZhy{}list\PYGZhy{}routing\PYGZhy{}helper.\PYGZob{}cc,h\PYGZcb{}
src/internet/helper/ipv6\PYGZhy{}routing\PYGZhy{}helper.\PYGZob{}cc,h\PYGZcb{}
src/internet/helper/ipv6\PYGZhy{}static\PYGZhy{}routing\PYGZhy{}helper.\PYGZob{}cc,h\PYGZcb{}
\end{sphinxVerbatim}

The model files can be roughly divided into:
\begin{itemize}
\item {} 
protocol models (e.g., ipv6, ipv6\sphinxhyphen{}l3\sphinxhyphen{}protocol, icmpv6\sphinxhyphen{}l4\sphinxhyphen{}protocol, etc.)

\item {} 
routing models (i.e., anything with ‘routing’ in its name)

\item {} 
sockets and interfaces (e.g., ipv6\sphinxhyphen{}raw\sphinxhyphen{}socket, ipv6\sphinxhyphen{}interface, ipv6\sphinxhyphen{}end\sphinxhyphen{}point, etc.)

\item {} 
address\sphinxhyphen{}related things

\item {} 
headers, option headers, extension headers, etc.

\item {} 
accessory classes (e.g., ndisc\sphinxhyphen{}cache)

\end{itemize}


\subsection{Usage}
\label{\detokenize{ipv6:usage}}
The following description is based on using the typical helpers found in the example code.

IPv6 does not need to be activated in a node. it is automatically added to the
available protocols once the Internet Stack is installed.

In order to \sphinxstyleemphasis{not} install IPv6 along with IPv4, it is possible to use
\sphinxcode{\sphinxupquote{ns3::InternetStackHelper}} method \sphinxtitleref{SetIpv6StackInstall (bool enable)}
before installing the InternetStack in the nodes.

Note that to have an IPv6\sphinxhyphen{}only network (i.e., to not install the IPv4 stack in a node)
one should use \sphinxcode{\sphinxupquote{ns3::InternetStackHelper}} method \sphinxtitleref{SetIpv4StackInstall (bool enable)}
before the stack installation.

As an example, in the following code node 0 will have both IPv4 and IPv6, node 1 only
only IPv6 and node 2 only IPv4:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{n}\PYG{p}{;}
\PYG{n}{n}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{InternetStackHelper} \PYG{n}{internet}\PYG{p}{;}
\PYG{n}{InternetStackHelper} \PYG{n}{internetV4only}\PYG{p}{;}
\PYG{n}{InternetStackHelper} \PYG{n}{internetV6only}\PYG{p}{;}

\PYG{n}{internetV4only}\PYG{p}{.}\PYG{n}{SetIpv6StackInstall} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{internetV6only}\PYG{p}{.}\PYG{n}{SetIpv4StackInstall} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{internet}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{internetV6only}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{internetV4only}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{IPv6 addresses assignment}
\label{\detokenize{ipv6:ipv6-addresses-assignment}}
In order to use IPv6 on a network, the first thing to do is assigning IPv6 addresses.

Any IPv6\sphinxhyphen{}enabled \sphinxstyleemphasis{ns\sphinxhyphen{}3} node will have at least one NetDevice: the \sphinxcode{\sphinxupquote{ns3::LoopbackNetDevice}}.
The loopback device address is \sphinxcode{\sphinxupquote{::1}}.
All the other NetDevices will have one or more IPv6 addresses:
\begin{itemize}
\item {} 
One link\sphinxhyphen{}local address: \sphinxcode{\sphinxupquote{fe80::interface ID}}, where \sphinxcode{\sphinxupquote{interface ID}} is derived from the NetDevice MAC address.

\item {} 
Zero or more global addresses, e.g., \sphinxcode{\sphinxupquote{2001:db8::1}}.

\end{itemize}

Typically the first address on an interface will be the link\sphinxhyphen{}local one, with the global
address(es) being the following ones.

IPv6 global addresses might be:
\begin{itemize}
\item {} 
manually assigned

\item {} 
auto\sphinxhyphen{}generated

\end{itemize}

\sphinxstyleemphasis{ns\sphinxhyphen{}3} can use both methods, and it’s quite important to understand the implications of both.


\paragraph{Manually assigned IPv6 addresses}
\label{\detokenize{ipv6:manually-assigned-ipv6-addresses}}
This is probably the easiest and most used method. As an example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n0} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n1} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n+nf}{net} \PYG{p}{(}\PYG{n}{n0}\PYG{p}{,} \PYG{n}{n1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{ndc} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{net}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Assign IPv6 Addresses.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6AddressHelper} \PYG{n}{ipv6}\PYG{p}{;}
\PYG{n}{ipv6}\PYG{p}{.}\PYG{n}{SetBase} \PYG{p}{(}\PYG{n}{Ipv6Address} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2001:db8::}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Ipv6Prefix} \PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6InterfaceContainer} \PYG{n}{ic} \PYG{o}{=} \PYG{n}{ipv6}\PYG{p}{.}\PYG{n}{Assign} \PYG{p}{(}\PYG{n}{ndc}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This method will add two global IPv6 addresses to the nodes. Note that, as usual for IPv6,
all the nodes will also have a link\sphinxhyphen{}local address. Typically the first address on an
interface will be the link\sphinxhyphen{}local one, with the global address(es) being the following ones.

Note that the global addresses will be derived from the MAC address. As a consequence, expect
to have addresses similar to \sphinxcode{\sphinxupquote{2001:db8::200:ff:fe00:1}}.

It is possible to repeat the above to assign more than one global address to a node.
However, due to the \sphinxcode{\sphinxupquote{Ipv6AddressHelper}} singleton nature, one should first assign all the
addresses of a network, then change the network base (\sphinxcode{\sphinxupquote{SetBase}}), then do a new assignment.

Alternatively, it is possible to assign a specific address to a node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n0} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n+nf}{net} \PYG{p}{(}\PYG{n}{n0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{ndc} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{net}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Specifically Assign an IPv6 Address.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6AddressHelper} \PYG{n}{ipv6}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{device} \PYG{o}{=} \PYG{n}{ndc}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node} \PYG{o}{=} \PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetNode} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6}\PYG{o}{\PYGZgt{}} \PYG{n}{ipv6proto} \PYG{o}{=} \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{int32\PYGZus{}t} \PYG{n}{ifIndex} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;}
\PYG{n}{ifIndex} \PYG{o}{=} \PYG{n}{ipv6proto}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetInterfaceForDevice} \PYG{p}{(}\PYG{n}{device}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6InterfaceAddress} \PYG{n}{ipv6Addr} \PYG{o}{=} \PYG{n}{Ipv6InterfaceAddress} \PYG{p}{(}\PYG{n}{Ipv6Address} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2001:db8:f00d:cafe::42}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Ipv6Prefix} \PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ipv6proto}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddAddress} \PYG{p}{(}\PYG{n}{ifIndex}\PYG{p}{,} \PYG{n}{ipv6Addr}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subparagraph{Auto\sphinxhyphen{}generated IPv6 addresses}
\label{\detokenize{ipv6:auto-generated-ipv6-addresses}}
This is accomplished by relying on the RADVD protocol, implemented by the class
\sphinxcode{\sphinxupquote{Radvd}}. A helper class is available, which can be used to ease the most
common tasks, e.g., setting up a prefix on an interface, if it is announced periodically,
and if the router is the default router for that interface.

A fine grain configuration is possible though the \sphinxcode{\sphinxupquote{RadvdInterface}} class, which
allows to setup every parameter of the announced router advertisement on a given interface.

It is worth mentioning that the configurations must be set up before installing the
application in the node.

Upon using this method, the nodes will acquire dynamically (i.e., during the simulation)
one (or more) global address(es) according to the RADVD configuration.
These addresses will be bases on the RADVD announced prefix and the node’s EUI\sphinxhyphen{}64.

Examples of RADVD use are shown in \sphinxcode{\sphinxupquote{examples/ipv6/radvd.cc}}
and \sphinxcode{\sphinxupquote{examples/ipv6/radvd\sphinxhyphen{}two\sphinxhyphen{}prefix.cc}}.


\subparagraph{Random\sphinxhyphen{}generated IPv6 addresses}
\label{\detokenize{ipv6:random-generated-ipv6-addresses}}
While IPv6 real nodes will use randomly generated addresses to protect privacy, \sphinxstyleemphasis{ns\sphinxhyphen{}3}
does NOT have this capability. This feature haven’t been so far considered as interesting
for simulation.


\subparagraph{Duplicate Address Detection (DAD)}
\label{\detokenize{ipv6:duplicate-address-detection-dad}}
Nodes will perform DAD (it can be disabled using an \sphinxcode{\sphinxupquote{Icmpv6L4Protocol}} attribute).
Upon receiving a DAD, however, nodes will not react to it. As is: DAD reaction is
incomplete so far.
The main reason relies on the missing random\sphinxhyphen{}generated address capability. Moreover,
since \sphinxstyleemphasis{ns\sphinxhyphen{}3} nodes will usually be well\sphinxhyphen{}behaving, there shouldn’t be any Duplicate Address.
This might be changed in the future, so as to avoid issues with real\sphinxhyphen{}world
integrated simulations.


\subsubsection{Explicit Congestion Notification (ECN) bits in IPv6}
\label{\detokenize{ipv6:explicit-congestion-notification-ecn-bits-in-ipv6}}\begin{itemize}
\item {} 
In IPv6, ECN bits are the last 2 bits of the Traffic class and occupy 10th and 11th bit
in the header.

\item {} 
The IPv6 header class defines an EcnType enum with all four ECN codepoints
(ECN\_NotECT, ECN\_ECT1, ECN\_ECT0, ECN\_CE) mentioned
in RFC 3168, and also a setter and getter method to handle ECN values in
the Traffic Class field.

\end{itemize}


\subsection{Ipv6QueueDiscItem}
\label{\detokenize{ipv6:ipv6queuediscitem}}
The traffic control sublayer in \sphinxstyleemphasis{ns\sphinxhyphen{}3} handles objects of class
\sphinxcode{\sphinxupquote{QueueDiscItem}} which are used to hold an ns3::Packet and an ns3::Header.
This is done to facilitate the marking of packets for Explicit
Congestion Notification.  The \sphinxcode{\sphinxupquote{Mark ()}} method is implemented in
Ipv6QueueDiscItem. It returns true if marking the packet is successful, i.e.,
it successfully sets the CE bit in the IPv6 header. The \sphinxcode{\sphinxupquote{Mark ()}} method
will return false, however, if the IPv6 header indicates the \sphinxcode{\sphinxupquote{ECN\_NotECT}}
codepoint.


\subsubsection{Host and Router behaviour in IPv6 and \sphinxstyleemphasis{ns\sphinxhyphen{}3}}
\label{\detokenize{ipv6:host-and-router-behaviour-in-ipv6-and-ns3}}
In IPv6 there is a clear distinction between \sphinxstyleemphasis{routers} and \sphinxstyleemphasis{hosts}. As one might expect,
routers can forward packets from an interface to another interface, while hosts drop
packets not directed to them.

Unfortunately, forwarding is not the only thing affected by this distinction, and forwarding
itself might be fine\sphinxhyphen{}tuned, e.g., to forward packets incoming from an interface and drop
packets from another interface.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3} a node is configured to be an \sphinxstyleemphasis{host} by default. There are two main ways to change
this behaviour:
\begin{itemize}
\item {} 
Using \sphinxcode{\sphinxupquote{ns3::Ipv6InterfaceContainer}} \sphinxtitleref{SetForwarding(uint32\_t i, bool router)} where \sphinxcode{\sphinxupquote{i}} is the interface index in the container.

\item {} 
Changing the \sphinxcode{\sphinxupquote{ns3::Ipv6}} attribute \sphinxcode{\sphinxupquote{IpForward}}.

\end{itemize}

Either one can be used during the simulation.

A fine\sphinxhyphen{}grained setup can be accomplished by using \sphinxcode{\sphinxupquote{ns3::Ipv6Interface}} \sphinxtitleref{SetForwarding (bool forward);}
which allows to change the behaviour on a per\sphinxhyphen{}interface\sphinxhyphen{}basis.

Note that the node\sphinxhyphen{}wide configuration only serves as a convenient method to enable/disable the
\sphinxcode{\sphinxupquote{ns3::Ipv6Interface}} specific setting. An Ipv6Interface added to a node
with forwarding enabled will be set to be forwarding as well.
This is really important when a node has interfaces added during the simulation.

According to the \sphinxcode{\sphinxupquote{ns3::Ipv6Interface}} forwarding state, the following happens:
\begin{itemize}
\item {} 
Forwarding OFF

\end{itemize}
\begin{itemize}
\item {} 
The node will NOT reply to Router Solicitation

\item {} 
The node will react to Router Advertisement

\item {} 
The node will periodically send Router Solicitation

\item {} 
Routing protocols MUST DROP packets not directed to the node

\end{itemize}
\begin{itemize}
\item {} 
Forwarding ON

\end{itemize}
\begin{itemize}
\item {} 
The node will reply to Router Solicitation

\item {} 
The node will NOT react to Router Advertisement

\item {} 
The node will NOT send Router Solicitation

\item {} 
Routing protocols MUST forward packets

\end{itemize}

The behaviour is matching ip\sphinxhyphen{}sysctl.txt (\sphinxurl{http://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt})
with the difference that it’s not possible to override the behaviour using esoteric settings
(e.g., forwarding but accept router advertisements, accept\_ra=2, or forwarding but send router solicitations
forwarding=2).

Consider carefully the implications of packet forwarding. As an example, a node will NOT send
ICMPv6 PACKET\_TOO\_BIG messages from an interface with forwarding off. This is completely normal,
as the Routing protocol will drop the packet before attempting to forward it.


\subsubsection{Helpers}
\label{\detokenize{ipv6:helpers}}
Typically the helpers used in IPv6 setup are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::InternetStackHelper}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6AddressHelper}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6InterfaceContainer}}

\end{itemize}

The use is almost identical to the corresponding IPv4 case, e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{n}\PYG{p}{;}
\PYG{n}{n}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Create IPv6 Internet Stack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{InternetStackHelper} \PYG{n}{internetv6}\PYG{p}{;}
\PYG{n}{internetv6}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Create channels.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{CsmaHelper} \PYG{n}{csma}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{d} \PYG{o}{=} \PYG{n}{csma}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Create networks and assign IPv6 Addresses.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6AddressHelper} \PYG{n}{ipv6}\PYG{p}{;}
\PYG{n}{ipv6}\PYG{p}{.}\PYG{n}{SetBase} \PYG{p}{(}\PYG{n}{Ipv6Address} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2001:db8::}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{Ipv6Prefix} \PYG{p}{(}\PYG{l+m+mi}{64}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ipv6InterfaceContainer} \PYG{n}{iic} \PYG{o}{=} \PYG{n}{ipv6}\PYG{p}{.}\PYG{n}{Assign} \PYG{p}{(}\PYG{n}{d}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Additionally, a common task is to enable forwarding on one of the nodes and to
setup a default route toward it in the other nodes, e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{iic}\PYG{p}{.}\PYG{n}{SetForwarding} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{iic}\PYG{p}{.}\PYG{n}{SetDefaultRouteInAllNodes} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This will enable forwarding on the node \sphinxstyleemphasis{0} and will setup a default route in
\sphinxcode{\sphinxupquote{ns3::Ipv6StaticRouting}} on all the other nodes. Note that this
requires that Ipv6StaticRouting is present in the nodes.

The IPv6 routing helpers enable the user to perform specific tasks on the
particular routing algorithm and to print the routing tables.


\subsubsection{Attributes}
\label{\detokenize{ipv6:attributes}}
Many classes in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} IPv6 implementation contain attributes. The most
useful ones are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{IpForward}, boolean, default false. Globally enable or disable IP forwarding for all current and future IPv6 devices.

\item {} 
\sphinxtitleref{MtuDiscover}, boolean, default true. If disabled, every interface will have its MTU set to 1280 bytes.

\end{itemize}
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6L3Protocol}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{DefaultTtl}, uint8\_t, default 64. The TTL value set by default on all outgoing packets generated on this node.

\item {} 
\sphinxtitleref{SendIcmpv6Redirect}, boolean, default true. Send the ICMPv6 Redirect when appropriate.

\end{itemize}
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Icmpv6L4Protocol}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{DAD}, boolean, default true. Always do DAD (Duplicate Address Detection) check.

\end{itemize}
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::NdiscCache}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{UnresolvedQueueSize}, uint32\_t, default 3. Size of the queue for packets pending an NA reply.

\end{itemize}


\subsubsection{Output}
\label{\detokenize{ipv6:output}}
The IPv6 stack provides some useful trace sources:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6L3Protocol}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{Tx}, Send IPv6 packet to outgoing interface.

\item {} 
\sphinxtitleref{Rx}, Receive IPv6 packet from incoming interface.

\item {} 
\sphinxtitleref{Drop}, Drop IPv6 packet.

\end{itemize}
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Ipv6Extension}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxtitleref{Drop}, Drop IPv6 packet.

\end{itemize}

The latest trace source is generated when a packet contains an unknown option blocking its processing.

Mind that \sphinxcode{\sphinxupquote{ns3::NdiscCache}} could drop packets as well, and they are not logged
in a trace source (yet). This might generate some confusion in the sent/received packets counters.


\subsubsection{Advanced Usage}
\label{\detokenize{ipv6:advanced-usage}}

\paragraph{IPv6 maximum transmission unit (MTU) and fragmentation}
\label{\detokenize{ipv6:ipv6-maximum-transmission-unit-mtu-and-fragmentation}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} NetDevices define the MTU according to the L2 simulated Device. IPv6 requires
that the minimum MTU is 1280 bytes, so all NetDevices are required to support at least
this MTU. This is the link\sphinxhyphen{}MTU.

In order to support different MTUs in a source\sphinxhyphen{}destination path, \sphinxstyleemphasis{ns\sphinxhyphen{}3} IPv6 model can
perform fragmentation.
This can be either triggered by receiving a packet bigger than the link\sphinxhyphen{}MTU from the L4
protocols (UDP, TCP, etc.), or by receiving an ICMPv6 PACKET\_TOO\_BIG message.
The model mimics RFC 1981, with the following notable exceptions:
\begin{itemize}
\item {} 
L4 protocols are not informed of the Path MTU change

\item {} 
TCP can not change its Segment Size according to the Path\sphinxhyphen{}MTU.

\end{itemize}

Both limitations are going to be removed in due time.

The Path\sphinxhyphen{}MTU cache is currently based on the source\sphinxhyphen{}destination IPv6 addresses. Further
classifications (e.g., flow label) are possible but not yet implemented.

The Path\sphinxhyphen{}MTU default validity time is 10 minutes. After the cache entry expiration, the
Path\sphinxhyphen{}MTU information is removed and the next packet will (eventually) trigger a new ICMPv6
PACKET\_TOO\_BIG message.
Note that 1) this is consistent with the RFC specification and 2) L4 protocols are
responsible for retransmitting the packets.


\subsubsection{Examples}
\label{\detokenize{ipv6:examples}}
The examples for IPv6 are in the directory \sphinxcode{\sphinxupquote{examples/ipv6}}. These examples focus on
the most interesting IPv6 peculiarities, such as fragmentation, redirect and so on.

Moreover, most TCP and UDP examples located in \sphinxcode{\sphinxupquote{examples/udp}}, \sphinxcode{\sphinxupquote{examples/tcp}}, etc.
have a command\sphinxhyphen{}line option to use IPv6 instead of IPv4.


\subsubsection{Troubleshooting}
\label{\detokenize{ipv6:troubleshooting}}
There are just a few pitfalls to avoid while using \sphinxstyleemphasis{ns\sphinxhyphen{}3} IPv6.


\paragraph{Routing loops}
\label{\detokenize{ipv6:routing-loops}}
Since the only (so far) routing scheme available for IPv6 is \sphinxcode{\sphinxupquote{ns3::Ipv6StaticRouting}},
default router have to be setup manually. When there are two or more routers in a network
(e.g., node A and node B), avoid using the helper function \sphinxtitleref{SetDefaultRouteInAllNodes}
for more than one router.

The consequence would be to install a default route to B in A and a default route pointing to
A in B, generating a loop.


\paragraph{Global address leakage}
\label{\detokenize{ipv6:global-address-leakage}}
Remember that addresses in IPv6 are \sphinxstyleemphasis{global} by definition. When using IPv6 with an emulation
\sphinxstyleemphasis{ns\sphinxhyphen{}3} capability, avoid at all costs address leakage toward the global Internet.
It is advisable to setup an external firewall to prevent leakage.


\paragraph{2001:DB8::/32 addresses}
\label{\detokenize{ipv6:db8-32-addresses}}
IPv6 standard (RFC 3849) defines the \sphinxcode{\sphinxupquote{2001:DB8::/32}} address class for the \sphinxstyleemphasis{documentation}.
This manual uses this convention. The addresses in this class are, however, only usable in
a document, and routers should discard them.


\subsection{Validation}
\label{\detokenize{ipv6:validation}}
The IPv6 protocols has not yet been extensively validated against real implementations.
The actual tests involve mainly performing checks of the .pcap trace files with Wireshark,
and the results are positive.


\section{Routing overview}
\label{\detokenize{routing-overview:routing-overview}}\label{\detokenize{routing-overview::doc}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} is intended to support traditional routing approaches and protocols,
support ports of open source routing implementations, and facilitate research
into unorthodox routing techniques. The overall routing architecture is
described below in {\hyperref[\detokenize{routing-overview:routing-architecture}]{\sphinxcrossref{\DUrole{std,std-ref}{Routing architecture}}}}. Users who wish to just read
about how to configure global routing for wired topologies can read
{\hyperref[\detokenize{routing-overview:global-centralized-routing}]{\sphinxcrossref{\DUrole{std,std-ref}{Global centralized routing}}}}. Unicast routing protocols are described in
{\hyperref[\detokenize{routing-overview:unicast-routing}]{\sphinxcrossref{\DUrole{std,std-ref}{Unicast routing}}}}.  Multicast routing is documented in
{\hyperref[\detokenize{routing-overview:multicast-routing}]{\sphinxcrossref{\DUrole{std,std-ref}{Multicast routing}}}}.


\subsection{Routing architecture}
\label{\detokenize{routing-overview:routing-architecture}}\label{\detokenize{routing-overview:id1}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{routing}.pdf}
\caption{Overview of routing}\label{\detokenize{routing-overview:id5}}\label{\detokenize{routing-overview:fig-routing}}\end{figure}

{\hyperref[\detokenize{routing-overview:fig-routing}]{\sphinxcrossref{\DUrole{std,std-ref}{Overview of routing}}}} shows the overall routing architecture for Ipv4. The key
objects are Ipv4L3Protocol, Ipv4RoutingProtocol(s) (a class to which all
routing/forwarding has been delegated from Ipv4L3Protocol), and Ipv4Route(s).

Ipv4L3Protocol must have at least one Ipv4RoutingProtocol added to it at
simulation setup time. This is done explicitly by calling
Ipv4::SetRoutingProtocol ().

The abstract base class Ipv4RoutingProtocol () declares a minimal interface,
consisting of two methods:  RouteOutput () and RouteInput ().  For packets
traveling outbound from a host, the transport protocol will query Ipv4 for the
Ipv4RoutingProtocol object interface, and will request a route via
Ipv4RoutingProtocol::RouteOutput ().  A Ptr to Ipv4Route object is returned.
This is analogous to a dst\_cache entry in Linux. The Ipv4Route is carried down
to the Ipv4L3Protocol to avoid a second lookup there. However, some cases (e.g.
Ipv4 raw sockets) will require a call to RouteOutput()
directly from Ipv4L3Protocol.

For packets received inbound for forwarding or delivery,
the following steps occur. Ipv4L3Protocol::Receive() calls
Ipv4RoutingProtocol::RouteInput(). This passes the packet ownership to the
Ipv4RoutingProtocol object. There are four callbacks associated with this call:
\begin{itemize}
\item {} 
LocalDeliver

\item {} 
UnicastForward

\item {} 
MulticastForward

\item {} 
Error

\end{itemize}

The Ipv4RoutingProtocol must eventually call one of these callbacks for each
packet that it takes responsibility for. This is basically how the input routing
process works in Linux.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{routing-specialization}.pdf}
\caption{Ipv4Routing specialization.}\label{\detokenize{routing-overview:id6}}\label{\detokenize{routing-overview:routing-specialization}}\end{figure}

This overall architecture is designed to support different routing approaches,
including (in the future) a Linux\sphinxhyphen{}like policy\sphinxhyphen{}based routing implementation,
proactive and on\sphinxhyphen{}demand routing protocols, and simple routing protocols for when
the simulation user does not really care about routing.

{\hyperref[\detokenize{routing-overview:routing-specialization}]{\sphinxcrossref{\DUrole{std,std-ref}{Ipv4Routing specialization.}}}} illustrates how multiple routing protocols derive
from this base class. A class Ipv4ListRouting (implementation class
Ipv4ListRoutingImpl) provides the existing list routing approach in \sphinxstyleemphasis{ns\sphinxhyphen{}3}. Its
API is the same as base class Ipv4Routing except for the ability to add multiple
prioritized routing protocols (Ipv4ListRouting::AddRoutingProtocol(),
Ipv4ListRouting::GetRoutingProtocol()).

The details of these routing protocols are described below in
{\hyperref[\detokenize{routing-overview:unicast-routing}]{\sphinxcrossref{\DUrole{std,std-ref}{Unicast routing}}}}.  For now, we will first start with a basic
unicast routing capability that is intended to globally build routing
tables at simulation time t=0 for simulation users who do not care
about dynamic routing.


\subsection{Unicast routing}
\label{\detokenize{routing-overview:unicast-routing}}\label{\detokenize{routing-overview:id2}}
The following unicast routing protocols are defined for IPv4 and IPv6:
\begin{itemize}
\item {} 
classes Ipv4ListRouting and Ipv6ListRouting (used to store a prioritized list of routing protocols)

\item {} 
classes Ipv4StaticRouting and Ipv6StaticRouting (covering both unicast and multicast)

\item {} 
class Ipv4GlobalRouting (used to store routes computed by the global route
manager, if that is used)

\item {} 
class Ipv4NixVectorRouting (a more efficient version of global routing that
stores source routes in a packet header field)

\item {} 
class Rip \sphinxhyphen{} the IPv4 RIPv2 protocol (\index{RFC@\spxentry{RFC}!RFC 2453@\spxentry{RFC 2453}}\sphinxhref{https://tools.ietf.org/html/rfc2453.html}{\sphinxstylestrong{RFC 2453}})

\item {} 
class RipNg \sphinxhyphen{} the IPv6 RIPng protocol (\index{RFC@\spxentry{RFC}!RFC 2080@\spxentry{RFC 2080}}\sphinxhref{https://tools.ietf.org/html/rfc2080.html}{\sphinxstylestrong{RFC 2080}})

\item {} 
IPv4 Optimized Link State Routing (OLSR) (a MANET protocol defined in
\index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}})

\item {} 
IPv4 Ad Hoc On Demand Distance Vector (AODV) (a MANET protocol defined in
\index{RFC@\spxentry{RFC}!RFC 3561@\spxentry{RFC 3561}}\sphinxhref{https://tools.ietf.org/html/rfc3561.html}{\sphinxstylestrong{RFC 3561}})

\item {} 
IPv4 Destination Sequenced Distance Vector (DSDV) (a MANET protocol)

\item {} 
IPv4 Dynamic Source Routing (DSR) (a MANET protocol)

\end{itemize}

In the future, this architecture should also allow someone to implement a
Linux\sphinxhyphen{}like implementation with routing cache, or a Click modular router, but
those are out of scope for now.


\subsubsection{Ipv{[}4,6{]}ListRouting}
\label{\detokenize{routing-overview:ipv-4-6-listrouting}}
This section describes the current default \sphinxstyleemphasis{ns\sphinxhyphen{}3} Ipv{[}4,6{]}RoutingProtocol. Typically,
multiple routing protocols are supported in user space and coordinate to write a
single forwarding table in the kernel. Presently in \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the implementation
instead allows for multiple routing protocols to build/keep their own routing
state, and the IP implementation will query each one of these routing
protocols (in some order determined by the simulation author) until a route is
found.

We chose this approach because it may better facilitate the integration of
disparate routing approaches that may be difficult to coordinate the writing to
a single table, approaches where more information than destination IP address
(e.g., source routing) is used to determine the next hop, and on\sphinxhyphen{}demand routing
approaches where packets must be cached.


\paragraph{Ipv{[}4,6{]}ListRouting::AddRoutingProtocol}
\label{\detokenize{routing-overview:ipv-4-6-listrouting-addroutingprotocol}}
Classes Ipv4ListRouting and Ipv6ListRouting provides a pure virtual function declaration
for the method that allows one to add a routing protocol:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{AddRoutingProtocol} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv4RoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{n}{routingProtocol}\PYG{p}{,}
                         \PYG{k+kt}{int16\PYGZus{}t} \PYG{n}{priority}\PYG{p}{)}\PYG{p}{;}

\PYG{k+kt}{void} \PYG{n+nf}{AddRoutingProtocol} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Ipv6RoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{n}{routingProtocol}\PYG{p}{,}
                         \PYG{k+kt}{int16\PYGZus{}t} \PYG{n}{priority}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

These methods are implemented respectively by class Ipv4ListRoutingImpl and by class
Ipv6ListRoutingImpl in the internet module.

The priority variable above governs the priority in which the routing protocols
are inserted. Notice that it is a signed int.  By default in \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the helper
classes will instantiate a Ipv{[}4,6{]}ListRoutingImpl object, and add to it an
Ipv{[}4,6{]}StaticRoutingImpl object at priority zero.  Internally, a list of
Ipv{[}4,6{]}RoutingProtocols is stored, and and the routing protocols are each consulted
in decreasing order of priority to see whether a match is found. Therefore, if
you want your Ipv4RoutingProtocol to have priority lower than the static
routing, insert it with priority less than 0; e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{MyRoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{n}{myRoutingProto} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{MyRoutingProtocol}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{listRoutingPtr}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddRoutingProtocol} \PYG{p}{(}\PYG{n}{myRoutingProto}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Upon calls to RouteOutput() or RouteInput(), the list routing object will search
the list of routing protocols, in priority order, until a route is found. Such
routing protocol will invoke the appropriate callback and no further routing
protocols will be searched.


\subsubsection{Global centralized routing}
\label{\detokenize{routing-overview:global-centralized-routing}}\label{\detokenize{routing-overview:id3}}
Global centralized routing is sometimes called “God” routing; it is a special
implementation that walks the simulation topology and runs a shortest path
algorithm, and populates each node’s routing tables. No actual protocol overhead
(on the simulated links) is incurred with this approach. It does have a few
constraints:
\begin{itemize}
\item {} 
\sphinxstylestrong{Wired only:}  It is not intended for use in wireless networks.

\item {} 
\sphinxstylestrong{Unicast only:} It does not do multicast.

\item {} 
\sphinxstylestrong{Scalability:}  Some users of this on large topologies (e.g. 1000 nodes)
have noticed that the current implementation is not very scalable. The global
centralized routing will be modified in the future to reduce computations and
runtime performance.

\end{itemize}

Presently, global centralized IPv4 unicast routing over both point\sphinxhyphen{}to\sphinxhyphen{}point and
shared (CSMA) links is supported.

By default, when using the \sphinxstyleemphasis{ns\sphinxhyphen{}3} helper API and the default InternetStackHelper,
global routing capability will be added to the node, and global routing will be
inserted as a routing protocol with lower priority than the static routes (i.e.,
users can insert routes via Ipv4StaticRouting API and they will take precedence
over routes found by global routing).


\paragraph{Global Unicast Routing API}
\label{\detokenize{routing-overview:global-unicast-routing-api}}
The public API is very minimal. User scripts include the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cp}{\PYGZsh{}}\PYG{c+cp}{include} \PYG{c+cpf}{\PYGZdq{}ns3/internet\PYGZhy{}module.h\PYGZdq{}}
\end{sphinxVerbatim}

If the default InternetStackHelper is used, then an instance of global routing
will be aggregated to each node.  After IP addresses are configured, the
following function call will cause all of the nodes that have an Ipv4 interface
to receive forwarding tables entered automatically by the GlobalRouteManager:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ipv4GlobalRoutingHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{PopulateRoutingTables} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Note:} A reminder that the wifi NetDevice will work but does not take any
wireless effects into account. For wireless, we recommend OLSR dynamic routing
described below.

It is possible to call this function again in the midst of a simulation using
the following additional public function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ipv4GlobalRoutingHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{RecomputeRoutingTables} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which flushes the old tables, queries the nodes for new interface information,
and rebuilds the routes.

For instance, this scheduling call will cause the tables to be rebuilt
at time 5 seconds:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,}
                     \PYG{o}{\PYGZam{}}\PYG{n}{Ipv4GlobalRoutingHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{RecomputeRoutingTables}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

There are two attributes that govern the behavior. The first is
Ipv4GlobalRouting::RandomEcmpRouting. If set to true, packets are randomly
routed across equal\sphinxhyphen{}cost multipath routes. If set to false (default), only one
route is consistently used. The second is
Ipv4GlobalRouting::RespondToInterfaceEvents. If set to true, dynamically
recompute the global routes upon Interface notification events (up/down, or
add/remove address). If set to false (default), routing may break unless the
user manually calls RecomputeRoutingTables() after such events. The default is
set to false to preserve legacy \sphinxstyleemphasis{ns\sphinxhyphen{}3} program behavior.


\paragraph{Global Routing Implementation}
\label{\detokenize{routing-overview:global-routing-implementation}}
This section is for those readers who care about how this is implemented.  A
singleton object (GlobalRouteManager) is responsible for populating the static
routes on each node, using the public Ipv4 API of that node.  It queries each
node in the topology for a “globalRouter” interface.  If found, it uses the API
of that interface to obtain a “link state advertisement (LSA)” for the router.
Link State Advertisements are used in OSPF routing, and we follow their
formatting.

It is important to note that all of these computations are done before
packets are flowing in the network.  In particular, there are no
overhead or control packets being exchanged when using this implementation.
Instead, this global route manager just walks the list of nodes to
build the necessary information and configure each node’s routing table.

The GlobalRouteManager populates a link state database with LSAs gathered from
the entire topology. Then, for each router in the topology, the
GlobalRouteManager executes the OSPF shortest path first (SPF) computation on
the database, and populates the routing tables on each node.

The quagga (\sphinxurl{http://www.quagga.net}) OSPF implementation was used as the
basis for the routing computation logic. One benefit of following an existing
OSPF SPF implementation is that OSPF already has defined link state
advertisements for all common types of network links:
\begin{itemize}
\item {} 
point\sphinxhyphen{}to\sphinxhyphen{}point (serial links)

\item {} 
point\sphinxhyphen{}to\sphinxhyphen{}multipoint (Frame Relay, ad hoc wireless)

\item {} 
non\sphinxhyphen{}broadcast multiple access (ATM)

\item {} 
broadcast (Ethernet)

\end{itemize}

Therefore, we think that enabling these other link types will be more
straightforward now that the underlying OSPF SPF framework is in place.

Presently, we can handle IPv4 point\sphinxhyphen{}to\sphinxhyphen{}point, numbered links, as well as shared
broadcast (CSMA) links.  Equal\sphinxhyphen{}cost multipath is also supported.  Although
wireless link types are supported by the implementation, note that due
to the nature of this implementation, any channel effects will not be
considered and the routing tables will assume that every node on the
same shared channel is reachable from every other node (i.e. it will
be treated like a broadcast CSMA link).

The GlobalRouteManager first walks the list of nodes and aggregates
a GlobalRouter interface to each one as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{typedef} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector} \PYG{o}{\PYGZlt{}} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZgt{}}\PYG{o}{:}\PYG{o}{:}\PYG{n}{iterator} \PYG{n}{Iterator}\PYG{p}{;}
\PYG{k}{for} \PYG{p}{(}\PYG{n}{Iterator} \PYG{n}{i} \PYG{o}{=} \PYG{n}{NodeList}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Begin} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i} \PYG{o}{!}\PYG{o}{=} \PYG{n}{NodeList}\PYG{o}{:}\PYG{o}{:}\PYG{n}{End} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i}\PYG{o}{+}\PYG{o}{+}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node} \PYG{o}{=} \PYG{o}{*}\PYG{n}{i}\PYG{p}{;}
    \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{GlobalRouter}\PYG{o}{\PYGZgt{}} \PYG{n}{globalRouter} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{GlobalRouter}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AggregateObject} \PYG{p}{(}\PYG{n}{globalRouter}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

This interface is later queried and used to generate a Link State
Advertisement for each router, and this link state database is
fed into the OSPF shortest path computation logic. The Ipv4 API
is finally used to populate the routes themselves.


\subsubsection{RIP and RIPng}
\label{\detokenize{routing-overview:rip-and-ripng}}
The RIPv2 protocol for IPv4 is described in the \index{RFC@\spxentry{RFC}!RFC 2453@\spxentry{RFC 2453}}\sphinxhref{https://tools.ietf.org/html/rfc2453.html}{\sphinxstylestrong{RFC 2453}}, and it consolidates
a number of improvements over the base protocol defined in \index{RFC@\spxentry{RFC}!RFC 1058@\spxentry{RFC 1058}}\sphinxhref{https://tools.ietf.org/html/rfc1058.html}{\sphinxstylestrong{RFC 1058}}.

This IPv6 routing protocol (\index{RFC@\spxentry{RFC}!RFC 2080@\spxentry{RFC 2080}}\sphinxhref{https://tools.ietf.org/html/rfc2080.html}{\sphinxstylestrong{RFC 2080}}) is the evolution of the well\sphinxhyphen{}known
RIPv1 (see \index{RFC@\spxentry{RFC}!RFC 1058@\spxentry{RFC 1058}}\sphinxhref{https://tools.ietf.org/html/rfc1058.html}{\sphinxstylestrong{RFC 1058}} and \index{RFC@\spxentry{RFC}!RFC 1723@\spxentry{RFC 1723}}\sphinxhref{https://tools.ietf.org/html/rfc1723.html}{\sphinxstylestrong{RFC 1723}}) routing protocol for IPv4.

The protocols are very simple, and are normally suitable for flat, simple
network topologies.

RIPv1, RIPv2, and RIPng have the very same goals and limitations.
In particular, RIP considers any route with a metric equal or greater
than 16 as unreachable. As a consequence, the maximum number of hops is the
network must be less than 15 (the number of routers is not set).
Users are encouraged to read \index{RFC@\spxentry{RFC}!RFC 2080@\spxentry{RFC 2080}}\sphinxhref{https://tools.ietf.org/html/rfc2080.html}{\sphinxstylestrong{RFC 2080}} and \index{RFC@\spxentry{RFC}!RFC 1058@\spxentry{RFC 1058}}\sphinxhref{https://tools.ietf.org/html/rfc1058.html}{\sphinxstylestrong{RFC 1058}} to fully understand
RIP behaviour and limitations.


\paragraph{Routing convergence}
\label{\detokenize{routing-overview:routing-convergence}}
RIP uses a Distance\sphinxhyphen{}Vector algorithm, and routes are updated according to
the Bellman\sphinxhyphen{}Ford algorithm (sometimes known as Ford\sphinxhyphen{}Fulkerson algorithm).
The algorithm has a convergence time of O(|V|*|E|) where |V| and |E|
are the number of vertices (routers) and edges (links) respectively.
It should be stressed that the convergence time is the number of steps in
the algorithm, and each step is triggered by a message.
Since Triggered Updates (i.e., when a route is changed) have a 1\sphinxhyphen{}5 seconds
cooldown, the topology can require some time to be stabilized.

Users should be aware that, during routing tables construction, the routers
might drop packets. Data traffic should be sent only after a time long
enough to allow RIP to build the network topology.
Usually 80 seconds should be enough to have a suboptimal (but working)
routing setup. This includes the time needed to propagate the routes to the
most distant router (16 hops) with Triggered Updates.

If the network topology is changed (e.g., a link is broken), the recovery
time might be quite high, and it might be even higher than the initial
setup time. Moreover, the network topology recovery is affected by
the Split Horizoning strategy.

The examples \sphinxcode{\sphinxupquote{examples/routing/ripng\sphinxhyphen{}simple\sphinxhyphen{}network.cc}} and
\sphinxcode{\sphinxupquote{examples/routing/rip\sphinxhyphen{}simple\sphinxhyphen{}network.cc}}
shows both the network setup and network recovery phases.


\paragraph{Split Horizoning}
\label{\detokenize{routing-overview:split-horizoning}}
Split Horizon is a strategy to prevent routing instability.
Three options are possible:
\begin{itemize}
\item {} 
No Split Horizon

\item {} 
Split Horizon

\item {} 
Poison Reverse

\end{itemize}

In the first case, routes are advertised on all the router’s interfaces.
In the second case, routers will not advertise a route on the interface
from which it was learned.
Poison Reverse will advertise the route on the interface from which it
was learned, but with a metric of 16 (infinity).
For a full analysis of the three techniques, see \index{RFC@\spxentry{RFC}!RFC 1058@\spxentry{RFC 1058}}\sphinxhref{https://tools.ietf.org/html/rfc1058.html}{\sphinxstylestrong{RFC 1058}}, section 2.2.

The examples are based on the network topology
described in the RFC, but it does not show the effect described there.

The reason are the Triggered Updates, together with the fact that when a
router invalidates a route, it will immediately propagate the route
unreachability, thus preventing most of the issues described in the RFC.

However, with complex toplogies, it is still possible to have route
instability phenomena similar to the one described in the RFC after a
link failure. As a consequence, all the considerations about Split Horizon
remanins valid.


\paragraph{Default routes}
\label{\detokenize{routing-overview:default-routes}}
RIP protocol should be installed \sphinxstyleemphasis{only} on routers. As a consequence,
nodes will not know what is the default router.

To overcome this limitation, users should either install the default route
manually (e.g., by resorting to Ipv4StaticRouting or Ipv6StaticRouting), or
by using RADVd (in case of IPv6).
RADVd is available in \sphinxstyleemphasis{ns\sphinxhyphen{}3} in the Applications module, and it is strongly
suggested.


\paragraph{Protocol parameters and options}
\label{\detokenize{routing-overview:protocol-parameters-and-options}}
The RIP \sphinxstyleemphasis{ns\sphinxhyphen{}3} implementations allow to change all the timers associated
with route updates and routes lifetime.

Moreover, users can change the interface metrics on a per\sphinxhyphen{}node basis.

The type of Split Horizoning (to avoid routes back\sphinxhyphen{}propagation) can be
selected on a per\sphinxhyphen{}node basis, with the choices being “no split horizon”,
“split horizon” and “poison reverse”. See \index{RFC@\spxentry{RFC}!RFC 2080@\spxentry{RFC 2080}}\sphinxhref{https://tools.ietf.org/html/rfc2080.html}{\sphinxstylestrong{RFC 2080}} for further details,
and \index{RFC@\spxentry{RFC}!RFC 1058@\spxentry{RFC 1058}}\sphinxhref{https://tools.ietf.org/html/rfc1058.html}{\sphinxstylestrong{RFC 1058}} for a complete discussion on the split horizoning strategies.

Moreover, it is possible to use a non\sphinxhyphen{}standard value for Link Down Value (i.e.,
the value after which a link is considered down). The defaul is value is 16.


\paragraph{Limitations}
\label{\detokenize{routing-overview:limitations}}
There is no support for the Next Hop option (\index{RFC@\spxentry{RFC}!RFC 2080@\spxentry{RFC 2080}}\sphinxhref{https://tools.ietf.org/html/rfc2080.html}{\sphinxstylestrong{RFC 2080}}, Section 2.1.1).
The Next Hop option is useful when RIP is not being run on all of the
routers on a network.
Support for this option may be considered in the future.

There is no support for CIDR prefix aggregation. As a result, both routing
tables and route advertisements may be larger than necessary.
Prefix aggregation may be added in the future.


\subsubsection{Other routing protocols}
\label{\detokenize{routing-overview:other-routing-protocols}}
Other routing protocols documentation can be found under the respective
modules sections, e.g.:
\begin{itemize}
\item {} 
AODV

\item {} 
Click

\item {} 
DSDV

\item {} 
DSR

\item {} 
NixVectorRouting

\item {} 
OLSR

\item {} 
etc.

\end{itemize}


\subsection{Multicast routing}
\label{\detokenize{routing-overview:multicast-routing}}\label{\detokenize{routing-overview:id4}}
The following function is used to add a static multicast route
to a node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{Ipv4StaticRouting}\PYG{o}{:}\PYG{o}{:}\PYG{n}{AddMulticastRoute} \PYG{p}{(}\PYG{n}{Ipv4Address} \PYG{n}{origin}\PYG{p}{,}
                                      \PYG{n}{Ipv4Address} \PYG{n}{group}\PYG{p}{,}
                                      \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{inputInterface}\PYG{p}{,}
                                      \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{k+kt}{uint32\PYGZus{}t}\PYG{o}{\PYGZgt{}} \PYG{n}{outputInterfaces}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

A multicast route must specify an origin IP address, a multicast group and an
input network interface index as conditions and provide a vector of output
network interface indices over which packets matching the conditions are sent.

Typically there are two main types of multicast routes:  routes of the first
kind are used during forwarding. All of the conditions must be explicitly
provided. The second kind of routes are used to get packets off of a local node.
The difference is in the input interface. Routes for forwarding will always
have an explicit input interface specified. Routes off of a node will always
set the input interface to a wildcard specified by the index
Ipv4RoutingProtocol::IF\_INDEX\_ANY.

For routes off of a local node wildcards may be used in the origin and multicast
group addresses. The wildcard used for Ipv4Adresses is that address returned by
Ipv4Address::GetAny () \textendash{} typically “0.0.0.0”. Usage of a wildcard allows one to
specify default behavior to varying degrees.

For example, making the origin address a wildcard, but leaving the multicast
group specific allows one (in the case of a node with multiple interfaces) to
create different routes using different output interfaces for each multicast
group.

If the origin and multicast addresses are made wildcards, you have created
essentially a default multicast address that can forward to multiple
interfaces. Compare this to the actual default multicast address that is
limited to specifying a single output interface for compatibility with
existing functionality in other systems.

Another command sets the default multicast route:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{Ipv4StaticRouting}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefaultMulticastRoute} \PYG{p}{(}\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{outputInterface}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This is the multicast equivalent of the unicast version SetDefaultRoute. We
tell the routing system what to do in the case where a specific route to a
destination multicast group is not found. The system forwards packets out the
specified interface in the hope that “something out there” knows better how to
route the packet. This method is only used in initially sending packets off of a
host. The default multicast route is not consulted during forwarding \textendash{} exact
routes must be specified using AddMulticastRoute for that case.

Since we’re basically sending packets to some entity we think may know better
what to do, we don’t pay attention to “subtleties” like origin address, nor do
we worry about forwarding out multiple  interfaces. If the default multicast
route is set, it is returned as the selected route from LookupStatic
irrespective of origin or multicast group if another specific route is not
found.

Finally, a number of additional functions are provided to fetch and remove
multicast routes:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{GetNMulticastRoutes} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}

\PYG{n}{Ipv4MulticastRoute} \PYG{o}{*}\PYG{n+nf}{GetMulticastRoute} \PYG{p}{(}\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{i}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}

\PYG{n}{Ipv4MulticastRoute} \PYG{o}{*}\PYG{n+nf}{GetDefaultMulticastRoute} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}

\PYG{k+kt}{bool} \PYG{n+nf}{RemoveMulticastRoute} \PYG{p}{(}\PYG{n}{Ipv4Address} \PYG{n}{origin}\PYG{p}{,}
                           \PYG{n}{Ipv4Address} \PYG{n}{group}\PYG{p}{,}
                           \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{inputInterface}\PYG{p}{)}\PYG{p}{;}

\PYG{k+kt}{void} \PYG{n+nf}{RemoveMulticastRoute} \PYG{p}{(}\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{index}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\section{TCP models in ns\sphinxhyphen{}3}
\label{\detokenize{tcp:tcp-models-in-ns-3}}\label{\detokenize{tcp::doc}}
This chapter describes the TCP models available in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.


\subsection{Overview of support for TCP}
\label{\detokenize{tcp:overview-of-support-for-tcp}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} was written to support multiple TCP implementations. The implementations
inherit from a few common header classes in the \sphinxcode{\sphinxupquote{src/network}} directory, so that
user code can swap out implementations with minimal changes to the scripts.

There are two important abstract base classes:
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{TcpSocket}}: This is defined in
\sphinxcode{\sphinxupquote{src/internet/model/tcp\sphinxhyphen{}socket.\{cc,h\}}}. This class exists for hosting TcpSocket
attributes that can be reused across different implementations. For instance,
the attribute \sphinxcode{\sphinxupquote{InitialCwnd}} can be used for any of the implementations
that derive from class \sphinxcode{\sphinxupquote{TcpSocket}}.

\item {} 
class \sphinxcode{\sphinxupquote{TcpSocketFactory}}: This is used by the layer\sphinxhyphen{}4 protocol
instance to create TCP sockets of the right type.

\end{itemize}

There are presently two active and one legacy implementations of TCP available for \sphinxstyleemphasis{ns\sphinxhyphen{}3}.
\begin{itemize}
\item {} 
a natively implemented TCP for ns\sphinxhyphen{}3

\item {} 
support for kernel implementations via \sphinxhref{https://www.nsnam.org/overview/projects/direct-code-execution/}{Direct Code Execution (DCE)}

\item {} 
(legacy) support for kernel implementations for the \sphinxhref{http://www.wand.net.nz/~stj2/nsc/}{Network Simulation Cradle (NSC)}

\end{itemize}

NSC is no longer actively supported; it requires use of gcc\sphinxhyphen{}5 or gcc\sphinxhyphen{}4.9, and
only covers up to Linux kernel version 2.6.29.

It should also be mentioned that various ways of combining virtual machines
with \sphinxstyleemphasis{ns\sphinxhyphen{}3} makes available also some additional TCP implementations, but
those are out of scope for this chapter.


\subsection{ns\sphinxhyphen{}3 TCP}
\label{\detokenize{tcp:ns-3-tcp}}
In brief, the native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP model supports a full bidirectional TCP with
connection setup and close logic. Several congestion control algorithms
are supported, with NewReno the default, and Westwood, Hybla, HighSpeed,
Vegas, Scalable, Veno, Binary Increase Congestion Control (BIC), Yet Another
HighSpeed TCP (YeAH), Illinois, H\sphinxhyphen{}TCP, Low Extra Delay Background Transport
(LEDBAT), TCP Low Priority (TCP\sphinxhyphen{}LP) and and Data Center TCP (DCTCP) also supported. The model also supports
Selective Acknowledgements (SACK), Proportional Rate Reduction (PRR) and
Explicit Congestion Notification (ECN). Multipath\sphinxhyphen{}TCP is not yet supported in
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} releases.


\subsubsection{Model history}
\label{\detokenize{tcp:model-history}}
Until the ns\sphinxhyphen{}3.10 release, \sphinxstyleemphasis{ns\sphinxhyphen{}3} contained a port of the TCP model from \sphinxhref{http://www.ece.gatech.edu/research/labs/MANIACS/GTNetS/index.html}{GTNetS},
developed initially by George Riley and ported to \sphinxstyleemphasis{ns\sphinxhyphen{}3} by Raj Bhattacharjea.
This implementation was substantially rewritten by Adriam Tam for ns\sphinxhyphen{}3.10.
In 2015, the TCP module was redesigned in order to create a better
environment for creating and carrying out automated tests. One of the main
changes involves congestion control algorithms, and how they are implemented.

Before the ns\sphinxhyphen{}3.25 release, a congestion control was considered as a stand\sphinxhyphen{}alone TCP
through an inheritance relation: each congestion control (e.g. TcpNewReno) was
a subclass of TcpSocketBase, reimplementing some inherited methods. The
architecture was redone to avoid this inheritance,
the fundamental principle of the GSoC proposal was avoiding this inheritance,
by making each congestion control a separate class, and making an interface
to exchange important data between TcpSocketBase and the congestion modules.
For instance, similar modularity is used in Linux.

Along with congestion control, Fast Retransmit and Fast Recovery algorithms
have been modified; in previous releases, these algorithms were demanded to
TcpSocketBase subclasses. Starting from ns\sphinxhyphen{}3.25, they have been merged inside
TcpSocketBase. In future releases, they can be extracted as separate modules,
following the congestion control design.


\subsubsection{Acknowledgments}
\label{\detokenize{tcp:acknowledgments}}
As mentioned above, \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP has had multiple authors and maintainers over
the years. Several publications exist on aspects of \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP, and users
of \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP are requested to cite one of the applicable papers when
publishing new work.

A general reference on the current architecture is found in the following paper:
\begin{itemize}
\item {} 
Maurizio Casoni, Natale Patriciello, Next\sphinxhyphen{}generation TCP for ns\sphinxhyphen{}3 simulator, Simulation Modelling Practice and Theory, Volume 66, 2016, Pages 81\sphinxhyphen{}93. (\sphinxurl{http://www.sciencedirect.com/science/article/pii/S1569190X15300939})

\end{itemize}

For an academic peer\sphinxhyphen{}reviewed paper on the SACK implementation in ns\sphinxhyphen{}3,
please refer to:
\begin{itemize}
\item {} 
Natale Patriciello. 2017. A SACK\sphinxhyphen{}based Conservative Loss Recovery Algorithm for ns\sphinxhyphen{}3 TCP: a Linux\sphinxhyphen{}inspired Proposal. In Proceedings of the Workshop on ns\sphinxhyphen{}3 (WNS3 ‘17). ACM, New York, NY, USA, 1\sphinxhyphen{}8. (\sphinxurl{https://dl.acm.org/citation.cfm?id=3067666})

\end{itemize}


\subsubsection{Usage}
\label{\detokenize{tcp:usage}}
In many cases, usage of TCP is set at the application layer by telling
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} application which kind of socket factory to use.

Using the helper functions defined in \sphinxcode{\sphinxupquote{src/applications/helper}} and
\sphinxcode{\sphinxupquote{src/network/helper}}, here is how one would create a TCP receiver:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create a packet sink on the star \PYGZdq{}hub\PYGZdq{} to receive these packets}
\PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{port} \PYG{o}{=} \PYG{l+m+mi}{50000}\PYG{p}{;}
\PYG{n}{Address} \PYG{n+nf}{sinkLocalAddress}\PYG{p}{(}\PYG{n}{InetSocketAddress} \PYG{p}{(}\PYG{n}{Ipv4Address}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetAny} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{port}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{PacketSinkHelper} \PYG{n+nf}{sinkHelper} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sinkLocalAddress}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ApplicationContainer} \PYG{n}{sinkApp} \PYG{o}{=} \PYG{n}{sinkHelper}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{serverNode}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{sinkApp}\PYG{p}{.}\PYG{n}{Start} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{1.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{sinkApp}\PYG{p}{.}\PYG{n}{Stop} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{10.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Similarly, the below snippet configures OnOffApplication traffic source to use
TCP:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create the OnOff applications to send TCP to the server}
\PYG{n}{OnOffHelper} \PYG{n+nf}{clientHelper} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Address} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The careful reader will note above that we have specified the TypeId of an
abstract base class \sphinxcode{\sphinxupquote{TcpSocketFactory}}. How does the script tell
\sphinxstyleemphasis{ns\sphinxhyphen{}3} that it wants the native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP vs. some other one? Well, when
internet stacks are added to the node, the default TCP implementation that is
aggregated to the node is the \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP. This can be overridden as we show
below when using Network Simulation Cradle. So, by default, when using the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
helper API, the TCP that is aggregated to nodes with an Internet stack is the
native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP.

To configure behavior of TCP, a number of parameters are exported through the
\sphinxstyleemphasis{ns\sphinxhyphen{}3} attribute system. These are documented in the \sphinxhref{http://www.nsnam.org/doxygen/classns3\_1\_1\_tcp\_socket.html}{Doxygen} for class
\sphinxcode{\sphinxupquote{TcpSocket}}. For example, the maximum segment size is a
settable attribute.

To set the default socket type before any internet stack\sphinxhyphen{}related objects are
created, one may put the following statement at the top of the simulation
program:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpL4Protocol::SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpNewReno}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For users who wish to have a pointer to the actual socket (so that
socket operations like Bind(), setting socket options, etc. can be
done on a per\sphinxhyphen{}socket basis), Tcp sockets can be created by using the
\sphinxcode{\sphinxupquote{Socket::CreateSocket()}} method. The TypeId passed to CreateSocket()
must be of type \sphinxcode{\sphinxupquote{ns3::SocketFactory}}, so configuring the underlying
socket type must be done by twiddling the attribute associated with the
underlying TcpL4Protocol object. The easiest way to get at this would be
through the attribute configuration system. In the below example,
the Node container “n0n1” is accessed to get the zeroth element, and a socket is
created on this node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create and bind the socket...}
\PYG{n}{TypeId} \PYG{n}{tid} \PYG{o}{=} \PYG{n}{TypeId}\PYG{o}{:}\PYG{o}{:}\PYG{n}{LookupByName} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpNewReno}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/\PYGZdl{}ns3::TcpL4Protocol/SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{tid}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{localSocket} \PYG{o}{=}
  \PYG{n}{Socket}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{n}{n0n1}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{TcpSocketFactory}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Above, the “*” wild card for node number is passed to the attribute
configuration system, so that all future sockets on all nodes are set to
NewReno, not just on node ‘n0n1.Get (0)’. If one wants to limit it to just
the specified node, one would have to do something like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create and bind the socket...}
\PYG{n}{TypeId} \PYG{n}{tid} \PYG{o}{=} \PYG{n}{TypeId}\PYG{o}{:}\PYG{o}{:}\PYG{n}{LookupByName} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpNewReno}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{stringstream} \PYG{n}{nodeId}\PYG{p}{;}
\PYG{n}{nodeId} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{n0n1}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{specificNode} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/}\PYG{l+s}{\PYGZdq{}} \PYG{o}{+} \PYG{n}{nodeId}\PYG{p}{.}\PYG{n}{str} \PYG{p}{(}\PYG{p}{)} \PYG{o}{+} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/\PYGZdl{}ns3::TcpL4Protocol/SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{n}{specificNode}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{tid}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{localSocket} \PYG{o}{=}
  \PYG{n}{Socket}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{n}{n0n1}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{TcpSocketFactory}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once a TCP socket is created, one will want to follow conventional socket logic
and either connect() and send() (for a TCP client) or bind(), listen(), and
accept() (for a TCP server).
Please note that applications usually create the sockets they use automatically,
and so is not straightforward to connect directly to them using pointers. Please
refer to the source code of your preferred application to discover how and when
it creates the socket.


\paragraph{TCP Socket interaction and interface with Application layer}
\label{\detokenize{tcp:tcp-socket-interaction-and-interface-with-application-layer}}
In the following there is an analysis on the public interface of the TCP socket,
and how it can be used to interact with the socket itself. An analysis of the
callback fired by the socket is also carried out. Please note that, for
the sake of clarity, we will use the terminology “Sender” and “Receiver” to clearly
divide the functionality of the socket. However, in TCP these two roles can be
applied at the same time (i.e. a socket could be a sender and a receiver at the
same time): our distinction does not lose generality, since the following
definition can be applied to both sockets in case of full\sphinxhyphen{}duplex mode.


\bigskip\hrule\bigskip


\sphinxstylestrong{TCP state machine (for commodity use)}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{tcp-state-machine}.png}
\caption{TCP State machine}\label{\detokenize{tcp:id7}}\label{\detokenize{tcp:fig-tcp-state-machine}}\end{figure}

In ns\sphinxhyphen{}3 we are fully compliant with the state machine depicted in
Figure {\hyperref[\detokenize{tcp:fig-tcp-state-machine}]{\sphinxcrossref{\DUrole{std,std-ref}{TCP State machine}}}}.


\bigskip\hrule\bigskip


\sphinxstylestrong{Public interface for receivers (e.g. servers receiving data)}
\begin{description}
\item[{\sphinxstyleemphasis{Bind()}}] \leavevmode
Bind the socket to an address, or to a general endpoint. A general endpoint
is an endpoint with an ephemeral port allocation (that is, a random port
allocation) on the 0.0.0.0 IP address. For instance, in current applications,
data senders usually binds automatically after a \sphinxstyleemphasis{Connect()} over a random
port. Consequently, the connection will start from this random port towards
the well\sphinxhyphen{}defined port of the receiver. The IP 0.0.0.0 is then translated by
lower layers into the real IP of the device.

\item[{\sphinxstyleemphasis{Bind6()}}] \leavevmode
Same as \sphinxstyleemphasis{Bind()}, but for IPv6.

\item[{\sphinxstyleemphasis{BindToNetDevice()}}] \leavevmode
Bind the socket to the specified NetDevice, creating a general endpoint.

\item[{\sphinxstyleemphasis{Listen()}}] \leavevmode
Listen on the endpoint for an incoming connection. Please note that this
function can be called only in the TCP CLOSED state, and transit in the
LISTEN state. When an incoming request for connection is detected (i.e. the
other peer invoked \sphinxstyleemphasis{Connect()}) the application will be signaled with the
callback \sphinxstyleemphasis{NotifyConnectionRequest} (set in \sphinxstyleemphasis{SetAcceptCallback()} beforehand).
If the connection is accepted (the default behavior, when the associated
callback is a null one) the Socket will fork itself, i.e. a new socket is
created to handle the incoming data/connection, in the state SYN\_RCVD. Please
note that this newly created socket is not connected anymore to the callbacks
on the “father” socket (e.g. DataSent, Recv); the pointer of the newly
created socket is provided in the Callback \sphinxstyleemphasis{NotifyNewConnectionCreated} (set
beforehand in \sphinxstyleemphasis{SetAcceptCallback}), and should be used to connect new
callbacks to interesting events (e.g. Recv callback). After receiving the ACK
of the SYN\sphinxhyphen{}ACK, the socket will set the congestion control, move into
ESTABLISHED state, and then notify the application with
\sphinxstyleemphasis{NotifyNewConnectionCreated}.

\item[{\sphinxstyleemphasis{ShutdownSend()}}] \leavevmode
Signal a termination of send, or in other words prevents data from being added
to the buffer. After this call, if buffer is already empty, the socket
will send a FIN, otherwise FIN will go when buffer empties. Please note
that this is useful only for modeling “Sink” applications. If you have
data to transmit, please refer to the \sphinxstyleemphasis{Send()} / \sphinxstyleemphasis{Close()} combination of
API.

\item[{\sphinxstyleemphasis{GetRxAvailable()}}] \leavevmode
Get the amount of data that could be returned by the Socket in one or multiple
call to Recv or RecvFrom. Please use the Attribute system to configure the
maximum available space on the receiver buffer (property “RcvBufSize”).

\item[{\sphinxstyleemphasis{Recv()}}] \leavevmode
Grab data from the TCP socket. Please remember that TCP is a stream socket,
and it is allowed to concatenate multiple packets into bigger ones. If no data
is present (i.e. \sphinxstyleemphasis{GetRxAvailable} returns 0) an empty packet is returned.
Set the callback \sphinxstyleemphasis{RecvCallback} through \sphinxstyleemphasis{SetRecvCallback()} in order to have
the application automatically notified when some data is ready to be read.
It’s important to connect that callback to the newly created socket in case
of forks.

\item[{\sphinxstyleemphasis{RecvFrom()}}] \leavevmode
Same as Recv, but with the source address as parameter.

\end{description}


\bigskip\hrule\bigskip


\sphinxstylestrong{Public interface for senders (e.g. clients uploading data)}
\begin{description}
\item[{\sphinxstyleemphasis{Connect()}}] \leavevmode
Set the remote endpoint, and try to connect to it. The local endpoint should
be set before this call, or otherwise an ephemeral one will be created. The
TCP then will be in the SYN\_SENT state. If a SYN\sphinxhyphen{}ACK is received, the TCP will
setup the congestion control, and then call the callback
\sphinxstyleemphasis{ConnectionSucceeded}.

\item[{\sphinxstyleemphasis{GetTxAvailable()}}] \leavevmode
Return the amount of data that can be stored in the TCP Tx buffer. Set this
property through the Attribute system (“SndBufSize”).

\item[{\sphinxstyleemphasis{Send()}}] \leavevmode
Send the data into the TCP Tx buffer. From there, the TCP rules will decide
if, and when, this data will be transmitted. Please note that, if the tx
buffer has enough data to fill the congestion (or the receiver) window, dynamically
varying the rate at which data is injected in the TCP buffer does not have any
noticeable effect on the amount of data transmitted on the wire, that will
continue to be decided by the TCP rules.

\item[{\sphinxstyleemphasis{SendTo()}}] \leavevmode
Same as \sphinxstyleemphasis{Send()}.

\item[{\sphinxstyleemphasis{Close()}}] \leavevmode
Terminate the local side of the connection, by sending a FIN (after all data
in the tx buffer has been transmitted). This does not prevent the socket in
receiving data, and employing retransmit mechanism if losses are detected. If
the application calls \sphinxstyleemphasis{Close()} with unread data in its rx buffer, the socket
will send a reset. If the socket is in the state SYN\_SENT, CLOSING, LISTEN,
FIN\_WAIT\_2, or LAST\_ACK, after that call the application will be notified with
\sphinxstyleemphasis{NotifyNormalClose()}. In other cases, the notification is delayed
(see \sphinxstyleemphasis{NotifyNormalClose()}).

\end{description}


\bigskip\hrule\bigskip


\sphinxstylestrong{Public callbacks}

These callbacks are called by the TCP socket to notify the application of
interesting events. We will refer to these with the protected name used in
socket.h, but we will provide the API function to set the pointers to these
callback as well.
\begin{description}
\item[{\sphinxstyleemphasis{NotifyConnectionSucceeded}: \sphinxstyleemphasis{SetConnectCallback}, 1st argument}] \leavevmode
Called in the SYN\_SENT state, before moving to ESTABLISHED. In other words, we
have sent the SYN, and we received the SYN\sphinxhyphen{}ACK: the socket prepares the
sequence numbers, sends the ACK for the SYN\sphinxhyphen{}ACK, tries to send out more data (in
another segment) and then invokes this callback. After this callback, it
invokes the NotifySend callback.

\item[{\sphinxstyleemphasis{NotifyConnectionFailed}: \sphinxstyleemphasis{SetConnectCallback}, 2nd argument}] \leavevmode
Called after the SYN retransmission count goes to 0. SYN packet is lost
multiple times, and the socket gives up.

\item[{\sphinxstyleemphasis{NotifyNormalClose}: \sphinxstyleemphasis{SetCloseCallbacks}, 1st argument}] \leavevmode
A normal close is invoked. A rare case is when we receive an RST segment (or a
segment with bad flags) in normal states. All other cases are:
\sphinxhyphen{} The application tries to \sphinxstyleemphasis{Connect()} over an already connected socket
\sphinxhyphen{} Received an ACK for the FIN sent, with or without the FIN bit set (we are in LAST\_ACK)
\sphinxhyphen{} The socket reaches the maximum amount of retries in retransmitting the SYN (*)
\sphinxhyphen{} We receive a timeout in the LAST\_ACK state
\sphinxhyphen{} Upon entering the TIME\_WAIT state, before waiting the 2*Maximum Segment Lifetime seconds to finally deallocate the socket.

\item[{\sphinxstyleemphasis{NotifyErrorClose}: \sphinxstyleemphasis{SetCloseCallbacks}, 2nd argument}] \leavevmode
Invoked when we send an RST segment (for whatever reason) or we reached the
maximum amount of data retries.

\item[{\sphinxstyleemphasis{NotifyConnectionRequest}: \sphinxstyleemphasis{SetAcceptCallback}, 1st argument}] \leavevmode
Invoked in the LISTEN state, when we receive a SYN. The return value indicates
if the socket should accept the connection (return true) or should ignore it
(return false).

\item[{\sphinxstyleemphasis{NotifyNewConnectionCreated}: \sphinxstyleemphasis{SetAcceptCallback}, 2nd argument}] \leavevmode
Invoked when from SYN\_RCVD the socket passes to ESTABLISHED, and after setting
up the congestion control, the sequence numbers, and processing the incoming
ACK. If there is some space in the buffer, \sphinxstyleemphasis{NotifySend} is called shortly
after this callback. The Socket pointer, passed with this callback, is the
newly created socket, after a Fork().

\item[{\sphinxstyleemphasis{NotifyDataSent}: \sphinxstyleemphasis{SetDataSentCallback}}] \leavevmode
The Socket notifies the application that some bytes have been transmitted on
the IP level. These bytes could still be lost in the node (traffic control
layer) or in the network.

\item[{\sphinxstyleemphasis{NotifySend}: \sphinxstyleemphasis{SetSendCallback}}] \leavevmode
Invoked if there is some space in the tx buffer when entering the ESTABLISHED
state (e.g. after the ACK for SYN\sphinxhyphen{}ACK is received), after the connection
succeeds (e.g. after the SYN\sphinxhyphen{}ACK is received) and after each new ACK (i.e.
that advances SND.UNA).

\item[{\sphinxstyleemphasis{NotifyDataRecv}: \sphinxstyleemphasis{SetRecvCallback}}] \leavevmode
Called when in the receiver buffer there are in\sphinxhyphen{}order bytes, and when in
FIN\_WAIT\_1 or FIN\_WAIT\_2 the socket receive a in\sphinxhyphen{}sequence FIN (that can carry
data).

\end{description}


\subsubsection{Congestion Control Algorithms}
\label{\detokenize{tcp:congestion-control-algorithms}}
Here follows a list of supported TCP congestion control algorithms. For an
academic peer\sphinxhyphen{}reviewed paper on these congestion control algorithms, see
\sphinxurl{http://dl.acm.org/citation.cfm?id=2756518} .


\paragraph{NewReno}
\label{\detokenize{tcp:newreno}}
NewReno algorithm introduces partial ACKs inside the well\sphinxhyphen{}established Reno
algorithm. This and other modifications are described in RFC 6582. We have two
possible congestion window increment strategy: slow start and congestion
avoidance. Taken from RFC 5681:
\begin{quote}

During slow start, a TCP increments cwnd by at most SMSS bytes for
each ACK received that cumulatively acknowledges new data. Slow
start ends when cwnd exceeds ssthresh (or, optionally, when it
reaches it, as noted above) or when congestion is observed. While
traditionally TCP implementations have increased cwnd by precisely
SMSS bytes upon receipt of an ACK covering new data, we RECOMMEND
that TCP implementations increase cwnd, per Equation \eqref{equation:tcp:newrenocongavoid},
where N is the number of previously unacknowledged bytes acknowledged
in the incoming ACK.
\end{quote}
\begin{equation}\label{equation:tcp:newrenocongavoid}
\begin{split}cwnd += min (N, SMSS)\end{split}
\end{equation}
During congestion avoidance, cwnd is incremented by roughly 1 full\sphinxhyphen{}sized
segment per round\sphinxhyphen{}trip time (RTT), and for each congestion event, the slow
start threshold is halved.


\paragraph{HighSpeed}
\label{\detokenize{tcp:highspeed}}
TCP HighSpeed is designed for high\sphinxhyphen{}capacity channels or, in general, for
TCP connections with large congestion windows.
Conceptually, with respect to the standard TCP, HighSpeed makes the
cWnd grow faster during the probing phases and accelerates the
cWnd recovery from losses.
This behavior is executed only when the window grows beyond a
certain threshold, which allows TCP HighSpeed to be friendly with standard
TCP in environments with heavy congestion, without introducing new dangers
of congestion collapse.

Mathematically:
\begin{equation}\label{equation:tcp:highspeedcwndincrement}
\begin{split}cWnd = cWnd + \frac{a(cWnd)}{cWnd}\end{split}
\end{equation}
The function a() is calculated using a fixed RTT the value 100 ms (the
lookup table for this function is taken from RFC 3649). For each congestion
event, the slow start threshold is decreased by a value that depends on the
size of the slow start threshold itself. Then, the congestion window is set
to such value.
\begin{equation}\label{equation:tcp:highspeedcwnddecrement}
\begin{split}cWnd = (1-b(cWnd)) \cdot cWnd\end{split}
\end{equation}
The lookup table for the function b() is taken from the same RFC.
More information at: \sphinxurl{http://dl.acm.org/citation.cfm?id=2756518}


\paragraph{Hybla}
\label{\detokenize{tcp:hybla}}
The key idea behind TCP Hybla is to obtain for long RTT connections the same
instantaneous transmission rate of a reference TCP connection with lower RTT.
With analytical steps, it is shown that this goal can be achieved by
modifying the time scale, in order for the throughput to be independent from
the RTT. This independence is obtained through the use of a coefficient rho.

This coefficient is used to calculate both the slow start threshold
and the congestion window when in slow start and in congestion avoidance,
respectively.

More information at: \sphinxurl{http://dl.acm.org/citation.cfm?id=2756518}


\paragraph{Westwood}
\label{\detokenize{tcp:westwood}}
Westwood and Westwood+ employ the AIAD (Additive Increase/Adaptive Decrease)·
congestion control paradigm. When a congestion episode happens,·
instead of halving the cwnd, these protocols try to estimate the network’s
bandwidth and use the estimated value to adjust the cwnd.·
While Westwood performs the bandwidth sampling every ACK reception,·
Westwood+ samples the bandwidth every RTT.

More information at: \sphinxurl{http://dl.acm.org/citation.cfm?id=381704} and
\sphinxurl{http://dl.acm.org/citation.cfm?id=2512757}


\paragraph{Vegas}
\label{\detokenize{tcp:vegas}}
TCP Vegas is a pure delay\sphinxhyphen{}based congestion control algorithm implementing a
proactive scheme that tries to prevent packet drops by maintaining a small
backlog at the bottleneck queue. Vegas continuously samples the RTT and computes
the actual throughput a connection achieves using Equation \eqref{equation:tcp:vegasactual} and compares it
with the expected throughput calculated in Equation \eqref{equation:tcp:vegasexpected}. The difference between
these 2 sending rates in Equation \eqref{equation:tcp:vegasdiff} reflects the amount of extra packets being
queued at the bottleneck.
\begin{equation}\label{equation:tcp:vegasactual}
\begin{split}actual &= \frac{cWnd}{RTT}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:vegasexpected}
\begin{split}expected &= \frac{cWnd}{BaseRTT}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:vegasdiff}
\begin{split}diff &= expected - actual\end{split}
\end{equation}
To avoid congestion, Vegas linearly increases/decreases its congestion window
to ensure the diff value falls between the two predefined thresholds, alpha and
beta. diff and another threshold, gamma, are used to determine when Vegas
should change from its slow\sphinxhyphen{}start mode to linear increase/decrease mode.
Following the implementation of Vegas in Linux, we use 2, 4, and 1 as the
default values of alpha, beta, and gamma, respectively, but they can be
modified through the Attribute system.

More information at: \sphinxurl{http://dx.doi.org/10.1109/49.464716}


\paragraph{Scalable}
\label{\detokenize{tcp:scalable}}
Scalable improves TCP performance to better utilize the available bandwidth of
a highspeed wide area network by altering NewReno congestion window adjustment
algorithm. When congestion has not been detected, for each ACK received in an
RTT, Scalable increases its cwnd per:
\begin{equation}\label{equation:tcp:scalablecwndincrement}
\begin{split}cwnd = cwnd + 0.01\end{split}
\end{equation}
Following Linux implementation of Scalable, we use 50 instead of 100 to account
for delayed ACK.

On the first detection of congestion in a given RTT, cwnd is reduced based on
the following equation:
\begin{equation}\label{equation:tcp:scalablecwnddecrement}
\begin{split}cwnd = cwnd - ceil(0.125 \cdot cwnd)\end{split}
\end{equation}
More information at: \sphinxurl{http://dl.acm.org/citation.cfm?id=956989}


\paragraph{Veno}
\label{\detokenize{tcp:veno}}
TCP Veno enhances Reno algorithm for more effectively dealing with random
packet loss in wireless access networks by employing Vegas’s method in
estimating the backlog at the bottleneck queue to distinguish between
congestive and non\sphinxhyphen{}congestive states.

The backlog (the number of packets accumulated at the bottleneck queue) is
calculated using Equation \eqref{equation:tcp:venoN}:
\begin{equation}\label{equation:tcp:venoN}
\begin{split}N &= Actual \cdot (RTT - BaseRTT) \\
  &= Diff \cdot BaseRTT\end{split}
\end{equation}
where:
\begin{equation}\label{equation:tcp:venoDiff}
\begin{split}Diff &= Expected - Actual \\
     &= \frac{cWnd}{BaseRTT} - \frac{cWnd}{RTT}\end{split}
\end{equation}
Veno makes decision on cwnd modification based on the calculated N and its
predefined threshold beta.

Specifically, it refines the additive increase algorithm of Reno so that the
connection can stay longer in the stable state by incrementing cwnd by
1/cwnd for every other new ACK received after the available bandwidth has
been fully utilized, i.e. when N exceeds beta. Otherwise, Veno increases
its cwnd by 1/cwnd upon every new ACK receipt as in Reno.

In the multiplicative decrease algorithm, when Veno is in the non\sphinxhyphen{}congestive
state, i.e. when N is less than beta, Veno decrements its cwnd by only 1/5
because the loss encountered is more likely a corruption\sphinxhyphen{}based loss than a
congestion\sphinxhyphen{}based. Only when N is greater than beta, Veno halves its sending
rate as in Reno.

More information at: \sphinxurl{http://dx.doi.org/10.1109/JSAC.2002.807336}


\paragraph{BIC}
\label{\detokenize{tcp:bic}}
In TCP BIC the congestion control problem is viewed as a search
problem. Taking as a starting point the current window value
and as a target point the last maximum window value
(i.e. the cWnd value just before the loss event) a binary search
technique can be used to update the cWnd value at the midpoint between
the two, directly or using an additive increase strategy if the distance from
the current window is too large.

This way, assuming a no\sphinxhyphen{}loss period, the congestion window logarithmically
approaches the maximum value of cWnd until the difference between it and cWnd
falls below a preset threshold. After reaching such a value (or the maximum
window is unknown, i.e. the binary search does not start at all) the algorithm
switches to probing the new maximum window with a ‘slow start’ strategy.

If a loss occur in either these phases, the current window (before the loss)
can be treated as the new maximum, and the reduced (with a multiplicative
decrease factor Beta) window size can be used as the new minimum.

More information at: \sphinxurl{http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1354672}


\paragraph{YeAH}
\label{\detokenize{tcp:yeah}}
YeAH\sphinxhyphen{}TCP (Yet Another HighSpeed TCP) is a heuristic designed to balance various
requirements of a state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art congestion control algorithm:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
fully exploit the link capacity of high BDP networks while inducing a small number of congestion events

\item {} 
compete friendly with Reno flows

\item {} 
achieve intra and RTT fairness

\item {} 
robust to random losses

\item {} 
achieve high performance regardless of buffer size

\end{enumerate}

YeAH operates between 2 modes: Fast and Slow mode. In the Fast mode when the queue
occupancy is small and the network congestion level is low, YeAH increments
its congestion window according to the aggressive HSTCP rule. When the number of packets
in the queue grows beyond a threshold and the network congestion level is high, YeAH enters
its Slow mode, acting as Reno with a decongestion algorithm. YeAH employs Vegas’ mechanism
for calculating the backlog as in Equation \eqref{equation:tcp:q_yeah}. The estimation of the network congestion
level is shown in Equation \eqref{equation:tcp:l_yeah}.
\begin{equation}\label{equation:tcp:q_yeah}
\begin{split}Q = (RTT - BaseRTT) \cdot \frac{cWnd}{RTT}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:l_yeah}
\begin{split}L = \frac{RTT - BaseRTT}{BaseRTT}\end{split}
\end{equation}
To ensure TCP friendliness, YeAH also implements an algorithm to detect the presence of legacy
Reno flows. Upon the receipt of 3 duplicate ACKs, YeAH decreases its slow start threshold
according to Equation \eqref{equation:tcp:yeahssthresh} if it’s not competing with Reno flows. Otherwise, the ssthresh is
halved as in Reno:
\begin{equation}\label{equation:tcp:yeahssthresh}
\begin{split}ssthresh = min(max(\frac{cWnd}{8}, Q), \frac{cWnd}{2})\end{split}
\end{equation}
More information: \sphinxurl{http://www.csc.lsu.edu/~sjpark/cs7601/4-YeAH\_TCP.pdf}


\paragraph{Illinois}
\label{\detokenize{tcp:illinois}}
TCP Illinois is a hybrid congestion control algorithm designed for
high\sphinxhyphen{}speed networks. Illinois implements a Concave\sphinxhyphen{}AIMD (or C\sphinxhyphen{}AIMD)
algorithm that uses packet loss as the primary congestion signal to
determine the direction of window update and queueing delay as the
secondary congestion signal to determine the amount of change.

The additive increase and multiplicative decrease factors (denoted as
alpha and beta, respectively) are functions of the current average queueing
delay da as shown in Equations \eqref{equation:tcp:illinoisalpha} and \eqref{equation:tcp:illinoisbeta}. To improve the protocol
robustness against sudden fluctuations in its delay sampling,
Illinois allows the increment of alpha to alphaMax
only if da stays below d1 for a some (theta) amount of time.
\begin{equation}\label{equation:tcp:illinoisalpha}
\begin{split}alpha &=
\begin{cases}
   \quad alphaMax              & \quad \text{if } da <= d1 \\
   \quad k1 / (k2 + da)        & \quad \text{otherwise} \\
\end{cases}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisbeta}
\begin{split}beta &=
\begin{cases}
   \quad betaMin               & \quad \text{if } da <= d2 \\
   \quad k3 + k4 \, da         & \quad \text{if } d2 < da < d3 \\
   \quad betaMax               & \quad \text{otherwise}
\end{cases}\end{split}
\end{equation}
where the calculations of k1, k2, k3, and k4 are shown in the following:
\begin{equation}\label{equation:tcp:illinoisk1}
\begin{split}k1 &= \frac{(dm - d1) \cdot alphaMin \cdot alphaMax}{alphaMax - alphaMin}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisk2}
\begin{split}k2 &= \frac{(dm - d1) \cdot alphaMin}{alphaMax - alphaMin} - d1\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisk3}
\begin{split}k3 &= \frac{alphaMin \cdot d3 - alphaMax \cdot d2}{d3 - d2}\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisk4}
\begin{split}k4 &= \frac{alphaMax - alphaMin}{d3 - d2}\end{split}
\end{equation}
Other parameters include da (the current average queueing delay), and
Ta (the average RTT, calculated as sumRtt / cntRtt in the implementation) and
Tmin (baseRtt in the implementation) which is the minimum RTT ever seen.
dm is the maximum (average) queueing delay, and Tmax (maxRtt in the
implementation) is the maximum RTT ever seen.
\begin{equation}\label{equation:tcp:illinoisda}
\begin{split}da &= Ta - Tmin\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisdm}
\begin{split}dm &= Tmax - Tmin\end{split}
\end{equation}\begin{equation}\label{equation:tcp:illinoisdi}
\begin{split}d_i &= eta_i \cdot dm\end{split}
\end{equation}
Illinois only executes its adaptation of alpha and beta when cwnd exceeds a threshold
called winThresh. Otherwise, it sets alpha and beta to the base values of 1 and 0.5,
respectively.

Following the implementation of Illinois in the Linux kernel, we use the following
default parameter settings:
\begin{itemize}
\item {} 
alphaMin = 0.3      (0.1 in the Illinois paper)

\item {} 
alphaMax = 10.0

\item {} 
betaMin = 0.125

\item {} 
betaMax = 0.5

\item {} 
winThresh = 15      (10 in the Illinois paper)

\item {} 
theta = 5

\item {} 
eta1 = 0.01

\item {} 
eta2 = 0.1

\item {} 
eta3 = 0.8

\end{itemize}

More information: \sphinxurl{http://www.doi.org/10.1145/1190095.1190166}


\paragraph{H\sphinxhyphen{}TCP}
\label{\detokenize{tcp:h-tcp}}
H\sphinxhyphen{}TCP has been designed for high BDP (Bandwidth\sphinxhyphen{}Delay Product) paths. It is
a dual mode protocol. In normal conditions, it works like traditional TCP
with the same rate of increment and decrement for the congestion window.
However, in high BDP networks, when it finds no congestion on the path
after \sphinxcode{\sphinxupquote{deltal}} seconds, it increases the window size based on the alpha
function in the following:
\begin{equation}\label{equation:tcp:htcpalpha}
\begin{split}alpha(delta)=1+10(delta-deltal)+0.5(delta-deltal)^2\end{split}
\end{equation}
where \sphinxcode{\sphinxupquote{deltal}} is a threshold in seconds for switching between the modes and
\sphinxcode{\sphinxupquote{delta}} is the elapsed time from the last congestion. During congestion,
it reduces the window size by multiplying by beta function provided
in the reference paper. The calculated throughput between the last two
consecutive congestion events is considered for beta calculation.

The transport \sphinxcode{\sphinxupquote{TcpHtcp}} can be selected in the program
\sphinxcode{\sphinxupquote{examples/tcp/tcp\sphinxhyphen{}variants\sphinxhyphen{}comparison.cc}} to perform an experiment with H\sphinxhyphen{}TCP,
although it is useful to increase the bandwidth in this example (e.g.
to 20 Mb/s) to create a higher BDP link, such as

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{.}\PYG{o}{/}\PYG{n}{waf} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{run} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{tcp\PYGZhy{}variants\PYGZhy{}comparison \PYGZhy{}\PYGZhy{}transport\PYGZus{}prot=TcpHtcp \PYGZhy{}\PYGZhy{}bandwidth=20Mbps \PYGZhy{}\PYGZhy{}duration=10}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

More information (paper): \sphinxurl{http://www.hamilton.ie/net/htcp3.pdf}

More information (Internet Draft): \sphinxurl{https://tools.ietf.org/html/draft-leith-tcp-htcp-06}


\paragraph{LEDBAT}
\label{\detokenize{tcp:ledbat}}
Low Extra Delay Background Transport (LEDBAT) is an experimental delay\sphinxhyphen{}based
congestion control algorithm that seeks to utilize the available bandwidth on
an end\sphinxhyphen{}to\sphinxhyphen{}end path while limiting the consequent increase in queueing delay
on that path. LEDBAT uses changes in one\sphinxhyphen{}way delay measurements to limit
congestion that the flow itself induces in the network.

As a first approximation, the LEDBAT sender operates as shown below:

On receipt of an ACK:
\begin{equation*}
\begin{split}currentdelay = acknowledgement.delay
basedelay = min (basedelay, currentdelay)
queuingdelay = currentdelay - basedelay
offtarget = (TARGET - queuingdelay) / TARGET
cWnd += GAIN * offtarget * bytesnewlyacked * MSS / cWnd\end{split}
\end{equation*}
\sphinxcode{\sphinxupquote{TARGET}} is the maximum queueing delay that LEDBAT itself may introduce in the
network, and \sphinxcode{\sphinxupquote{GAIN}} determines the rate at which the cwnd responds to changes in
queueing delay; \sphinxcode{\sphinxupquote{offtarget}} is a normalized value representing the difference between
the measured current queueing delay and the predetermined TARGET delay. offtarget can
be positive or negative; consequently, cwnd increases or decreases in proportion to
offtarget.

Following the recommendation of RFC 6817, the default values of the parameters are:
\begin{itemize}
\item {} 
TargetDelay = 100

\item {} 
baseHistoryLen = 10

\item {} 
noiseFilterLen = 4

\item {} 
Gain = 1

\end{itemize}

To enable LEDBAT on all TCP sockets, the following configuration can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpL4Protocol::SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{TcpLedbat}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

To enable LEDBAT on a chosen TCP socket, the following configuration can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdl{}ns3::NodeListPriv/NodeList/1/\PYGZdl{}ns3::TcpL4Protocol/SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{TcpLedbat}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The following unit tests have been written to validate the implementation of LEDBAT:
\begin{itemize}
\item {} 
LEDBAT should operate same as NewReno during slow start

\item {} 
LEDBAT should operate same as NewReno if timestamps are disabled

\item {} 
Test to validate cwnd increment in LEDBAT

\end{itemize}

In comparison to RFC 6817, the scope and limitations of the current LEDBAT
implementation are:
\begin{itemize}
\item {} 
It assumes that the clocks on the sender side and receiver side are synchronised

\item {} 
In line with Linux implementation, the one\sphinxhyphen{}way delay is calculated at the sender side by using the timestamps option in TCP header

\item {} 
Only the MIN function is used for noise filtering

\end{itemize}

More information about LEDBAT is available in RFC 6817: \sphinxurl{https://tools.ietf.org/html/rfc6817}


\paragraph{TCP\sphinxhyphen{}LP}
\label{\detokenize{tcp:tcp-lp}}
TCP\sphinxhyphen{}Low Priority (TCP\sphinxhyphen{}LP) is a delay based congestion control protocol in which the low
priority data utilizes only the excess bandwidth available on an end\sphinxhyphen{}to\sphinxhyphen{}end path.
TCP\sphinxhyphen{}LP uses one way delay measurements as an indicator of congestion as it does
not influence cross\sphinxhyphen{}traffic in the reverse direction.

On receipt of an ACK:
\begin{equation*}
\begin{split}One way delay = Receiver timestamp - Receiver timestamp echo reply
Smoothed one way delay = 7/8 * Old Smoothed one way delay + 1/8 * one way delay
If smoothed one way delay > owdMin + 15 * (owdMax - owdMin) / 100
  if LP_WITHIN_INF
    cwnd = 1
  else
    cwnd = cwnd / 2
  Inference timer is set\end{split}
\end{equation*}
where owdMin and owdMax are the minimum and maximum one way delays experienced
throughout the connection, LP\_WITHIN\_INF indicates if TCP\sphinxhyphen{}LP is in inference
phase or not

More information (paper): \sphinxurl{http://cs.northwestern.edu/~akuzma/rice/doc/TCP-LP.pdf}


\paragraph{Data Center TCP (DCTCP)}
\label{\detokenize{tcp:data-center-tcp-dctcp}}
DCTCP is an enhancement to the TCP congestion control algorithm for data center
networks and leverages Explicit Congestion Notification (ECN) to provide more fine\sphinxhyphen{}grained congestion
feedback to the end hosts. DCTCP extends the Explicit Congestion Notification
to estimate the fraction of bytes that encounter congestion, rather than simply
detecting that the congestion has occurred. DCTCP then scales the congestion
window based on this estimate. This approach achieves high burst tolerance, low
latency, and high throughput with shallow\sphinxhyphen{}buffered switches.
\begin{itemize}
\item {} 
Receiver functionality: If CE is set in IP header of incoming packet, send congestion notification to the sender by setting ECE in TCP header. This processing is different from standard ECN processing which sets ECE bit for every ACK until it observes CWR

\item {} 
Sender functionality: The sender makes use of the modified receiver ECE semantics to maintain an average of fraction of packets marked (α) by using the exponential weighted moving average as shown below:

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
α = (1 \PYGZhy{} g) x α + g x F
\end{sphinxVerbatim}

where
\begin{itemize}
\item {} 
g is the estimation gain (between 0 and 1)

\item {} 
F is the fraction of packets marked in current RTT.

\end{itemize}

For windows in which at least one ACK was received with ECE set,
the sender should respond by reducing the congestion
window as follows, once for every window of data:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cwnd = cwnd * (1 \PYGZhy{} α / 2)
\end{sphinxVerbatim}

Following the recommendation of RFC 8257, the default values of the parameters are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
g = 0.0625 (i.e., 1/16)

initial alpha (α) = 1
\end{sphinxVerbatim}

To enable DCTCP on all TCP sockets, the following configuration can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpL4Protocol::SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{TcpDctcp}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

To enable DCTCP on a chosen TCP socket, the following configuration can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdl{}ns3::NodeListPriv/NodeList/1/\PYGZdl{}ns3::TcpL4Protocol/SocketType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TypeIdValue} \PYG{p}{(}\PYG{n}{TcpDctcp}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This will take effect only if socket has already instantiated.

The ECN is enabled automatically when DCTCP is used, even if the user has not explicitly enabled it.

DCTCP depends on a simple queue management algorithm in routers / switches to
mark packets. The current implementation of DCTCP in ns\sphinxhyphen{}3 uses RED with a simple
configuration to achieve the behavior of desired queue management algorithm.

To configure RED router for DCTCP:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::UseEcn}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::QW}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{1.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::MinTh}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::MaxTh}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The following unit tests have been written to validate the implementation of DCTCP:
\begin{itemize}
\item {} 
ECT flags should be set for SYN, SYN+ACK, ACK and data packets for DCTCP traffic

\item {} 
ECT flags should not be set for SYN, SYN+ACK and pure ACK packets, but should be set on data packets for ECN enabled traditional TCP flows

\item {} 
ECE should be set only when CE flags are received at receiver and even if sender doesn’t send CWR, receiver should not send ECE if it doesn’t receive packets with CE flags

\item {} 
DCTCP follows NewReno behavior for slow start

\item {} 
Test to validate cwnd decrement in DCTCP

\end{itemize}

An example program based on an experimental topology found in the original
DCTCP SIGCOMM paper is provided in \sphinxcode{\sphinxupquote{examples/tcp/dctcp\sphinxhyphen{}example.cc}}.
This example uses a simple topology consisting of forty DCTCP senders
and receivers and two ECN\sphinxhyphen{}enabled switches to examine throughput,
fairness, and queue delay properties of the network.

This implementation was tested extensively against a version of DCTCP in
the Linux kernel version 4.4 using the ns\sphinxhyphen{}3 direct code execution (DCE)
environment. Some differences were noted:
\begin{itemize}
\item {} 
Linux maintains its congestion window in segments and not bytes, and
the arithmetic is not floating point, so some differences in the
evolution of congestion window have been observed.

\item {} 
Linux uses pacing, while ns\sphinxhyphen{}3 currently does not provide a dynamically
adjusting pacing implementation; segments are sent out at the line rate
unless the user has enabled pacing and set the maximum pacing rate to
less than the line rate.

\item {} 
Linux implements a state called ‘Congestion Window Reduced’ (CWR)
immediately following a cwnd reduction, and performs proportional rate
reduction similar to how a fast retransmit event is handled.  During
CWR, no cwnd additive increases are performed.  This implementation does
not implement CWR and performs additive increase during the round trip
time that immediately follows a cwnd reduction.

\end{itemize}

More information about DCTCP is available in the RFC 8257:
\sphinxurl{https://tools.ietf.org/html/rfc8257}


\subsubsection{Support for Explicit Congestion Notification (ECN)}
\label{\detokenize{tcp:support-for-explicit-congestion-notification-ecn}}
ECN provides end\sphinxhyphen{}to\sphinxhyphen{}end notification of network congestion without dropping
packets. It uses two bits in the IP header: ECN Capable Transport (ECT bit)
and Congestion Experienced (CE bit), and two bits in the TCP header: Congestion
Window Reduced (CWR) and ECN Echo (ECE).

More information is available in RFC 3168: \sphinxurl{https://tools.ietf.org/html/rfc3168}

The following ECN states are declared in \sphinxcode{\sphinxupquote{src/internet/model/tcp\sphinxhyphen{}socket\sphinxhyphen{}state.h}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{typedef} \PYG{k}{enum}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{ECN\PYGZus{}DISABLED} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{c+c1}{//!\PYGZlt{} ECN disabled traffic}
    \PYG{n}{ECN\PYGZus{}IDLE}\PYG{p}{,}         \PYG{c+c1}{//!\PYGZlt{} ECN is enabled but currently there is no action pertaining to ECE or CWR to be taken}
    \PYG{n}{ECN\PYGZus{}CE\PYGZus{}RCVD}\PYG{p}{,}      \PYG{c+c1}{//!\PYGZlt{} Last packet received had CE bit set in IP header}
    \PYG{n}{ECN\PYGZus{}SENDING\PYGZus{}ECE}\PYG{p}{,}  \PYG{c+c1}{//!\PYGZlt{} Receiver sends an ACK with ECE bit set in TCP header}
    \PYG{n}{ECN\PYGZus{}ECE\PYGZus{}RCVD}\PYG{p}{,}     \PYG{c+c1}{//!\PYGZlt{} Last ACK received had ECE bit set in TCP header}
    \PYG{n}{ECN\PYGZus{}CWR\PYGZus{}SENT}      \PYG{c+c1}{//!\PYGZlt{} Sender has reduced the congestion window, and sent a packet with CWR bit set in TCP header. This is used for tracing.}
  \PYG{p}{\PYGZcb{}} \PYG{n}{EcnStates\PYGZus{}t}\PYG{p}{;}
\end{sphinxVerbatim}

Current implementation of ECN is based on RFC 3168 and is referred as Classic ECN.

The following enum represents the mode of ECN:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{typedef} \PYG{k}{enum}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{ClassicEcn}\PYG{p}{,}  \PYG{c+c1}{//!\PYGZlt{} ECN functionality as described in RFC 3168.}
    \PYG{n}{DctcpEcn}\PYG{p}{,}    \PYG{c+c1}{//!\PYGZlt{} ECN functionality as described in RFC 8257. Note: this mode is specific to DCTCP.}
  \PYG{p}{\PYGZcb{}} \PYG{n}{EcnMode\PYGZus{}t}\PYG{p}{;}
\end{sphinxVerbatim}

The following are some important ECN parameters:
\begin{description}
\item[{::}] \leavevmode
// ECN parameters
EcnMode\_t              m\_ecnMode \{ClassicEcn\}; //!\textless{} ECN mode
UseEcn\_t               m\_useEcn \{Off\};         //!\textless{} Socket ECN capability

\end{description}


\paragraph{Enabling ECN}
\label{\detokenize{tcp:enabling-ecn}}
By default, support for ECN is disabled in TCP sockets. To enable, change
the value of the attribute \sphinxcode{\sphinxupquote{ns3::TcpSocketBase::UseEcn}} to \sphinxcode{\sphinxupquote{On}}.
Following are supported values for the same, this functionality is aligned with
Linux: \sphinxurl{https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{typedef} \PYG{k}{enum}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{Off}        \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,}   \PYG{c+c1}{//!\PYGZlt{} Disable}
    \PYG{n}{On}         \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}   \PYG{c+c1}{//!\PYGZlt{} Enable}
    \PYG{n}{AcceptOnly} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{,}   \PYG{c+c1}{//!\PYGZlt{} Enable only when the peer endpoint is ECN capable}
  \PYG{p}{\PYGZcb{}} \PYG{n}{UseEcn\PYGZus{}t}\PYG{p}{;}
\end{sphinxVerbatim}

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::TcpSocketBase::UseEcn}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{On}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}


\paragraph{ECN negotiation}
\label{\detokenize{tcp:ecn-negotiation}}
ECN capability is negotiated during the three\sphinxhyphen{}way TCP handshake:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Sender sends SYN + CWR + ECE

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}useEcn} \PYG{o}{=}\PYG{o}{=} \PYG{n}{UseEcn\PYGZus{}t}\PYG{o}{:}\PYG{o}{:}\PYG{n}{On}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{SendEmptyPacket} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CWR}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{k}{else}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{SendEmptyPacket} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{n}{m\PYGZus{}ecnState} \PYG{o}{=} \PYG{n}{ECN\PYGZus{}DISABLED}\PYG{p}{;}
\end{sphinxVerbatim}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
Receiver sends SYN + ACK + ECE

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}useEcn} \PYG{o}{!}\PYG{o}{=} \PYG{n}{UseEcn\PYGZus{}t}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Off} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}} \PYG{p}{(}\PYG{n}{tcpHeader}\PYG{p}{.}\PYG{n}{GetFlags} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZam{}} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CWR} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE}\PYG{p}{)}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CWR} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE}\PYG{p}{)}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{SendEmptyPacket} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ACK} \PYG{o}{|}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{m\PYGZus{}ecnState} \PYG{o}{=} \PYG{n}{ECN\PYGZus{}IDLE}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{k}{else}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{SendEmptyPacket} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ACK}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{m\PYGZus{}ecnState} \PYG{o}{=} \PYG{n}{ECN\PYGZus{}DISABLED}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
Sender sends ACK

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{m\PYGZus{}useEcn} \PYG{o}{!}\PYG{o}{=} \PYG{n}{UseEcn\PYGZus{}t}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Off} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}}  \PYG{p}{(}\PYG{n}{tcpHeader}\PYG{p}{.}\PYG{n}{GetFlags} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZam{}} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CWR} \PYG{o}{|} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE}\PYG{p}{)}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{p}{(}\PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ECE}\PYG{p}{)}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{m\PYGZus{}ecnState} \PYG{o}{=} \PYG{n}{ECN\PYGZus{}IDLE}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{k}{else}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{m\PYGZus{}ecnState} \PYG{o}{=} \PYG{n}{ECN\PYGZus{}DISABLED}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Once the ECN\sphinxhyphen{}negotiation is successful, the sender sends data packets with ECT
bits set in the IP header.

Note: As mentioned in \sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.1}{Section 6.1.1 of RFC 3168}, ECT bits should not be set
during ECN negotiation. The ECN negotiation implemented in \sphinxstyleemphasis{ns\sphinxhyphen{}3} follows
this guideline.


\paragraph{ECN State Transitions}
\label{\detokenize{tcp:ecn-state-transitions}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Initially both sender and receiver have their m\_ecnState set as ECN\_DISABLED

\item {} 
Once the ECN negotiation is successful, their states are set to ECN\_IDLE

\item {} 
The receiver’s state changes to ECN\_CE\_RCVD when it receives a packet with
CE bit set. The state then moves to ECN\_SENDING\_ECE when the receiver sends
an ACK with ECE set. This state is retained until a CWR is received
, following which, the state changes to ECN\_IDLE.

\item {} 
When the sender receives an ACK with ECE bit set from receiver, its state
is set as ECN\_ECE\_RCVD

\item {} 
The sender’s state changes to ECN\_CWR\_SENT when it sends a packet with
CWR bit set. It remains in this state until an ACK with valid ECE is received
(i.e., ECE is received for a packet that belongs to a new window),
following which, its state changes to ECN\_ECE\_RCVD.

\end{enumerate}


\paragraph{RFC 3168 compliance}
\label{\detokenize{tcp:rfc-3168-compliance}}
Based on the suggestions provided in RFC 3168, the following behavior has
been implemented:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Pure ACK packets should not have the ECT bit set (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.4}{Section 6.1.4}).

\item {} 
In the current implementation, the sender only sends ECT(0) in the IP header.

\item {} 
The sender should should reduce the congestion window only once in each
window (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.2}{Section 6.1.2}).

\item {} 
The receiver should ignore the CE bits set in a packet arriving out of
window (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.5}{Section 6.1.5}).

\item {} 
The sender should ignore the ECE bits set in the packet arriving out of
window (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.2}{Section 6.1.2}).

\end{enumerate}


\paragraph{Open issues}
\label{\detokenize{tcp:open-issues}}
The following issues are yet to be addressed:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Retransmitted packets should not have the CWR bit set (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.5}{Section 6.1.5}).

\item {} 
Despite the congestion window size being 1 MSS, the sender should reduce its
congestion window by half when it receives a packet with the ECE bit set. The
sender must reset the retransmit timer on receiving the ECN\sphinxhyphen{}Echo packet when
the congestion window is one. The sending TCP will then be able to send a
new packet only when the retransmit timer expires (\sphinxhref{https://tools.ietf.org/html/rfc3168\#section-6.1.2}{Section 6.1.2}).

\item {} 
Support for separately handling the enabling of ECN on the incoming and
outgoing TCP sessions (e.g. a TCP may perform ECN echoing but not set the
ECT codepoints on its outbound data segments).

\end{enumerate}


\subsubsection{Validation}
\label{\detokenize{tcp:validation}}
The following tests are found in the \sphinxcode{\sphinxupquote{src/internet/test}} directory. In
general, TCP tests inherit from a class called \sphinxcode{\sphinxupquote{TcpGeneralTest}},
which provides common operations to set up test scenarios involving TCP
objects. For more information on how to write new tests, see the
section below on {\hyperref[\detokenize{tcp:writing-tcp-tests}]{\sphinxcrossref{\DUrole{std,std-ref}{Writing TCP tests}}}}.
\begin{itemize}
\item {} 
\sphinxstylestrong{tcp:} Basic transmission of string of data from client to server

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}bytes\sphinxhyphen{}in\sphinxhyphen{}flight\sphinxhyphen{}test:} TCP correctly estimates bytes in flight under loss conditions

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}cong\sphinxhyphen{}avoid\sphinxhyphen{}test:} TCP congestion avoidance for different packet sizes

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}datasentcb:} Check TCP’s ‘data sent’ callback

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}endpoint\sphinxhyphen{}bug2211\sphinxhyphen{}test:} A test for an issue that was causing stack overflow

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}fast\sphinxhyphen{}retr\sphinxhyphen{}test:} Fast Retransmit testing

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}header:} Unit tests on the TCP header

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}highspeed\sphinxhyphen{}test:} Unit tests on the HighSpeed congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}htcp\sphinxhyphen{}test:} Unit tests on the H\sphinxhyphen{}TCP congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}hybla\sphinxhyphen{}test:} Unit tests on the Hybla congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}vegas\sphinxhyphen{}test:} Unit tests on the Vegas congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}veno\sphinxhyphen{}test:} Unit tests on the Veno congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}scalable\sphinxhyphen{}test:} Unit tests on the Scalable congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}bic\sphinxhyphen{}test:} Unit tests on the BIC congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}yeah\sphinxhyphen{}test:} Unit tests on the YeAH congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}illinois\sphinxhyphen{}test:} Unit tests on the Illinois congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}ledbat\sphinxhyphen{}test:} Unit tests on the LEDBAT congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}lp\sphinxhyphen{}test:} Unit tests on the TCP\sphinxhyphen{}LP congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}dctcp\sphinxhyphen{}test:} Unit tests on the DCTCP congestion control

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}option:} Unit tests on TCP options

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}pkts\sphinxhyphen{}acked\sphinxhyphen{}test:} Unit test the number of time that PktsAcked is called

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}rto\sphinxhyphen{}test:} Unit test behavior after a RTO occurs

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}rtt\sphinxhyphen{}estimation\sphinxhyphen{}test:} Check RTT calculations, including retransmission cases

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}slow\sphinxhyphen{}start\sphinxhyphen{}test:} Check behavior of slow start

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}timestamp:} Unit test on the timestamp option

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}wscaling:} Unit test on the window scaling option

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}zero\sphinxhyphen{}window\sphinxhyphen{}test:} Unit test persist behavior for zero window conditions

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}close\sphinxhyphen{}test:} Unit test on the socket closing: both receiver and sender have to close their socket when all bytes are transferred

\item {} 
\sphinxstylestrong{tcp\sphinxhyphen{}ecn\sphinxhyphen{}test:} Unit tests on Explicit Congestion Notification

\end{itemize}

Several tests have dependencies outside of the \sphinxcode{\sphinxupquote{internet}} module, so they
are located in a system test directory called \sphinxcode{\sphinxupquote{src/test/ns3tcp}}. Three
of these six tests involve use of the Network Simulation Cradle, and are
disabled if NSC is not enabled in the build.
\begin{itemize}
\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}cwnd:} Check to see that ns\sphinxhyphen{}3 TCP congestion control works against liblinux2.6.26.so implementation

\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}interoperability:} Check to see that ns\sphinxhyphen{}3 TCP interoperates with liblinux2.6.26.so implementation

\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}loss:} Check behavior of ns\sphinxhyphen{}3 TCP upon packet losses

\item {} 
\sphinxstylestrong{nsc\sphinxhyphen{}tcp\sphinxhyphen{}loss:} Check behavior of NSC TCP upon packet losses

\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}no\sphinxhyphen{}delay:} Check that ns\sphinxhyphen{}3 TCP Nagle’s algorithm works correctly and that it can be disabled

\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}socket:} Check that ns\sphinxhyphen{}3 TCP successfully transfers an application data write of various sizes

\item {} 
\sphinxstylestrong{ns3\sphinxhyphen{}tcp\sphinxhyphen{}state:} Check the operation of the TCP state machine for several cases

\end{itemize}

Several TCP validation test results can also be found in the
\sphinxhref{http://www.nsnam.org/wiki/New\_TCP\_Socket\_Architecture}{wiki page}
describing this implementation.

TCP ECN operation is tested in the ARED and RED tests that are documented in the traffic\sphinxhyphen{}control
module documentation.


\subsubsection{Writing a new congestion control algorithm}
\label{\detokenize{tcp:writing-a-new-congestion-control-algorithm}}
Writing (or porting) a congestion control algorithms from scratch (or from
other systems) is a process completely separated from the internals of
TcpSocketBase.

All operations that are delegated to a congestion control are contained in
the class TcpCongestionOps. It mimics the structure tcp\_congestion\_ops of
Linux, and the following operations are defined:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{virtual} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{GetName} \PYG{p}{(}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{GetSsThresh} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{bytesInFlight}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{IncreaseWindow} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{segmentsAcked}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{PktsAcked} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{segmentsAcked}\PYG{p}{,}\PYG{k}{const} \PYG{n}{Time}\PYG{o}{\PYGZam{}} \PYG{n}{rtt}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpCongestionOps}\PYG{o}{\PYGZgt{}} \PYG{n}{Fork} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{CwndEvent} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k}{const} \PYG{n}{TcpSocketState}\PYG{o}{:}\PYG{o}{:}\PYG{n}{TcpCaEvent\PYGZus{}t} \PYG{n}{event}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The most interesting methods to write are GetSsThresh and IncreaseWindow.
The latter is called when TcpSocketBase decides that it is time to increase
the congestion window. Much information is available in the Transmission
Control Block, and the method should increase cWnd and/or ssThresh based
on the number of segments acked.

GetSsThresh is called whenever the socket needs an updated value of the
slow start threshold. This happens after a loss; congestion control algorithms
are then asked to lower such value, and to return it.

PktsAcked is used in case the algorithm needs timing information (such as
RTT), and it is called each time an ACK is received.

CwndEvent is used in case the algorithm needs the state of socket during different
congestion window event.


\subsubsection{TCP SACK and non\sphinxhyphen{}SACK}
\label{\detokenize{tcp:tcp-sack-and-non-sack}}
To avoid code duplication and the effort of maintaining two different versions
of the TCP core, namely RFC 6675 (TCP\sphinxhyphen{}SACK) and RFC 5681 (TCP congestion control),
we have merged RFC 6675 in the current code base. If the receiver supports the
option, the sender bases its retransmissions over the received SACK information.
However, in the absence of that option, the best it can do is to follow the RFC
5681 specification (on Fast Retransmit/Recovery) and employing NewReno
modifications in case of partial ACKs.

A similar concept is used in Linux with the function tcp\_add\_reno\_sack.
Our implementation resides in the TcpTxBuffer class that implements a scoreboard
through two different lists of segments. TcpSocketBase actively uses the API
provided by TcpTxBuffer to query the scoreboard; please refer to the Doxygen
documentation (and to in\sphinxhyphen{}code comments) if you want to learn more about this
implementation.

For an academic peer\sphinxhyphen{}reviewed paper on the SACK implementation in ns\sphinxhyphen{}3,
please refer to \sphinxurl{https://dl.acm.org/citation.cfm?id=3067666}.


\subsubsection{Loss Recovery Algorithms}
\label{\detokenize{tcp:loss-recovery-algorithms}}
The following loss recovery algorithms are supported in ns\sphinxhyphen{}3 TCP:


\paragraph{Classic Recovery}
\label{\detokenize{tcp:classic-recovery}}
Classic Recovery refers to the combination of NewReno algorithm described in
RFC 6582 along with SACK based loss recovery algorithm mentioned in RFC 6675.
SACK based loss recovery is used when sender and receiver support SACK options.
In the case when SACK options are disabled, the NewReno modification handles
the recovery.

At the start of recovery phase the congestion window is reduced diffently for
NewReno and SACK based recovery. For NewReno the reduction is done as given below:
\begin{equation*}
\begin{split}cWnd = ssThresh\end{split}
\end{equation*}
For SACK based recovery, this is done as follows:
\begin{equation*}
\begin{split}cWnd = ssThresh + (dupAckCount * segmentSize)\end{split}
\end{equation*}
While in the recovery phase, the congestion window is inflated by segmentSize
on arrival of every ACK when NewReno is used. The congestion window is kept
same when SACK based loss recovery is used.


\paragraph{Proportional Rate Reduction}
\label{\detokenize{tcp:proportional-rate-reduction}}
Proportional Rate Reduction (PRR) is a loss recovery algorithm described in
RFC 6937 and currently used in Linux. The design of PRR helps in avoiding
excess window adjustments and aims to keep the congestion window as close as
possible to ssThresh.

PRR updates the congestion window by comparing the values of bytesInFlight and
ssThresh. If the value of bytesInFlight is greater than ssThresh, congestion window
is updated as shown below:
\begin{equation*}
\begin{split}sndcnt = CEIL(prrDelivered * ssThresh / RecoverFS) - prrOut\end{split}
\end{equation*}\begin{equation*}
\begin{split}cWnd = pipe + sndcnt\end{split}
\end{equation*}
where \sphinxcode{\sphinxupquote{RecoverFS}} is the value of bytesInFlight at the start of recovery phase,
\sphinxcode{\sphinxupquote{prrDelivered}} is the total bytes delivered during recovery phase,
\sphinxcode{\sphinxupquote{prrOut}} is the total bytes sent during recovery phase and
\sphinxcode{\sphinxupquote{sndcnt}} represents the number of bytes to be sent in response to each ACK.

Otherwise, the congestion window is updated by either using Conservative Reduction
Bound (CRB) or Slow Start Reduction Bound (SSRB) with SSRB being the default
Reduction Bound. Each Reduction Bound calculates a maximum data sending limit.
For CRB, the limit is calculated as shown below:
\begin{equation*}
\begin{split}limit = prrDelivered - prr out\end{split}
\end{equation*}
For SSRB, it is calculated as:
\begin{equation*}
\begin{split}limit = MAX(prrDelivered - prrOut, DeliveredData) + MSS\end{split}
\end{equation*}
where \sphinxcode{\sphinxupquote{DeliveredData}} represets the total number of bytes delivered to the
receiver as indicated by the current ACK and \sphinxcode{\sphinxupquote{MSS}} is the maximum segment size.

After limit calculation, the cWnd is updated as given below:
\begin{equation*}
\begin{split}sndcnt = MIN (ssThresh - pipe, limit)\end{split}
\end{equation*}\begin{equation*}
\begin{split}cWnd = pipe + sndcnt\end{split}
\end{equation*}
More information (paper): \sphinxurl{https://dl.acm.org/citation.cfm?id=2068832}

More information (RFC): \sphinxurl{https://tools.ietf.org/html/rfc6937}


\subsubsection{Adding a new loss recovery algorithm in ns\sphinxhyphen{}3}
\label{\detokenize{tcp:adding-a-new-loss-recovery-algorithm-in-ns-3}}
Writing (or porting) a loss recovery algorithms from scratch (or from
other systems) is a process completely separated from the internals of
TcpSocketBase.

All operations that are delegated to a loss recovery are contained in
the class TcpRecoveryOps and are given below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{virtual} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{GetName} \PYG{p}{(}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{EnterRecovery} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{unAckDataCount}\PYG{p}{,}
                            \PYG{k+kt}{bool} \PYG{n}{isSackEnabled}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{dupAckCount}\PYG{p}{,}
                            \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{bytesInFlight}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{lastDeliveredBytes}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{DoRecovery} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{unAckDataCount}\PYG{p}{,}
                         \PYG{k+kt}{bool} \PYG{n}{isSackEnabled}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{dupAckCount}\PYG{p}{,}
                         \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{bytesInFlight}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{lastDeliveredBytes}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{ExitRecovery} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{bytesInFlight}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{k+kt}{void} \PYG{n+nf}{UpdateBytesSent} \PYG{p}{(}\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{bytesSent}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{virtual} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpRecoveryOps}\PYG{o}{\PYGZgt{}} \PYG{n}{Fork} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

EnterRecovery is called when packet loss is detected and recovery is triggered.
While in recovery phase, each time when an ACK arrives, DoRecovery is called which
performs the necessary congestion window changes as per the recovery algorithm.
ExitRecovery is called just prior to exiting recovery phase in order to perform the
required congestion window ajustments. UpdateBytesSent is used to keep track of
bytes sent and is called whenever a data packet is sent during recovery phase.


\subsubsection{Delivery Rate Estimation}
\label{\detokenize{tcp:delivery-rate-estimation}}
Current TCP implementation measures the approximate value of the delivery rate of
inflight data based on Delivery Rate Estimation.

As high level idea, keep in mind that the algorithm keeps track of 2 variables:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxtitleref{delivered}: Total amount of data delivered so far.

\item {} 
\sphinxtitleref{deliveredStamp}: Last time \sphinxtitleref{delivered} was updated.

\end{enumerate}

When a packet is transmitted, the value of \sphinxtitleref{delivered (d0)} and \sphinxtitleref{deliveredStamp (t0)}
is stored in its respective TcpTxItem.

When an acknowledgement comes for this packet, the value of \sphinxtitleref{delivered} and \sphinxtitleref{deliveredStamp}
is updated to \sphinxtitleref{d1} and \sphinxtitleref{t1} in the same TcpTxItem.

After processing the acknowledgement, the rate sample is calculated and then passed
to a congestion avoidance algorithm:
\begin{equation*}
\begin{split}delivery_rate = (d1 - d0)/(t1 - t0)\end{split}
\end{equation*}
The implementation to estimate delivery rate is a joint work between TcpTxBuffer and TcpRateOps.
For more information, please take a look at their Doxygen documentation.

The implementation follows the Internet draft (Delivery Rate Estimation):
\sphinxurl{https://tools.ietf.org/html/draft-cheng-iccrg-delivery-rate-estimation-00}


\subsubsection{Current limitations}
\label{\detokenize{tcp:current-limitations}}\begin{itemize}
\item {} 
TcpCongestionOps interface does not contain every possible Linux operation

\end{itemize}


\subsubsection{Writing TCP tests}
\label{\detokenize{tcp:writing-tcp-tests}}\label{\detokenize{tcp:id4}}
The TCP subsystem supports automated test
cases on both socket functions and congestion control algorithms. To show
how to write tests for TCP, here we explain the process of creating a test
case that reproduces the {\color{red}\bfseries{}\textasciigrave{}Bug \#1571\textless{}https://www.nsnam.org/bugzilla/show\_bug.cgi?id=1571\textgreater{}\textasciigrave{}\_}.

The bug concerns the zero window situation, which happens when the receiver
cannot handle more data. In this case, it advertises a zero window, which causes
the sender to pause transmission and wait for the receiver to increase the
window.

The sender has a timer to periodically check the receiver’s window: however, in
modern TCP implementations, when the receiver has freed a “significant” amount
of data, the receiver itself sends an “active” window update, meaning that
the transmission could be resumed. Nevertheless, the sender timer is still
necessary because window updates can be lost.

\begin{sphinxadmonition}{note}{Note:}
During the text, we will assume some knowledge about the general design
of the TCP test infrastructure, which is explained in detail into the
Doxygen documentation. As a brief summary, the strategy is to have a class
that sets up a TCP connection, and that calls protected members of itself.
In this way, subclasses can implement the necessary members, which will
be called by the main TcpGeneralTest class when events occur. For example,
after processing an ACK, the method ProcessedAck will be invoked. Subclasses
interested in checking some particular things which must have happened during
an ACK processing, should implement the ProcessedAck method and check
the interesting values inside the method. To get a list of available methods,
please check the Doxygen documentation.
\end{sphinxadmonition}

We describe the writing of two test cases, covering both situations: the
sender’s zero\sphinxhyphen{}window probing and the receiver “active” window update. Our focus
will be on dealing with the reported problems, which are:
\begin{itemize}
\item {} 
an ns\sphinxhyphen{}3 receiver does not send “active” window update when its receive buffer
is being freed;

\item {} 
even if the window update is artificially crafted, the transmission does not
resume.

\end{itemize}

However, other things should be checked in the test:
\begin{itemize}
\item {} 
Persistent timer setup

\item {} 
Persistent timer teardown if rWnd increases

\end{itemize}

To construct the test case, one first derives from the TcpGeneralTest class:

The code is the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{TcpZeroWindowTest} \PYG{p}{(}\PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{desc}\PYG{p}{)}
   \PYG{o}{:} \PYG{n}{TcpGeneralTest} \PYG{p}{(}\PYG{n}{desc}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Then, one should define the general parameters for the TCP connection, which
will be one\sphinxhyphen{}sided (one node is acting as SENDER, while the other is acting as
RECEIVER):
\begin{itemize}
\item {} 
Application packet size set to 500, and 20 packets in total (meaning a stream
of 10k bytes)

\item {} 
Segment size for both SENDER and RECEIVER set to 500 bytes

\item {} 
Initial slow start threshold set to UINT32\_MAX

\item {} 
Initial congestion window for the SENDER set to 10 segments (5000 bytes)

\item {} 
Congestion control: NewReno

\end{itemize}

We have also to define the link properties, because the above definition does
not work for every combination of propagation delay and sender application behavior.
\begin{itemize}
\item {} 
Link one\sphinxhyphen{}way propagation delay: 50 ms

\item {} 
Application packet generation interval: 10 ms

\item {} 
Application starting time: 20 s after the starting point

\end{itemize}

To define the properties of the environment (e.g. properties which should be
set before the object creation, such as propagation delay) one next implements
the method ConfigureEnvironment:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ConfigureEnvironment} \PYG{p}{(}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{TcpGeneralTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ConfigureEnvironment} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetAppPktCount} \PYG{p}{(}\PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetMTU} \PYG{p}{(}\PYG{l+m+mi}{500}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetTransmitStart} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetPropagationDelay} \PYG{p}{(}\PYG{n}{MilliSeconds} \PYG{p}{(}\PYG{l+m+mi}{50}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

For other properties, set after the object creation, one can use
ConfigureProperties ().
The difference is that some values, such as initial congestion window
or initial slow start threshold, are applicable only to a single instance, not
to every instance we have. Usually, methods that requires an id and a value
are meant to be called inside ConfigureProperties (). Please see the Doxygen
documentation for an exhaustive list of the tunable properties.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ConfigureProperties} \PYG{p}{(}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{TcpGeneralTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ConfigureProperties} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{SetInitialCwnd} \PYG{p}{(}\PYG{n}{SENDER}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

To see the default value for the experiment, please see the implementation of
both methods inside TcpGeneralTest class.

\begin{sphinxadmonition}{note}{Note:}
If some configuration parameters are missing, add a method called
“SetSomeValue” which takes as input the value only (if it is meant to be
called inside ConfigureEnvironment) or the socket and the value (if it is
meant to be called inside ConfigureProperties).
\end{sphinxadmonition}

To define a zero\sphinxhyphen{}window situation, we choose (by design) to initiate the connection
with a 0\sphinxhyphen{}byte rx buffer. This implies that the RECEIVER, in its first SYN\sphinxhyphen{}ACK,
advertises a zero window. This can be accomplished by implementing the method
CreateReceiverSocket, setting an Rx buffer value of 0 bytes (at line 6 of the
following code):

\fvset{hllines={, 6, 7, 8,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketMsgBase}\PYG{o}{\PYGZgt{}}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CreateReceiverSocket} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{TcpSocketMsgBase}\PYG{o}{\PYGZgt{}} \PYG{n}{socket} \PYG{o}{=} \PYG{n}{TcpGeneralTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CreateReceiverSocket} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}

  \PYG{n}{socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{RcvBufSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{10.0}\PYG{p}{)}\PYG{p}{,}
                       \PYG{o}{\PYGZam{}}\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{IncreaseBufSize}\PYG{p}{,} \PYG{k}{this}\PYG{p}{)}\PYG{p}{;}

  \PYG{k}{return} \PYG{n}{socket}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\sphinxresetverbatimhllines

Even so, to check the active window update, we should schedule an increase
of the buffer size. We do this at line 7 and 8, scheduling the function
IncreaseBufSize.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{IncreaseBufSize} \PYG{p}{(}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{SetRcvBufSize} \PYG{p}{(}\PYG{n}{RECEIVER}\PYG{p}{,} \PYG{l+m+mi}{2500}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Which utilizes the SetRcvBufSize method to edit the RxBuffer object of the
RECEIVER. As said before, check the Doxygen documentation for class TcpGeneralTest
to be aware of the various possibilities that it offers.

\begin{sphinxadmonition}{note}{Note:}
By design, we choose to maintain a close relationship between TcpSocketBase
and TcpGeneralTest: they are connected by a friendship relation. Since
friendship is not passed through inheritance, if one discovers that one
needs to access or to modify a private (or protected) member of TcpSocketBase,
one can do so by adding a method in the class TcpGeneralSocket. An example
of such method is SetRcvBufSize, which allows TcpGeneralSocket subclasses
to forcefully set the RxBuffer size.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpGeneralTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetRcvBufSize} \PYG{p}{(}\PYG{n}{SocketWho} \PYG{n}{who}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{size}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{SENDER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{m\PYGZus{}senderSocket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetRcvBufSize} \PYG{p}{(}\PYG{n}{size}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
  \PYG{k}{else} \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{RECEIVER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{m\PYGZus{}receiverSocket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetRcvBufSize} \PYG{p}{(}\PYG{n}{size}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
  \PYG{k}{else}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{NS\PYGZus{}FATAL\PYGZus{}ERROR} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Not defined}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\end{sphinxadmonition}

Next, we can start to follow the TCP connection:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
At time 0.0 s the connection is opened sender side, with a SYN packet sent from
SENDER to RECEIVER

\item {} 
At time 0.05 s the RECEIVER gets the SYN and replies with a SYN\sphinxhyphen{}ACK

\item {} 
At time 0.10 s the SENDER gets the SYN\sphinxhyphen{}ACK and replies with a SYN.

\end{enumerate}

While the general structure is defined, and the connection is started,
we need to define a way to check the rWnd field on the segments. To this aim,
we can implement the methods Rx and Tx in the TcpGeneralTest subclass,
checking each time the actions of the RECEIVER and the SENDER. These methods are
defined in TcpGeneralTest, and they are attached to the Rx and Tx traces in the
TcpSocketBase. One should write small tests for every detail that one wants to ensure during the
connection (it will prevent the test from changing over the time, and it ensures
that the behavior will stay consistent through releases). We start by ensuring that
the first SYN\sphinxhyphen{}ACK has 0 as advertised window size:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Tx}\PYG{p}{(}\PYG{k}{const} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{p}\PYG{p}{,} \PYG{k}{const} \PYG{n}{TcpHeader} \PYG{o}{\PYGZam{}}\PYG{n}{h}\PYG{p}{,} \PYG{n}{SocketWho} \PYG{n}{who}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
  \PYG{k}{else} \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{RECEIVER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s}{RECEIVER TX }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{h} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ size }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

      \PYG{k}{if} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetFlags} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZam{}} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN}\PYG{p}{)}
        \PYG{p}{\PYGZob{}}
          \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetWindowSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,}
                                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{RECEIVER window size is not 0 in the SYN\PYGZhy{}ACK}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
    \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
 \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Pratically, we are checking that every SYN packet sent by the RECEIVER has the
advertised window set to 0. The same thing is done also by checking, in the Rx
method, that each SYN received by SENDER has the advertised window set to 0.
Thanks to the log subsystem, we can print what is happening through messages.
If we run the experiment, enabling the logging, we can see the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf shell
gdb \PYGZhy{}\PYGZhy{}args ./build/utils/ns3\PYGZhy{}dev\PYGZhy{}test\PYGZhy{}runner\PYGZhy{}debug \PYGZhy{}\PYGZhy{}test\PYGZhy{}name\PYG{o}{=}tcp\PYGZhy{}zero\PYGZhy{}window\PYGZhy{}test \PYGZhy{}\PYGZhy{}stop\PYGZhy{}on\PYGZhy{}failure \PYGZhy{}\PYGZhy{}fullness\PYG{o}{=}QUICK \PYGZhy{}\PYGZhy{}assert\PYGZhy{}on\PYGZhy{}failure \PYGZhy{}\PYGZhy{}verbose
\PYG{o}{(}gdb\PYG{o}{)} run

\PYG{l+m}{0}.00s TcpZeroWindowTestSuite:Tx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.00      SENDER TX \PYG{l+m}{49153} \PYGZgt{} \PYG{l+m}{4477} \PYG{o}{[}SYN\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{32768} ns3::TcpOptionWinScale\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{0}\PYG{p}{;}\PYG{l+m}{0}\PYG{o}{)} size \PYG{l+m}{36}
\PYG{l+m}{0}.05s TcpZeroWindowTestSuite:Rx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.05      RECEIVER RX \PYG{l+m}{49153} \PYGZgt{} \PYG{l+m}{4477} \PYG{o}{[}SYN\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{32768} ns3::TcpOptionWinScale\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{0}\PYG{p}{;}\PYG{l+m}{0}\PYG{o}{)} ns3::TcpOptionEnd\PYG{o}{(}EOL\PYG{o}{)} size \PYG{l+m}{0}
\PYG{l+m}{0}.05s TcpZeroWindowTestSuite:Tx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.05      RECEIVER TX \PYG{l+m}{4477} \PYGZgt{} \PYG{l+m}{49153} \PYG{o}{[}SYN\PYG{p}{|}ACK\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{0} ns3::TcpOptionWinScale\PYG{o}{(}\PYG{l+m}{0}\PYG{o}{)} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{50}\PYG{p}{;}\PYG{l+m}{0}\PYG{o}{)} size \PYG{l+m}{36}
\PYG{l+m}{0}.10s TcpZeroWindowTestSuite:Rx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.10      SENDER RX \PYG{l+m}{4477} \PYGZgt{} \PYG{l+m}{49153} \PYG{o}{[}SYN\PYG{p}{|}ACK\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{0} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{0} ns3::TcpOptionWinScale\PYG{o}{(}\PYG{l+m}{0}\PYG{o}{)} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{50}\PYG{p}{;}\PYG{l+m}{0}\PYG{o}{)} ns3::TcpOptionEnd\PYG{o}{(}EOL\PYG{o}{)} size \PYG{l+m}{0}
\PYG{l+m}{0}.10s TcpZeroWindowTestSuite:Tx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.10      SENDER TX \PYG{l+m}{49153} \PYGZgt{} \PYG{l+m}{4477} \PYG{o}{[}ACK\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{32768} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{100}\PYG{p}{;}\PYG{l+m}{50}\PYG{o}{)} size \PYG{l+m}{32}
\PYG{l+m}{0}.15s TcpZeroWindowTestSuite:Rx\PYG{o}{(}\PYG{o}{)}: \PYG{l+m}{0}.15      RECEIVER RX \PYG{l+m}{49153} \PYGZgt{} \PYG{l+m}{4477} \PYG{o}{[}ACK\PYG{o}{]} \PYG{n+nv}{Seq}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Ack}\PYG{o}{=}\PYG{l+m}{1} \PYG{n+nv}{Win}\PYG{o}{=}\PYG{l+m}{32768} ns3::TcpOptionTS\PYG{o}{(}\PYG{l+m}{100}\PYG{p}{;}\PYG{l+m}{50}\PYG{o}{)} ns3::TcpOptionEnd\PYG{o}{(}EOL\PYG{o}{)} size \PYG{l+m}{0}
\PYG{o}{(}...\PYG{o}{)}
\end{sphinxVerbatim}

The output is cut to show the threeway handshake. As we can see from the headers,
the rWnd of RECEIVER is set to 0, and thankfully our tests are not failing.
Now we need to test for the persistent timer, which should be started by
the SENDER after it receives the SYN\sphinxhyphen{}ACK. Since the Rx method is called before
any computation on the received packet, we should utilize another method, namely
ProcessedAck, which is the method called after each processed ACK. In the
following, we show how to check if the persistent event is running after the
processing of the SYN\sphinxhyphen{}ACK:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ProcessedAck} \PYG{p}{(}\PYG{k}{const} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{n}{TcpSocketState}\PYG{o}{\PYGZgt{}} \PYG{n}{tcb}\PYG{p}{,}
                                 \PYG{k}{const} \PYG{n}{TcpHeader}\PYG{o}{\PYGZam{}} \PYG{n}{h}\PYG{p}{,} \PYG{n}{SocketWho} \PYG{n}{who}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{SENDER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{k}{if} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetFlags} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZam{}} \PYG{n}{TcpHeader}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SYN}\PYG{p}{)}
        \PYG{p}{\PYGZob{}}
          \PYG{n}{EventId} \PYG{n}{persistentEvent} \PYG{o}{=} \PYG{n}{GetPersistentEvent} \PYG{p}{(}\PYG{n}{SENDER}\PYG{p}{)}\PYG{p}{;}
          \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{persistentEvent}\PYG{p}{.}\PYG{n}{IsRunning} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,}
                                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Persistent event not started}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
 \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Since we programmed the increase of the buffer size after 10 simulated seconds,
we expect the persistent timer to fire before any rWnd changes. When it fires,
the SENDER should send a window probe, and the receiver should reply reporting
again a zero window situation. At first, we investigates on what the sender sends:

\fvset{hllines={, 1, 6, 7, 11,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{l+m+mf}{6.0}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetSize} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{h}\PYG{p}{.}\PYG{n}{GetSerializedSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,}
                             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Data packet sent anyway}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
  \PYG{k}{else} \PYG{k}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{6.0} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}}
           \PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{l+m+mf}{7.0}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{m\PYGZus{}zeroWindowProbe}\PYG{p}{,} \PYG{n+nb}{false}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Sent another probe}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

      \PYG{k}{if} \PYG{p}{(}\PYG{o}{!} \PYG{n}{m\PYGZus{}zeroWindowProbe}\PYG{p}{)}
        \PYG{p}{\PYGZob{}}
          \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetSize} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{h}\PYG{p}{.}\PYG{n}{GetSerializedSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,}
                                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Data packet sent instead of window probe}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
          \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetSequenceNumber}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{SequenceNumber32} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
                                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Data packet sent instead of window probe}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
          \PYG{n}{m\PYGZus{}zeroWindowProbe} \PYG{o}{=} \PYG{n+nb}{true}\PYG{p}{;}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\sphinxresetverbatimhllines

We divide the events by simulated time. At line 1, we check everything that
happens before the 6.0 seconds mark; for instance, that no data packets are sent,
and that the state remains OPEN for both sender and receiver.

Since the persist timeout is initialized at 6 seconds (exercise left for the
reader: edit the test, getting this value from the Attribute system), we need
to check (line 6) between 6.0 and 7.0 simulated seconds that the probe is sent.
Only one probe is allowed, and this is the reason for the check at line 11.

\fvset{hllines={, 6, 7,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{6.0} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}}
    \PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{l+m+mf}{7.0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetSequenceNumber}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{SequenceNumber32} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Data packet sent instead of window probe}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetWindowSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,}
                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{No zero window advertised by RECEIVER}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\sphinxresetverbatimhllines

For the RECEIVER, the interval between 6 and 7 seconds is when the zero\sphinxhyphen{}window
segment is sent.

Other checks are redundant; the safest approach is to deny any other packet
exchange between the 7 and 10 seconds mark.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{else} \PYG{n+nf}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{7.0} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}}
         \PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now} \PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds} \PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}} \PYG{l+m+mf}{10.0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{NS\PYGZus{}FATAL\PYGZus{}ERROR} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{No packets should be sent before the window update}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

The state checks are performed at the end of the methods, since they are valid
in every condition:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{GetCongStateFrom} \PYG{p}{(}\PYG{n}{GetTcb}\PYG{p}{(}\PYG{n}{SENDER}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{TcpSocketState}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CA\PYGZus{}OPEN}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Sender State is not OPEN}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{GetCongStateFrom} \PYG{p}{(}\PYG{n}{GetTcb}\PYG{p}{(}\PYG{n}{RECEIVER}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{TcpSocketState}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CA\PYGZus{}OPEN}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Receiver State is not OPEN}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Now, the interesting part in the Tx method is to check that after the 10.0
seconds mark (when the RECEIVER sends the active window update) the value of
the window should be greater than zero (and precisely, set to 2500):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{else} \PYG{n+nf}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now}\PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{l+m+mf}{10.0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetWindowSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{2500}\PYG{p}{,}
                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Receiver window not updated}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

To be sure that the sender receives the window update, we can use the Rx
method:

\fvset{hllines={, 5,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{Simulator}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Now}\PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{GetSeconds}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{l+m+mf}{10.0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{h}\PYG{p}{.}\PYG{n}{GetWindowSize}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{2500}\PYG{p}{,}
                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Receiver window not updated}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{m\PYGZus{}windowUpdated} \PYG{o}{=} \PYG{n+nb}{true}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\sphinxresetverbatimhllines

We check every packet after the 10 seconds mark to see if it has the
window updated. At line 5, we also set to true a boolean variable, to check
that we effectively reach this test.

Last but not least, we implement also the NormalClose() method, to check that
the connection ends with a success:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{NormalClose} \PYG{p}{(}\PYG{n}{SocketWho} \PYG{n}{who}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{SENDER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{m\PYGZus{}senderFinished} \PYG{o}{=} \PYG{n+nb}{true}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
  \PYG{k}{else} \PYG{k}{if} \PYG{p}{(}\PYG{n}{who} \PYG{o}{=}\PYG{o}{=} \PYG{n}{RECEIVER}\PYG{p}{)}
    \PYG{p}{\PYGZob{}}
      \PYG{n}{m\PYGZus{}receiverFinished} \PYG{o}{=} \PYG{n+nb}{true}\PYG{p}{;}
    \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

The method is called only if all bytes are transmitted successfully. Then, in
the method FinalChecks(), we check all variables, which should be true (which
indicates that we have perfectly closed the connection).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void}
\PYG{n}{TcpZeroWindowTest}\PYG{o}{:}\PYG{o}{:}\PYG{n}{FinalChecks} \PYG{p}{(}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
  \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{m\PYGZus{}zeroWindowProbe}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,}
                         \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Zero window probe not sent}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{m\PYGZus{}windowUpdated}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,}
                         \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Window has not updated during the connection}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{m\PYGZus{}senderFinished}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,}
                         \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Connection not closed successfully (SENDER)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{NS\PYGZus{}TEST\PYGZus{}ASSERT\PYGZus{}MSG\PYGZus{}EQ} \PYG{p}{(}\PYG{n}{m\PYGZus{}receiverFinished}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,}
                         \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Connection not closed successfully (RECEIVER)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

To run the test, the usual way is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./test.py \PYGZhy{}s tcp\PYGZhy{}zero\PYGZhy{}window\PYGZhy{}test

PASS: TestSuite tcp\PYGZhy{}zero\PYGZhy{}window\PYGZhy{}test
\PYG{l+m}{1} of \PYG{l+m}{1} tests passed \PYG{o}{(}\PYG{l+m}{1} passed, \PYG{l+m}{0} skipped, \PYG{l+m}{0} failed, \PYG{l+m}{0} crashed, \PYG{l+m}{0} valgrind errors\PYG{o}{)}
\end{sphinxVerbatim}

To see INFO messages, use a combination of ./waf shell and gdb (really useful):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf shell \PYG{o}{\PYGZam{}\PYGZam{}} gdb \PYGZhy{}\PYGZhy{}args ./build/utils/ns3\PYGZhy{}dev\PYGZhy{}test\PYGZhy{}runner\PYGZhy{}debug \PYGZhy{}\PYGZhy{}test\PYGZhy{}name\PYG{o}{=}tcp\PYGZhy{}zero\PYGZhy{}window\PYGZhy{}test \PYGZhy{}\PYGZhy{}stop\PYGZhy{}on\PYGZhy{}failure \PYGZhy{}\PYGZhy{}fullness\PYG{o}{=}QUICK \PYGZhy{}\PYGZhy{}assert\PYGZhy{}on\PYGZhy{}failure \PYGZhy{}\PYGZhy{}verbose
\end{sphinxVerbatim}

and then, hit “Run”.

\begin{sphinxadmonition}{note}{Note:}
This code magically runs without any reported errors; however, in real cases,
when you discover a bug you should expect the existing test to fail (this
could indicate a well\sphinxhyphen{}written test and a bad\sphinxhyphen{}writted model, or a bad\sphinxhyphen{}written
test; hopefully the first situation). Correcting bugs is an iterative
process. For instance, commits created to make this test case running without
errors are 11633:6b74df04cf44, (others to be merged).
\end{sphinxadmonition}


\subsection{Network Simulation Cradle}
\label{\detokenize{tcp:network-simulation-cradle}}
The \sphinxhref{http://www.wand.net.nz/~stj2/nsc/}{Network Simulation Cradle (NSC)} is a
framework for wrapping real\sphinxhyphen{}world network code into simulators, allowing
simulation of real\sphinxhyphen{}world behavior at little extra cost. This work has been
validated by comparing situations using a test network with the same situations
in the simulator. To date, it has been shown that the NSC is able to produce
extremely accurate results. NSC supports four real world stacks: FreeBSD,
OpenBSD, lwIP and Linux. Emphasis has been placed on not changing any of the
network stacks by hand. Not a single line of code has been changed in the
network protocol implementations of any of the above four stacks. However, a
custom C parser was built to programmatically change source code.

NSC has previously been ported to \sphinxstyleemphasis{ns\sphinxhyphen{}2} and OMNeT++, and was
was added to \sphinxstyleemphasis{ns\sphinxhyphen{}3} in September 2008 (ns\sphinxhyphen{}3.2 release). This section
describes the \sphinxstyleemphasis{ns\sphinxhyphen{}3} port of NSC and how to use it.

NSC has been obsoleted by the Linux kernel support within
\sphinxhref{http://www.nsnam.org/docs/dce/manual/singlehtml/index.html}{Direct Code Execution (DCE)}. However, NSC is still available through the bake build
system. NSC supports Linux kernels 2.6.18 and 2.6.26, and an experimental
version of 2.6.29 exists on ns\sphinxhyphen{}3’s code server
(\sphinxurl{http://code.nsnam.org/fw/nsc-linux-2.6.29/}), but newer
versions of the kernel have not been ported.


\subsubsection{Prerequisites}
\label{\detokenize{tcp:prerequisites}}
Presently, NSC has been tested and shown to work on these platforms:
Linux i386 and Linux x86\sphinxhyphen{}64. NSC does not support powerpc. Use on
FreeBSD or OS X is unsupported (although it may be able to work).

Building NSC requires the packages flex and bison.

NSC requires use of gcc\sphinxhyphen{}4.9 or gcc\sphinxhyphen{}5 series, and will not build on
newer systems lacking the older compilers.


\subsubsection{Configuring and Downloading}
\label{\detokenize{tcp:configuring-and-downloading}}
NSC must either be downloaded separately from
its own repository, or downloading when using the
\sphinxhref{http://www.nsnam.org/docs/tutorial/html/getting-started.html\#downloading-ns3-using-bake}{bake build system} of
\sphinxstyleemphasis{ns\sphinxhyphen{}3}.

For ns\sphinxhyphen{}3.17 through ns\sphinxhyphen{}3.28 releases, when using bake, one obtains NSC implicitly as part of an “allinone” configuration, such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{cd} bake
\PYGZdl{} python bake.py configure \PYGZhy{}e ns\PYGZhy{}allinone\PYGZhy{}3.27
\PYGZdl{} python bake.py download
\PYGZdl{} python bake.py build
\end{sphinxVerbatim}

For ns\sphinxhyphen{}3.29 and later versions, including the ‘ns\sphinxhyphen{}3\sphinxhyphen{}allinone’ development
version, one must explicitly add NSC (‘nsc\sphinxhyphen{}0.5.3’) to the bake configuration,
such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{cd} bake
\PYGZdl{} python bake.py configure \PYGZhy{}e ns\PYGZhy{}allinone\PYGZhy{}3.29 \PYGZhy{}e nsc\PYGZhy{}0.5.3
\PYGZdl{} python bake.py download
\PYGZdl{} python bake.py build
\end{sphinxVerbatim}

Instead of a released version, one may use the ns\sphinxhyphen{}3 development version
by specifying “ns\sphinxhyphen{}3\sphinxhyphen{}allinone” to the configure step above.

NSC may also be downloaded from
\sphinxhref{http://research.wand.net.nz/software/nsc.php}{its download site}
using Mercurial:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} hg clone https://secure.wand.net.nz/mercurial/nsc
\end{sphinxVerbatim}

Prior to the ns\sphinxhyphen{}3.17 release, NSC was included in the allinone tarball and
the released version did not need to be separately downloaded.


\subsubsection{Building and validating}
\label{\detokenize{tcp:building-and-validating}}
NSC may be built as part of the bake build process; alternatively, one
may build NSC by itself using its build system; e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{cd} nsc\PYGZhy{}dev
\PYGZdl{} python scons.py
\end{sphinxVerbatim}

Once NSC has been built either manually or through the bake system, change
into the \sphinxstyleemphasis{ns\sphinxhyphen{}3} source directory and try running the following configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure
\end{sphinxVerbatim}

If NSC has been previously built and found by waf, then you will see:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Network Simulation Cradle     : enabled
\end{sphinxVerbatim}

If NSC has not been found, you will see:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Network Simulation Cradle     : not enabled \PYG{o}{(}NSC not found \PYG{o}{(}see option \PYGZhy{}\PYGZhy{}with\PYGZhy{}nsc\PYG{o}{)}\PYG{o}{)}
\end{sphinxVerbatim}

In this case, you must pass the relative or absolute path to the NSC libraries
with the “\textendash{}with\sphinxhyphen{}nsc” configure option; e.g.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}with\PYGZhy{}nsc\PYG{o}{=}/path/to/my/nsc/directory
\end{sphinxVerbatim}

For \sphinxstyleemphasis{ns\sphinxhyphen{}3} releases prior to the ns\sphinxhyphen{}3.17 release, using the \sphinxcode{\sphinxupquote{build.py}}
script in ns\sphinxhyphen{}3\sphinxhyphen{}allinone directory, NSC will be built by default unless the
platform does not support it. To explicitly disable it when building \sphinxstyleemphasis{ns\sphinxhyphen{}3},
type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}disable\PYGZhy{}nsc
\end{sphinxVerbatim}

If waf detects NSC, then building \sphinxstyleemphasis{ns\sphinxhyphen{}3} with NSC is performed the same way
with waf as without it. Once \sphinxstyleemphasis{ns\sphinxhyphen{}3} is built, try running the following
test suite:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}s ns3\PYGZhy{}tcp\PYGZhy{}interoperability
\end{sphinxVerbatim}

If NSC has been successfully built, the following test should show up
in the results:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
PASS TestSuite ns3\PYGZhy{}tcp\PYGZhy{}interoperability
\end{sphinxVerbatim}

This confirms that NSC is ready to use.


\subsubsection{Usage}
\label{\detokenize{tcp:id5}}
There are a few example files. Try:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run tcp\PYGZhy{}nsc\PYGZhy{}zoo
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run tcp\PYGZhy{}nsc\PYGZhy{}lfn
\end{sphinxVerbatim}

These examples will deposit some \sphinxcode{\sphinxupquote{.pcap}} files in your directory,
which can be examined by tcpdump or wireshark.

Let’s look at the \sphinxcode{\sphinxupquote{examples/tcp/tcp\sphinxhyphen{}nsc\sphinxhyphen{}zoo.cc}} file for some typical
usage. How does it differ from using native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP? There is one main
configuration line, when using NSC and the \sphinxstyleemphasis{ns\sphinxhyphen{}3} helper API, that needs to be
set:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{InternetStackHelper} \PYG{n}{internetStack}\PYG{p}{;}

\PYG{n}{internetStack}\PYG{p}{.}\PYG{n}{SetNscStack} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{liblinux2.6.26.so}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// this switches nodes 0 and 1 to NSCs Linux 2.6.26 stack.}
\PYG{n}{internetStack}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{.}\PYG{n}{Get}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{internetStack}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n}\PYG{p}{.}\PYG{n}{Get}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The key line is the \sphinxcode{\sphinxupquote{SetNscStack}}. This tells the InternetStack
helper to aggregate instances of NSC TCP instead of native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP
to the remaining nodes. It is important that this function be called
\sphinxstylestrong{before} calling the \sphinxcode{\sphinxupquote{Install()}} function, as shown above.

Which stacks are available to use? Presently, the focus has been on
Linux 2.6.18 and Linux 2.6.26 stacks for \sphinxstyleemphasis{ns\sphinxhyphen{}3}. To see which stacks
were built, one can execute the following find command at the \sphinxstyleemphasis{ns\sphinxhyphen{}3} top level
directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} find nsc \PYGZhy{}name \PYG{l+s+s2}{\PYGZdq{}*.so\PYGZdq{}} \PYGZhy{}type f
nsc/linux\PYGZhy{}2.6.18/liblinux2.6.18.so
nsc/linux\PYGZhy{}2.6.26/liblinux2.6.26.so
\end{sphinxVerbatim}

This tells us that we may either pass the library name liblinux2.6.18.so or
liblinux2.6.26.so to the above configuration step.


\subsubsection{Stack configuration}
\label{\detokenize{tcp:stack-configuration}}
NSC TCP shares the same configuration attributes that are common across TCP
sockets, as described above and documented in \sphinxhref{http://www.nsnam.org/doxygen/classns3\_1\_1\_tcp\_socket.html}{Doxygen}

Additionally, NSC TCP exports a lot of configuration variables into the
\sphinxstyleemphasis{ns\sphinxhyphen{}3} attributes system, via a \sphinxhref{http://en.wikipedia.org/wiki/Sysctl}{sysctl}\sphinxhyphen{}like interface. In the \sphinxcode{\sphinxupquote{examples/tcp/tcp\sphinxhyphen{}nsc\sphinxhyphen{}zoo}} example, you
can see the following configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// this disables TCP SACK, wscale and timestamps on node 1 (the attributes}
  \PYG{n}{represent} \PYG{n}{sysctl}\PYG{o}{\PYGZhy{}}\PYG{n}{values}\PYG{p}{)}\PYG{p}{.}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/1/\PYGZdl{}ns3::Ns3NscStack\PYGZlt{}linux2.6.26\PYGZgt{}/net.ipv4.tcp\PYGZus{}sack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
  \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/1/\PYGZdl{}ns3::Ns3NscStack\PYGZlt{}linux2.6.26\PYGZgt{}/net.ipv4.tcp\PYGZus{}timestamps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
\PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/1/\PYGZdl{}ns3::Ns3NscStack\PYGZlt{}linux2.6.26\PYGZgt{}/net.ipv4.tcp\PYGZus{}window\PYGZus{}scaling}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
\PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

These additional configuration variables are not available to native \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP.

Also note that default values for TCP attributes in \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP may differ from the NSC TCP implementation. Specifically in \sphinxstyleemphasis{ns\sphinxhyphen{}3}:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{)}%
\item {} 
TCP default MSS is 536

\item {} 
TCP Delayed ACK count is 2

\end{enumerate}

Therefore when making comparisons between results obtained using NSC and \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP, care must be taken to ensure these values are set appropriately. See /examples/tcp/tcp\sphinxhyphen{}nsc\sphinxhyphen{}comparison.cc for an example.


\subsubsection{NSC API}
\label{\detokenize{tcp:nsc-api}}
This subsection describes the API that NSC presents to \sphinxstyleemphasis{ns\sphinxhyphen{}3} or any other
simulator. NSC provides its API in the form of a number of classes that are
defined in \sphinxcode{\sphinxupquote{sim/sim\_interface.h}} in the nsc directory.
\begin{itemize}
\item {} 
\sphinxstylestrong{INetStack} INetStack contains the ‘low level’ operations for the operating
system network stack, e.g. in and output functions from and to the network
stack (think of this as the ‘network driver interface’). There are also
functions to create new TCP or UDP sockets.

\item {} 
\sphinxstylestrong{ISendCallback} This is called by NSC when a packet should be sent out to
the network. This simulator should use this callback to re\sphinxhyphen{}inject the packet
into the simulator so the actual data can be delivered/routed to its
destination, where it will eventually be handed into Receive() (and eventually
back to the receivers NSC instance via INetStack\sphinxhyphen{}\textgreater{}if\_receive()).

\item {} 
\sphinxstylestrong{INetStreamSocket} This is the structure defining a particular connection
endpoint (file descriptor). It contains methods to operate on this endpoint,
e.g. connect, disconnect, accept, listen, send\_data/read\_data, …

\item {} 
\sphinxstylestrong{IInterruptCallback} This contains the wakeup() callback, which is called by
NSC whenever something of interest happens. Think of wakeup() as a replacement
of the operating systems wakeup function: Whenever the operating system would
wake up a process that has been waiting for an operation to complete (for
example the TCP handshake during connect()), NSC invokes the wakeup() callback
to allow the simulator to check for state changes in its connection endpoints.

\end{itemize}


\subsubsection{ns\sphinxhyphen{}3 implementation}
\label{\detokenize{tcp:ns-3-implementation}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} implementation makes use of the above NSC API, and is implemented as
follows.

The three main parts are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::NscTcpL4Protocol}}: a subclass of Ipv4L4Protocol (and two NSC
classes: ISendCallback and IInterruptCallback)

\item {} 
\sphinxcode{\sphinxupquote{ns3::NscTcpSocketImpl}}: a subclass of TcpSocket

\item {} 
\sphinxcode{\sphinxupquote{ns3::NscTcpSocketFactoryImpl}}: a factory to create new NSC
sockets

\end{itemize}

\sphinxcode{\sphinxupquote{src/internet/model/nsc\sphinxhyphen{}tcp\sphinxhyphen{}l4\sphinxhyphen{}protocol}} is the main class. Upon
Initialization, it loads an NSC network stack to use (via dlopen()). Each
instance of this class may use a different stack. The stack (=shared library) to
use is set using the SetNscLibrary() method (at this time its called indirectly
via the internet stack helper). The NSC stack is then set up accordingly (timers
etc). The NscTcpL4Protocol::Receive() function hands the packet it receives
(must be a complete TCP/IP packet) to the NSC stack for further processing. To
be able to send packets, this class implements the NSC send\_callback() method.
This method is called by NSC whenever the NSC stack wishes to send a packet out
to the network. Its arguments are a raw buffer, containing a complete TCP/IP
packet, and a length value. This method therefore has to convert the raw data to
a Ptr\textless{}Packet\textgreater{} usable by \sphinxstyleemphasis{ns\sphinxhyphen{}3}. In order to avoid various IPv4 header issues,
the NSC IP header is not included. Instead, the TCP header and the actual
payload are put into the Ptr\textless{}Packet\textgreater{}, after this the Packet is passed down to
layer 3 for sending the packet out (no further special treatment is needed in
the send code path).

This class calls \sphinxcode{\sphinxupquote{ns3::NscTcpSocketImpl}} both from the NSC wakeup() callback
and from the receive path (to ensure that possibly queued data is scheduled for
sending).

\sphinxcode{\sphinxupquote{src/internet/model/nsc\sphinxhyphen{}tcp\sphinxhyphen{}socket\sphinxhyphen{}impl}} implements the NSC socket interface.
Each instance has its own m\_nscTcpSocket. Data that is sent will be handed to
the NSC stack via m\_nscTcpSocket\sphinxhyphen{}\textgreater{}send\_data() (and not to NscTcpL4Protocol, this
is the major difference compared to \sphinxstyleemphasis{ns\sphinxhyphen{}3} TCP). The class also queues up data
that is sent before the underlying descriptor has entered an ESTABLISHED state.
This class is called from the NscTcpL4Protocol class, when the NscTcpL4Protocol
wakeup() callback is invoked by NSC. NscTcpSocketImpl then checks the current
connection state (SYN\_SENT, ESTABLISHED, LISTEN…) and schedules appropriate
callbacks as needed, e.g. a LISTEN socket will schedule accept() to see if a new
connection must be accepted, an ESTABLISHED socket schedules any pending data
for writing, schedule a read() callback, etc.

Note that \sphinxcode{\sphinxupquote{ns3::NscTcpSocketImpl}} does not interact with NSC TCP directly:
instead, data is redirected to NSC. NSC TCP calls the NSC TCP sockets of a node
when its wakeup() callback is invoked by NSC.


\subsubsection{Limitations}
\label{\detokenize{tcp:limitations}}\begin{itemize}
\item {} 
NSC only works on single\sphinxhyphen{}interface nodes; attempting to run it on a
multi\sphinxhyphen{}interface node will cause a program error.

\item {} 
Cygwin and OS X PPC are not supported; OS X Intel is not supported but may work

\item {} 
The non\sphinxhyphen{}Linux stacks of NSC are not supported in \sphinxstyleemphasis{ns\sphinxhyphen{}3}

\item {} 
Not all socket API callbacks are supported

\end{itemize}

For more information, see \sphinxhref{http://www.nsnam.org/wiki/Network\_Simulation\_Cradle\_Integration}{this wiki page}.


\section{UDP model in ns\sphinxhyphen{}3}
\label{\detokenize{udp:udp-model-in-ns-3}}\label{\detokenize{udp::doc}}
This chapter describes the UDP model available in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.


\subsection{Generic support for UDP}
\label{\detokenize{udp:generic-support-for-udp}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} supports a native implementation of UDP. It provides a connectionless,
unreliable datagram packet service. Packets may be reordered or duplicated before
they arrive. UDP calculates and checks checksums to catch transmission errors.

This implementation inherits from a few common header classes in the \sphinxcode{\sphinxupquote{src/network}}
directory, so that user code can swap out implementations with minimal changes to
the scripts.

Here are the important abstract base classes:
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{UdpSocket}}: This is defined in:
\sphinxcode{\sphinxupquote{src/internet/model/udp\sphinxhyphen{}socket.\{cc,h\}}}
This is an abstract base class of all UDP sockets. This class exists solely
for hosting \sphinxcode{\sphinxupquote{UdpSocket}} attributes that can be reused across different
implementations, and for declaring UDP\sphinxhyphen{}specific multicast API.

\item {} 
class \sphinxcode{\sphinxupquote{UdpSocketImpl}}: This class subclasses \sphinxcode{\sphinxupquote{UdpSocket}}, and
provides a socket interface to ns\sphinxhyphen{}3’s implementation of UDP.

\item {} 
class \sphinxcode{\sphinxupquote{UdpSocketFactory}}: This is used by the layer\sphinxhyphen{}4 protocol
instance to create UDP sockets.

\item {} 
class \sphinxcode{\sphinxupquote{UdpSocketFactoryImpl}}: This class is derived from \sphinxcode{\sphinxupquote{SocketFactory}}
and implements the API for creating UDP sockets.

\item {} 
class \sphinxcode{\sphinxupquote{UdpHeader}}: This class contains fields corresponding to those
in a network UDP header (port numbers, payload size, checksum) as well as methods
for serialization to and deserialization from a byte buffer.

\item {} 
class \sphinxcode{\sphinxupquote{UdpL4Protocol}}: This is a subclass of \sphinxcode{\sphinxupquote{IpL4Protocol}} and
provides an implementation of the UDP protocol.

\end{itemize}


\subsection{ns\sphinxhyphen{}3 UDP}
\label{\detokenize{udp:ns-3-udp}}
This is an implementation of the User Datagram Protocol described in RFC 768.
UDP uses a simple connectionless communication model with a minimum of protocol
mechanism. The implementation provides checksums for data integrity, and port
numbers for addressing different functions at the source and destination of the
datagram. It has no handshaking dialogues, and thus exposes the user’s data to
any unreliability of the underlying network. There is no guarantee of data delivery,
ordering, or duplicate protection.


\subsubsection{Usage}
\label{\detokenize{udp:usage}}
In many cases, usage of UDP is set at the application layer by telling
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} application which kind of socket factory to use.

Using the helper functions defined in \sphinxcode{\sphinxupquote{src/applications/helper}}, here
is how one would create a UDP receiver:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create a packet sink on the receiver}
\PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{port} \PYG{o}{=} \PYG{l+m+mi}{50000}\PYG{p}{;}
\PYG{n}{Address} \PYG{n+nf}{sinkLocalAddress}\PYG{p}{(}\PYG{n}{InetSocketAddress} \PYG{p}{(}\PYG{n}{Ipv4Address}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetAny} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{port}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{PacketSinkHelper} \PYG{n+nf}{sinkHelper} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::UdpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sinkLocalAddress}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ApplicationContainer} \PYG{n}{sinkApp} \PYG{o}{=} \PYG{n}{sinkHelper}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{serverNode}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{sinkApp}\PYG{p}{.}\PYG{n}{Start} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{1.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{sinkApp}\PYG{p}{.}\PYG{n}{Stop} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{10.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Similarly, the below snippet configures OnOffApplication traffic source to use
UDP:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// Create the OnOff applications to send data to the UDP receiver}
\PYG{n}{OnOffHelper} \PYG{n+nf}{clientHelper} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::UdpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{Address} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{clientHelper}\PYG{p}{.}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Remote}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{remoteAddress}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ApplicationContainer} \PYG{n}{clientApps} \PYG{o}{=} \PYG{p}{(}\PYG{n}{clientHelper}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{clientNode}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{clientApps}\PYG{p}{.}\PYG{n}{Start} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{clientApps}\PYG{p}{.}\PYG{n}{Stop} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{9.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For users who wish to have a pointer to the actual socket (so that
socket operations like \sphinxcode{\sphinxupquote{Bind()}}, setting socket options, etc. can be
done on a per\sphinxhyphen{}socket basis), UDP sockets can be created by using the
\sphinxcode{\sphinxupquote{Socket::CreateSocket()}} method as given below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{InternetStackHelper} \PYG{n}{internet}\PYG{p}{;}
\PYG{n}{internet}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{node}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{SocketFactory}\PYG{o}{\PYGZgt{}} \PYG{n}{socketFactory} \PYG{o}{=} \PYG{n}{node}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{UdpSocketFactory}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{socket} \PYG{o}{=} \PYG{n}{socketFactory}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{socket}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Bind} \PYG{p}{(}\PYG{n}{InetSocketAddress} \PYG{p}{(}\PYG{n}{Ipv4Address}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetAny} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once a UDP socket is created, we do not need an explicit connection setup before
sending and receiving data. Being a connectionless protocol, all we need to do
is to create a socket and bind it to a known port. For a client, simply create a
socket and start sending data. The \sphinxcode{\sphinxupquote{Bind()}} call allows an application to specify
a port number and an address on the local machine. It allocates a local IPv4
endpoint for this socket.

At the end of data transmission, the socket is closed using the \sphinxcode{\sphinxupquote{Socket::Close()}}.
It returns a 0 on success and \sphinxhyphen{}1 on failure.

Please note that applications usually create the sockets automatically. Please
refer to the source code of your preferred application to discover how and
when it creates the socket.


\paragraph{UDP Socket interaction and interface with Application layer}
\label{\detokenize{udp:udp-socket-interaction-and-interface-with-application-layer}}
The following is the description of the public interface of the UDP socket,
and how the interface is used to interact with the socket itself.

\sphinxstylestrong{Socket APIs for UDP connections}:
\begin{description}
\item[{\sphinxstyleemphasis{Connect()}}] \leavevmode
This is called when \sphinxcode{\sphinxupquote{Send()}} is used instead of \sphinxcode{\sphinxupquote{SendTo()}} by the user.
It sets the address of the remote endpoint which is used by \sphinxcode{\sphinxupquote{Send()}}. If the
remote address is valid, this method makes a callback to \sphinxstyleemphasis{ConnectionSucceeded}.

\item[{\sphinxstyleemphasis{Bind()}}] \leavevmode
Bind the socket to an address, or to a general endpoint. A general endpoint
is an endpoint with an ephemeral port allocation (that is, a random port
allocation) on the 0.0.0.0 IP address. For instance, in current applications,
data senders usually bind automatically after a \sphinxcode{\sphinxupquote{Connect()}} over a random
port. Consequently, the connection will start from this random port towards
the well\sphinxhyphen{}defined port of the receiver. The IP 0.0.0.0 is then translated by
lower layers into the real IP of the device.

\item[{\sphinxstyleemphasis{Bind6()}}] \leavevmode
Same as \sphinxcode{\sphinxupquote{Bind()}}, but for IPv6.

\item[{\sphinxstyleemphasis{BindToNetDevice()}}] \leavevmode
Bind the socket to the specified \sphinxcode{\sphinxupquote{NetDevice}}. If set on a socket, this option
will force packets to leave the bound device regardless of the device that IP
routing would naturally choose. In the receive direction, only packets received
from the bound interface will be delivered.

\item[{\sphinxstyleemphasis{ShutdownSend()}}] \leavevmode
Signals the termination of send, or in other words, prevents data from being added
to the buffer.

\item[{\sphinxstyleemphasis{Recv()}}] \leavevmode
Grabs data from the UDP socket and forwards it to the application layer. If no
data is present (i.e. \sphinxcode{\sphinxupquote{m\_deliveryQueue.empty()}} returns 0), an empty packet is
returned.

\item[{\sphinxstyleemphasis{RecvFrom()}}] \leavevmode
Same as \sphinxcode{\sphinxupquote{Recv()}}, but with the source address as parameter.

\item[{\sphinxstyleemphasis{SendTo()}}] \leavevmode
The \sphinxcode{\sphinxupquote{SendTo()}} API is the UDP counterpart of the TCP API \sphinxcode{\sphinxupquote{Send()}}. It
additionally specifies the address to which the message is to be sent
because no prior connection is established in UDP communication. It returns
the number of bytes sent or \sphinxhyphen{}1 in case of failure.

\item[{\sphinxstyleemphasis{Close()}}] \leavevmode
The close API closes a socket and terminates the connection. This
results in freeing all the data structures previously allocated.

\end{description}


\bigskip\hrule\bigskip


\sphinxstylestrong{Public callbacks}

These callbacks are called by the UDP socket to notify the application of
interesting events. We will refer to these with the protected name used in
\sphinxcode{\sphinxupquote{socket.h}}, but we will provide the API function to set the pointers to these
callback as well.
\begin{description}
\item[{\sphinxstyleemphasis{NotifyConnectionSucceeded}: \sphinxstyleemphasis{SetConnectCallback}, 1st argument}] \leavevmode
Called when the \sphinxcode{\sphinxupquote{Connect()}} succeeds and the remote address is validated.

\item[{\sphinxstyleemphasis{NotifyConnectionFailed}: \sphinxstyleemphasis{SetConnectCallback}, 2nd argument}] \leavevmode
Called in \sphinxcode{\sphinxupquote{Connect()}} when the the remote address validation fails.

\item[{\sphinxstyleemphasis{NotifyDataSent}: \sphinxstyleemphasis{SetDataSentCallback}}] \leavevmode
The socket notifies the application that some bytes have been transmitted at
the IP layer. These bytes could still be lost in the node (traffic control
layer) or in the network.

\item[{\sphinxstyleemphasis{NotifySend}: \sphinxstyleemphasis{SetSendCallback}}] \leavevmode
Invoked to get the space available in the tx buffer when a packet (that carries
data) is sent.

\item[{\sphinxstyleemphasis{NotifyDataRecv}: \sphinxstyleemphasis{SetRecvCallback}}] \leavevmode
Called when the socket receives a packet (that carries data) in the receiver
buffer.

\end{description}


\subsubsection{Validation}
\label{\detokenize{udp:validation}}
The following test cases have been provided for UDP implementation in the
\sphinxcode{\sphinxupquote{src/internet/test/udp\sphinxhyphen{}test.cc}} file.
\begin{itemize}
\item {} 
\sphinxstylestrong{UdpSocketImplTest:} Checks data received via UDP Socket over IPv4.

\item {} 
\sphinxstylestrong{UdpSocketLoopbackTest:} Checks data received via UDP Socket Loopback over IPv4.

\item {} 
\sphinxstylestrong{Udp6SocketImplTest :} Checks data received via UDP Socket over IPv6.

\item {} 
\sphinxstylestrong{Udp6SocketLoopbackTest :} Checks data received via UDP Socket Loopback over IPv6 Test.

\end{itemize}


\subsubsection{Limitations}
\label{\detokenize{udp:limitations}}\begin{itemize}
\item {} 
UDP\_CORK is presently not the part of this implementation.

\item {} 
\sphinxcode{\sphinxupquote{NotifyNormalClose}}, \sphinxcode{\sphinxupquote{NotifyErrorClose}}, \sphinxcode{\sphinxupquote{NotifyConnectionRequest}} and
\sphinxcode{\sphinxupquote{NotifyNewConnectionCreated}} socket API callbacks are not supported.

\end{itemize}


\section{Internet Applications Module Documentation}
\label{\detokenize{internet-apps:internet-applications-module-documentation}}\label{\detokenize{internet-apps::doc}}
The goal of this module is to hold all the Internet\sphinxhyphen{}specific applications,
and most notably some very specific applications (e.g., ping) or daemons (e.g., radvd).  Other non\sphinxhyphen{}Internet\sphinxhyphen{}specific applications such as packet generators
are contained in other modules.

The source code for the new module lives in the directory \sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps}}.

Each application has its own goals, limitations and scope, which are briefly explained
in the following.

All the applications are extensively used in the top\sphinxhyphen{}level \sphinxcode{\sphinxupquote{examples}}
directories. The users are encouraged to check the scripts therein to have a
clear overview of the various options and usage tricks.


\subsection{V4Ping}
\label{\detokenize{internet-apps:v4ping}}
This app mimics a “ping” (ICMP Echo) using IPv4. The application allows the
following attributes to be set:
\begin{itemize}
\item {} 
Remote address

\item {} 
Verbose mode

\item {} 
Packet size (default 56 bytes)

\item {} 
Packet interval  (default 1 second)

\end{itemize}

Moreover, the user can access the measured RTT value (as a Traced Source).


\subsection{Ping6}
\label{\detokenize{internet-apps:ping6}}
This app mimics a “ping” (ICMP Echo) using IPv6. The application allows the
following attributes to be set:
\begin{itemize}
\item {} 
Remote address

\item {} 
Local address (sender address)

\item {} 
Packet size (default 56 bytes)

\item {} 
Packet interval  (default 1 second)

\item {} 
Max number of packets to send

\end{itemize}


\subsection{Radvd}
\label{\detokenize{internet-apps:radvd}}
This app mimics a “RADVD” daemon. I.e., the daemon responsible for IPv6 routers
advertisements. All the IPv6 routers should have a RADVD daemon installed.

The configuration of the Radvd application mimics the one of the radvd Linux program.


\subsection{DHCPv4}
\label{\detokenize{internet-apps:dhcpv4}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} implementation of Dynamic Host Configuration Protocol (DHCP)
follows the specifications of \index{RFC@\spxentry{RFC}!RFC 2131@\spxentry{RFC 2131}}\sphinxhref{https://tools.ietf.org/html/rfc2131.html}{\sphinxstylestrong{RFC 2131}} and \index{RFC@\spxentry{RFC}!RFC 2132@\spxentry{RFC 2132}}\sphinxhref{https://tools.ietf.org/html/rfc2132.html}{\sphinxstylestrong{RFC 2132}}.

The source code for DHCP is located in \sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps/model}} and consists of the
following 6 files:
\begin{itemize}
\item {} 
dhcp\sphinxhyphen{}server.h,

\item {} 
dhcp\sphinxhyphen{}server.cc,

\item {} 
dhcp\sphinxhyphen{}client.h,

\item {} 
dhcp\sphinxhyphen{}client.cc,

\item {} 
dhcp\sphinxhyphen{}header.h and

\item {} 
dhcp\sphinxhyphen{}header.cc

\end{itemize}


\subsubsection{Helpers}
\label{\detokenize{internet-apps:helpers}}
The following two files have been added to \sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps/helper}} for DHCP:
\begin{itemize}
\item {} 
dhcp\sphinxhyphen{}helper.h and

\item {} 
dhcp\sphinxhyphen{}helper.cc

\end{itemize}


\subsubsection{Tests}
\label{\detokenize{internet-apps:tests}}
The tests for DHCP can be found at \sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps/test/dhcp\sphinxhyphen{}test.cc}}


\subsubsection{Examples}
\label{\detokenize{internet-apps:examples}}
The examples for DHCP can be found at \sphinxcode{\sphinxupquote{src/internet\sphinxhyphen{}apps/examples/dhcp\sphinxhyphen{}example.cc}}


\subsubsection{Scope and Limitations}
\label{\detokenize{internet-apps:scope-and-limitations}}
The server should be provided with a network address, mask and a range of address
for the pool. One client application can be installed on only one netdevice in a
node, and can configure address for only that netdevice.

The following five basic DHCP messages are supported:
\begin{itemize}
\item {} 
DHCP DISCOVER

\item {} 
DHCP OFFER

\item {} 
DHCP REQUEST

\item {} 
DHCP ACK

\item {} 
DHCP NACK

\end{itemize}

Also, the following eight options of BootP are supported:
\begin{itemize}
\item {} 
1 (Mask)

\item {} 
50 (Requested Address)

\item {} 
51 (Address Lease Time)

\item {} 
53 (DHCP message type)

\item {} 
54 (DHCP server identifier)

\item {} 
58 (Address renew time)

\item {} 
59 (Address rebind time)

\item {} 
255 (end)

\end{itemize}

The client identifier option (61) can be implemented in near future.

In the current implementation, a DHCP client can obtain IPv4 address dynamically
from the DHCP server, and can renew it within a lease time period.

Multiple DHCP servers can be configured, but the implementation does not support
the use of a DHCP Relay yet.


\chapter{LoRaWAN Module}
\label{\detokenize{lorawan:lorawan-module}}\label{\detokenize{lorawan::doc}}
This module contains a series of classes and examples aimed at modeling the
modulation and medium access technology of a LoRaWAN network. Thanks to a simple
underlying physical layer model and to the regulations imposed on traffic in the
unlicensed bands this technology operates on, this module can support
simulations featuring a large number of devices that access the wireless channel
infrequently.

The following parts of this documentation first outline how the technology works
and then describe how it was translated into a system of classes in order to
simulate a LoRaWAN system.


\section{Technology}
\label{\detokenize{lorawan:technology}}
LoRaWAN is a Low Power Wide Area Network (LPWAN) technology built on the LoRa
modulation. This technology allows a large number of devices to communicate
wirelessly over long distances (in the order of 5\sphinxhyphen{}15 km, depending on the
propagation environment) at low data rates. The typical scenario in which this
technology is expected to be employed is that of an IoT network, where devices
need to communicate sparsely and only need short payloads to transmit
some information coming from, typically, a sensor.


\subsection{LoRa}
\label{\detokenize{lorawan:lora}}
The basis of LoRaWAN is the proprietary Long Range (LoRa) modulation, owned by
Semtech. This modulation, based on Chirp Spread Spectrum (CSS), spreads a signal
over a certain band by leveraging a chirp signal that scans the available
bandwidth linearly.

One of the key parameters of the modulation is the Spreading Factor (SF): this
value, ranging from 7 to 12, expresses how much a packet is spread in time
(i.e., how long it takes for a chirp to complete a complete scan of the
available bandwidth). Transmissions using a low SF need a lower Time on Air
(ToA) (assuming the same bandwidth) than packets using SF values closer to 12.
The advantage of using higher SFs is in the increased sensitivity of the
receiver: as an example, a transmission using SF7 that cannot be detected by a
LoRa receiver may be correctly demodulated if performed using SF12. Another
key feature of the modulation is the quasi\sphinxhyphen{}orthogonality between transmissions
using different SF values: even if two packets overlap in time, a receiver may
still be able to demodulate one of the packets, assuming that they are using
different SF and that some restrictions on their reciprocal power are respected.

More details on how the modulation works can be found in
\sphinxcite{lorawan:semtech2015modulation} (an official document explaining the modulation) and in
\sphinxcite{lorawan:knight2016reversing} (a reverse engineering of the modulation by Matt Knight).


\subsection{LoRaWAN}
\label{\detokenize{lorawan:lorawan}}
The LoRa Alliance first defined the LoRaWAN standard in \sphinxcite{lorawan:lorawanstandard},
with the objective of creating a medium access scheme and a set of network
management policies that leverage the properties of the modulation to achieve
good network performance at a low price in the complexity of the devices.

The topology of a LoRaWAN network is represented in the figure
{\hyperref[\detokenize{lorawan:lorawan-topology}]{\sphinxcrossref{\DUrole{std,std-ref}{Topology of the LoRaWAN architecture.}}}}, where dotted lines represent a LoRa wireless link while
solid lines are other kinds of high throughput, high reliability connections. It
can be seen that there are three kinds of devices in a LoRaWAN network: End
Devices (EDs), Gateways (GWs) and a Network Server (NS). End Devices are basic
network nodes: typically inexpensive, they are constrained by low computational
capabilities and are usually powered by a battery. Gateways are high\sphinxhyphen{}end, mains
powered devices that are tasked with collecting the data transmitted by End
Devices leveraging the LoRa modulation. After a packet is correctly received, it
is forwarded to the Network Server via a link with high reliability and speed.
The Network Server functions as a sink for data coming from all devices, and as
a controller of the network that can leverage some MAC commands to change
transmission settings in the End Devices.

End Devices of the most basic type are defined as Class A devices, and are
currently the only kind of device supported by this module. Class A devices
perform transmission in a totally asynchronous way, and open two receive windows
of fixed duration after each transmission to allow the Network Server to
transmit acknowledgments or MAC commands.

Another important characteristic of the standard is that it is defined to work
on unlicensed bands in various regions, which usually subject transmitters to
regulations on duty cycle. This fact will be explained in greater detail in the
MAC layer model section of this document.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{LoRaWANTopology}.pdf}
\caption{Topology of the LoRaWAN architecture.}\label{\detokenize{lorawan:id8}}\label{\detokenize{lorawan:lorawan-topology}}\end{figure}


\section{Module design}
\label{\detokenize{lorawan:module-design}}
This module comprises two main models: one for the LoRa PHY layer that needs to
represent LoRa chips and the behavior of LoRa transmissions, and one for the
LoRaWAN MAC layer, that needs to behave according to the official
specifications.

To represent these two models, the module features two generic \sphinxcode{\sphinxupquote{LoraPhy}} and
\sphinxcode{\sphinxupquote{LorawanMac}} base classes. These classes are then extended by classes that
model the peculiarities of the two wireless network devices: the End Device (ED)
and the Gateway (GW). So, the PHY layers can be modeled by use of
\sphinxcode{\sphinxupquote{EndDeviceLoraPhy}} and \sphinxcode{\sphinxupquote{GatewayLoraPhy}} classes, while objects of class
\sphinxcode{\sphinxupquote{EndDeviceLorawanMac}}, \sphinxcode{\sphinxupquote{ClassAEndDeviceLorawanMac}}, and \sphinxcode{\sphinxupquote{GatewayLorawanMac}}
are used to represent the MAC layer. A \sphinxcode{\sphinxupquote{NetworkServer}} application can also be
installed on a node that will then administer the wireless network through the
GW’s forwarding application, \sphinxcode{\sphinxupquote{Forwarder}}, which leverages the gateway’s LoRa
communication capabilities to forward to End Devices the Network Server’s
packets.


\subsection{PHY layer model}
\label{\detokenize{lorawan:phy-layer-model}}
The model for the PHY layer needs to take into account the two key factors of
LoRa, sensitivity and orthogonality, to decide whether a transmission is
received correctly or not. Besides, it also needs to be aware of how the chips
implementing the modulation work, and of their architecture.


\subsubsection{Link model}
\label{\detokenize{lorawan:link-model}}
The link model takes into account three main components to determine the
performance of a LoRa transmission:
\begin{itemize}
\item {} 
Data about device sensitivity taken from device datasheets;

\item {} 
A model to account for the interference between different LoRa transmissions;

\item {} 
A series of assumptions regarding this interference model.

\end{itemize}

In this section, we will describe each portion of the model with a particular
focus on its implementation in the code.

The \sphinxcode{\sphinxupquote{LoraChannel}} class is used to interconnect the LoRa PHY layers of all
devices wishing to communicate using this technology. The class holds a list of
connected PHY layers, and notifies them about incoming transmissions, following
the same paradigm of other \sphinxcode{\sphinxupquote{Channel}} classes in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

PHY layers that are connected to the channel expose a public \sphinxcode{\sphinxupquote{StartReceive}}
method that allows the channel to start reception at a certain PHY. At this
point, these PHY classes rely on a \sphinxcode{\sphinxupquote{LoraInterferenceHelper}} object to keep
track of all incoming packets, both as potentially desirable packets and as
interference. Once the channel notifies the PHY layer of the incoming packet,
the PHY informs its \sphinxcode{\sphinxupquote{LoraInterferenceHelper}} right away of the incoming
transmission. After this, if a PHY fills certain prerequisites, it can lock on
the incoming packet for reception. In order to do so:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
The receiver must be idle (in STANDBY state) when the \sphinxcode{\sphinxupquote{StartReceive}}
function is called;

\item {} 
The packet receive power must be above a sensitivity threshold;

\item {} 
The receiver must be listening on the correct frequency;

\item {} 
The receiver must be listening for the correct SF.

\end{enumerate}

The sensitivity threshold that is currently implemented can be seen below
(values in dBm):
\begin{equation*}
\begin{split}\begin{matrix}
\scriptstyle{\rm SF7} & \scriptstyle{\rm SF8} & \scriptstyle{\rm SF9} & \scriptstyle{\rm SF10} & \scriptstyle{\rm SF11} & \scriptstyle{\rm SF12}\\
-124 & -127 & -130 & -133 & -135 & -137 \\
\end{matrix}\end{split}
\end{equation*}
After the PHY layer locks on the incoming packet, it schedules an \sphinxcode{\sphinxupquote{EndReceive}}
function call after the packet duration. The reception power is considered to be
constant throughout the packet reception process. When reception ends,
\sphinxcode{\sphinxupquote{EndReceive}} calls the \sphinxcode{\sphinxupquote{IsDestroyedByInterference}} method of the PHY’s
instance of \sphinxcode{\sphinxupquote{LoraInterferenceHelper}} to determine whether the packet is lost
due to interference.

The \sphinxcode{\sphinxupquote{IsDestroyedByInterference}} function compares the desired packet’s
reception power with the interference energy of packets that overlap with it on
a SF basis, and compares the obtained SIR value against the isolation matrix
that was tabulated in \sphinxcite{lorawan:goursaud2015dedicated} and reproduced below. For
example, if the desired packet is using SF7, and it is (even partially)
overlapped to two packets using SF10, the desired signal’s energy (computed as
the product of reception power and signal duration) is compared to the summed
energy of the two interferers (computed as the product of the interferer’s power
at the receiver and overlap time). The ratio between the desired and the
interference energy from each spreading factor (considered separately) is then
compared to the table below, in which rows identify the desired signal’s SF,
while columns represent the interfering SF that is currently being considered.
If the SIR is above the tabulated threshold, the packet is received correctly
and forwarded to the MAC layer.
\begin{equation*}
\begin{split}\begin{matrix}
 & \scriptstyle{\rm SF7 } & \scriptstyle{\rm SF8 }& \scriptstyle{\rm SF9 }& \scriptstyle{\rm SF10} & \scriptstyle{\rm SF11} & \scriptstyle{\rm SF12}\\
\scriptstyle{\rm SF7 }& 6    &-16    &-18    &-19    &-19    &-20\\
\scriptstyle{\rm SF8 }& -24  &6      &-20    &-22    &-22    &-22\\
\scriptstyle{\rm SF9 }& -27  &-27    &6      &-23    &-25    &-25\\
\scriptstyle{\rm SF10} & -30 &-30    &-30    &6      &-26    &-28\\
\scriptstyle{\rm SF11} & -33 &-33    &-33    &-33    &6      &-29\\
\scriptstyle{\rm SF12} & -36 &-36    &-36    &-36    &-36    &6\\
\end{matrix}\end{split}
\end{equation*}
A full description of the link layer model can also be found in
\sphinxcite{lorawan:magrin2017performance} and in \sphinxcite{lorawan:magrin2017thesis}.


\subsubsection{Gateway model}
\label{\detokenize{lorawan:gateway-model}}
The chip installed on LoRa GWs needs special attention because of its
architecture: since it is characterized by the presence of 8 parallel \sphinxstyleemphasis{receive
paths}, it can receive multiple packets in parallel \sphinxcite{lorawan:sx1301}. This
behavior is represented in the simulator through a \sphinxcode{\sphinxupquote{ReceptionPath}} object that
behaves as an \sphinxcode{\sphinxupquote{EndDeviceLoraPhy}}, locking into incoming packets and comparing
them to others to determine correct reception by using the gateway’s
\sphinxcode{\sphinxupquote{LoraInterferenceHelper}} instance. A \sphinxcode{\sphinxupquote{GatewayLoraPhy}}, then, is essentially
a manager of this collection of \sphinxcode{\sphinxupquote{ReceptionPath}} objects. Upon arrival of a
packet, the gateway picks a free reception path (if there are any), marks it as
occupied and locks it into the incoming packet. Once the scheduled
\sphinxcode{\sphinxupquote{EndReceive}} method is executed, the gateway’s \sphinxcode{\sphinxupquote{LoraInterferenceHelper}}
(which contains information used by all \sphinxcode{\sphinxupquote{ReceptionPaths}}) is queried, and it
is decided whether the packet is correctly received or not.

Some further assumptions on the collaboration behavior of these reception paths
were made to establish a consistent model despite the SX1301 gateway chip
datasheet not going into full detail on how the chip administers the available
reception paths:
\begin{itemize}
\item {} 
Receive paths can be configured to listen for incoming packets on any
frequency;

\item {} 
Receive paths can be allocated freely on the available frequencies;

\item {} 
Receive paths don’t need to be pre\sphinxhyphen{}configured to listen for a certain
spreading factor (thus, point 4 of the prerequisites stated above for End
Devices doesn’t apply);

\item {} 
If a packet is incoming and multiple receive paths are listening for the same
channel, only one locks into the incoming packet;

\item {} 
If all reception paths listening on a channel are locked into an incoming
packet and another packet arrives, the new packet is immediately marked as
lost.

\end{itemize}


\subsection{MAC layer model}
\label{\detokenize{lorawan:mac-layer-model}}
The MAC models contained in this module aim at implementing the LoRaWAN
standard. To facilitate this task, a series of side classes were created to
handle headers, MAC commands, logical channels and duty cycle computations.
Furthermore, a simplified version of a Network Server (NS) is also provided in
the form of an application that can be installed on a \sphinxstyleemphasis{ns\sphinxhyphen{}3} \sphinxcode{\sphinxupquote{Node}} and
connected to the GWs via a \sphinxcode{\sphinxupquote{PointToPoint}} link to also simulate a backbone
channel.


\subsubsection{Headers, MAC commands and addressing system}
\label{\detokenize{lorawan:headers-mac-commands-and-addressing-system}}
The packet structure defined by the LoRaWAN standard is implemented through two
classes that extend the \sphinxcode{\sphinxupquote{Header}} class: \sphinxcode{\sphinxupquote{LorawanMacHeader}} and
\sphinxcode{\sphinxupquote{LoraFrameHeader}}. In particular, \sphinxcode{\sphinxupquote{LoraFrameHeader}} can include MAC commands
by leveraging the \sphinxcode{\sphinxupquote{MacCommand}} and \sphinxcode{\sphinxupquote{LoraDeviceAddress}} classes, that are
used to make serialization, deserialization and interpretation of MAC commands
and the LoRaWAN address system easier.

MAC commands are implemented by extending the \sphinxcode{\sphinxupquote{MacCommand}} class. Each child
class is used to define a set of command variables, methods to serialize and
deserialize the commands inside a \sphinxcode{\sphinxupquote{LoraFrameHeader}}, and callbacks to the MAC
layer to perform actions. This structure can facilitate the implementation and
testing of custom MAC commands, as allowed by the specification.

The \sphinxcode{\sphinxupquote{LoraDeviceAddress}} class is used to represent the address of a LoRaWAN
ED, and to handle serialization and deserialization.


\subsubsection{Logical channels and duty cycle}
\label{\detokenize{lorawan:logical-channels-and-duty-cycle}}
Since LoRaWAN operates in unlicensed bands that are subject to restrictions on
duty cycle, a series of objects were created to keep track of available
transmission time and limit transmission at the MAC layer in case the layers
above aren’t aware of these limitations. A \sphinxcode{\sphinxupquote{LogicalLoraChannelHelper}} is
assigned to each \sphinxcode{\sphinxupquote{LorawanMac}} instance, and is tasked with keeping track of all
available logical channels (which can be added and modified with MAC commands,
and are represented by the \sphinxcode{\sphinxupquote{LogicalLoraChannel}} class) and is aware of the
sub\sphinxhyphen{}band they are in (through instances of the \sphinxcode{\sphinxupquote{SubBand}} class).

Additionally, in order to enforce duty cycle limitations, this object also
registers all transmissions that are performed on each channel, and can be
queried by the \sphinxcode{\sphinxupquote{LorawanMac}} instance to know the next time in which transmission
will be possible according to the regulation. If a transmission of duration
\(t_{\rm air}\) is performed by the device on a channel where the duty cycle
expressed in fractional form is \(\rm dc\), the time the device needs to
stay off is computed according to the following formula:
\begin{equation*}
\begin{split}t_{\rm off} = \frac{t_{\rm air}}{\rm dc} - t_{\rm air}\end{split}
\end{equation*}
This time is kept track of on a sub band basis, so that if two channels are
under the same regulation, a transmission on one of them will also block the
other one.


\subsection{The Network Server}
\label{\detokenize{lorawan:the-network-server}}
The \sphinxcode{\sphinxupquote{NetworkServer}} is an application which is running on a node that is
connected to the simulation GWs. The GWs forward incoming LoRa packets to the
NS, and expect to be given packets to transmit in the downlink to EDs by the NS.
In order to keep track of all players in the network, the NS keeps two lists of
\sphinxcode{\sphinxupquote{DeviceStatus}} and \sphinxcode{\sphinxupquote{GatewayStatus}} objects, which represent the current
status of each ED and GW in the network, respectively. These objects are used to
keep track of downlink packets that will need to be sent during the ED’s receive
windows, and they also hold pointers to the Mac layer instances of each GW. This
is done in order to be able to perform queries on the gateway’s current duty
cycle limitations and always forward downlink packets to gateways that will be
able to transmit the packet in the LoRa network. The current iteration of the
Network Server only sends downlink packets to devices that require an
acknowledgment, ignoring the contents of the packet and of MAC commands it may
contain. Transmission is performed on the first receive window whenever
possible, and the second receive window is used only when no more resources are
available to leverage the first chance to respond to the device. More complex
and realistic NS behaviors are definitely possible, however they also come at a
complexity cost that is non\sphinxhyphen{}negligible.


\section{Scope and Limitations}
\label{\detokenize{lorawan:scope-and-limitations}}
Since this is still a first version of the module, a few caveats are listed
below.


\subsection{Inter\sphinxhyphen{}protocol interference}
\label{\detokenize{lorawan:inter-protocol-interference}}
Since the \sphinxcode{\sphinxupquote{LoraChannel}} class can only be connected to LoRa PHY layers, the
model is currently unable to account for interference by other technologies.

It’s expected that it will become possible, in the future, to handle
inter\sphinxhyphen{}protocol interference by leveraging the \sphinxcode{\sphinxupquote{SpectrumChannel}} class, once
more accurate models of how interference affects LoRa signals become available.


\subsection{Inter\sphinxhyphen{}channel interference}
\label{\detokenize{lorawan:inter-channel-interference}}
Interference between partially overlapping channels is not checked for.
Furthermore, there currently is no model to account for interference between
signals using different bandwidths.


\subsection{Network Server}
\label{\detokenize{lorawan:network-server}}
The current implementation of the Network Server tries to provide a general
structure to handle EDs and GWs in a network, but still lacks some possibly
complex code to simulate advanced features like different Adaptive Data Rate
(ADR) algorithms, responding to the ED’s MAC commands and supporting join
procedures. Other limitations of the Network Server is that it doesn’t employ a
protocol to communicate with the Gateways (since no official ones exist), and
that it informs the gateway in real time about downlink messages it needs to
send (in other words, no “booking” of the gateway resource is done in advance,
and downlink packets take priority over incoming packets at the gateway).

As of now, the Network Server implementation should be considered as an
experimental feature, prone to yet undiscovered bugs.


\subsection{Device Classes}
\label{\detokenize{lorawan:device-classes}}
Currently, only Class A End Devices are supported.


\subsection{Regional parameters}
\label{\detokenize{lorawan:regional-parameters}}
Since LoRaWAN parameters like default channel lineup and MAC command
interpretations vary based on the operational region of the network,
\sphinxcode{\sphinxupquote{LorawanMacHelper}} includes methods to specify the region. While the current
implementation is predisposed to support different configurations of the network
based on the region it’s meant to be operating in, currently only the EU region
using the 868 MHz sub band is supported.


\subsection{MAC layer details}
\label{\detokenize{lorawan:mac-layer-details}}
Some details that are not crucial for the evaluation of the system performance
of a network still need to be implemented. These include:
\begin{itemize}
\item {} 
Frame counters, both at the End Devices and at the Network Server’s
DeviceStatus

\item {} 
Proper setting of ADR flags (no ADR mechanism is implemented still)

\item {} 
Join procedure management (both at the NS and at the EDs)

\end{itemize}


\section{Usage}
\label{\detokenize{lorawan:usage}}
A typical usage of the model follows some typical \sphinxstyleemphasis{ns\sphinxhyphen{}3} paradigms, like the
usage of helpers to configure a complex network. This section illustrates the
setup of a LoRaWAN network using the module and some other side classes that
weren’t described in the previous sections because they are mainly used to
configure the network.


\subsection{Helpers}
\label{\detokenize{lorawan:helpers}}
The \sphinxcode{\sphinxupquote{lorawan}} module features helpers to configure the PHY and MAC layers on a
large number of devices. The two layers are split in two different classes,
\sphinxcode{\sphinxupquote{LorawanMacHelper}} and \sphinxcode{\sphinxupquote{LoraPhyHelper}}, which can be leveraged by a
\sphinxcode{\sphinxupquote{LoraHelper}} object to fully configure a LoRa device (both for EDs and for
GWs). Since the helpers are general purpose (i.e., they can be used both for ED
and GW configuration), it is necessary to specify the device type via the
\sphinxcode{\sphinxupquote{SetDeviceType}} method before the \sphinxcode{\sphinxupquote{Install}} method can be called.

The \sphinxcode{\sphinxupquote{LorawanMacHelper}} also exposes a method to set up the Spreading Factors used
by the devices participating in the network automatically, based on the channel
conditions and on the placement of devices and gateways. This procedure is
contained in the static method \sphinxcode{\sphinxupquote{SetSpreadingFactorsUp}}, and works by trying to
minimize the time\sphinxhyphen{}on\sphinxhyphen{}air of packets, thus assigning the lowest possible
spreading factor such that reception by at least one gateway is still possible.
It should be noted that this is an heuristic, and that it doesn’t guarantee that
the SF distribution is optimal for the best possible operation of the network.
In fact, finding such a distribution based on the network scenario is still an
open challenge.


\subsection{Attributes}
\label{\detokenize{lorawan:attributes}}
Currently, the following attributes are available:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Interval}} and \sphinxcode{\sphinxupquote{PacketSize}} in \sphinxcode{\sphinxupquote{PeriodicSender}} determine the interval
between packet sends of the application, and the size of the packets that are
generated by the application.

\end{itemize}


\subsection{Trace Sources}
\label{\detokenize{lorawan:trace-sources}}
Various trace sources can be used to keep track of events throughout the
simulation, mainly regarding the lifetime of a packet. At the PHY layer, the
following trace sources are exposed:
\begin{itemize}
\item {} 
In \sphinxcode{\sphinxupquote{LoraPhy}} (both \sphinxcode{\sphinxupquote{EndDeviceLoraPhy}} and \sphinxcode{\sphinxupquote{GatewayLoraPhy}}):
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{StartSending}}, fired when a PHY layer begins transmitting a packet;

\item {} 
\sphinxcode{\sphinxupquote{PhyRxBegin}}, fired when a PHY layer becomes locked on a packet;

\item {} 
\sphinxcode{\sphinxupquote{PhyRxEnd}}, fired when a PHY’s reception of a packet ends;

\item {} 
\sphinxcode{\sphinxupquote{ReceivedPacket}}, fired when a packet is correctly received;

\item {} 
\sphinxcode{\sphinxupquote{LostPacketBecauseInterference}}, fired when a packet is lost because of
interference from other transmissions;

\item {} 
\sphinxcode{\sphinxupquote{LostPacketBecauseUnderSensitivity}}, fired when a PHY cannot lock on a
packet because it’s being received with a power below the device sensitivity;

\end{itemize}

\item {} 
In \sphinxcode{\sphinxupquote{EndDeviceLoraPhy}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{LoraPacketBecauseWrongFrequency}} is fired when an incoming packet is
using a frequency that is different from that on which the PHY is listening;

\item {} 
\sphinxcode{\sphinxupquote{LoraPacketBecauseWrongSpreadingFactor}} is fired when an incoming packet
is using a SF that is different from that for which the PHY is listening;

\item {} 
\sphinxcode{\sphinxupquote{EndDeviceState}} is used to keep track of the state of the device’s PHY
layer.

\end{itemize}

\item {} 
In \sphinxcode{\sphinxupquote{GatewayLoraPhy}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{LostPacketBecauseNoMoreReceivers}} is fired when a packet is lost because
no more receive paths are available to lock onto the incoming packet;

\item {} 
\sphinxcode{\sphinxupquote{OccupiedReceptionPaths}} is used to keep track of the number of occupied
reception paths out of the 8 that are available at the gateway;

\end{itemize}

\item {} 
In \sphinxcode{\sphinxupquote{LorawanMac}} (both \sphinxcode{\sphinxupquote{EndDeviceLorawanMac}} and \sphinxcode{\sphinxupquote{GatewayLorawanMac}}):
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{CannotSendBecauseDutyCycle}} is used to keep track of the number of when a
packet coming from the application layer cannot be sent on any of the
available channels because of duty cycle limitations;

\end{itemize}

\item {} 
In \sphinxcode{\sphinxupquote{EndDeviceLorawanMac}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{DataRate}} keeps track of the data rate that is employed by the device;

\item {} 
\sphinxcode{\sphinxupquote{LastKnownLinkMargin}} keeps track of the last link margin of this device’s
uplink transmissions; This information is gathered through the \sphinxcode{\sphinxupquote{LinkCheck}}
MAC commands;

\item {} 
\sphinxcode{\sphinxupquote{LastKnownGatewayCount}} keeps track of the last known number of gateways
that this device is able to reach; This information is gathered through the
\sphinxcode{\sphinxupquote{LinkCheck}} MAC commands;

\item {} 
\sphinxcode{\sphinxupquote{AggregatedDutyCycle}} keeps track of the currently set aggregated duty
cycle limitations;

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{PacketSent}} in \sphinxcode{\sphinxupquote{LoraChannel}} is fired when a packet is sent on the channel;

\end{itemize}


\section{Examples}
\label{\detokenize{lorawan:examples}}

\subsection{simple\sphinxhyphen{}lorawan\sphinxhyphen{}network\sphinxhyphen{}example}
\label{\detokenize{lorawan:simple-lorawan-network-example}}
This example is used to showcase how wireless communication between a device and
a gateway happens: one LoRa ED is configured to send a packet, and a GW receives
it. When logging is enabled, the various steps that are needed to send a packet
from the APP layer of an ED to the MAC layer of a GW can be observed.


\subsection{network\sphinxhyphen{}server\sphinxhyphen{}example}
\label{\detokenize{lorawan:network-server-example}}
This example builds on the \sphinxcode{\sphinxupquote{simple\sphinxhyphen{}lorawan\sphinxhyphen{}network\sphinxhyphen{}example}} to add a Network
Server and multiple EDs and GWs to the scenario. This example works as a
showcase for how communication between the End Devices and the Network Server
happens.


\subsection{complete\sphinxhyphen{}lorawan\sphinxhyphen{}network\sphinxhyphen{}example}
\label{\detokenize{lorawan:complete-lorawan-network-example}}
This example shows how to configure a whole LoRaWAN network using the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
\sphinxcode{\sphinxupquote{lorawan}} module. A big network featuring several thousand devices and tens of
gateways is built, and each device is equipped with a \sphinxcode{\sphinxupquote{PeriodicSender}}
application that periodically sends a packet to the NetworkServer through the
Gateways. The example keeps track of the sent and received packets, and computes
some statistics at the end of the simulation. No Network Server is used in this
simulation, since performance metrics are collected through the GW trace sources
and packets don’t require an acknowledgment.


\section{Tests}
\label{\detokenize{lorawan:tests}}
Tests are contained in the \sphinxcode{\sphinxupquote{lorawan\sphinxhyphen{}test\sphinxhyphen{}suite.cc}} file. The tests currently
cover the following classes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{LoraInterferenceHelper}}

\item {} 
\sphinxcode{\sphinxupquote{LoraDeviceAddress}} and \sphinxcode{\sphinxupquote{LoraDeviceAddressHelper}}

\item {} 
\sphinxcode{\sphinxupquote{LoraFrameHeader}} and \sphinxcode{\sphinxupquote{LorawanMacHeader}}

\item {} 
\sphinxcode{\sphinxupquote{ReceivePath}} and \sphinxcode{\sphinxupquote{GatewayLoraPhy}}

\item {} 
\sphinxcode{\sphinxupquote{LogicalLoraChannel}} and \sphinxcode{\sphinxupquote{LogicalLoraChannelHelper}}

\item {} 
\sphinxcode{\sphinxupquote{LoraPhy}}

\item {} 
\sphinxcode{\sphinxupquote{EndDeviceLoraPhy}} and \sphinxcode{\sphinxupquote{LoraChannel}}

\end{itemize}


\section{References}
\label{\detokenize{lorawan:references}}
PageBreak


\chapter{Low\sphinxhyphen{}Rate Wireless Personal Area Network (LR\sphinxhyphen{}WPAN)}
\label{\detokenize{lr-wpan:low-rate-wireless-personal-area-network-lr-wpan}}\label{\detokenize{lr-wpan::doc}}
This chapter describes the implementation of ns\sphinxhyphen{}3 models for the
low\sphinxhyphen{}rate, wireless personal area network (LR\sphinxhyphen{}WPAN) as specified by
IEEE standard 802.15.4 (2006).


\section{Model Description}
\label{\detokenize{lr-wpan:model-description}}
The source code for the lr\sphinxhyphen{}wpan module lives in the directory \sphinxcode{\sphinxupquote{src/lr\sphinxhyphen{}wpan}}.


\subsection{Design}
\label{\detokenize{lr-wpan:design}}
The model design closely follows the standard from an architectural standpoint.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lr-wpan-arch}.pdf}
\caption{Architecture and scope of lr\sphinxhyphen{}wpan models}\label{\detokenize{lr-wpan:id1}}\label{\detokenize{lr-wpan:fig-lr-wpan-arch}}\end{figure}

The grey areas in the figure (adapted from Fig 3. of IEEE Std. 802.15.4\sphinxhyphen{}2006)
show the scope of the model.

The Spectrum NetDevice from Nicola Baldo is the basis for the implementation.

The implementation also plans to borrow from the ns\sphinxhyphen{}2 models developed by
Zheng and Lee in the future.


\subsubsection{APIs}
\label{\detokenize{lr-wpan:apis}}
The APIs closely follow the standard, adapted for ns\sphinxhyphen{}3 naming conventions
and idioms.  The APIs are organized around the concept of service primitives
as shown in the following figure adapted from Figure 14 of
IEEE Std. 802.15.4\sphinxhyphen{}2006.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lr-wpan-primitives}.pdf}
\caption{Service primitives}\label{\detokenize{lr-wpan:id2}}\label{\detokenize{lr-wpan:fig-lr-wpan-primitives}}\end{figure}

The APIs are organized around four conceptual services and service access
points (SAP):
\begin{itemize}
\item {} 
MAC data service (MCPS)

\item {} 
MAC management service  (MLME)

\item {} 
PHY data service (PD)

\item {} 
PHY management service (PLME)

\end{itemize}

In general, primitives are standardized as follows (e.g. Sec 7.1.1.1.1
of IEEE 802.15.4\sphinxhyphen{}2006)::

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{MCPS}\PYG{o}{\PYGZhy{}}\PYG{n}{DATA}\PYG{o}{.}\PYG{n}{request}      \PYG{p}{(}
                        \PYG{n}{SrcAddrMode}\PYG{p}{,}
                        \PYG{n}{DstAddrMode}\PYG{p}{,}
                        \PYG{n}{DstPANId}\PYG{p}{,}
                        \PYG{n}{DstAddr}\PYG{p}{,}
                        \PYG{n}{msduLength}\PYG{p}{,}
                        \PYG{n}{msdu}\PYG{p}{,}
                        \PYG{n}{msduHandle}\PYG{p}{,}
                        \PYG{n}{TxOptions}\PYG{p}{,}
                        \PYG{n}{SecurityLevel}\PYG{p}{,}
                        \PYG{n}{KeyIdMode}\PYG{p}{,}
                        \PYG{n}{KeySource}\PYG{p}{,}
                        \PYG{n}{KeyIndex}
                        \PYG{p}{)}
\end{sphinxVerbatim}

This maps to ns\sphinxhyphen{}3 classes and methods such as::

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{struct} \PYG{n}{McpsDataRequestParameters}
\PYG{p}{\PYGZob{}}
  \PYG{n}{uint8\PYGZus{}t} \PYG{n}{m\PYGZus{}srcAddrMode}\PYG{p}{;}
  \PYG{n}{uint8\PYGZus{}t} \PYG{n}{m\PYGZus{}dstAddrMode}\PYG{p}{;}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}

\PYG{n}{void}
\PYG{n}{LrWpanMac}\PYG{p}{:}\PYG{p}{:}\PYG{n}{McpsDataRequest} \PYG{p}{(}\PYG{n}{McpsDataRequestParameters} \PYG{n}{params}\PYG{p}{)}
\PYG{p}{\PYGZob{}}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsubsection{MAC}
\label{\detokenize{lr-wpan:mac}}
The MAC at present implements the unslotted CSMA/CA variant, without beaconing.
Currently there is no support for coordinators and the relevant APIs.

The implemented MAC is similar to Contiki’s NullMAC, i.e., a MAC without sleep
features. The radio is assumed to be always active (receiving or transmitting),
of completely shut down. Frame reception is not disabled while performing the
CCA.

The main API supported is the data transfer API
(McpsDataRequest/Indication/Confirm).  CSMA/CA according to Stc 802.15.4\sphinxhyphen{}2006,
section 7.5.1.4 is supported. Frame reception and rejection according to
Std 802.15.4\sphinxhyphen{}2006, section 7.5.6.2 is supported, including acknowledgements.
Only short addressing completely implemented. Various trace sources are
supported, and trace sources can be hooked to sinks.


\subsubsection{PHY}
\label{\detokenize{lr-wpan:phy}}
The physical layer components consist of a Phy model, an error rate model,
and a loss model.  The error rate model presently models the error rate
for IEEE 802.15.4 2.4 GHz AWGN channel for OQPSK; the model description can
be found in IEEE Std 802.15.4\sphinxhyphen{}2006, section E.4.1.7.   The Phy model is
based on SpectrumPhy and it follows specification described in section 6
of IEEE Std 802.15.4\sphinxhyphen{}2006. It models PHY service specifications, PPDU
formats, PHY constants and PIB attributes. It currently only supports
the transmit power spectral density mask specified in 2.4 GHz per section
6.5.3.1. The noise power density assumes uniformly distributed thermal
noise across the frequency bands. The loss model can fully utilize all
existing simple (non\sphinxhyphen{}spectrum phy) loss models. The Phy model uses
the existing single spectrum channel model.
The physical layer is modeled on packet level, that is, no preamble/SFD
detection is done. Packet reception will be started with the first bit of the
preamble (which is not modeled), if the SNR is more than \sphinxhyphen{}5 dB, see IEEE
Std 802.15.4\sphinxhyphen{}2006, appendix E, Figure E.2. Reception of the packet will finish
after the packet was completely transmitted. Other packets arriving during
reception will add up to the interference/noise.

Currently the receiver sensitivity is set to a fixed value of \sphinxhyphen{}106.58 dBm. This
corresponds to a packet error rate of 1\% for 20 byte reference packets for this
signal power, according to IEEE Std 802.15.4\sphinxhyphen{}2006, section 6.1.7. In the future
we will provide support for changing the sensitivity to different values.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{802-15-4-per-sens}.pdf}
\caption{Packet error rate vs. signal power}\label{\detokenize{lr-wpan:id3}}\label{\detokenize{lr-wpan:fig-802-15-4-per-sens}}\end{figure}


\subsubsection{NetDevice}
\label{\detokenize{lr-wpan:netdevice}}
Although it is expected that other technology profiles (such as
6LoWPAN and ZigBee) will write their own NetDevice classes, a basic
LrWpanNetDevice is provided, which encapsulates the common operations
of creating a generic LrWpan device and hooking things together.


\subsection{Scope and Limitations}
\label{\detokenize{lr-wpan:scope-and-limitations}}
Future versions of this document will contain a PICS proforma similar to
Appendix D of IEEE 802.15.4\sphinxhyphen{}2006.  The current emphasis is on the
unslotted mode of 802.15.4 operation for use in Zigbee, and the scope
is limited to enabling a single mode (CSMA/CA) with basic data transfer
capabilities. Association with PAN coordinators is not yet supported, nor the
use of extended addressing. Interference is modeled as AWGN but this is
currently not thoroughly tested.

The NetDevice Tx queue is not limited, i.e., packets are never dropped
due to queue becoming full. They may be dropped due to excessive transmission
retries or channel access failure.


\subsection{References}
\label{\detokenize{lr-wpan:references}}\begin{itemize}
\item {} 
Wireless Medium Access Control (MAC) and Physical Layer (PHY) Specifications for Low\sphinxhyphen{}Rate Wireless Personal Area Networks (WPANs), IEEE Computer Society, IEEE Std 802.15.4\sphinxhyphen{}2006, 8 September 2006.

\item {} \begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{9}
\item {} 
Zheng and Myung J. Lee, “A comprehensive performance study of IEEE 802.15.4,” Sensor Network Operations, IEEE Press, Wiley Interscience, Chapter 4, pp. 218\sphinxhyphen{}237, 2006.

\end{enumerate}

\end{itemize}


\section{Usage}
\label{\detokenize{lr-wpan:usage}}

\subsection{Enabling lr\sphinxhyphen{}wpan}
\label{\detokenize{lr-wpan:enabling-lr-wpan}}
Add \sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan}} to the list of modules built with ns\sphinxhyphen{}3.


\subsection{Helper}
\label{\detokenize{lr-wpan:helper}}
The helper is patterned after other device helpers.  In particular,
tracing (ascii and pcap) is enabled similarly, and enabling of all
lr\sphinxhyphen{}wpan log components is performed similarly.  Use of the helper
is exemplified in \sphinxcode{\sphinxupquote{examples/lr\sphinxhyphen{}wpan\sphinxhyphen{}data.cc}}.  For ascii tracing,
the transmit and receive traces are hooked at the Mac layer.

The default propagation loss model added to the channel, when this helper
is used, is the LogDistancePropagationLossModel with default parameters.


\subsection{Examples}
\label{\detokenize{lr-wpan:examples}}
The following examples have been written, which can be found in \sphinxcode{\sphinxupquote{src/lr\sphinxhyphen{}wpan/examples/}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}data.cc}}:  A simple example showing end\sphinxhyphen{}to\sphinxhyphen{}end data transfer.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}distance\sphinxhyphen{}plot.cc}}:  An example to plot variations of the packet success ratio as a function of distance.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}model\sphinxhyphen{}plot.cc}}:  An example to test the phy.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}packet\sphinxhyphen{}print.cc}}:  An example to print out the MAC header fields.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}phy\sphinxhyphen{}test.cc}}:  An example to test the phy.

\end{itemize}

In particular, the module enables a very simplified end\sphinxhyphen{}to\sphinxhyphen{}end data
transfer scenario, implemented in \sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}data.cc}}.  The figure
shows a sequence of events that are triggered when the MAC receives
a DataRequest from the higher layer.  It invokes a Clear Channel
Assessment (CCA) from the PHY, and if successful, sends the frame
down to the PHY where it is transmitted over the channel and results
in a DataIndication on the peer node.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lr-wpan-data-example}.pdf}
\caption{Data example for simple LR\sphinxhyphen{}WPAN data transfer end\sphinxhyphen{}to\sphinxhyphen{}end}\label{\detokenize{lr-wpan:id4}}\label{\detokenize{lr-wpan:fig-lr-wpan-data}}\end{figure}

The example \sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}distance\sphinxhyphen{}plot.cc}} plots the packet success
ratio (PSR) as a function of distance, using the default LogDistance
propagation loss model and the 802.15.4 error model.  The channel (default 11),
packet size (default 20 bytes) and transmit power (default 0 dBm) can be
varied by command line arguments.  The program outputs a file named
\sphinxcode{\sphinxupquote{802.15.4\sphinxhyphen{}psr\sphinxhyphen{}distance.plt}}.  Loading this file into gnuplot yields
a file \sphinxcode{\sphinxupquote{802.15.4\sphinxhyphen{}psr\sphinxhyphen{}distance.eps}}, which can be converted to pdf or
other formats.  The default output is shown below.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{802-15-4-psr-distance}.pdf}
\caption{Default output of the program \sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}distance\sphinxhyphen{}plot.cc}}}\label{\detokenize{lr-wpan:id5}}\label{\detokenize{lr-wpan:fig-802-15-4-psr-distance}}\end{figure}


\subsection{Tests}
\label{\detokenize{lr-wpan:tests}}
The following tests have been written, which can be found in \sphinxcode{\sphinxupquote{src/lr\sphinxhyphen{}wpan/tests/}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}ack\sphinxhyphen{}test.cc}}:  Check that acknowledgments are being used and issued in the correct order.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}collision\sphinxhyphen{}test.cc}}:  Test correct reception of packets with interference and collisions.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}model\sphinxhyphen{}test.cc}}:  Check that the error model gives predictable values.

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}packet\sphinxhyphen{}test.cc}}:  Test the 802.15.4 MAC header/trailer classes

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}pd\sphinxhyphen{}plme\sphinxhyphen{}sap\sphinxhyphen{}test.cc}}:  Test the PLME and PD SAP per IEEE 802.15.4

\item {} 
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}spectrum\sphinxhyphen{}value\sphinxhyphen{}helper\sphinxhyphen{}test.cc}}:  Test that the conversion between power (expressed as a scalar quantity) and spectral power, and back again, falls within a 25\% tolerance across the range of possible channels and input powers.

\end{itemize}


\section{Validation}
\label{\detokenize{lr-wpan:validation}}
The model has not been validated against real hardware.  The error model
has been validated against the data in IEEE Std 802.15.4\sphinxhyphen{}2006,
section E.4.1.7 (Figure E.2). The MAC behavior (CSMA backoff) has been
validated by hand against expected behavior.  The below plot is an example
of the error model validation and can be reproduced by running
\sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}model\sphinxhyphen{}plot.cc}}:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{802-15-4-ber}.pdf}
\caption{Default output of the program \sphinxcode{\sphinxupquote{lr\sphinxhyphen{}wpan\sphinxhyphen{}error\sphinxhyphen{}model\sphinxhyphen{}plot.cc}}}\label{\detokenize{lr-wpan:id6}}\label{\detokenize{lr-wpan:fig-802-15-4-ber}}\end{figure}


\chapter{LTE Module}
\label{\detokenize{lte:lte-module}}\label{\detokenize{lte::doc}}

\section{Design Documentation}
\label{\detokenize{lte-design:design-documentation}}\label{\detokenize{lte-design::doc}}

\subsection{Overview}
\label{\detokenize{lte-design:overview}}
An overview of the  LTE\sphinxhyphen{}EPC simulation model is depicted in
the figure {\hyperref[\detokenize{lte-design:fig-epc-topology}]{\sphinxcrossref{\DUrole{std,std-ref}{Overview of the LTE\sphinxhyphen{}EPC simulation model}}}}. There are two main components:
\begin{itemize}
\item {} 
the LTE Model. This model includes the LTE Radio Protocol
stack (RRC, PDCP, RLC, MAC, PHY). These entities reside entirely within the
UE and the eNB nodes.

\item {} 
the EPC Model. This model includes core network
interfaces, protocols and entities. These entities and protocols
reside within the SGW, PGW and MME nodes, and partially within the
eNB nodes.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{epc-topology-with-split}.pdf}
\caption{Overview of the LTE\sphinxhyphen{}EPC simulation model}\label{\detokenize{lte-design:id143}}\label{\detokenize{lte-design:fig-epc-topology}}\end{figure}


\subsection{Design Criteria}
\label{\detokenize{lte-design:design-criteria}}\label{\detokenize{lte-design:sec-design-criteria}}

\subsubsection{LTE Model}
\label{\detokenize{lte-design:lte-model}}
The LTE model has been designed to support the evaluation of the following aspects of LTE systems:
\begin{itemize}
\item {} 
Radio Resource Management

\item {} 
QoS\sphinxhyphen{}aware Packet Scheduling

\item {} 
Inter\sphinxhyphen{}cell Interference Coordination

\item {} 
Dynamic Spectrum Access

\end{itemize}

In order to model LTE systems to a level of detail that is sufficient to allow a
correct evaluation of the above mentioned aspects, the following requirements
have been considered:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
At the radio level, the granularity of the model should be at least that
of the Resource Block (RB). In fact, this is the fundamental unit being used for
resource allocation. Without this minimum level of granularity, it is not
possible to model accurately packet scheduling and
inter\sphinxhyphen{}cell\sphinxhyphen{}interference.
The reason is that, since packet scheduling is done on
a per\sphinxhyphen{}RB basis, an eNB might transmit on a subset only of all the available
RBs, hence interfering with other eNBs only on those RBs where it is
transmitting.
Note that this requirement rules out the adoption of a system level simulation
approach, which evaluates resource allocation only at the granularity of
call/bearer establishment.

\item {} 
The simulator should scale up to tens of eNBs and hundreds of User
Equipment (UEs). This
rules out the use of a link level simulator, i.e., a simulator whose radio
interface is modeled with a granularity up to the symbol level. This is because
to have a symbol level model it is necessary to implement all the PHY
layer signal processing, whose huge computational complexity severely limits
simulation. In fact, link\sphinxhyphen{}level simulators are normally limited to a single eNB
and one or a few UEs.

\item {} 
It should be possible within the simulation to configure different cells
so that they use different carrier frequencies and system bandwidths. The
bandwidth used by different cells should be allowed to overlap, in order to
support dynamic spectrum licensing solutions such as those described
in \sphinxcite{lte-references:ofcom2600mhz} and \sphinxcite{lte-references:realwireless}. The calculation of interference should
handle appropriately this case.

\item {} 
To be more representative of the LTE standard, as well as to be as
close as possible to real\sphinxhyphen{}world implementations, the simulator
should support the MAC Scheduler API published by the FemtoForum
\sphinxcite{lte-references:ffapi}. This interface is expected to be used by femtocell manufacturers
for the implementation of scheduling and Radio Resource Management
(RRM) algorithms. By introducing support for this interface in the
simulator, we make it possible for LTE equipment vendors and
operators to test in a simulative environment exactly the same
algorithms that would be deployed in a real system.

\item {} 
The LTE simulation model should contain its own implementation of
the API defined in \sphinxcite{lte-references:ffapi}. Neither
binary nor data structure compatibility with vendor\sphinxhyphen{}specific implementations
of the same interface are expected; hence, a compatibility layer should be
interposed whenever a vendor\sphinxhyphen{}specific MAC scheduler is to be used
with the simulator. This requirement is necessary to allow the
simulator to be independent from vendor\sphinxhyphen{}specific implementations of this
interface specification. We note that \sphinxcite{lte-references:ffapi} is a logical
specification only, and its implementation (e.g., translation to some specific
programming language) is left to the vendors.

\item {} 
The model is to be used to simulate the transmission of IP packets
by the upper layers. With this respect, it shall be considered
that in LTE the Scheduling and Radio Resource Management do not
work with IP packets directly, but rather with RLC PDUs, which are
obtained by segmentation and concatenation of IP packets done by
the RLC entities. Hence, these functionalities of the RLC layer
should be modeled accurately.

\end{enumerate}


\subsubsection{EPC Model}
\label{\detokenize{lte-design:epc-model}}
The main objective of the EPC model is to provides means for the
simulation of end\sphinxhyphen{}to\sphinxhyphen{}end IP connectivity over the LTE model.
To this aim, it supports for the
interconnection of multiple UEs to the Internet, via a radio access
network of multiple eNBs connected to the core network, as shown
in Figure {\hyperref[\detokenize{lte-design:fig-epc-topology}]{\sphinxcrossref{\DUrole{std,std-ref}{Overview of the LTE\sphinxhyphen{}EPC simulation model}}}}.

The following design choices have been made for the EPC model:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
The Packet Data Network (PDN) type supported is both IPv4 and IPv6.
In other words, the end\sphinxhyphen{}to\sphinxhyphen{}end connections between the UEs and the remote
hosts can be IPv4 and IPv6. However, the networks between the core network
elements (MME, SGWs and PGWs) are IPv4\sphinxhyphen{}only.

\item {} 
The SGW and PGW functional entities are implemented in different
nodes, which are hence referred to as the SGW node and PGW node,
respectively.

\item {} 
The MME functional entities is implemented as a network node,
which is hence referred to as the MME node.

\item {} 
The scenarios with inter\sphinxhyphen{}SGW mobility are not of interest. But
several SGW nodes may be present in simulations scenarios.

\item {} 
A requirement for the EPC model is that it can be used to simulate the
end\sphinxhyphen{}to\sphinxhyphen{}end performance of realistic applications. Hence, it should
be possible to use with the EPC model any regular ns\sphinxhyphen{}3 application
working on top of TCP or UDP.

\item {} 
Another requirement is the possibility of simulating network topologies
with the presence of multiple eNBs, some of which might be
equipped with a backhaul connection with limited capabilities. In
order to simulate such scenarios, the user data plane
protocols being used between the eNBs and the SGW should be
modeled accurately.

\item {} 
It should be possible for a single UE to use different applications
with different QoS profiles. Hence, multiple EPS bearers should be
supported for each UE. This includes the necessary classification
of TCP/UDP traffic over IP done at the UE in the uplink and at the
PGW in the downlink.

\item {} 
The initial focus of the EPC model is mainly on the EPC data plane.
The accurate modeling of the EPC control plane is,
for the time being, not a requirement; however, the necessary control
plane interactions among the different network nodes of the core network
are realized by implementing control protocols/messages among them.
Direct interaction among the different simulation objects via the
provided helper objects should be avoided as much as possible.

\item {} 
The focus of the EPC model is on simulations of active users in ECM
connected mode. Hence, all the functionality that is only relevant
for ECM idle mode (in particular, tracking area update and paging)
are not modeled at all.

\item {} 
The model should allow the possibility to perform an X2\sphinxhyphen{}based
handover between two eNBs.

\end{enumerate}


\subsection{Architecture}
\label{\detokenize{lte-design:architecture}}\label{\detokenize{lte-design:sec-overall-architecture}}

\subsubsection{LTE Model}
\label{\detokenize{lte-design:id6}}

\paragraph{UE architecture}
\label{\detokenize{lte-design:ue-architecture}}
The architecture of the LTE radio protocol stack model of the UE is
represented in the figures {\hyperref[\detokenize{lte-design:fig-lte-arch-ue-data}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the UE on the data plane}}}} and
{\hyperref[\detokenize{lte-design:fig-lte-arch-ue-ctrl}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the UE on the control plane}}}} which highlight respectively the data
plane and the control plane.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-arch-ue-data}.pdf}
\caption{LTE radio protocol stack architecture for the UE on the data plane}\label{\detokenize{lte-design:id144}}\label{\detokenize{lte-design:fig-lte-arch-ue-data}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-arch-ue-ctrl}.pdf}
\caption{LTE radio protocol stack architecture for the UE on the control plane}\label{\detokenize{lte-design:id145}}\label{\detokenize{lte-design:fig-lte-arch-ue-ctrl}}\end{figure}

The architecture of the PHY/channel model of the UE is represented in figure {\hyperref[\detokenize{lte-design:fig-lte-ue-phy}]{\sphinxcrossref{\DUrole{std,std-ref}{PHY and channel model architecture for the UE}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-ue-phy}.pdf}
\caption{PHY and channel model architecture for the UE}\label{\detokenize{lte-design:id146}}\label{\detokenize{lte-design:fig-lte-ue-phy}}\end{figure}


\paragraph{eNB architecture}
\label{\detokenize{lte-design:enb-architecture}}
The architecture of the LTE radio protocol stack model of the eNB is
represented in the figures {\hyperref[\detokenize{lte-design:fig-lte-arch-enb-data}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the eNB on the data plane}}}} and
{\hyperref[\detokenize{lte-design:fig-lte-arch-enb-ctrl}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the eNB on the control plane}}}} which highlight respectively the data plane
and the control plane.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-arch-enb-data}.pdf}
\caption{LTE radio protocol stack architecture for the eNB on the data plane}\label{\detokenize{lte-design:id147}}\label{\detokenize{lte-design:fig-lte-arch-enb-data}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-arch-enb-ctrl}.pdf}
\caption{LTE radio protocol stack architecture for the eNB on the control plane}\label{\detokenize{lte-design:id148}}\label{\detokenize{lte-design:fig-lte-arch-enb-ctrl}}\end{figure}

The architecture of the PHY/channel model of the eNB is represented in figure {\hyperref[\detokenize{lte-design:fig-lte-enb-phy}]{\sphinxcrossref{\DUrole{std,std-ref}{PHY and channel model architecture for the eNB}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-enb-phy}.pdf}
\caption{PHY and channel model architecture for the eNB}\label{\detokenize{lte-design:id149}}\label{\detokenize{lte-design:fig-lte-enb-phy}}\end{figure}


\subsubsection{EPC Model}
\label{\detokenize{lte-design:id7}}

\paragraph{EPC data plane}
\label{\detokenize{lte-design:epc-data-plane}}
In Figure {\hyperref[\detokenize{lte-design:fig-lte-epc-e2e-data-protocol-stack-with-split}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE\sphinxhyphen{}EPC data plane protocol stack}}}}, we represent the
end\sphinxhyphen{}to\sphinxhyphen{}end LTE\sphinxhyphen{}EPC data plane protocol stack as it is modeled in the
simulator. The figure shows all nodes in the data path, i.e. UE, eNB,
SGW, PGW and a remote host in the Internet. All protocol stacks
(S5 protocol stack, S1\sphinxhyphen{}U protocol stack and the LTE radio protocol stack)
specified by 3GPP are present.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-epc-e2e-data-protocol-stack-with-split}.pdf}
\caption{LTE\sphinxhyphen{}EPC data plane protocol stack}\label{\detokenize{lte-design:id150}}\label{\detokenize{lte-design:fig-lte-epc-e2e-data-protocol-stack-with-split}}\end{figure}


\paragraph{EPC control plane}
\label{\detokenize{lte-design:epc-control-plane}}
The architecture of the implementation of the control plane model is
shown in figure {\hyperref[\detokenize{lte-design:fig-lte-epc-e2e-control-protocol-stack-with-split}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE\sphinxhyphen{}EPC control plane protocol stack}}}}.
The control interfaces that are modeled explicitly are the S1\sphinxhyphen{}MME, the S11, and the S5
interfaces. The X2 interface is also modeled explicitly and it is described in more
detail in section {\hyperref[\detokenize{lte-design:sec-x2}]{\sphinxcrossref{\DUrole{std,std-ref}{X2}}}}

The S1\sphinxhyphen{}MME, the S11 and the S5 interfaces are modeled using procotol data units sent
over its respective links. These interfaces use the SCTP protocol as transport protocol
but currently, the SCTP protocol is not modeled in the ns\sphinxhyphen{}3 simulator, so the
UDP protocol is used instead of the SCTP protocol.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-epc-e2e-control-protocol-stack-with-split}.pdf}
\caption{LTE\sphinxhyphen{}EPC control plane protocol stack}\label{\detokenize{lte-design:id151}}\label{\detokenize{lte-design:fig-lte-epc-e2e-control-protocol-stack-with-split}}\end{figure}

\clearpage


\subsection{Channel and Propagation}
\label{\detokenize{lte-design:channel-and-propagation}}
For channel modeling purposes, the LTE module uses the \sphinxcode{\sphinxupquote{SpectrumChannel}}
interface provided by the spectrum module. At the time of this
writing, two implementations of such interface are available:
\sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}}, and the
LTE module requires the use of the \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} in
order to work properly. This is because of the need to support
different frequency and bandwidth configurations. All the
propagation models supported by \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} can be
used within the LTE module.


\subsubsection{Use of the Buildings model with LTE}
\label{\detokenize{lte-design:use-of-the-buildings-model-with-lte}}
The recommended propagation model to be used with the LTE
module is the one provided by the Buildings module, which was in fact
designed specifically with LTE (though it can be used with other
wireless technologies as well). Please refer to the documentation of
the Buildings module for generic information on the propagation model
it provides.

In this section we will highlight some considerations that
specifically apply when the Buildings module is used together with the
LTE module.

The naming convention used in the following will be:
\begin{itemize}
\item {} 
User equipment:  UE

\item {} 
Macro Base Station: MBS

\item {} 
Small cell Base Station (e.g., pico/femtocell): SC

\end{itemize}

The LTE module considers FDD only, and implements downlink and uplink propagation separately. As a consequence, the following pathloss computations are performed
\begin{itemize}
\item {} 
MBS \textless{}\sphinxhyphen{}\textgreater{} UE (indoor and outdoor)

\item {} 
SC (indoor and outdoor) \textless{}\sphinxhyphen{}\textgreater{} UE (indoor and outdoor)

\end{itemize}

The LTE model does not provide the following pathloss computations:
\begin{itemize}
\item {} 
UE \textless{}\sphinxhyphen{}\textgreater{} UE

\item {} 
MBS \textless{}\sphinxhyphen{}\textgreater{} MBS

\item {} 
MBS \textless{}\sphinxhyphen{}\textgreater{} SC

\item {} 
SC \textless{}\sphinxhyphen{}\textgreater{} SC

\end{itemize}

The Buildings model does not know the actual type of the node; i.e.,
it is not aware of whether a transmitter node is a UE, a MBS, or a
SC. Rather, the Buildings model only cares about the position of the
node: whether it is indoor and outdoor, and what is its z\sphinxhyphen{}axis respect
to the rooftop level. As a consequence, for an eNB node that is placed
outdoor and at a z\sphinxhyphen{}coordinate above the rooftop level, the propagation
models typical of MBS will be used by the Buildings
module. Conversely, for an eNB that is placed outdoor but below the
rooftop,  or indoor, the propagation models typical of pico and
femtocells will be used.

For communications involving at least one indoor node, the
corresponding wall penetration losses will be calculated by the
Buildings model. This covers the following use cases:
\begin{itemize}
\item {} 
MBS \textless{}\sphinxhyphen{}\textgreater{} indoor UE

\item {} 
outdoor SC \textless{}\sphinxhyphen{}\textgreater{} indoor UE

\item {} 
indoor SC \textless{}\sphinxhyphen{}\textgreater{} indoor UE

\item {} 
indoor SC \textless{}\sphinxhyphen{}\textgreater{} outdoor UE

\end{itemize}

Please refer to the documentation of the Buildings module for details
on the actual models used in each case.


\subsubsection{Fading Model}
\label{\detokenize{lte-design:fading-model}}\label{\detokenize{lte-design:sec-fading-model}}
The LTE module includes a trace\sphinxhyphen{}based fading model derived from the one developed during the GSoC 2010 \sphinxcite{lte-references:piro2011}. The main characteristic of this model is the fact that the fading evaluation during simulation run\sphinxhyphen{}time is based on per\sphinxhyphen{}calculated traces. This is done to limit the computational complexity of the simulator. On the other hand, it needs huge structures for storing the traces; therefore, a trade\sphinxhyphen{}off between the number of possible parameters and the memory occupancy has to be found. The most important ones are:
\begin{itemize}
\item {} 
users’ speed: relative speed between users (affects the Doppler frequency, which in turns affects the time\sphinxhyphen{}variance property of the fading)

\item {} 
number of taps (and relative power): number of multiple paths considered, which affects the frequency property of the fading.

\item {} 
time granularity of the trace: sampling time of the trace.

\item {} 
frequency granularity of the trace: number of values in frequency to be evaluated.

\item {} 
length of trace: ideally large as the simulation time, might be reduced by windowing mechanism.

\item {} 
number of users: number of independent traces to be used (ideally one trace per user).

\end{itemize}

With respect to the mathematical channel propagation model, we suggest the one provided by the \sphinxcode{\sphinxupquote{rayleighchan}} function of Matlab, since it provides a well accepted channel modelization both in time and frequency domain. For more information, the reader is referred to  \sphinxcite{lte-references:mathworks}.

The simulator provides a matlab script (\sphinxcode{\sphinxupquote{src/lte/model/fading\sphinxhyphen{}traces/fading\sphinxhyphen{}trace\sphinxhyphen{}generator.m}}) for generating traces based on the format used by the simulator.
In detail, the channel object created with the rayleighchan function is used for filtering a discrete\sphinxhyphen{}time impulse signal in order to obtain the channel impulse response. The filtering is repeated for different TTI, thus yielding subsequent time\sphinxhyphen{}correlated channel responses (one per TTI). The channel response is then processed with the \sphinxcode{\sphinxupquote{pwelch}} function for obtaining its power spectral density values, which are then saved in a file with the proper format compatible with the simulator model.

Since the number of variable it is pretty high, generate traces considering all of them might produce a high number of traces of huge size. On this matter, we considered the following assumptions of the parameters based on the 3GPP fading propagation conditions (see Annex B.2 of \sphinxcite{lte-references:ts36104}):
\begin{itemize}
\item {} 
users’ speed: typically only a few discrete values are considered, i.e.:
\begin{itemize}
\item {} 
0 and 3 kmph for pedestrian scenarios

\item {} 
30 and 60 kmph for vehicular scenarios

\item {} 
0, 3, 30 and 60 for urban scenarios

\end{itemize}

\item {} 
channel taps: only a limited number of sets of channel taps are normally considered, for example three models are mentioned in Annex B.2 of \sphinxcite{lte-references:ts36104}.

\item {} 
time granularity: we need one fading value per TTI, i.e., every 1 ms (as this is the granularity in time of the ns\sphinxhyphen{}3 LTE PHY model).

\item {} 
frequency granularity: we need one fading value per RB (which is the frequency granularity of the spectrum model used by the ns\sphinxhyphen{}3 LTE model).

\item {} 
length of the trace: the simulator includes the windowing mechanism implemented during the GSoC 2011, which consists of picking up a window of the trace each window length in a random fashion.

\item {} 
per\sphinxhyphen{}user fading process: users share the same fading trace, but for each user a different starting point in the trace is randomly picked up. This choice was made to avoid the need to provide one fading trace per user.

\end{itemize}

According to the parameters we considered, the following formula express in detail the total size \(S_{traces}\) of the fading traces:
\begin{equation*}
\begin{split}S_{traces} = S_{sample} \times N_{RB} \times \frac{T_{trace}}{T_{sample}} \times N_{scenarios} \mbox{ [bytes]}\end{split}
\end{equation*}
where \(S_{sample}\) is the size in bytes of the sample (e.g., 8 in case of double precision, 4 in case of float precision), \(N_{RB}\) is the number of RB or set of RBs to be considered, \(T_{trace}\) is the total length of the trace, \(T_{sample}\) is the time resolution of the trace (1 ms), and \(N_{scenarios}\) is the number of fading scenarios that are desired (i.e., combinations of different sets of channel taps and user speed values). We provide traces for 3 different scenarios one for each taps configuration defined in Annex B.2 of \sphinxcite{lte-references:ts36104}:
\begin{itemize}
\item {} 
Pedestrian: with nodes’ speed of 3 kmph.

\item {} 
Vehicular: with nodes’ speed of 60 kmph.

\item {} 
Urban: with nodes’ speed of 3 kmph.

\end{itemize}

hence \(N_{scenarios} = 3\). All traces have \(T_{trace} = 10\) s and \(RB_{NUM} = 100\). This results in a total 24 MB bytes of traces.


\subsubsection{Antennas}
\label{\detokenize{lte-design:antennas}}
Being based on the \sphinxcode{\sphinxupquote{SpectrumPhy}}, the LTE PHY model supports antenna
modeling via the ns\sphinxhyphen{}3 \sphinxcode{\sphinxupquote{AntennaModel}} class. Hence, any model based on
this class can be associated with any eNB or UE instance. For
instance, the use of the \sphinxcode{\sphinxupquote{CosineAntennaModel}} associated with an eNB
device allows to model one sector of a macro base station. By default,
the \sphinxcode{\sphinxupquote{IsotropicAntennaModel}} is used for both eNBs and UEs.

\clearpage


\subsection{PHY}
\label{\detokenize{lte-design:phy}}

\subsubsection{Overview}
\label{\detokenize{lte-design:id13}}
The physical layer model provided in this LTE simulator is based on
the one described in \sphinxcite{lte-references:piro2011}, with the following modifications.  The model now includes the
inter cell interference calculation and the simulation of uplink traffic, including both packet transmission and CQI generation.


\subsubsection{Subframe Structure}
\label{\detokenize{lte-design:subframe-structure}}
The subframe is divided into control and data part as described in Figure {\hyperref[\detokenize{lte-design:fig-lte-subframe-structure}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE subframe division.}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=300\sphinxpxdimen]{{lte-subframe-structure}.pdf}
\caption{LTE subframe division.}\label{\detokenize{lte-design:id152}}\label{\detokenize{lte-design:fig-lte-subframe-structure}}\end{figure}

Considering the granularity of the simulator based on RB, the control and the reference signaling have to be consequently modeled considering this constraint.  According to the standard \sphinxcite{lte-references:ts36211}, the downlink control frame starts at the beginning of each subframe and lasts up to three symbols across the whole system bandwidth, where the actual duration is provided by the Physical Control Format Indicator Channel (PCFICH). The information on the allocation are then mapped in the remaining resource up to the duration defined by the PCFICH, in the so called Physical Downlink Control Channel (PDCCH). A PDCCH transports a single message called Downlink Control Information (DCI) coming from the MAC layer, where the scheduler indicates the resource allocation for a specific user.
The PCFICH and PDCCH are modeled with the transmission of the control frame of a fixed duration of 3/14 of milliseconds spanning in the whole available bandwidth, since the scheduler does not estimate the size of the control region. This implies that a single transmission block models the entire control frame with a fixed power (i.e., the one used for the PDSCH) across all the available RBs. According to this feature, this transmission represents also a valuable support for the Reference Signal (RS). This allows of having every TTI an evaluation of the interference scenario since all the eNB are transmitting (simultaneously) the control frame over the respective available bandwidths. We note that, the model does not include the power boosting since it does not reflect any improvement in the implemented model of the channel estimation.

The Sounding Reference Signal (SRS) is modeled similar to the downlink control frame. The SRS is periodically placed in the last symbol of the subframe in the whole system bandwidth. The RRC module already includes an algorithm for dynamically assigning the periodicity as function of the actual number of UEs attached to a eNB according to the UE\sphinxhyphen{}specific procedure (see Section 8.2 of \sphinxcite{lte-references:ts36213}).


\subsubsection{MAC to Channel delay}
\label{\detokenize{lte-design:mac-to-channel-delay}}
To model the latency of real MAC and PHY implementations, the PHY model simulates a MAC\sphinxhyphen{}to\sphinxhyphen{}channel delay in multiples of TTIs (1ms). The transmission of both data and control packets are delayed by this amount.


\subsubsection{CQI feedback}
\label{\detokenize{lte-design:cqi-feedback}}\label{\detokenize{lte-design:sec-cqi-feedback}}
The generation of CQI feedback is done accordingly to what specified in \sphinxcite{lte-references:ffapi}. In detail, we considered the generation
of periodic wideband CQI (i.e., a single value of channel state that is deemed representative of all RBs
in use) and inband CQIs (i.e., a set of value representing the channel state for each RB).

The CQI index to be reported is obtained by first obtaining a SINR measurement and then passing this SINR measurement to the {\hyperref[\detokenize{lte-design:adaptive-modulation-and-coding}]{\sphinxcrossref{Adaptive Modulation and Coding}}} module which will map it to the CQI index.

In downlink, the SINR used to generate CQI feedback can be calculated in two different ways:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxstyleemphasis{Ctrl} method: SINR is calculated combining the signal power from the reference signals (which in the simulation is equivalent to the PDCCH) and the interference power from the PDCCH. This approach results in considering any neighboring eNB as an interferer, regardless of whether this eNB is actually performing any PDSCH transmission, and regardless of the power and RBs used for eventual interfering PDSCH transmissions.

\item {} 
\sphinxstyleemphasis{Mixed} method: SINR is calculated combining the signal power from the reference signals (which in the simulation is equivalent to the PDCCH) and the interference power from the PDSCH. This approach results in considering as interferers only those neighboring eNBs that are actively transmitting data on the PDSCH, and allows to generate inband CQIs that account for different amounts of interference on different RBs according to the actual interference level. In the case that no PDSCH transmission is performed by any eNB, this method consider that interference is zero, i.e., the SINR will be calculated as the ratio of signal to noise only.

\end{enumerate}

To switch between this two CQI generation approaches, \sphinxcode{\sphinxupquote{LteHelper::UsePdschForCqiGeneration}} needs to be configured: false for first approach and true for second approach (true is default value):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteHelper::UsePdschForCqiGeneration}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In uplink, two types of CQIs are implemented:
\begin{itemize}
\item {} 
SRS based, periodically sent by the UEs.

\item {} 
PUSCH based, calculated from the actual transmitted data.

\end{itemize}

The scheduler interface include an attribute system called \sphinxcode{\sphinxupquote{UlCqiFilter}} for managing the filtering of the CQIs according to their nature, in detail:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SRS\_UL\_CQI}} for storing only SRS based CQIs.

\item {} 
\sphinxcode{\sphinxupquote{PUSCH\_UL\_CQI}} for storing only PUSCH based CQIs.

\end{itemize}

It has to be noted that, the \sphinxcode{\sphinxupquote{FfMacScheduler}} provides only the interface and it is matter of the actual scheduler implementation to include the code for managing these attributes (see scheduler related section for more information on this matter).


\subsubsection{Interference Model}
\label{\detokenize{lte-design:interference-model}}
The PHY model is based on the well\sphinxhyphen{}known Gaussian interference models, according to which the powers of interfering signals (in linear units) are summed up together to determine the overall interference power.

The sequence diagram of Figure {\hyperref[\detokenize{lte-design:fig-lte-phy-interference}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the PHY interference calculation procedure}}}} shows how interfering signals are processed to calculate the SINR, and how SINR is then used for the generation of CQI feedback.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-phy-interference}.pdf}
\caption{Sequence diagram of the PHY interference calculation procedure}\label{\detokenize{lte-design:id153}}\label{\detokenize{lte-design:fig-lte-phy-interference}}\end{figure}


\subsubsection{LTE Spectrum Model}
\label{\detokenize{lte-design:lte-spectrum-model}}
The usage of the radio spectrum by eNBs and UEs in LTE is described in
\sphinxcite{lte-references:ts36101}. In the simulator, radio spectrum usage is modeled as follows.
Let \(f_c\) denote the  LTE Absolute Radio Frequency Channel Number, which
identifies the carrier frequency on a 100 kHz raster; furthermore, let \(B\) be
the Transmission Bandwidth Configuration in number of Resource Blocks. For every
pair \((f_c,B)\) used in the simulation we define a corresponding SpectrumModel using
the functionality provided by the {\hyperref[\detokenize{spectrum:sec-spectrum-module}]{\sphinxcrossref{\DUrole{std,std-ref}{Spectrum Module}}}} .
model using the Spectrum framework described
in \sphinxcite{lte-references:baldo2009}.  \(f_c\) and \(B\) can be configured for every eNB instantiated
in the simulation; hence, each eNB can use a different spectrum model. Every UE
will automatically use the spectrum model of the eNB it is attached to. Using
the MultiModelSpectrumChannel described in \sphinxcite{lte-references:baldo2009}, the interference
among eNBs that use different spectrum models is properly accounted for.
This allows to simulate dynamic spectrum access policies, such as for
example the spectrum licensing policies that are
discussed in \sphinxcite{lte-references:ofcom2600mhz}.


\subsubsection{Data PHY Error Model}
\label{\detokenize{lte-design:data-phy-error-model}}
The simulator includes an error model of the data plane (i.e., PDSCH and PUSCH) according to the standard link\sphinxhyphen{}to\sphinxhyphen{}system mapping (LSM) techniques. The choice is aligned with the standard system simulation methodology of OFDMA  radio transmission technology. Thanks to LSM we are able to maintain a good level of accuracy and at the same time limiting the computational complexity increase. It is based on the mapping of single link layer performance obtained by means of link level simulators to system (in our case network) simulators. In particular link the layer simulator is used for generating the performance of a single link from a PHY layer perspective, usually in terms of code block error rate (BLER), under specific static conditions. LSM allows the usage of these parameters in more complex scenarios, typical of system/network simulators, where we have more links, interference and “colored” channel propagation phenomena (e.g., frequency selective fading).

To do this the Vienna LTE Simulator \sphinxcite{lte-references:viennaltesim} has been used for what concerns the extraction of link layer performance and the Mutual Information Based Effective SINR (MIESM) as LSM mapping function using part of the work recently published by the Signet Group of University of Padua \sphinxcite{lte-references:paduapem}.


\paragraph{MIESM}
\label{\detokenize{lte-design:miesm}}
The specific LSM method adopted is the one based on the usage of a mutual information metric, commonly referred to as the mutual information per per coded bit (MIB or MMIB when a mean of multiples MIBs is involved). Another option would be represented by the Exponential ESM (EESM); however, recent studies demonstrate that MIESM outperforms EESM in terms of accuracy \sphinxcite{lte-references:lozanocost}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{miesm_scheme}.pdf}
\caption{MIESM computational procedure diagram}\label{\detokenize{lte-design:id154}}\label{\detokenize{lte-design:fig-miesm-architecture}}\end{figure}

The mutual information (MI) is dependent on the constellation mapping and can be calculated per transport block (TB) basis, by evaluating the MI over the symbols and the subcarrier. However, this would be too complex for a network simulator. Hence, in our implementation a flat channel response within the RB has been considered; therefore the overall MI of a TB is calculated averaging the MI evaluated per each RB used in the TB. In detail, the implemented scheme is depicted in Figure {\hyperref[\detokenize{lte-design:fig-miesm-architecture}]{\sphinxcrossref{\DUrole{std,std-ref}{MIESM computational procedure diagram}}}}, where we see that the model starts by evaluating the MI value for each RB, represented in the figure by the SINR samples. Then the equivalent MI is evaluated per TB basis by averaging the MI values. Finally, a further step has to be done since the link level simulator returns the performance of the link in terms of block error rate (BLER) in a addive white gaussian noise  (AWGN) channel, where the blocks are the code blocks (CBs) independently encoded/decoded by the turbo encoder. On this matter the
standard 3GPP segmentation scheme has been used for estimating the actual CB size (described in section 5.1.2 of \sphinxcite{lte-references:ts36212}). This scheme divides the TB in \(N_{K_-}\) blocks of size \(K_-\) and \(N_{K+}\) blocks of size \(K_+\). Therefore the overall TB BLER (TBLER) can be expressed as
\begin{equation*}
\begin{split}TBLER = 1- \prod\limits_{i=1}^{C}(1-CBLER_i)\end{split}
\end{equation*}
where the \(CBLER_i\) is the BLER of the CB \(i\) obtained according to the link level simulator CB BLER curves.
For estimating the \(CBLER_i\), the MI evaluation has been implemented according to its numerical approximation defined in \sphinxcite{lte-references:wimaxemd}. Moreover, for reducing the complexity of the computation, the approximation has been converted into lookup tables. In detail, Gaussian cumulative model has been used for approximating the AWGN BLER curves with three parameters which provides a close fit to the standard AWGN performances, in formula:
\begin{equation*}
\begin{split}CBLER_i = \frac{1}{2}\left[1-erf\left(\frac{x-b_{ECR}}{\sqrt{2}c_{ECR}} \right) \right]\end{split}
\end{equation*}
where \(x\) is the MI of the TB, \(b_{ECR}\) represents the “transition center” and \(c_{ECR}\) is related to the “transition width” of the Gaussian cumulative distribution for each Effective Code Rate (ECR) which is the actual transmission rate according to the channel coding and MCS. For limiting the computational complexity of the model we considered only a subset of the possible ECRs in fact we would have potentially 5076 possible ECRs (i.e., 27 MCSs and 188 CB sizes). On this respect, we will limit the CB sizes to some representative values (i.e., 40, 140, 160, 256, 512, 1024, 2048, 4032, 6144), while for the others the worst one approximating the real one will be used (i.e., the smaller CB size value available respect to the real one). This choice is aligned to the typical performance of turbo codes, where the CB size is not strongly impacting on the BLER. However, it is to be notes that for CB sizes lower than 1000 bits the effect might be relevant (i.e., till 2 dB); therefore, we adopt
this unbalanced sampling interval for having more precision where it is necessary. This behaviour is confirmed by the figures presented in the Annes Section.


\paragraph{BLER Curves}
\label{\detokenize{lte-design:bler-curves}}
On this respect, we reused part of the curves obtained within \sphinxcite{lte-references:paduapem}. In detail, we introduced the CB size dependency to the CB BLER curves with the support of the developers of \sphinxcite{lte-references:paduapem} and of the LTE Vienna Simulator. In fact, the module released provides the link layer performance only for what concerns the MCSs (i.e, with a given fixed ECR). In detail the new error rate curves for each has been evaluated with a simulation campaign with the link layer simulator for a single link with AWGN noise and for CB size of 104, 140, 256, 512, 1024, 2048, 4032 and 6144. These curves has been mapped with the Gaussian cumulative model formula presented above for obtaining the correspondents \(b_{ECR}\) and \(c_{ECR}\) parameters.

The BLER performance of all MCS obtained with the link level simulator are plotted in the following figures (blue lines) together with their correspondent mapping to the Gaussian cumulative distribution (red dashed lines).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_1_4}.pdf}
\caption{BLER for MCS 1, 2, 3 and 4.}\label{\detokenize{lte-design:id155}}\label{\detokenize{lte-design:fig-mcs-1-4-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_5_8}.pdf}
\caption{BLER for MCS 5, 6, 7 and 8.}\label{\detokenize{lte-design:id156}}\label{\detokenize{lte-design:fig-mcs-5-8-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_9_12}.pdf}
\caption{BLER for MCS 9, 10, 11 and 12.}\label{\detokenize{lte-design:id157}}\label{\detokenize{lte-design:fig-mcs-9-12-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_13_16}.pdf}
\caption{BLER for MCS 13, 14, 15 and 16.}\label{\detokenize{lte-design:id158}}\label{\detokenize{lte-design:fig-mcs-13-16-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_17_20}.pdf}
\caption{BLER for MCS 17, 17, 19 and 20.}\label{\detokenize{lte-design:id159}}\label{\detokenize{lte-design:fig-mcs-17-20-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_21_24}.pdf}
\caption{BLER for MCS 21, 22, 23 and 24.}\label{\detokenize{lte-design:id160}}\label{\detokenize{lte-design:fig-mcs-21-24-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_25_28}.pdf}
\caption{BLER for MCS 25, 26, 27 and 28.}\label{\detokenize{lte-design:id161}}\label{\detokenize{lte-design:fig-mcs-25-28-ber}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_29_29}.pdf}
\caption{BLER for MCS 29.}\label{\detokenize{lte-design:id162}}\label{\detokenize{lte-design:fig-mcs-29-29-ber}}\end{figure}


\paragraph{Integration of the BLER curves in the ns\sphinxhyphen{}3 LTE module}
\label{\detokenize{lte-design:integration-of-the-bler-curves-in-the-ns-3-lte-module}}
The model implemented uses the curves for the LSM of the recently LTE PHY Error Model released in the ns3 community by the Signet Group \sphinxcite{lte-references:paduapem} and the new ones generated for different CB sizes. The \sphinxcode{\sphinxupquote{LteSpectrumPhy}} class is in charge of evaluating the TB BLER thanks to the methods provided by the \sphinxcode{\sphinxupquote{LteMiErrorModel}} class, which is in charge of evaluating the TB BLER according to the vector of the perceived SINR per RB, the MCS and the size in order to proper model the segmentation of the TB in CBs. In order to obtain the vector of the perceived SINR two instances of \sphinxcode{\sphinxupquote{LtePemSinrChunkProcessor}} (child of \sphinxcode{\sphinxupquote{LteChunkProcessor}} dedicated to evaluate the SINR for obtaining physical error performance) have been attached to UE downlink and eNB uplink \sphinxcode{\sphinxupquote{LteSpectrumPhy}} modules for evaluating the error model distribution respectively of PDSCH (UE side) and ULSCH (eNB side).

The model can be disabled for working with a zero\sphinxhyphen{}losses channel by setting the \sphinxcode{\sphinxupquote{PemEnabled}} attribute of the \sphinxcode{\sphinxupquote{LteSpectrumPhy}} class (by default is active). This can be done according to the standard ns3 attribute system procedure, that is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteSpectrumPhy::DataErrorModelEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Control Channels PHY Error Model}
\label{\detokenize{lte-design:control-channels-phy-error-model}}\label{\detokenize{lte-design:sec-control-channles-phy-error-model}}
The simulator includes the error model for downlink control channels (PCFICH and PDCCH), while in uplink it is assumed and ideal error\sphinxhyphen{}free channel. The model is based on the MIESM approach presented before for considering the effects of the frequency selective channel since most of the control channels span the whole available bandwidth.


\paragraph{PCFICH + PDCCH Error Model}
\label{\detokenize{lte-design:pcfich-pdcch-error-model}}
The model adopted for the error distribution of these channels is based on an evaluation study carried out in the RAN4 of 3GPP, where different vendors investigated the demodulation performance of the PCFICH jointly with PDCCH. This is due to the fact that the PCFICH is the channel in charge of communicating to the UEs the actual dimension of the PDCCH (which spans between 1 and 3 symbols); therefore the correct decodification of the DCIs  depends on the correct interpretation of both ones. In 3GPP this problem have been evaluated for improving the cell\sphinxhyphen{}edge performance \sphinxcite{lte-references:fujitsuwhitepaper}, where the interference among neighboring cells can be relatively high due to signal degradation. A similar problem has been notices in femto\sphinxhyphen{}cell scenario and, more in general, in HetNet scenarios the bottleneck has been detected mainly as the PCFICH channel \sphinxcite{lte-references:bharucha2011}, where in case of many eNBs are deployed in the same service area, this channel may collide in frequency, making impossible the correct detection of
the PDCCH channel, too.

In the simulator, the SINR perceived during the reception has been estimated according to the MIESM model presented above in order to evaluate the error distribution of PCFICH and PDCCH. In detail, the SINR samples of all the RBs are included in the evaluation of the MI associated to the control frame and, according to this values, the effective SINR (eSINR) is obtained by inverting the MI evaluation process. It has to be noted that, in case of MIMO transmission, both PCFICH and the PDCCH use always the transmit diversity mode as defined by the standard. According to the eSINR perceived the decodification error probability can be estimated as function of the results presented in \sphinxcite{lte-references:r4-081920}. In case an error occur, the DCIs discarded and therefore the UE will be not able to receive the correspondent Tbs, therefore resulting lost.


\subsubsection{MIMO Model}
\label{\detokenize{lte-design:mimo-model}}
The use of multiple antennas both at transmitter and receiver side, known as multiple\sphinxhyphen{}input and multiple\sphinxhyphen{}output (MIMO), is a problem well studied in literature during the past years. Most of the work concentrate on evaluating analytically the gain that the different MIMO schemes might have in term of capacity; however someones provide also information of the gain in terms of received power \sphinxcite{lte-references:catreuxmimo}.

According to the considerations above, a model more flexible can be obtained considering the gain that MIMO schemes bring in the system from a statistical point of view. As highlighted before, \sphinxcite{lte-references:catreuxmimo} presents the statistical gain of several MIMO solutions respect to the SISO one in case of no correlation between the antennas. In the work the gain is presented as the cumulative distribution function (CDF) of the output SINR for what concern SISO, MIMO\sphinxhyphen{}Alamouti, MIMO\sphinxhyphen{}MMSE, MIMO\sphinxhyphen{}OSIC\sphinxhyphen{}MMSE and MIMO\sphinxhyphen{}ZF schemes. Elaborating the results, the output SINR distribution can be approximated with a log\sphinxhyphen{}normal one with different mean and variance as function of the scheme considered. However, the variances are not so different and they are approximatively equal to the one of the SISO mode already included in the shadowing component of the \sphinxcode{\sphinxupquote{BuildingsPropagationLossModel}}, in detail:
\begin{itemize}
\item {} 
SISO: \(\mu = 13.5\) and \(\sigma = 20\) {[}dB{]}.

\item {} 
MIMO\sphinxhyphen{}Alamouti: \(\mu = 17.7\) and \(\sigma = 11.1\) {[}dB{]}.

\item {} 
MIMO\sphinxhyphen{}MMSE: \(\mu = 10.7\) and \(\sigma = 16.6\) {[}dB{]}.

\item {} 
MIMO\sphinxhyphen{}OSIC\sphinxhyphen{}MMSE: \(\mu = 12.6\) and \(\sigma = 15.5\) {[}dB{]}.

\item {} 
MIMO\sphinxhyphen{}ZF: \(\mu = 10.3\) and \(\sigma = 12.6\) {[}dB{]}.

\end{itemize}

Therefore the PHY layer implements the MIMO model as the gain perceived by the receiver when using a MIMO scheme respect to the one obtained using SISO one. We note that, these gains referred to a case where there is no correlation between the antennas in MIMO scheme; therefore do not model degradation due to paths correlation.


\subsubsection{UE PHY Measurements Model}
\label{\detokenize{lte-design:ue-phy-measurements-model}}\label{\detokenize{lte-design:sec-phy-ue-measurements}}
According to \sphinxcite{lte-references:ts36214}, the UE has to report a set of measurements of the eNBs that the device is able to perceive: the reference signal received power (RSRP) and the reference signal received quality (RSRQ). The former is a measure of the received power of a specific eNB, while the latter includes also channel interference and thermal noise.
The UE has to report the measurements jointly with the physical cell identity (PCI) of the cell. Both the RSRP and RSRQ measurements are performed during the reception of the RS, while the PCI is obtained with the Primary Synchronization Signal (PSS). The PSS is sent by the eNB each 5 subframes and in detail in the subframes 1 and 6. In real systems, only 504 distinct PCIs are available, and hence it could occur that two nearby eNBs use the same PCI; however, in the simulator we model PCIs using simulation metadata, and we allow up to 65535 distinct PCIs, thereby avoiding PCI collisions provided that less that 65535 eNBs are simulated in the same scenario.

According to \sphinxcite{lte-references:ts36133} sections 9.1.4 and 9.1.7, RSRP is reported by PHY layer in dBm while RSRQ in dB. The values of RSRP and RSRQ are provided to higher layers through the C\sphinxhyphen{}PHY SAP (by means of \sphinxcode{\sphinxupquote{UeMeasurementsParameters}} struct) every 200 ms as defined in \sphinxcite{lte-references:ts36331}. Layer 1 filtering is performed by averaging the all the measurements collected during the last window slot. The periodicity of reporting can be adjusted for research purposes by means of the \sphinxcode{\sphinxupquote{LteUePhy::UeMeasurementsFilterPeriod}} attribute.

The formulas of the RSRP and RSRQ can be simplified considering the assumption of the PHY layer that the channel is flat within the RB, the finest level of accuracy. In fact, this implies that all the REs within a RB have the same power, therefore:
\begin{equation*}
\begin{split}RSRP = \frac{\sum_{k=0}^{K-1}\frac{\sum_{m=0}^{M-1}(P(k,m))}{M}}{K}
     = \frac{\sum_{k=0}^{K-1}\frac{(M \times P(k))}{M}}{K}
     = \frac{\sum_{k=0}^{K-1}(P(k))}{K}\end{split}
\end{equation*}
where \(P(k,m)\) represents the signal power of the RE \(m\) within the RB \(k\), which, as observed before, is constant within the same RB and equal to \(P(k)\), \(M\) is the number of REs carrying the RS in a RB and \(K\) is the number of RBs. It is to be noted that \(P(k)\), and in general all the powers defined in this section, is obtained in the simulator from the PSD of the RB (which is provided by  the \sphinxcode{\sphinxupquote{LteInterferencePowerChunkProcessor}}), in detail:
\begin{equation*}
\begin{split}P(k) = PSD_{RB}(k)*180000/12\end{split}
\end{equation*}
where \(PSD_{RB}(k)\) is the power spectral density of the RB \(k\), \(180000\) is the bandwidth in Hz of the RB and \(12\) is the number of REs per RB in an OFDM symbol.
Similarly, for RSSI we have
\begin{equation*}
\begin{split}RSSI = \sum_{k=0}^{K-1} \frac{\sum_{s=0}^{S-1} \sum_{r=0}^{R-1}( P(k,s,r) + I(k,s,r) + N(k,s,r))}{S}\end{split}
\end{equation*}
where \(S\) is the number of OFDM symbols carrying RS in a RB and \(R\) is the number of REs carrying a RS in a OFDM symbol (which is fixed to \(2\)) while \(P(k,s,r)\), \(I(k,s,r)\) and \(N(k,s,r)\) represent respectively the perceived power of the serving cell, the interference power and the noise power of the RE \(r\) in symbol \(s\). As for RSRP, the measurements within a RB are always equals among each others according to the PHY model; therefore \(P(k,s,r) = P(k)\), \(I(k,s,r) = I(k)\) and \(N(k,s,r) = N(k)\), which implies that the RSSI can be calculated as:
\begin{equation*}
\begin{split}RSSI = \sum_{k=0}^{K-1} \frac{S \times 2 \times ( P(k) + I(k) + N(k))}{S}
     = \sum_{k=0}^{K-1} 2 \times ( P(k) + I(k) + N (k))\end{split}
\end{equation*}
Considering the constraints of the PHY reception chain implementation, and in order to maintain the level of computational complexity low, only RSRP can be directly obtained for all the cells. This is due to the fact that \sphinxcode{\sphinxupquote{LteSpectrumPhy}} is designed for evaluating the interference only respect to the signal of the serving eNB. This implies that the PHY layer is optimized for managing the power signals information with the serving eNB as a reference. However, RSRP and RSRQ of neighbor cell \(i\) can be extracted by the current information available of the serving cell \(j\) as detailed in the following:
\begin{align*}\!\begin{aligned}
RSRP_i = \frac{\sum_{k=0}^{K-1}(P_i(k))}{K}\\
RSSI_i = RSSI_j = \sum_{k=0}^{K-1} 2 \times ( I_j(k) + P_j(k) + N_j(k) )\\
RSRQ_i^j = K \times RSRP_i / RSSI_j\\
\end{aligned}\end{align*}
where \(RSRP_i\) is the RSRP of the neighbor cell \(i\), \(P_i(k)\) is the power perceived at any RE within the RB \(k\), \(K\) is the total number of RBs, \(RSSI_i\) is the RSSI of the neighbor cell \(i\) when the UE is attached to cell  \(j\) (which, since it is the sum of all the received powers, coincides with \(RSSI_j\)), \(I_j(k)\) is the total interference perceived by UE in any RE of RB \(k\) when attached to cell \(i\) (obtained by the \sphinxcode{\sphinxupquote{LteInterferencePowerChunkProcessor}}), \(P_j(k)\) is the power perceived of cell \(j\) in any RE of the RB \(k\) and \(N\) is the power noise spectral density in any RE. The sample is considered as valid in case of the RSRQ evaluated is above the \sphinxcode{\sphinxupquote{LteUePhy::RsrqUeMeasThreshold}} attribute.


\subsection{HARQ}
\label{\detokenize{lte-design:harq}}
The HARQ scheme implemented is based on a incremental redundancy (IR) solutions combined with multiple stop\sphinxhyphen{}and\sphinxhyphen{}wait processes for enabling a continuous data flow. In detail, the solution adopted is the \sphinxstyleemphasis{soft combining hybrid IR Full incremental redundancy} (also called IR Type II), which implies that the retransmissions contain only new information respect to the previous ones. The resource allocation algorithm of the HARQ has been implemented within the respective scheduler classes (i.e., \sphinxcode{\sphinxupquote{RrFfMacScheduler}} and \sphinxcode{\sphinxupquote{PfFfMacScheduler}}, refer to their correspondent sections for more info), while the decodification part of the HARQ has been implemented in the \sphinxcode{\sphinxupquote{LteSpectrumPhy}} and \sphinxcode{\sphinxupquote{LteHarqPhy}} classes which will be detailed in this section.

According to the standard, the UL retransmissions are synchronous and therefore are allocated 7 ms after the original transmission. On the other hand, for the DL, they are asynchronous and therefore can be allocated in a more flexible way starting from 7 ms and it is a matter of the specific scheduler implementation. The HARQ processes behavior is depicted in Figure:ref:\sphinxtitleref{fig\sphinxhyphen{}harq\sphinxhyphen{}processes\sphinxhyphen{}scheme}.

At the MAC layer, the HARQ entity residing in the scheduler is in charge of controlling the 8 HARQ processes for generating new packets and managing the retransmissions both for the DL and the UL. The scheduler collects the HARQ feedback from eNB and UE PHY layers (respectively for UL and DL connection) by means of the FF API primitives \sphinxcode{\sphinxupquote{SchedUlTriggerReq}} and \sphinxcode{\sphinxupquote{SchedUlTriggerReq}}. According to the HARQ feedback and the RLC buffers status, the scheduler generates a set of DCIs including both retransmissions of HARQ blocks received erroneous and new transmissions, in general, giving priority to the former. On this matter, the scheduler has to take into consideration one constraint when allocating the resource for HARQ retransmissions, it must use the same modulation order of the first transmission attempt (i.e., QPSK for MCS \(\in [0..9]\), 16QAM for MCS \(\in [10..16]\) and 64QAM for MCS \(\in [17..28]\)). This restriction comes from the specification of the rate matcher in the 3GPP standard {[}
TS36212{]}\_, where the algorithm fixes the modulation order for generating the different blocks of the redundancy versions.

The PHY Error Model model (i.e., the \sphinxcode{\sphinxupquote{LteMiErrorModel}} class already presented before) has been extended for considering IR HARQ according to \sphinxcite{lte-references:wimaxemd}, where the parameters for the AWGN curves mapping for MIESM mapping in case of retransmissions are given by:
\begin{align*}\!\begin{aligned}
R_{eff} = \frac{X}{\sum\limits_{i=1}^q C_i}\\
M_{I eff} = \frac{\sum\limits_{i=1}^q C_i M_i}{\sum\limits_{i=1}^q C_i}\\
\end{aligned}\end{align*}
where \(X\) is the number of original information bits, \(C_i\) are number of coded bits, \(M_i\) are the mutual information per HARQ block received on the total number of \(q\) retransmissions. Therefore, in order to be able to return the error probability with the error model implemented in the simulator evaluates the \(R_{eff}\) and the \(MI_{I eff}\) and return the value of error probability of the ECR of the same modulation with closest lower rate respect to the \(R_{eff}\). In order to consider the effect of HARQ retransmissions a new sets of curves have been integrated respect to the standard one used for the original MCS. The new curves are intended for covering the cases when the most conservative MCS of a modulation is used which implies the generation of \(R_{eff}\) lower respect to the one of standard MCSs. On this matter the curves for 1, 2 and 3 retransmissions have been evaluated for 10 and 17. For MCS 0 we considered only the first retransmission since the
produced code rate is already very conservative (i.e., 0.04) and returns an error rate enough robust for the reception (i.e., the downturn of the BLER is centered around \sphinxhyphen{}18 dB).
It is to be noted that, the size of first TB transmission has been assumed as containing all the information bits to be coded; therefore \(X\) is equal to the size of the first TB sent of a an HARQ process. The model assumes that the eventual presence of parity bits in the codewords is already considered in the link level curves. This implies that as soon as the minimum \(R_{eff}\) is reached the model is not including the gain due to the transmission of further parity bits.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-harq-processes-scheme}.pdf}
\caption{HARQ processes behavior in LTE}\label{\detokenize{lte-design:id163}}\label{\detokenize{lte-design:fig-harq-processes-scheme}}\end{figure}

The part of HARQ devoted to manage the decodification of the HARQ blocks has been implemented in the \sphinxcode{\sphinxupquote{LteHarqPhy}} and \sphinxcode{\sphinxupquote{LteSpectrumPhy}} classes. The former is in charge of maintaining the HARQ information for each active process . The latter interacts with \sphinxcode{\sphinxupquote{LteMiErrorModel}} class for evaluating the correctness of the blocks received and includes the messaging algorithm in charge of communicating to the HARQ entity in the scheduler the result of the decodifications. These messages are encapsulated in the \sphinxcode{\sphinxupquote{dlInfoListElement}} for DL and \sphinxcode{\sphinxupquote{ulInfoListElement}} for UL and sent through the PUCCH and the PHICH respectively with an ideal error free model according to the assumptions in their implementation. A sketch of the iteration between HARQ and LTE protocol stack in represented in Figure:ref:\sphinxtitleref{fig\sphinxhyphen{}harq\sphinxhyphen{}architecture}.

Finally, the HARQ engine is always active both at MAC and PHY layer; however, in case of the scheduler does not support HARQ the system will continue to work with the HARQ functions inhibited (i.e., buffers are filled but not used). This implementation characteristic gives backward compatibility with schedulers implemented before HARQ integration.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-harq-architecture}.pdf}
\caption{Interaction between HARQ and LTE protocol stack}\label{\detokenize{lte-design:id164}}\label{\detokenize{lte-design:fig-harq-architecture}}\end{figure}


\subsection{MAC}
\label{\detokenize{lte-design:mac}}

\subsubsection{Resource Allocation Model}
\label{\detokenize{lte-design:resource-allocation-model}}
We now briefly describe how resource allocation is handled in LTE,
clarifying how it is modeled in the simulator. The scheduler is in
charge of generating specific structures called \sphinxstyleemphasis{Data Control Indication} (DCI)
which are then transmitted by the PHY of the eNB to the connected UEs, in order
to inform them of the resource allocation on a per subframe basis. In doing this
in the downlink direction, the scheduler has to fill some specific fields of the
DCI structure with all the information, such as: the Modulation and Coding
Scheme (MCS) to be used, the MAC Transport Block (TB) size, and the allocation
bitmap which identifies which RBs will contain the data
transmitted by the eNB to each user.

For the mapping of resources to
physical RBs, we adopt a \sphinxstyleemphasis{localized mapping} approach
(see \sphinxcite{lte-references:sesia2009}, Section 9.2.2.1);
hence in a given subframe each RB is always allocated to the same user in both
slots.
The allocation bitmap can be coded in
different formats; in this implementation, we considered the \sphinxstyleemphasis{Allocation
Type 0} defined in \sphinxcite{lte-references:ts36213}, according to which the RBs are grouped in
Resource Block Groups (RBG) of different size determined as a function of the
Transmission Bandwidth Configuration in use.

For certain bandwidth
values not all the RBs are usable, since the
group size is not a common divisor of the group. This is for instance the case
when the bandwidth is equal to 25 RBs, which results in a RBG size of 2 RBs, and
therefore 1 RB will result not addressable.
In uplink the format of the DCIs is different, since only adjacent RBs
can be used because of the SC\sphinxhyphen{}FDMA modulation. As a consequence, all
RBs can be allocated by the eNB regardless of the bandwidth
configuration.


\subsubsection{Adaptive Modulation and Coding}
\label{\detokenize{lte-design:adaptive-modulation-and-coding}}\label{\detokenize{lte-design:sec-lte-amc}}
The simulator provides two Adaptive Modulation and Coding (AMC) models: one based on the GSoC model \sphinxcite{lte-references:piro2011} and one based on the physical error model (described in the following sections).

The former model is a modified version of the model described in \sphinxcite{lte-references:piro2011},
which in turn is inspired from \sphinxcite{lte-references:seo2004}. Our version is described in the
following. Let \(i\) denote the
generic user, and let \(\gamma_i\) be its SINR. We get the spectral efficiency
\(\eta_i\) of user \(i\) using the following equations:
\begin{align*}\!\begin{aligned}
\mathrm{BER} = 0.00005\\
\Gamma = \frac{ -\ln{ (5 * \mathrm{BER}) } }{ 1.5}\\
\eta_i = \log_2 { \left( 1 + \frac{ {\gamma}_i }{ \Gamma } \right)}\\
\end{aligned}\end{align*}
The procedure described in \sphinxcite{lte-references:r1-081483} is used to get
the corresponding MCS scheme. The spectral efficiency is quantized based on the
channel quality indicator (CQI), rounding to the lowest value, and is mapped to the corresponding MCS
scheme.

Finally, we note that there are some discrepancies between the MCS index
in \sphinxcite{lte-references:r1-081483}
and that indicated by the standard:  \sphinxcite{lte-references:ts36213} Table
7.1.7.1\sphinxhyphen{}1 says that the MCS index goes from 0 to 31, and 0 appears to be a valid
MCS scheme (TB size is not 0) but in \sphinxcite{lte-references:r1-081483} the first useful MCS
index
is 1. Hence to get the value as intended by the standard we need to subtract 1
from the index reported in \sphinxcite{lte-references:r1-081483}.

The alternative model is based on the physical error model developed for this simulator and explained in the following subsections. This scheme is able to adapt the MCS selection to the actual PHY layer performance according to the specific CQI report. According to their definition, a CQI index is assigned when a single PDSCH TB with the modulation coding scheme and code rate correspondent to that CQI index in table 7.2.3\sphinxhyphen{}1 of \sphinxcite{lte-references:ts36213} can be received with an error probability less than 0.1. In case of wideband CQIs, the reference TB includes all the RBGs available in order to have a reference based on the whole available resources; while, for subband CQIs, the reference TB is sized as the RBGs.


\subsubsection{Transport Block model}
\label{\detokenize{lte-design:transport-block-model}}
The model of the MAC Transport Blocks (TBs) provided by the simulator
is simplified with respect to the 3GPP specifications. In particular,
a simulator\sphinxhyphen{}specific class (PacketBurst) is used to aggregate
MAC SDUs in order to achieve the simulator’s equivalent of a TB,
without the corresponding implementation complexity.
The multiplexing of different logical channels to and from the RLC
layer is performed using a dedicated packet tag (LteRadioBearerTag), which
performs a functionality which is partially equivalent to that of the
MAC headers specified by 3GPP.


\subsubsection{The FemtoForum MAC Scheduler Interface}
\label{\detokenize{lte-design:the-femtoforum-mac-scheduler-interface}}\label{\detokenize{lte-design:sec-ff-mac-scheduler}}
This section describes the ns\sphinxhyphen{}3 specific version of the LTE MAC
Scheduler Interface Specification published by the FemtoForum \sphinxcite{lte-references:ffapi}.

We implemented the ns\sphinxhyphen{}3 specific version of the FemtoForum MAC Scheduler
Interface \sphinxcite{lte-references:ffapi} as a set of C++ abstract
classes; in particular, each primitive is translated to a C++ method of a
given class. The term \sphinxstyleemphasis{implemented} here is used with the same
meaning adopted in \sphinxcite{lte-references:ffapi}, and hence refers to the process of translating
the logical interface specification to a particular programming language.
The primitives in \sphinxcite{lte-references:ffapi} are grouped in two groups: the CSCHED
primitives, which deal with scheduler configuration, and the SCHED primitives,
which deal with the execution of the scheduler. Furthermore, \sphinxcite{lte-references:ffapi}
defines primitives of two different kinds: those of type REQ go from the MAC to
the Scheduler, and those of type IND/CNF go from the scheduler to the MAC. To
translate these characteristics into C++, we define the following abstract
classes that implement Service Access Points (SAPs) to be used to issue the
primitives:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{FfMacSchedSapProvider}} class defines all the C++ methods that
correspond to SCHED primitives of type REQ;

\item {} 
the \sphinxcode{\sphinxupquote{FfMacSchedSapUser}} class defines all the C++ methods that
correspond to SCHED primitives of type CNF/IND;

\item {} 
the \sphinxcode{\sphinxupquote{FfMacCschedSapProvider}} class defines all the C++ methods that
correspond to CSCHED primitives of type REQ;

\item {} 
the \sphinxcode{\sphinxupquote{FfMacCschedSapUser}} class defines all the C++ methods that
correspond to CSCHED primitives of type CNF/IND;

\end{itemize}

There are 3 blocks involved in the MAC Scheduler interface: Control block,
Subframe block and Scheduler block. Each of these blocks provide one part of the
MAC Scheduler interface. The figure below shows the relationship
between the blocks and the SAPs defined in our implementation of the MAC
Scheduler Interface.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{ff-mac-saps}.pdf}
\end{figure}

In addition to the above principles, the following design choices have been
taken:
\begin{itemize}
\item {} 
The definition of the MAC Scheduler interface classes follows the naming
conventions of the \sphinxstyleemphasis{ns\sphinxhyphen{}3} Coding Style. In particular, we follow the
CamelCase convention for the primitive names. For example, the primitive
\sphinxcode{\sphinxupquote{CSCHED\_CELL\_CONFIG\_REQ}} is translated to \sphinxcode{\sphinxupquote{CschedCellConfigReq}}
in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} code.

\item {} 
The same naming conventions are followed for the primitive parameters. As
the primitive parameters are member variables of classes, they are also prefixed
with a \sphinxcode{\sphinxupquote{m\_}}.

\item {} 
regarding the use of vectors and lists in data structures, we note
that \sphinxcite{lte-references:ffapi} is a pretty much C\sphinxhyphen{}oriented API. However, considered that
C++ is used in ns\sphinxhyphen{}3, and that the use of C arrays is discouraged, we used STL
vectors (\sphinxcode{\sphinxupquote{std::vector}}) for the implementation of the MAC Scheduler
Interface, instead of using C arrays as implicitly suggested by the
way \sphinxcite{lte-references:ffapi} is written.

\item {} 
In C++, members with constructors and destructors are not allow in
\sphinxcode{\sphinxupquote{unions}}. Hence all those data structures that are said to be
\sphinxcode{\sphinxupquote{unions}} in \sphinxcite{lte-references:ffapi} have been defined as \sphinxcode{\sphinxupquote{structs}} in our code.

\end{itemize}

The figure below shows how the MAC Scheduler Interface is
used within the eNB.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{ff-example}.pdf}
\end{figure}

The User side of both the CSCHED SAP and the SCHED SAP are
implemented within the eNB MAC, i.e., in the file \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}enb\sphinxhyphen{}mac.cc}}.
The eNB MAC can be used with different scheduler implementations without
modifications. The same figure also shows, as an example, how the Round Robin
Scheduler is implemented: to interact with the MAC of the eNB, the Round Robin
scheduler implements the Provider side of the SCHED SAP and CSCHED
SAP interfaces. A similar approach can be used to implement other schedulers as
well. A description of each of the scheduler implementations that we provide as
part of our LTE simulation module is provided in the following subsections.


\paragraph{Round Robin (RR) Scheduler}
\label{\detokenize{lte-design:round-robin-rr-scheduler}}
The Round Robin (RR) scheduler is probably the simplest scheduler found in the literature. It works by dividing the
available resources among the active flows, i.e., those logical channels which have a non\sphinxhyphen{}empty RLC queue. If the number of RBGs is greater than the number of active flows, all the flows can be allocated in the same subframe. Otherwise, if the number of active flows is greater than the number of RBGs, not all the flows can be scheduled in a given subframe; then, in the next subframe the allocation will start from the last flow that was not allocated.  The MCS to be adopted for each user is done according to the received wideband CQIs.

For what concern the HARQ, RR implements the non adaptive version, which implies that in allocating the retransmission attempts RR uses the same allocation configuration of the original block, which means maintaining the same RBGs and MCS. UEs that are allocated for HARQ retransmissions are not considered for the transmission of new data in case they have a transmission opportunity available in the same TTI. Finally, HARQ can be disabled with ns3 attribute system for maintaining backward compatibility with old test cases and code, in detail:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RrFfMacScheduler::HarqEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The scheduler implements the filtering of the uplink CQIs according to their nature with \sphinxcode{\sphinxupquote{UlCqiFilter}} attribute, in detail:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SRS\_UL\_CQI}}: only SRS based CQI are stored in the internal attributes.

\item {} 
\sphinxcode{\sphinxupquote{PUSCH\_UL\_CQI}}: only PUSCH based CQI are stored in the internal attributes.

\end{itemize}


\paragraph{Proportional Fair (PF) Scheduler}
\label{\detokenize{lte-design:proportional-fair-pf-scheduler}}
The Proportional Fair (PF) scheduler \sphinxcite{lte-references:sesia2009} works by scheduling a user
when its
instantaneous channel quality is high relative to its own average channel
condition over time. Let \(i,j\) denote generic users; let \(t\) be the
subframe index, and \(k\) be the resource block index; let \(M_{i,k}(t)\) be MCS
usable by user \(i\) on resource block \(k\) according to what reported by the AMC
model (see {\hyperref[\detokenize{lte-design:adaptive-modulation-and-coding}]{\sphinxcrossref{Adaptive Modulation and Coding}}}); finally, let \(S(M, B)\) be the TB
size in bits as defined in \sphinxcite{lte-references:ts36213} for the case where a number \(B\) of
resource blocks is used. The achievable rate \(R_{i}(k,t)\) in bit/s for user \(i\)
on resource block group \(k\) at subframe \(t\) is defined as
\begin{equation*}
\begin{split}R_{i}(k,t) =  \frac{S\left( M_{i,k}(t), 1\right)}{\tau}\end{split}
\end{equation*}
where \(\tau\) is the TTI duration.
At the start of each subframe \(t\), each RBG is assigned to a certain user.
In detail, the index \(\widehat{i}_{k}(t)\) to which RBG \(k\) is assigned at time
\(t\) is determined as
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ R_{j}(k,t) }{ T_\mathrm{j}(t) } \right)\end{split}
\end{equation*}
where \(T_{j}(t)\) is the past througput performance perceived by the
user \(j\).
According to the above scheduling algorithm, a user can be allocated to
different RBGs, which can be either adjacent or not, depending on the current
condition of the channel and the past throughput performance \(T_{j}(t)\). The
latter is determined at the end of the subframe \(t\) using the following
exponential moving average approach:
\begin{equation*}
\begin{split}T_{j}(t) =
(1-\frac{1}{\alpha})T_{j}(t-1)
+\frac{1}{\alpha} \widehat{T}_{j}(t)\end{split}
\end{equation*}
where \(\alpha\) is the time constant (in number of subframes) of
the exponential moving average, and \(\widehat{T}_{j}(t)\) is the actual
throughput achieved by the user \(i\) in the subframe \(t\). \(\widehat{T}_{j}(t)\)
is measured according to the following procedure. First we
determine the MCS \(\widehat{M}_j(t)\) actually used by user
\(j\):
\begin{equation*}
\begin{split}\widehat{M}_j(t) = \min_{k: \widehat{i}_{k}(t) = j}{M_{j,k}(t)}\end{split}
\end{equation*}
then we determine the total number \(\widehat{B}_j(t)\) of RBGs allocated to user
\(j\):
\begin{equation*}
\begin{split}\widehat{B}_j(t) = \left| \{ k :  \widehat{i}_{k}(t) = j \} \right|\end{split}
\end{equation*}
where \(|\cdot|\) indicates the cardinality of the set; finally,
\begin{equation*}
\begin{split}\widehat{T}_{j}(t) = \frac{S\left( \widehat{M}_j(t), \widehat{B}_j(t)
\right)}{\tau}\end{split}
\end{equation*}
For what concern the HARQ, PF implements the non adaptive version, which implies that in allocating the retransmission attempts the scheduler uses the same allocation configuration of the original block, which means maintaining the same RBGs and MCS. UEs that are allocated for HARQ retransmissions are not considered for the transmission of new data in case they have a transmission opportunity available in the same TTI. Finally, HARQ can be disabled with ns3 attribute system for maintaining backward compatibility with old test cases and code, in detail:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::PfFfMacScheduler::HarqEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\paragraph{Maximum Throughput (MT) Scheduler}
\label{\detokenize{lte-design:maximum-throughput-mt-scheduler}}
The Maximum Throughput (MT) scheduler \sphinxcite{lte-references:fcapo2012} aims to maximize the overall throughput of eNB.
It allocates each RB to the user that can achieve the maximum achievable rate in the current TTI.
Currently, MT scheduler in NS\sphinxhyphen{}3 has two versions: frequency domain (FDMT) and time domain (TDMT).
In FDMT, every TTI, MAC scheduler allocates RBGs to the UE who has highest achievable rate calculated
by subband CQI. In TDMT, every TTI, MAC scheduler selects one UE which has highest achievable rate
calculated by wideband CQI. Then MAC scheduler allocates all RBGs to this UE in current TTI.
The calculation of achievable rate in FDMT and TDMT is as same as the one in PF.
Let \(i,j\) denote generic users; let \(t\) be the
subframe index, and \(k\) be the resource block index; let \(M_{i,k}(t)\) be MCS
usable by user \(i\) on resource block \(k\) according to what reported by the AMC
model (see {\hyperref[\detokenize{lte-design:adaptive-modulation-and-coding}]{\sphinxcrossref{Adaptive Modulation and Coding}}}); finally, let \(S(M, B)\) be the TB
size in bits as defined in \sphinxcite{lte-references:ts36213} for the case where a number \(B\) of
resource blocks is used. The achievable rate \(R_{i}(k,t)\) in bit/s for user \(i\)
on resource block \(k\) at subframe \(t\) is defined as
\begin{equation*}
\begin{split}R_{i}(k,t) =  \frac{S\left( M_{i,k}(t), 1\right)}{\tau}\end{split}
\end{equation*}
where \(\tau\) is the TTI duration.
At the start of each subframe \(t\), each RB is assigned to a certain user.
In detail, the index \(\widehat{i}_{k}(t)\) to which RB \(k\) is assigned at time
\(t\) is determined as
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
    \left( { R_{j}(k,t) } \right)\end{split}
\end{equation*}
When there are several UEs having the same achievable rate, current implementation always selects
the first UE created in script. Although MT can maximize cell throughput, it cannot provide
fairness to UEs in poor channel condition.


\paragraph{Throughput to Average (TTA) Scheduler}
\label{\detokenize{lte-design:throughput-to-average-tta-scheduler}}
The Throughput to Average (TTA) scheduler \sphinxcite{lte-references:fcapo2012} can be considered as an intermediate between MT and PF.
The metric used in TTA is calculated as follows:
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ R_{j}(k,t) }{ R_{j}(t) } \right)\end{split}
\end{equation*}
Here, \(R_{i}(k,t)\) in bit/s represents the achievable rate for user \(i\)
on resource block \(k\) at subframe \(t\). The
calculation method already is shown in MT and PF. Meanwhile, \(R_{i}(t)\) in bit/s stands
for the achievable rate for \(i\) at subframe \(t\). The difference between those two
achievable rates is how to get MCS. For \(R_{i}(k,t)\), MCS is calculated by subband CQI while
\(R_{i}(t)\) is calculated by wideband CQI. TTA scheduler can only be implemented in frequency domain (FD) because
the achievable rate of particular RBG is only related to FD scheduling.


\paragraph{Blind Average Throughput Scheduler}
\label{\detokenize{lte-design:blind-average-throughput-scheduler}}
The Blind Average Throughput scheduler \sphinxcite{lte-references:fcapo2012} aims to provide equal throughput to all UEs under eNB. The metric
used in TTA is calculated as follows:
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ 1 }{ T_\mathrm{j}(t) } \right)\end{split}
\end{equation*}
where \(T_{j}(t)\) is the past throughput performance perceived by the user \(j\) and can be calculated by the
same method in PF scheduler. In the time domain blind average throughput (TD\sphinxhyphen{}BET), the scheduler selects the UE
with largest priority metric and allocates all RBGs to this UE. On the other hand, in the frequency domain blind
average throughput (FD\sphinxhyphen{}BET), every TTI, the scheduler first selects one UE with lowest pastAverageThroughput (largest
priority metric). Then scheduler assigns one RBG to this UE, it calculates expected throughput of this UE and uses it
to compare with past average throughput \(T_{j}(t)\) of other UEs. The scheduler continues
to allocate RBG to this UE until its expected throughput is not the smallest one among past average throughput \(T_{j}(t)\)
of all UE. Then the scheduler will use the same way to allocate RBG for a new UE which has the
lowest past average throughput \(T_{j}(t)\) until all RBGs are allocated to UEs. The principle behind this is
that, in every TTI, the scheduler tries the best to achieve the equal throughput among all UEs.


\paragraph{Token Bank Fair Queue Scheduler}
\label{\detokenize{lte-design:token-bank-fair-queue-scheduler}}
Token Bank Fair Queue (TBFQ) is a QoS aware scheduler which derives from the leaky\sphinxhyphen{}bucket mechanism. In TBFQ,
a traffic flow of user \(i\) is characterized by following parameters:
\begin{itemize}
\item {} 
\(t_{i}\): packet arrival rate (byte/sec )

\item {} 
\(r_{i}\): token generation rate (byte/sec)

\item {} 
\(p_{i}\): token pool size (byte)

\item {} 
\(E_{i}\): counter that records the number of token borrowed from or given to the token bank by flow \(i\) ;
\(E_{i}\) can be smaller than zero

\end{itemize}

Each K bytes data consumes k tokens. Also, TBFQ maintains a shared token bank (\(B\)) so as to balance the traffic
between different flows. If token generation rate \(r_{i}\) is bigger than packet arrival rate \(t_{i}\), then tokens
overflowing from token pool are added to the token bank, and \(E_{i}\) is increased by the same amount. Otherwise,
flow \(i\) needs to withdraw tokens from token bank based on a priority metric \(frac{E_{i}}{r_{i}}\), and \(E_{i}\) is decreased.
Obviously, the user contributes more on token bank has higher priority to borrow tokens; on the other hand, the
user borrows more tokens from bank has lower priority to continue to withdraw tokens. Therefore, in case of several
users having the same token generation rate, traffic rate and token pool size, user suffers from higher interference
has more opportunity to borrow tokens from bank. In addition, TBFQ can police the traffic by setting the token
generation rate to limit the throughput.  Additionally, TBFQ also maintains following three parameters for each flow:
\begin{itemize}
\item {} 
Debt limit \(d_{i}\): if \(E_{i}\) belows this threshold, user i cannot further borrow tokens from bank. This is for
preventing malicious UE to borrow too much tokens.

\item {} 
Credit limit \(c_{i}\): the maximum number of tokens UE i can borrow from the bank in one time.

\item {} 
Credit threshold \(C\): once \(E_{i}\) reaches debt limit, UE i must store \(C\) tokens to bank in order to further
borrow token from bank.

\end{itemize}

LTE in NS\sphinxhyphen{}3 has two versions of TBFQ scheduler: frequency domain TBFQ (FD\sphinxhyphen{}TBFQ) and time domain TBFQ (TD\sphinxhyphen{}TBFQ).
In FD\sphinxhyphen{}TBFQ, the scheduler always select UE with highest metric and allocates RBG with highest subband CQI until
there are no packets within UE’s RLC buffer or all RBGs are allocated \sphinxcite{lte-references:fabokhari2009}. In TD\sphinxhyphen{}TBFQ, after selecting
UE with maximum metric, it allocates all RBGs to this UE by using wideband CQI \sphinxcite{lte-references:wkwong2004}.


\paragraph{Priority Set Scheduler}
\label{\detokenize{lte-design:priority-set-scheduler}}
Priority set scheduler (PSS) is a QoS aware scheduler which combines time domain (TD) and frequency domain (FD)
packet scheduling operations into one scheduler \sphinxcite{lte-references:gmonghal2008}. It controls the fairness among UEs by a specified
Target Bit Rate (TBR).

In TD scheduler part, PSS first selects UEs with non\sphinxhyphen{}empty RLC buffer and then divide them into two sets based
on the TBR:
\begin{itemize}
\item {} 
set 1: UE whose past average throughput is smaller than TBR; TD scheduler calculates their priority metric in
Blind Equal Throughput (BET) style:

\end{itemize}
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ 1 }{ T_\mathrm{j}(t) } \right)\end{split}
\end{equation*}\begin{itemize}
\item {} 
set 2: UE whose past average throughput is larger (or equal) than TBR; TD scheduler calculates their priority
metric in Proportional Fair (PF) style:

\end{itemize}
\begin{equation*}
\begin{split}\widehat{i}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ R_{j}(k,t) }{ T_\mathrm{j}(t) } \right)\end{split}
\end{equation*}
UEs belonged to set 1 have higher priority than ones in set 2. Then PSS will select \(N_{mux}\) UEs with
highest metric in two sets and forward those UE to FD scheduler. In PSS, FD scheduler allocates RBG k to UE n
that maximums the chosen metric. Two PF schedulers are used in PF scheduler:
\begin{itemize}
\item {} 
Proportional Fair scheduled (PFsch)

\end{itemize}
\begin{equation*}
\begin{split}\widehat{Msch}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ R_{j}(k,t) }{ Tsch_\mathrm{j}(t) } \right)\end{split}
\end{equation*}\begin{itemize}
\item {} 
Carrier over Interference to Average (CoIta)

\end{itemize}
\begin{equation*}
\begin{split}\widehat{Mcoi}_{k}(t) = \underset{j=1,...,N}{\operatorname{argmax}}
 \left( \frac{ CoI[j,k] }{ \sum_{k=0}^{N_{RBG}} CoI[j,k] } \right)\end{split}
\end{equation*}
where \(Tsch_{j}(t)\) is similar past throughput performance perceived by the user \(j\), with the
difference that it is updated only when the i\sphinxhyphen{}th user is actually served. \(CoI[j,k]\) is an
estimation of the SINR on the RBG \(k\) of UE \(j\). Both PFsch and CoIta is for decoupling
FD metric from TD scheduler. In addition, PSS FD scheduler also provide a weight metric W{[}n{]} for helping
controlling fairness in case of low number of UEs.
\begin{equation*}
\begin{split}W[n] =  max (1, \frac{TBR}{ T_{j}(t) })\end{split}
\end{equation*}
where \(T_{j}(t)\) is the past throughput performance perceived by the user \(j\) . Therefore, on
RBG k, the FD scheduler selects the UE \(j\) that maximizes the product of the frequency domain
metric (\(Msch\), \(MCoI\)) by weight \(W[n]\). This strategy will guarantee the throughput of lower
quality UE tend towards the TBR.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::PfFfMacScheduler::HarqEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The scheduler implements the filtering of the uplink CQIs according to their nature with \sphinxcode{\sphinxupquote{UlCqiFilter}} attribute, in detail:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SRS\_UL\_CQI}}: only SRS based CQI are stored in the internal attributes.

\item {} 
\sphinxcode{\sphinxupquote{PUSCH\_UL\_CQI}}: only PUSCH based CQI are stored in the internal attributes.

\end{itemize}


\paragraph{Channel and QoS Aware Scheduler}
\label{\detokenize{lte-design:channel-and-qos-aware-scheduler}}
The Channel and QoS Aware (CQA) Scheduler \sphinxcite{lte-references:bbojovic2014} is an LTE
MAC downlink scheduling algorithm that considers the head of line
(HOL) delay, the GBR parameters and channel quality over
different subbands. The CQA scheduler is based on joint TD and FD
scheduling.

In the TD (at each TTI) the CQA scheduler groups users by
priority. The purpose of grouping is to enforce the FD scheduling to
consider first the flows with highest HOL delay. The grouping metric
\(m_{td}\) for user \(j=1,...,N\) is defined in the
following way:
\begin{equation*}
\begin{split}m_{td}^{j}(t) = \lceil\frac{d_{hol}^{j}(t)}{g}\rceil \;,\end{split}
\end{equation*}
where \(d_{hol}^{j}(t)\) is the current value of HOL delay of flow
\(j\), and \(g\) is a grouping parameter that determines
granularity of the groups, i.e. the number of the flows that will be
considered in the FD scheduling iteration.

The groups of flows selected in the TD iteration are forwarded to the FD
scheduling starting from the flows with the highest value of the
\(m_{td}\) metric until all RBGs are assigned in the corresponding
TTI.  In the FD, for each RBG \(k=1,...,K\), the CQA scheduler
assigns the current RBG to the user \(j\) that has the maximum value of
the FD metric which we define in the following way:
\begin{equation*}
\begin{split}m_{fd}^{(k,j)}(t) = d_{HOL}^{j}(t) \cdot m_{GBR}^j(t) \cdot m_{ca}^{k,j}(t) \;,\end{split}
\end{equation*}
where \(m_{GBR}^j(t)\) is calculated as follows:
\begin{equation*}
\begin{split}m_{GBR}^j(t)=\frac{GBR^j}{\overline{R^j}(t)}=\frac{GBR^j}{(1-\alpha)\cdot\overline{R^j}(t-1)+\alpha \cdot r^j(t)} \;,\end{split}
\end{equation*}
where \(GBR^j\) is the bit rate specified in EPS bearer of the
flow \(j\), \(\overline{R^j}(t)\) is the past averaged throughput that is calculated with a
moving average, \(r^{j}(t)\) is the throughput achieved at the
time t, and \(\alpha\) is a coefficient such that \(0 \le \alpha
\le1\).

For \(m_{ca}^{(k,j)}(t)\) we consider two different
metrics: \(m_{pf}^{(k,j)}(t)\) and \(m_{ff}^{(k,j)}(t)\).
\(m_{pf}\) is the Proportional Fair metric which is defined as follows:
\begin{equation*}
\begin{split}m_{pf}^{(k,j)}(t) = \frac{R_e^{(k,j)}}{\overline{R^j}(t)} \;,\end{split}
\end{equation*}
where \(R_e^{(k,j)}(t)\) is the estimated achievable throughput of user
\(j\) over RBG \(k\) calculated by the Adaptive Modulation and Coding
(AMC) scheme that maps the channel quality indicator (CQI) value to
the transport block size in bits.

The other channel awareness metric that we consider is \(m_{ff}\) which
is proposed in \sphinxcite{lte-references:gmonghal2008} and it represents the frequency
selective fading gains over RBG \(k\) for user \(j\) and is calculated in
the following way:
\begin{equation*}
\begin{split}m_{ff}^{(k,j)}(t) = \frac{CQI^{(k,j)}(t)}{\sum_{k=1}^{K}CQI(t)^{(k,j)}} \;,\end{split}
\end{equation*}
where \(CQI^{(k,j)}(t)\) is the last reported CQI value from user
\(j\) for the \(k\)\sphinxhyphen{}th RBG.

The user can select whether \(m_{pf}\) or \(m_{ff}\) is used
by setting the attribute \sphinxcode{\sphinxupquote{ns3::CqaFfMacScheduler::CqaMetric}}
respectively to \sphinxcode{\sphinxupquote{"CqaPf"}} or \sphinxcode{\sphinxupquote{"CqaFf"}}.


\subsubsection{Random Access}
\label{\detokenize{lte-design:random-access}}\label{\detokenize{lte-design:sec-random-access}}
The LTE model includes a model of the Random Access procedure based on
some simplifying assumptions, which are detailed in the following for
each of the messages and signals described in the specs \sphinxcite{lte-references:ts36321}.
\begin{itemize}
\item {} 
\sphinxstylestrong{Random Access (RA) preamble}: in real LTE systems this
corresponds to a Zadoff\sphinxhyphen{}Chu (ZC)
sequence using one of several formats available and sent in the
PRACH slots which could in principle overlap with PUSCH.
PRACH Configuration Index 14 is assumed, i.e., preambles can be
sent on any system frame number and subframe number.
The RA preamble is modeled using the LteControlMessage class,
i.e., as an ideal message that does not consume any radio
resources. The collision of preamble transmission by multiple UEs
in the same cell are modeled using a protocol interference model,
i.e., whenever two or more identical preambles are transmitted in
same cell at the same TTI, no one of these identical preambles
will be received by the eNB. Other than this collision model, no
error model is associated with the reception of a RA preamble.

\item {} 
\sphinxstylestrong{Random Access Response (RAR)}: in real LTE systems, this is a
special MAC PDU sent on the DL\sphinxhyphen{}SCH. Since MAC control elements are not
accurately modeled in the simulator (only RLC and above PDUs
are), the RAR is modeled as an LteControlMessage that does not
consume any radio resources. Still, during the RA procedure, the
LteEnbMac will request to the scheduler the allocation of
resources for the RAR using the FF MAC Scheduler primitive
SCHED\_DL\_RACH\_INFO\_REQ. Hence, an enhanced scheduler
implementation (not available at the moment) could allocate radio
resources for the RAR, thus modeling the consumption of Radio
Resources for the transmission of the RAR.

\item {} 
\sphinxstylestrong{Message 3}:  in real LTE systems, this is an RLC TM
SDU sent over resources specified in the UL Grant in the RAR. In
the simulator, this is modeled as a real RLC TM RLC PDU
whose UL resources are allocated by the scheduler upon call to
SCHED\_DL\_RACH\_INFO\_REQ.

\item {} 
\sphinxstylestrong{Contention Resolution (CR)}: in real LTE system, the CR phase
is needed to address the case where two or more UE sent the same
RA preamble in the same TTI, and the eNB was able to detect this
preamble in spite of the collision. Since this event does not
occur due to the protocol interference model used for the
reception of RA preambles, the CR phase is not modeled in the
simulator, i.e., the CR MAC CE is never sent by the eNB and the
UEs consider the RA to be successful upon reception of the
RAR. As a consequence, the radio resources consumed for the
transmission of the CR MAC CE are not modeled.

\end{itemize}

Figure {\hyperref[\detokenize{lte-design:fig-mac-random-access-contention}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the Contention\sphinxhyphen{}based MAC Random Access procedure}}}} and
{\hyperref[\detokenize{lte-design:fig-mac-random-access-noncontention}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the Non\sphinxhyphen{}contention\sphinxhyphen{}based MAC Random Access procedure}}}} shows the sequence diagrams
of respectively the contention\sphinxhyphen{}based and non\sphinxhyphen{}contention\sphinxhyphen{}based MAC
random access procedure, highlighting the interactions between the MAC
and the other entities.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{mac-random-access-contention}.pdf}
\caption{Sequence diagram of the Contention\sphinxhyphen{}based MAC Random Access procedure}\label{\detokenize{lte-design:id165}}\label{\detokenize{lte-design:fig-mac-random-access-contention}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{mac-random-access-noncontention}.pdf}
\caption{Sequence diagram of the Non\sphinxhyphen{}contention\sphinxhyphen{}based MAC Random Access procedure}\label{\detokenize{lte-design:id166}}\label{\detokenize{lte-design:fig-mac-random-access-noncontention}}\end{figure}

\clearpage


\subsection{RLC}
\label{\detokenize{lte-design:rlc}}

\subsubsection{Overview}
\label{\detokenize{lte-design:id70}}
The RLC entity is specified in the 3GPP technical specification
\sphinxcite{lte-references:ts36322}, and comprises three different types of RLC: Transparent
Mode (TM), Unacknowledged Mode (UM) and Acknowledged Mode (AM). The
simulator includes one model for each of these entities

The RLC entities provide the RLC service interface to the upper PDCP layer and the MAC service interface
to the lower MAC layer. The RLC entities use the PDCP service interface from the upper PDCP layer and
the MAC service interface from the lower MAC layer.

Figure {\hyperref[\detokenize{lte-design:fig-lte-rlc-implementation-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Implementation Model of PDCP, RLC and MAC entities and SAPs}}}} shows the
implementation model of the RLC entities and its relationship
with all the other entities and services in the protocol stack.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-rlc-implementation-model}.pdf}
\caption{Implementation Model of PDCP, RLC and MAC entities and SAPs}\label{\detokenize{lte-design:id167}}\label{\detokenize{lte-design:fig-lte-rlc-implementation-model}}\end{figure}


\subsubsection{Service Interfaces}
\label{\detokenize{lte-design:service-interfaces}}

\paragraph{RLC Service Interface}
\label{\detokenize{lte-design:rlc-service-interface}}
The RLC service interface is divided into two parts:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{RlcSapProvider}} part is provided by the RLC layer and used by the upper PDCP layer and

\item {} 
the \sphinxcode{\sphinxupquote{RlcSapUser}} part is provided by the upper PDCP layer and used by the RLC layer.

\end{itemize}

Both the UM and the AM RLC entities provide the same RLC service interface to the upper PDCP layer.


\subparagraph{RLC Service Primitives}
\label{\detokenize{lte-design:rlc-service-primitives}}
The following list specifies which service primitives are provided by the RLC service interfaces:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{RlcSapProvider::TransmitPdcpPdu}}
\begin{itemize}
\item {} 
The PDCP entity uses this primitive to send a PDCP PDU to the lower RLC entity
in the transmitter peer

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{RlcSapUser::ReceivePdcpPdu}}
\begin{itemize}
\item {} 
The RLC entity uses this primitive to send a PDCP PDU to the upper PDCP entity
in the receiver peer

\end{itemize}

\end{itemize}


\paragraph{MAC Service Interface}
\label{\detokenize{lte-design:mac-service-interface}}
The MAC service interface is divided into two parts:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{MacSapProvider}} part is provided by the MAC layer and used by the upper RLC layer and

\item {} 
the \sphinxcode{\sphinxupquote{MacSapUser}}  part is provided by the upper RLC layer and used by the MAC layer.

\end{itemize}


\subparagraph{MAC Service Primitives}
\label{\detokenize{lte-design:mac-service-primitives}}
The following list specifies which service primitives are provided by the MAC service interfaces:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MacSapProvider::TransmitPdu}}
\begin{itemize}
\item {} 
The RLC entity uses this primitive to send a RLC PDU to the lower MAC entity
in the transmitter peer

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{MacSapProvider::ReportBufferStatus}}
\begin{itemize}
\item {} 
The RLC entity uses this primitive to report the MAC entity the size of pending buffers
in the transmitter peer

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{MacSapUser::NotifyTxOpportunity}}
\begin{itemize}
\item {} 
The MAC entity uses this primitive to notify the RLC entity a transmission opportunity

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{MacSapUser::ReceivePdu}}
\begin{itemize}
\item {} 
The MAC entity uses this primitive to send an RLC PDU to the upper RLC entity
in the receiver peer

\end{itemize}

\end{itemize}


\subsubsection{AM RLC}
\label{\detokenize{lte-design:am-rlc}}\label{\detokenize{lte-design:sec-am-data-transfer}}
The processing of the data transfer in the Acknowledge Mode (AM) RLC entity is explained in section 5.1.3 of \sphinxcite{lte-references:ts36322}.
In this section we describe some details of the implementation of the
RLC entity.


\paragraph{Buffers for the transmit operations}
\label{\detokenize{lte-design:buffers-for-the-transmit-operations}}
Our implementation of the AM RLC entity maintains 3 buffers for the
transmit operations:
\begin{itemize}
\item {} 
\sphinxstylestrong{Transmission Buffer}: it is the RLC SDU queue.
When the AM RLC entity receives a SDU in the TransmitPdcpPdu service primitive from the
upper PDCP entity, it enqueues it in the Transmission Buffer. We
put a limit on the RLC buffer size and just silently drop SDUs
when the buffer is full.

\item {} 
\sphinxstylestrong{Transmitted PDUs Buffer}: it is the queue of transmitted RLC PDUs for which an ACK/NACK has not
been received yet. When the AM RLC entity sends a PDU to the MAC
entity, it also puts a copy of the transmitted PDU in the Transmitted PDUs Buffer.

\item {} 
\sphinxstylestrong{Retransmission Buffer}: it is the queue of RLC PDUs which are considered for retransmission
(i.e., they have been NACKed). The AM RLC entity moves this PDU to the Retransmission Buffer,
when it retransmits a PDU from the Transmitted Buffer.

\end{itemize}


\paragraph{Transmit operations in downlink}
\label{\detokenize{lte-design:transmit-operations-in-downlink}}\label{\detokenize{lte-design:sec-rlc-am-tx-operations}}
The following sequence diagram shows the interactions between the
different entities (RRC, PDCP, AM RLC, MAC and MAC scheduler) of the
eNB in the downlink to perform data communications.

Figure {\hyperref[\detokenize{lte-design:fig-lte-rlc-data-txon-dl}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of data PDU transmission in downlink}}}} shows how the upper layers send
data PDUs and how the data flow is processed by the different
entities/services of the LTE protocol stack.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=550\sphinxpxdimen]{{lte-rlc-data-txon-dl}.pdf}
\caption{Sequence diagram of data PDU transmission in downlink}\label{\detokenize{lte-design:id168}}\label{\detokenize{lte-design:fig-lte-rlc-data-txon-dl}}\end{figure}

The PDCP entity calls the \sphinxcode{\sphinxupquote{Transmit\_PDCP\_PDU service primitive}} in
order to send a data PDU. The AM RLC entity processes this service
primitive according to the AM data transfer procedures defined in
section 5.1.3 of \sphinxcite{lte-references:ts36322}.

When the \sphinxcode{\sphinxupquote{Transmit\_PDCP\_PDU}} service primitive is called, the AM RLC
entity performs the following operations:
\begin{itemize}
\item {} 
Put the data SDU in the Transmission Buffer.

\item {} 
Compute the size of the buffers (how the size of buffers is
computed will be explained afterwards).

\item {} 
Call the \sphinxcode{\sphinxupquote{Report\_Buffer\_Status}} service primitive of the eNB
MAC entity in order to notify to the eNB MAC
entity the sizes of the buffers of the AM RLC entity. Then, the
eNB MAC entity updates the buffer status in the MAC scheduler
using the SchedDlRlcBufferReq service primitive of the FF MAC
Scheduler API.

\end{itemize}

Afterwards, when the MAC scheduler decides that some data can be sent,
the MAC entity notifies it to the RLC entity, i.e. it calls the
\sphinxcode{\sphinxupquote{Notify\_Tx\_Opportunity}} service primitive, then the AM RLC entity
does the following:
\begin{itemize}
\item {} 
Create a single data PDU by segmenting and/or concatenating the
SDUs in the Transmission Buffer.

\item {} 
Move the data PDU from the Transmission Buffer to the
Transmitted PDUs Buffer.

\item {} 
Update state variables according section 5.1.3.1.1 of
\sphinxcite{lte-references:ts36322}.

\item {} 
Call the \sphinxcode{\sphinxupquote{Transmit\_PDU}} primitive in order to send the data
PDU to the MAC entity.

\end{itemize}


\paragraph{Retransmission in downlink}
\label{\detokenize{lte-design:retransmission-in-downlink}}
The sequence diagram of Figure {\hyperref[\detokenize{lte-design:fig-lte-rlc-data-retx-dl}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of data PDU retransmission in downlink}}}} shows
the interactions between the different entities (AM RLC, MAC and MAC
scheduler) of the eNB in downlink when data PDUs must be retransmitted
by the AM RLC entity.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{lte-rlc-data-retx-dl}.pdf}
\caption{Sequence diagram of data PDU retransmission in downlink}\label{\detokenize{lte-design:id169}}\label{\detokenize{lte-design:fig-lte-rlc-data-retx-dl}}\end{figure}

The transmitting AM RLC entity can receive STATUS PDUs from the peer AM RLC entity. STATUS PDUs are
sent according section 5.3.2 of \sphinxcite{lte-references:ts36322} and the processing of reception is made according
section 5.2.1 of \sphinxcite{lte-references:ts36322}.

When a data PDUs is retransmitted from the Transmitted PDUs Buffer, it is also moved to the
Retransmission Buffer.


\paragraph{Transmit operations in uplink}
\label{\detokenize{lte-design:transmit-operations-in-uplink}}
The sequence diagram of Figure {\hyperref[\detokenize{lte-design:fig-lte-rlc-data-txon-ul}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of data PDU transmission in uplink}}}} shows
the interactions between the different entities of the UE (RRC, PDCP,
RLC and MAC) and the eNB (MAC and Scheduler) in uplink when data PDUs
are sent by the upper layers.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=550\sphinxpxdimen]{{lte-rlc-data-txon-ul}.pdf}
\caption{Sequence diagram of data PDU transmission in uplink}\label{\detokenize{lte-design:id170}}\label{\detokenize{lte-design:fig-lte-rlc-data-txon-ul}}\end{figure}

It is similar to the sequence diagram in downlink; the main difference
is that in this case the Report\_Buffer\_Status is sent from the UE MAC
to the MAC Scheduler in the eNB over the air using the control
channel.


\paragraph{Retransmission in uplink}
\label{\detokenize{lte-design:retransmission-in-uplink}}
The sequence diagram of Figure {\hyperref[\detokenize{lte-design:fig-lte-rlc-data-retx-ul}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of data PDU retransmission in uplink}}}} shows
the interactions between the different entities of the UE (AM RLC and
MAC) and the eNB (MAC) in uplink when data PDUs must be retransmitted
by the AM RLC entity.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{lte-rlc-data-retx-ul}.pdf}
\caption{Sequence diagram of data PDU retransmission in uplink}\label{\detokenize{lte-design:id171}}\label{\detokenize{lte-design:fig-lte-rlc-data-retx-ul}}\end{figure}


\paragraph{Calculation of the buffer size}
\label{\detokenize{lte-design:calculation-of-the-buffer-size}}\label{\detokenize{lte-design:sec-rlc-am-buffer-size}}
The Transmission Buffer contains RLC SDUs. A RLC PDU is one or more SDU segments plus an RLC header.
The size of the RLC header of one RLC PDU depends on the number of SDU segments the PDU contains.

The 3GPP standard  (section 6.1.3.1 of \sphinxcite{lte-references:ts36321}) says clearly that,
for the uplink, the RLC and MAC headers are not considered in the
buffer size that is to be report as part of the Buffer Status Report.
For the downlink, the behavior is not specified. Neither \sphinxcite{lte-references:ffapi} specifies
how to do it. Our RLC model works by assuming that the calculation of
the buffer size in the downlink is done exactly as in the uplink,
i.e., not considering the RLC and MAC header size.

We note that this choice affects the interoperation with the
MAC scheduler, since, in response to the
\sphinxcode{\sphinxupquote{Notify\_Tx\_Opportunity}} service primitive, the RLC is expected to
create a PDU of no more than the size requested by the MAC, including
RLC overhead. Hence, unneeded fragmentation can occur if (for example)
the MAC notifies a transmission exactly equal to the buffer size
previously reported by the RLC. We assume that it is left to the Scheduler
to implement smart strategies for the selection of the size of the
transmission opportunity, in order to eventually avoid the inefficiency
of unneeded fragmentation.


\paragraph{Concatenation and Segmentation}
\label{\detokenize{lte-design:concatenation-and-segmentation}}
The AM RLC entity generates and sends exactly one RLC PDU for each transmission opportunity even
if it is smaller than the size reported by the transmission opportunity. So for instance, if a
STATUS PDU is to be sent, then only this PDU will be sent in that transmission opportunity.

The segmentation and concatenation for the SDU queue of the AM RLC entity follows the same philosophy
as the same procedures of the UM RLC entity but there are new state
variables (see \sphinxcite{lte-references:ts36322} section 7.1) only present in the AM RLC entity.

It is noted that, according to the 3GPP specs, there is no concatenation for the Retransmission Buffer.


\paragraph{Re\sphinxhyphen{}segmentation}
\label{\detokenize{lte-design:re-segmentation}}
The current model of the AM RLC entity does not support the
re\sphinxhyphen{}segmentation of the retransmission buffer. Rather, the AM RLC
entity just waits to receive a big enough transmission
opportunity.


\paragraph{Unsupported features}
\label{\detokenize{lte-design:unsupported-features}}
We do not support the following procedures of \sphinxcite{lte-references:ts36322} :
\begin{itemize}
\item {} 
“Send an indication of successful delivery of RLC SDU” (See section 5.1.3.1.1)

\item {} 
“Indicate to upper layers that max retransmission has been reached” (See section 5.2.1)

\item {} 
“SDU discard procedures” (See section 5.3)

\item {} 
“Re\sphinxhyphen{}establishment procedure” (See section 5.4)

\end{itemize}

We do not support any of the additional primitives of RLC SAP for AM RLC entity. In particular:
\begin{itemize}
\item {} 
no SDU discard notified by PDCP

\item {} 
no notification of successful / failed delivery by AM RLC entity to PDCP entity

\end{itemize}


\subsubsection{UM RLC}
\label{\detokenize{lte-design:um-rlc}}
In this section we describe the implementation of the Unacknowledged Mode (UM) RLC entity.


\paragraph{Transmit operations in downlink}
\label{\detokenize{lte-design:id81}}
The transmit operations of the UM RLC are similar to those of the AM
RLC previously described in Section {\hyperref[\detokenize{lte-design:sec-rlc-am-tx-operations}]{\sphinxcrossref{\DUrole{std,std-ref}{Transmit operations in downlink}}}},
with the difference that, following the specifications of \sphinxcite{lte-references:ts36322},
retransmission are not performed, and there are no STATUS PDUs.


\paragraph{Transmit operations in uplink}
\label{\detokenize{lte-design:id83}}
The transmit operations in the uplink are similar to those of the
downlink, with the main difference that the Report\_Buffer\_Status is
sent from the UE MAC to the MAC Scheduler in the eNB over the air
using the control channel.


\paragraph{Calculation of the buffer size}
\label{\detokenize{lte-design:id84}}
The calculation of the buffer size for the UM RLC is done using the
same approach of the AM RLC, please refer to section
{\hyperref[\detokenize{lte-design:sec-rlc-am-buffer-size}]{\sphinxcrossref{\DUrole{std,std-ref}{Calculation of the buffer size}}}} for the corresponding description.


\subsubsection{TM RLC}
\label{\detokenize{lte-design:tm-rlc}}
In this section we describe the implementation of the Transparent Mode (TM) RLC entity.


\paragraph{Transmit operations in downlink}
\label{\detokenize{lte-design:id85}}
In the simulator, the TM RLC still provides to the upper layers the
same service interface provided by the AM and UM RLC
entities to the PDCP layer; in practice, this interface is used by an RRC
entity (not a PDCP entity) for the transmission of RLC SDUs. This
choice is motivated by the fact that the services provided by the TM
RLC to the upper layers, according to \sphinxcite{lte-references:ts36322}, is a subset of those
provided by the UM and AM RLC entities to the PDCP layer; hence,
we reused the same interface for simplicity.

The transmit operations in the downlink are performed as follows. When
the \sphinxcode{\sphinxupquote{Transmit\_PDCP\_PDU service primitive}} is called by the upper
layers, the TM RLC does the following:
\begin{itemize}
\item {} 
put the SDU in the Transmission Buffer

\item {} 
compute the size of the Transmission Buffer

\item {} 
call the \sphinxcode{\sphinxupquote{Report\_Buffer\_Status}} service primitive of the eNB
MAC entity

\end{itemize}

Afterwards, when the MAC scheduler decides that some data can be sent
by the logical channel to which the TM RLC entity belongs, the MAC
entity notifies it to the TM RLC entity by calling the
\sphinxcode{\sphinxupquote{Notify\_Tx\_Opportunity}} service primitive. Upon reception of this
primitive, the TM RLC entity does the following:
\begin{itemize}
\item {} 
if the TX opportunity has a size that is greater than or equal to
the size of the head\sphinxhyphen{}of\sphinxhyphen{}line SDU in the Transmission Buffer
\begin{itemize}
\item {} 
dequeue the head\sphinxhyphen{}of\sphinxhyphen{}line SDU from the Transmission Buffer

\item {} 
create one RLC PDU that contains entirely that SDU, without any
RLC header

\item {} 
Call the \sphinxcode{\sphinxupquote{Transmit\_PDU}} primitive in order to send the RLC
PDU to the MAC entity.

\end{itemize}

\end{itemize}


\paragraph{Transmit operations in uplink}
\label{\detokenize{lte-design:id87}}
The transmit operations in the uplink are similar to those of the
downlink, with the main difference that a transmission opportunity can
also arise from the assignment of the UL GRANT as part of the Random
Access procedure, without an explicit Buffer Status Report issued by
the TM RLC entity.


\paragraph{Calculation of the buffer size}
\label{\detokenize{lte-design:id88}}
As per the specifications \sphinxcite{lte-references:ts36322}, the TM RLC does not add any RLC
header to the PDUs being transmitted. Because of this, the buffer size
reported to the MAC layer is calculated simply by summing the size of
all packets in the transmission buffer, thus notifying to the MAC the
exact buffer size.


\subsubsection{SM RLC}
\label{\detokenize{lte-design:sm-rlc}}
In addition to the AM, UM and TM implementations that are modeled
after the 3GPP specifications, a simplified RLC model is provided,
which is called Saturation Mode (SM) RLC. This RLC model does not accept
PDUs from any above layer (such as PDCP); rather, the SM RLC takes care of the
generation of RLC PDUs in response to
the notification of transmission opportunities notified by the MAC.
In other words, the SM RLC simulates saturation conditions, i.e., it
assumes that the RLC buffer is always full and can generate a new PDU
whenever notified by the scheduler.

The SM RLC is used for simplified simulation scenarios in which only the
LTE Radio model is used, without the EPC and hence without any IP
networking support. We note that, although the SM RLC is an
unrealistic traffic model, it still allows for the correct simulation
of scenarios with multiple flows belonging to different (non real\sphinxhyphen{}time)
QoS classes, in order to test the QoS performance obtained by different
schedulers. This can be
done since it is the task of the Scheduler to assign transmission
resources based on the characteristics (e.g., Guaranteed Bit Rate) of
each Radio Bearer, which are specified upon the definition of each
Bearer within the simulation program.

As for schedulers designed to work with real\sphinxhyphen{}time QoS
traffic that has delay constraints, the SM RLC is probably not an appropriate choice.
This is because the absence of actual RLC SDUs (replaced by the artificial
generation of Buffer Status Reports) makes it not possible to provide
the Scheduler with meaningful head\sphinxhyphen{}of\sphinxhyphen{}line\sphinxhyphen{}delay information, which is
often the metric of choice for the implementation of scheduling
policies for real\sphinxhyphen{}time traffic flows. For the simulation and testing
of such schedulers, it is advisable to use either the UM or the AM RLC
models instead.


\subsection{PDCP}
\label{\detokenize{lte-design:pdcp}}

\subsubsection{PDCP Model Overview}
\label{\detokenize{lte-design:pdcp-model-overview}}
The reference document for the specification of the PDCP entity is
\sphinxcite{lte-references:ts36323}. With respect to this specification, the PDCP model
implemented in the simulator supports only the following features:
\begin{itemize}
\item {} 
transfer of data (user plane or control plane);

\item {} 
maintenance of PDCP SNs;

\item {} 
transfer of SN status (for use upon handover);

\end{itemize}

The following features are currently not supported:
\begin{itemize}
\item {} 
header compression and decompression of IP data flows using the ROHC protocol;

\item {} 
in\sphinxhyphen{}sequence delivery of upper layer PDUs at re\sphinxhyphen{}establishment of lower layers;

\item {} 
duplicate elimination of lower layer SDUs at re\sphinxhyphen{}establishment of lower layers for radio bearers mapped on RLC AM;

\item {} 
ciphering and deciphering of user plane data and control plane data;

\item {} 
integrity protection and integrity verification of control plane data;

\item {} 
timer based discard;

\item {} 
duplicate discarding.

\end{itemize}


\subsubsection{PDCP Service Interface}
\label{\detokenize{lte-design:pdcp-service-interface}}
The PDCP service interface is divided into two parts:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{PdcpSapProvider}} part is provided by the PDCP layer and used by the upper layer and

\item {} 
the \sphinxcode{\sphinxupquote{PdcpSapUser}} part is provided by the upper layer and used by the PDCP layer.

\end{itemize}


\paragraph{PDCP Service Primitives}
\label{\detokenize{lte-design:pdcp-service-primitives}}
The following list specifies which service primitives are provided by the PDCP service interfaces:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{PdcpSapProvider::TransmitPdcpSdu}}
\begin{itemize}
\item {} 
The RRC entity uses this primitive to send an RRC PDU to the lower PDCP entity
in the transmitter peer

\end{itemize}

\item {} 
\sphinxcode{\sphinxupquote{PdcpSapUser::ReceivePdcpSdu}}
\begin{itemize}
\item {} 
The PDCP entity uses this primitive to send an RRC PDU to the upper RRC entity
in the receiver peer

\end{itemize}

\end{itemize}

\clearpage


\subsection{RRC}
\label{\detokenize{lte-design:rrc}}

\subsubsection{Features}
\label{\detokenize{lte-design:features}}
The RRC model implemented in the simulator provides the following functionality:
\begin{itemize}
\item {} 
generation (at the eNB) and interpretation (at the UE) of System
Information (in particular the Master Information Block and, at the
time of this writing, only System Information Block Type 1 and 2)

\item {} 
initial cell selection

\item {} 
RRC connection establishment procedure

\item {} 
RRC reconfiguration procedure, supporting the following use cases:
+ reconfiguration of the SRS configuration index
+ reconfiguration of the PHY TX mode (MIMO)
+ reconfiguration of UE measurements
+ data radio bearer setup
+ handover

\item {} 
RRC connection re\sphinxhyphen{}establishment, supporting the following use
cases:
+ handover

\end{itemize}


\subsubsection{Architecture}
\label{\detokenize{lte-design:id91}}
The RRC model is divided into the following components:
\begin{itemize}
\item {} 
the RRC entities \sphinxtitleref{LteUeRrc} and \sphinxtitleref{LteEnbRrc}, which implement the state
machines of the RRC entities respectively at the UE and the eNB;

\item {} 
the RRC SAPs \sphinxtitleref{LteUeRrcSapProvider}, \sphinxtitleref{LteUeRrcSapUser},
\sphinxtitleref{LteEnbRrcSapProvider}, \sphinxtitleref{LteEnbRrcSapUser}, which allow the RRC
entities to send and receive RRC messages and information
elmenents;

\item {} 
the RRC protocol classes \sphinxtitleref{LteUeRrcProtocolIdeal},
\sphinxtitleref{LteEnbRrcProtocolIdeal}, \sphinxtitleref{LteUeRrcProtocolReal},
\sphinxtitleref{LteEnbRrcProtocolReal}, which implement two different models for
the transmission of RRC messages.

\end{itemize}

Additionally, the RRC components use various other SAPs in order to
interact with the rest of the protocol stack. A representation of all
the SAPs that are used is provided in the figures {\hyperref[\detokenize{lte-design:fig-lte-arch-ue-data}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the UE on the data plane}}}},
{\hyperref[\detokenize{lte-design:fig-lte-arch-ue-ctrl}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the UE on the control plane}}}}, {\hyperref[\detokenize{lte-design:fig-lte-arch-enb-data}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the eNB on the data plane}}}} and
{\hyperref[\detokenize{lte-design:fig-lte-arch-enb-ctrl}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE radio protocol stack architecture for the eNB on the control plane}}}}.


\subsubsection{UE RRC State Machine}
\label{\detokenize{lte-design:ue-rrc-state-machine}}
In Figure {\hyperref[\detokenize{lte-design:fig-lte-ue-rrc-states}]{\sphinxcrossref{\DUrole{std,std-ref}{UE RRC State Machine}}}} we represent the state machine
as implemented in the RRC UE entity.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{lte-ue-rrc-states}.pdf}
\caption{UE RRC State Machine}\label{\detokenize{lte-design:id172}}\label{\detokenize{lte-design:fig-lte-ue-rrc-states}}\end{figure}

All the states are transient, however, the UE in “CONNECTED\_NORMALLY” state will
only switch to the IDLE state if the downlink SINR is below a defined threshold,
which would lead to radio link failure {\hyperref[\detokenize{lte-design:sec-radio-link-failure}]{\sphinxcrossref{\DUrole{std,std-ref}{Radio Link Failure}}}}.
One the other hand, the UE would not be able switch to IDLE mode due to a handover
failure, as mentioned in {\hyperref[\detokenize{lte-design:sec-x2}]{\sphinxcrossref{\DUrole{std,std-ref}{X2}}}}.


\subsubsection{ENB RRC State Machine}
\label{\detokenize{lte-design:enb-rrc-state-machine}}
The eNB RRC maintains the state for each UE that is attached to the
cell. From an implementation point of view, the state of each UE is
contained in an instance of the UeManager class. The state machine is
represented in Figure {\hyperref[\detokenize{lte-design:fig-lte-enb-rrc-states}]{\sphinxcrossref{\DUrole{std,std-ref}{ENB RRC State Machine for each UE}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{lte-enb-rrc-states}.pdf}
\caption{ENB RRC State Machine for each UE}\label{\detokenize{lte-design:id173}}\label{\detokenize{lte-design:fig-lte-enb-rrc-states}}\end{figure}


\subsubsection{Initial Cell Selection}
\label{\detokenize{lte-design:initial-cell-selection}}\label{\detokenize{lte-design:sec-initial-cell-selection}}
Initial cell selection is an IDLE mode procedure, performed by UE when it has
not yet camped or attached to an eNodeB. The objective of the procedure is to
find a suitable cell and attach to it to gain access to the cellular network.

It is typically done at the beginning of simulation, as depicted in Figure
{\hyperref[\detokenize{lte-design:fig-lte-cell-selection-timeline}]{\sphinxcrossref{\DUrole{std,std-ref}{Sample runs of initial cell selection in UE and timing of related events}}}} below. The time diagram on the left side
is illustrating the case where initial cell selection succeed on first try,
while the diagram on the right side is for the case where it fails on the first
try and succeed on the second try. The timing assumes the use of real RRC
protocol model (see {\hyperref[\detokenize{lte-design:sec-rrc-protocol-models}]{\sphinxcrossref{\DUrole{std,std-ref}{RRC protocol models}}}}) and no transmission error.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-cell-selection-timeline}.pdf}
\caption{Sample runs of initial cell selection in UE and timing of related events}\label{\detokenize{lte-design:id174}}\label{\detokenize{lte-design:fig-lte-cell-selection-timeline}}\end{figure}

The functionality is based on 3GPP IDLE mode specifications, such as in
\sphinxcite{lte-references:ts36300}, \sphinxcite{lte-references:ts36304}, and \sphinxcite{lte-references:ts36331}. However, a proper implementation of IDLE
mode is still missing in the simulator, so we reserve several simplifying
assumptions:
\begin{itemize}
\item {} 
multiple carrier frequency is not supported;

\item {} 
multiple Public Land Mobile Network (PLMN) identities (i.e. multiple network
operators) is not supported;

\item {} 
RSRQ measurements are not utilized;

\item {} 
stored information cell selection is not supported;

\item {} 
“Any Cell Selection” state and camping to an acceptable cell is not
supported;

\item {} 
marking a cell as barred or reserved is not supported;

\item {} 
Idle cell reselection is not supported, hence it is not possible for UE to camp to
a different cell after the initial camp has been placed; and

\item {} 
UE’s Closed Subscriber Group (CSG) white list contains only one CSG identity.

\end{itemize}

Also note that initial cell selection is only available for EPC\sphinxhyphen{}enabled
simulations. LTE\sphinxhyphen{}only simulations must use the manual attachment method. See
section {\hyperref[\detokenize{lte-user:sec-network-attachment}]{\sphinxcrossref{\DUrole{std,std-ref}{Network Attachment}}}} of the User Documentation for more
information on their differences in usage.

The next subsections cover different parts of initial cell selection, namely
\sphinxstyleemphasis{cell search}, \sphinxstyleemphasis{broadcast of system information}, and \sphinxstyleemphasis{cell selection evaluation}.


\paragraph{Cell Search}
\label{\detokenize{lte-design:cell-search}}\label{\detokenize{lte-design:sec-cell-search}}
Cell search aims to detect surrounding cells and measure the strength of
received signal from each of these cells. One of these cells will become the
UE’s entry point to join the cellular network.

The measurements are based on the RSRP of the received PSS, averaged by Layer 1
filtering, and performed by the PHY layer, as previously described in more
detail in section {\hyperref[\detokenize{lte-design:sec-phy-ue-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{UE PHY Measurements Model}}}}. PSS is transmitted by eNodeB
over the central 72 sub\sphinxhyphen{}carriers of the DL channel (Section 5.1.7.3 \sphinxcite{lte-references:ts36300}),
hence we model cell search to operate using a DL bandwidth of 6 RBs. Note that
measurements of RSRQ are not available at this point of time in simulation. As
a consequence, the \sphinxcode{\sphinxupquote{LteUePhy::RsrqUeMeasThreshold}} attribute does not apply
during cell search.

By using the measured RSRP, the PHY entity is able to generate a list of
detected cells, each with its corresponding cell ID and averaged RSRP. This list
is periodically pushed via CPHY SAP to the RRC entity as a measurement report.

The RRC entity inspects the report and simply choose the cell with the strongest
RSRP, as also indicated in Section 5.2.3.1 of \sphinxcite{lte-references:ts36304}. Then it instructs back
the PHY entity to synchronize to this particular cell. The actual operating
bandwidth of the cell is still unknown at this time, so the PHY entity listens
only to the minimum bandwidth of 6 RBs. Nevertheless, the PHY entity will be
able to receive system broadcast message from this particular eNodeB, which is
the topic of the next subsection.


\paragraph{Broadcast of System Information}
\label{\detokenize{lte-design:broadcast-of-system-information}}
System information blocks are broadcasted by eNodeB to UEs at predefined time
intervals, adapted from Section 5.2.1.2 of \sphinxcite{lte-references:ts36331}. The supported system
information blocks are:
\begin{itemize}
\item {} \begin{description}
\item[{Master Information Block (MIB)}] \leavevmode
Contains parameters related to the PHY layer, generated during cell
configuration and broadcasted every 10 ms at the beginning of radio frame
as a control message.

\end{description}

\item {} \begin{description}
\item[{System Information Block Type 1 (SIB1)}] \leavevmode
Contains information regarding network access, broadcasted every 20 ms at
the middle of radio frame as a control message. Not used in manual
attachment method. UE must have decoded MIB before it can receive SIB1.

\end{description}

\item {} \begin{description}
\item[{System Information Block Type 2 (SIB2)}] \leavevmode
Contains UL\sphinxhyphen{} and RACH\sphinxhyphen{}related settings, scheduled to transmit via RRC
protocol at 16 ms after cell configuration, and then repeats every 80 ms
(configurable through \sphinxtitleref{LteEnbRrc::SystemInformationPeriodicity} attribute.
UE must be camped to a cell in order to be able to receive its SIB2.

\end{description}

\end{itemize}

Reception of system information is fundamental for UE to advance in its
lifecycle. MIB enables the UE to increase the initial DL bandwidth of 6 RBs to
the actual operating bandwidth of the network. SIB1 provides information
necessary for cell selection evaluation (explained in the next section). And
finally SIB2 is required before the UE is allowed to switch to CONNECTED state.


\paragraph{Cell Selection Evaluation}
\label{\detokenize{lte-design:cell-selection-evaluation}}\label{\detokenize{lte-design:sec-cell-selection-evaluation}}
UE RRC reviews the measurement report produced in {\hyperref[\detokenize{lte-design:sec-cell-search}]{\sphinxcrossref{\DUrole{std,std-ref}{Cell Search}}}} and the
cell access information provided by SIB1. Once both information is available for
a specific cell, the UE triggers the evaluation process. The purpose of this
process is to determine whether the cell is a suitable cell to camp to.

The evaluation process is a slightly simplified version of Section 5.2.3.2 of
\sphinxcite{lte-references:ts36304}. It consists of the following criteria:
\begin{itemize}
\item {} 
Rx level criterion; and

\item {} 
closed subscriber group (CSG) criterion.

\end{itemize}

The first criterion, Rx level, is based on the cell’s measured RSRP
\(Q_{rxlevmeas}\), which has to be higher than a required minimum
\(Q_{rxlevmin}\) in order to pass the criterion:
\begin{equation*}
\begin{split}Q_{rxlevmeas} - Q_{rxlevmin} > 0\end{split}
\end{equation*}
where \(Q_{rxlevmin}\) is determined by each eNodeB and is obtainable by UE
from SIB1.

The last criterion, CSG, is a combination of a true\sphinxhyphen{}or\sphinxhyphen{}false parameter called
\sphinxstyleemphasis{CSG indication} and a simple number \sphinxstyleemphasis{CSG identity}. The basic rule is that UE
shall not camp to eNodeB with a different CSG identity. But this rule is only
enforced when CSG indication is valued as true. More details are provided in
Section {\hyperref[\detokenize{lte-user:sec-network-attachment}]{\sphinxcrossref{\DUrole{std,std-ref}{Network Attachment}}}} of the User Documentation.

When the cell passes all the above criteria, the cell is deemed as \sphinxstyleemphasis{suitable}.
Then UE camps to it (\sphinxtitleref{IDLE\_CAMPED\_NORMALLY} state).

After this, upper layer may request UE to enter CONNECTED mode. Please refer to
section {\hyperref[\detokenize{lte-design:sec-rrc-connection-establishment}]{\sphinxcrossref{\DUrole{std,std-ref}{RRC connection establishment}}}} for details on this.

On the other hand, when the cell does not pass the CSG criterion, then the cell
is labeled as \sphinxstyleemphasis{acceptable} (Section 10.1.1.1 \sphinxcite{lte-references:ts36300}). In this case, the RRC
entity will tell the PHY entity to synchronize to the second strongest cell and
repeat the initial cell selection procedure using that cell. As long as no
suitable cell is found, the UE will repeat these steps while avoiding cells that
have been identified as acceptable.


\subsubsection{Radio Admission Control}
\label{\detokenize{lte-design:radio-admission-control}}
Radio Admission Control is supported by having the eNB RRC
reply to an RRC CONNECTION REQUEST message sent by the UE with either
an RRC CONNECTION SETUP message or an RRC CONNECTION REJECT message,
depending on whether the new UE is to be admitted or not. In the
current implementation, the behavior is determined by the boolean attribute
\sphinxcode{\sphinxupquote{ns3::LteEnbRrc::AdmitRrcConnectionRequest}}. There is currently no Radio Admission
Control algorithm that dynamically decides whether a new connection
shall be admitted or not.


\subsubsection{Radio Bearer Configuration}
\label{\detokenize{lte-design:radio-bearer-configuration}}
Some implementation choices have been made in the RRC regarding the setup of radio bearers:
\begin{itemize}
\item {} 
three Logical Channel Groups (out of four available) are configured
for uplink buffer status report purposes, according to the following policy:
\begin{itemize}
\item {} 
LCG 0 is for signaling radio bearers

\item {} 
LCG 1 is for GBR data radio bearers

\item {} 
LCG 2 is for Non\sphinxhyphen{}GBR data radio bearers

\end{itemize}

\end{itemize}


\subsubsection{Radio Link Failure}
\label{\detokenize{lte-design:radio-link-failure}}\label{\detokenize{lte-design:sec-radio-link-failure}}
In real LTE networks, Radio link failure (RLF) can happen due to several reasons.
It can be triggered if a UE is unable to decode PDCCH due to poor signal quality,
upon maximum RLC retransmissions, RACH problems and other reasons. 3GPP only
specifies guidelines to detect RLF at the UE side, in \sphinxcite{lte-references:ts36331} and \sphinxcite{lte-references:ts36133}.
On the other hand, the eNB implementation is expected to be vendor specific.
To implement the RLF functionality in ns\sphinxhyphen{}3, we have assumed the following
simplifications:
\begin{itemize}
\item {} 
The RLF detection procedure at eNodeB is not implemented. \sphinxstylestrong{Instead, a direct
function call by using the SAP between UE and eNB RRC (for both ideal and real
RRC) is used to notify the eNB about the RLF}.

\item {} 
No RRC connection re\sphinxhyphen{}establishment procedure is implemented, thus, the UE
directly goes to the IDLE state upon RLF. This is in fact as per the standard
\sphinxcite{lte-references:ts36331} sec 5.3.11.3, since, at this stage the LTE module does not support
the Access Stratum (AS) security.

\end{itemize}

The above mentioned RLF specifications can be divided into the following two
categories:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
RLF detection

\item {} 
Actions upon RLF detection

\end{enumerate}

In the following, we will explain the RLF implementation in context of these
two categories.


\paragraph{RLF detection implementation}
\label{\detokenize{lte-design:rlf-detection-implementation}}
The RLF detection at the UE is implemented as per \sphinxcite{lte-references:ts36133}, i.e., by monitoring
the radio link quality based on the reference signals (which in the simulation
is equivalent to the PDCCH) in the downlink. Thus, it is independent of the method
used for the downlink CQI computation, i.e., \sphinxstyleemphasis{Ctrl} method and \sphinxstyleemphasis{Mixed method}.
Moreover, when using FFR, especially for hard\sphinxhyphen{}FFR, and CQIs based on \sphinxstyleemphasis{Mixed method},
UEs might experience relatively good performance and RLF simultaneously. This is
due to the fact that the interference in PDSCH is affected by the actual data
transmissions on the specific RBs and the power control. Therefore, UEs might
experience good SINR in PDSCH, while bad SINR in PDCCH channel. For more details
about these methods please refer to {\hyperref[\detokenize{lte-design:sec-cqi-feedback}]{\sphinxcrossref{\DUrole{std,std-ref}{CQI feedback}}}}. Also, it does not
matter if the DL control error model is disabled, a UE can still detect the RLF
since the SINR based on the control channel is reported to the LteUePhy class,
using a callback hooked in LteHelper while installing a UE device.

The RLF detection starts once the RRC connection is established between UE and
eNodeB, i.e., UE is in “CONNECTED\_NORMALLY” state; upon which the RLF parameters
are configured (see \sphinxcode{\sphinxupquote{LteUePhy::DoConfigureRadioLinkFailureDetection}}). In real
networks, these parameters are transmitted by the eNB using IE UE\sphinxhyphen{}TimersAndConstants or
RLF\sphinxhyphen{}TimersAndConstants. However, for the sake of simplification, in the simulator
they are presented as the attributes of the LteUePhy and LteUeRrc classes.
Moreover, what concerns the carrier aggregation, i.e., when a UE is configured
with multiple component carriers, the RLF detection is only performed by the
primary component carrier, i.e. component carrier id 0
(see \sphinxcode{\sphinxupquote{LteUePhy::DoNotifyConnectionSuccessful}}). In LteUePhy class, CQI
calculation is triggered for every downlink subframe received,
and the average SINR value is measured across all resource blocks. For the RLF
detection, these SINR values are averaged over a downlink frame and if the result
is less than a defined threshold Qout (default: \sphinxhyphen{}5dB), the frame cannot be decoded
(see\textasciigrave{}\textasciigrave{}LteUePhy::RadioLinkFailureDetection\textasciigrave{}\textasciigrave{}). The Qout threshold corresponds to 10\%
block error rate (BLER) of a hypothetical PDCCH transmission taking into account
the PCFICH errors \sphinxcite{lte-references:r4-081920} (also refer to
{\hyperref[\detokenize{lte-design:sec-control-channles-phy-error-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Control Channels PHY Error Model}}}}). Once, the UE is unable to decode
20 consecutive frames, i.e., the Qout evaluation period (200ms) is reached, an
out\sphinxhyphen{}of\sphinxhyphen{}sync indication is sent to the UE RRC layer (see \sphinxcode{\sphinxupquote{LteUeRrc::DoNotifyOutOfSync}}).
Else, the counter for the unsuccessfully decoded frames is reset to zero. At the
LteUeRrc, when the number of consecutive out\sphinxhyphen{}of\sphinxhyphen{}sync indications matches with the
value of N310 parameter, the T310 timer is started and LteUePhy is notified to start
measuring for in\sphinxhyphen{}sync indications (see \sphinxcode{\sphinxupquote{LteUePhy::DoStartInSnycDetection}}). We note
that, the UE RRC state is not changed till the expiration of T310 timer. If the
resultant SINR values averaged over a downlink frame is greater than a defined
threshold Qin (default: \sphinxhyphen{}3.8dB), the frame is considered to be successfully
decoded. Qin corresponds to 2\% BLER \sphinxcite{lte-references:r4-081920} of a hypothetical PDCCH transmission
taking into account the PCFICH errors. Once the UE is able to decode 10
consecutive frames, an in\sphinxhyphen{}sync indication is sent to the UE RRC layer
(see \sphinxcode{\sphinxupquote{LteUeRrc::DoNotifyInSync}}). Else, the counter for the successfully decoded
frames is reset to zero. If prior to the T310 timer expiry, the number of
consecutive in\sphinxhyphen{}sync indications matches with N311 parameter of LteUeRRC, the UE
is considered back in\sphinxhyphen{}sync. At this stage, the related parameters are reset to
initiate the radio link failure detection from the beginning
(see \sphinxcode{\sphinxupquote{LteUePhy::DoConfigureRadioLinkFailureDetection}}). On the other hand, If the
T310 timer expires, the UE considers that a RLF has occurred
(see \sphinxcode{\sphinxupquote{LteUeRrc::RadioLinkFailureDetected}}).


\paragraph{Actions upon RLF}
\label{\detokenize{lte-design:actions-upon-rlf}}
Once the T310 timer is expired, a UE is considered to be in RLF; upon which the
UE RRC:
\begin{itemize}
\item {} 
Sends a request to the eNB RRC to remove the UE context

\item {} 
Moves to “CONNECTED\_PHY\_PROBLEM” state

\item {} 
Notifies the UE NAS layer about the release of RRC connection.

\end{itemize}

Then, after getting the notification from the UE RRC the NAS does the following:
\begin{itemize}
\item {} 
Delete all the TFTs

\item {} 
Reset the bearer counter

\item {} 
Restore the bearer list, which is used to activate the bearers for the next
RRC connection. This restoration of the bearers is achieved by maintaining an
additional list, i.e., m\_bearersToBeActivatedListForReconnection in EpcUeNas
class

\item {} 
Switch the NAS state to OFF by calling EpcUeNas::Disconnect

\item {} 
Tells the UE RRC to disconnect

\end{itemize}

The UE RRC, upon receiving the call to disconnect from the EpcUeNas class,
performs the action as specified by \sphinxcite{lte-references:ts36331} 5.3.11.3, and finally leaves the
connected state, i.e., its RRC state is changed from “CONNECTED\_PHY\_PROBLEM” to
“IDLE\_START” to perform cell selection as shown in figures {\hyperref[\detokenize{lte-design:fig-lte-ue-rrc-states}]{\sphinxcrossref{\DUrole{std,std-ref}{UE RRC State Machine}}}}
and {\hyperref[\detokenize{lte-design:fig-lte-ue-procedures-after-rlf}]{\sphinxcrossref{\DUrole{std,std-ref}{UE procedures after radio link failure}}}}.

At this stage, the LTE module does not support the paging functionality, therefore,
to allow a UE to read SIB2 message after camping on a suitable cell after RLF, a
work around is used in \sphinxcode{\sphinxupquote{LteUeRrc::EvaluateCellForSelection}} method. As per this
workaround, the UE RRC invokes the call to \sphinxcode{\sphinxupquote{LteUeRrc::DoConnect}} method, which
enables the UE to switch its state from “IDLE\_CAMPED\_NORMALLY” to “IDLE\_WAIT\_SIB2”,
thus, allowing it to perform the random access.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.95]{{lte-ue-procedures-after-rlf}.pdf}
\caption{UE procedures after radio link failure}\label{\detokenize{lte-design:id175}}\label{\detokenize{lte-design:fig-lte-ue-procedures-after-rlf}}\end{figure}

The eNB RRC, after receiving the notification from the UE RRC starts the procedure
of UE context deletion, which also involves the deletion of the UE context removal
from the EPC {\hyperref[\detokenize{lte-design:fig-lte-ue-context-removal-from-epc}]{\sphinxcrossref{\DUrole{std,std-ref}{UE context removal from EPC}}}} and the eNB stack
{\hyperref[\detokenize{lte-design:fig-lte-ue-context-removal-from-enb-stack}]{\sphinxcrossref{\DUrole{std,std-ref}{UE context removal from eNB stack}}}}. We note that, the UE context
at the MME is not removed since, bearers are only added at the start of a
simulation in MME, and cannot be added again unless scheduled for addition
during a simulation.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-ue-context-removal-from-epc}.pdf}
\caption{UE context removal from EPC}\label{\detokenize{lte-design:id176}}\label{\detokenize{lte-design:fig-lte-ue-context-removal-from-epc}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-ue-context-removal-from-enb-stack}.pdf}
\caption{UE context removal from eNB stack}\label{\detokenize{lte-design:id177}}\label{\detokenize{lte-design:fig-lte-ue-context-removal-from-enb-stack}}\end{figure}


\subsubsection{UE RRC Measurements Model}
\label{\detokenize{lte-design:ue-rrc-measurements-model}}\label{\detokenize{lte-design:sec-ue-measurements}}

\paragraph{UE RRC measurements support}
\label{\detokenize{lte-design:ue-rrc-measurements-support}}
The UE RRC entity provides support for UE measurements; in particular, it
implements the procedures described in Section 5.5 of \sphinxcite{lte-references:ts36331}, with the
following simplifying assumptions:
\begin{itemize}
\item {} 
only E\sphinxhyphen{}UTRA intra\sphinxhyphen{}frequency measurements are supported, which implies:
\begin{itemize}
\item {} 
only one measurement object is used during the simulation;

\item {} 
measurement gaps are not needed to perform the measurements;

\item {} 
Event B1 and B2 are not implemented;

\end{itemize}

\item {} 
only \sphinxtitleref{reportStrongestCells} purpose is supported, while \sphinxtitleref{reportCGI} and
\sphinxtitleref{reportStrongestCellsForSON} purposes are not supported;

\item {} 
\sphinxtitleref{s\sphinxhyphen{}Measure} is not supported;

\item {} 
carrier aggregation is now supported in the LTE module
\sphinxhyphen{} Event A6 is not implemented;

\item {} 
speed dependent scaling of time\sphinxhyphen{}to\sphinxhyphen{}trigger (Section 5.5.6.2 of \sphinxcite{lte-references:ts36331}) is
not supported.

\end{itemize}


\paragraph{Overall design}
\label{\detokenize{lte-design:overall-design}}
The model is based on the concept of \sphinxstyleemphasis{UE measurements consumer}, which is an
entity that may request an eNodeB RRC entity to provide UE measurement reports.
Consumers are, for example, {\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}}, which compute
handover decision based on UE measurement reports. Test cases and user’s
programs may also become consumers. Figure {\hyperref[\detokenize{lte-design:fig-ue-meas-consumer}]{\sphinxcrossref{\DUrole{std,std-ref}{Relationship between UE measurements and its consumers}}}} depicts
the relationship between these entities.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{ue-meas-consumer}.pdf}
\caption{Relationship between UE measurements and its consumers}\label{\detokenize{lte-design:id178}}\label{\detokenize{lte-design:fig-ue-meas-consumer}}\end{figure}

The whole UE measurements function at the RRC level is divided into 4 major
parts:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Measurement configuration (handled by \sphinxcode{\sphinxupquote{LteUeRrc::ApplyMeasConfig}})

\item {} 
Performing measurements (handled by \sphinxcode{\sphinxupquote{LteUeRrc::DoReportUeMeasurements}})

\item {} 
Measurement report triggering (handled by
\sphinxcode{\sphinxupquote{LteUeRrc::MeasurementReportTriggering}})

\item {} 
Measurement reporting (handled by \sphinxcode{\sphinxupquote{LteUeRrc::SendMeasurementReport}})

\end{enumerate}

The following sections will describe each of the parts above.


\paragraph{Measurement configuration}
\label{\detokenize{lte-design:measurement-configuration}}
An eNodeB RRC entity configures UE measurements by sending the configuration
parameters to the UE RRC entity. This set of parameters are defined within the
\sphinxcode{\sphinxupquote{MeasConfig}} Information Element (IE) of the RRC Connection Reconfiguration
message ({\hyperref[\detokenize{lte-design:sec-rrc-connection-reconfiguration}]{\sphinxcrossref{\DUrole{std,std-ref}{RRC connection reconfiguration}}}}).

The eNodeB RRC entity implements the configuration parameters and procedures
described in Section 5.5.2 of \sphinxcite{lte-references:ts36331}, with the following simplifying
assumption:
\begin{itemize}
\item {} 
configuration (i.e. addition, modification, and removal) can only be done
before the simulation begins;

\item {} 
all UEs attached to the eNodeB will be configured the same way, i.e. there is
no support for configuring specific measurement for specific UE; and

\item {} 
it is assumed that there is a one\sphinxhyphen{}to\sphinxhyphen{}one mapping between the PCI and the
E\sphinxhyphen{}UTRAN Global Cell Identifier (EGCI). This is consistent with the PCI
modeling assumptions described in {\hyperref[\detokenize{lte-design:sec-phy-ue-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{UE PHY Measurements Model}}}}.

\end{itemize}

The eNodeB RRC instance here acts as an intermediary between the consumers and
the attached UEs. At the beginning of simulation, each consumer provides the
eNodeB RRC instance with the UE measurements configuration that it requires.
After that, the eNodeB RRC distributes the configuration to attached UEs.

Users may customize the measurement configuration using several methods. Please
refer to Section {\hyperref[\detokenize{lte-user:sec-configure-ue-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{Configure UE measurements}}}} of the User Documentation
for the description of these methods.


\paragraph{Performing measurements}
\label{\detokenize{lte-design:performing-measurements}}\label{\detokenize{lte-design:sec-performing-measurements}}
UE RRC receives both RSRP and RSRQ measurements on periodical basis from UE PHY,
as described in {\hyperref[\detokenize{lte-design:sec-phy-ue-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{UE PHY Measurements Model}}}}. \sphinxstyleemphasis{Layer 3 filtering} will be
applied to these received measurements. The implementation of the filtering
follows Section 5.5.3.2 of \sphinxcite{lte-references:ts36331}:
\begin{equation*}
\begin{split}F_n = (1 - a) \times F_{n-1} + a \times M_n\end{split}
\end{equation*}
where:
\begin{itemize}
\item {} 
\(M_n\) is the latest received measurement result from the physical
layer;

\item {} 
\(F_n\) is the updated filtered measurement result;

\item {} 
\(F_{n-1}\) is the old filtered measurement result, where
\(F_0 = M_1\) (i.e. the first measurement is not filtered); and

\item {} 
\(a = (\frac{1}{2})^{\frac{k}{4}}\), where \(k\) is the configurable
\sphinxtitleref{filterCoefficent} provided by the \sphinxcode{\sphinxupquote{QuantityConfig}};

\end{itemize}

\(k = 4\) is the default value, but can be configured by setting the
\sphinxtitleref{RsrpFilterCoefficient} and \sphinxtitleref{RsrqFilterCoefficient} attributes in
\sphinxcode{\sphinxupquote{LteEnbRrc}}.

Therefore \(k = 0\) will disable Layer 3 filtering. On the other hand, past
measurements can be granted more influence on the filtering results by using
larger value of \(k\).


\paragraph{Measurement reporting triggering}
\label{\detokenize{lte-design:measurement-reporting-triggering}}
In this part, UE RRC will go through the list of active measurement
configuration and check whether the triggering condition is fulfilled in
accordance with Section 5.5.4 of \sphinxcite{lte-references:ts36331}. When at least one triggering
condition from all the active measurement configuration is fulfilled, the
measurement reporting procedure (described in the next subsection) will be
initiated.

3GPP defines two kinds of \sphinxtitleref{triggerType}: \sphinxstyleemphasis{periodical} and \sphinxstyleemphasis{event\sphinxhyphen{}based}. At the
moment, only event\sphinxhyphen{}based criterion is supported. There are various events that
can be selected, which are briefly described in the table below:


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{List of supported event\sphinxhyphen{}based triggering criteria}\label{\detokenize{lte-design:id179}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Description
\\
\hline
Event A1
&
Serving cell becomes better than \sphinxtitleref{threshold}
\\
\hline
Event A2
&
Serving cell becomes worse than \sphinxtitleref{threshold}
\\
\hline
Event A3
&
Neighbour becomes \sphinxtitleref{offset} dB better than serving cell
\\
\hline
Event A4
&
Neighbour becomes better than \sphinxtitleref{threshold}
\\
\hline
Event A5
&
Serving becomes worse than \sphinxtitleref{threshold1}
\sphinxstyleemphasis{AND} neighbour becomes better than \sphinxtitleref{threshold2}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Two main conditions to be checked in an event\sphinxhyphen{}based trigger are the \sphinxstyleemphasis{entering
condition} and the \sphinxstyleemphasis{leaving condition}. More details on these two can be found
in Section 5.5.4 of \sphinxcite{lte-references:ts36331}.

An event\sphinxhyphen{}based trigger can be further configured by introducing hysteresis and
time\sphinxhyphen{}to\sphinxhyphen{}trigger. \sphinxstyleemphasis{Hysteresis} (\(Hys\)) defines the distance between the
entering and leaving conditions in dB. Similarly, \sphinxstyleemphasis{time\sphinxhyphen{}to\sphinxhyphen{}trigger} introduces
delay to both entering and leaving conditions, but as a unit of time.

The \sphinxstyleemphasis{periodical} type of reporting trigger is not supported, but its behavior
can be easily obtained by using an event\sphinxhyphen{}based trigger. This can be done by
configuring the measurement in such a way that the entering condition is always
fulfilled, for example, by setting the threshold of Event A1 to zero (the
minimum level). As a result, the measurement reports will always be triggered
at every certain interval, as determined by the \sphinxtitleref{reportInterval} field within
\sphinxcode{\sphinxupquote{LteRrcSap::ReportConfigEutra}}, therefore producing the same behaviour as
periodical reporting.

As a limitation with respect to 3GPP specifications, the current model does not
support any cell\sphinxhyphen{}specific configuration. These configuration parameters are
defined in measurement object. As a consequence, incorporating a list of black
cells into the triggering process is not supported. Moreover, cell\sphinxhyphen{}specific
offset (i.e., \(O_{cn}\) and \(O_{cp}\) in Event A3, A4, and A5) are not
supported as well. The value equal to zero is always assumed in place of them.


\paragraph{Measurement reporting}
\label{\detokenize{lte-design:measurement-reporting}}
This part handles the submission of measurement report from the UE RRC entity
to the serving eNodeB entity via RRC protocol. Several simplifying assumptions
have been adopted:
\begin{itemize}
\item {} 
\sphinxtitleref{reportAmount} is \sphinxstyleemphasis{not} applicable (i.e. always assumed to be infinite);

\item {} 
in measurement reports, the \sphinxtitleref{reportQuantity} is always assumed to be \sphinxtitleref{BOTH},
i.e., both RSRP and RSRQ are always reported, regardless of the
\sphinxtitleref{triggerQuantity}.

\end{itemize}


\subsubsection{Handover}
\label{\detokenize{lte-design:handover}}\label{\detokenize{lte-design:sec-handover}}
The RRC model supports UE mobility in CONNECTED mode by invoking the X2\sphinxhyphen{}based
handover procedure. The model is intra\sphinxhyphen{}EUTRAN and intra\sphinxhyphen{}frequency, as based on
Section 10.1.2.1 of \sphinxcite{lte-references:ts36300}.

This section focuses on the process of triggering a handover. The handover
execution procedure itself is covered in Section {\hyperref[\detokenize{lte-design:sec-x2}]{\sphinxcrossref{\DUrole{std,std-ref}{X2}}}}.

There are two ways to trigger the handover procedure:
\begin{itemize}
\item {} 
\sphinxstyleemphasis{explicitly} (or manually) triggered by the simulation program by scheduling
an execution of the method \sphinxcode{\sphinxupquote{LteEnbRrc::SendHandoverRequest}}; or

\item {} 
\sphinxstyleemphasis{automatically} triggered by the eNodeB RRC entity based on UE measurements
and according to the selected handover algorithm.

\end{itemize}

Section {\hyperref[\detokenize{lte-user:sec-x2-based-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{X2\sphinxhyphen{}based handover}}}} of the User Documentation provides some
examples on using both explicit and automatic handover triggers in simulation.
The next subsection will take a closer look on the automatic method, by
describing the design aspects of the handover algorithm interface and the
available handover algorithms.


\paragraph{Handover algorithm}
\label{\detokenize{lte-design:handover-algorithm}}\label{\detokenize{lte-design:sec-handover-algorithm}}
Handover in 3GPP LTE has the following properties:
\begin{itemize}
\item {} \begin{description}
\item[{UE\sphinxhyphen{}assisted}] \leavevmode
The UE provides input to the network in the form of measurement reports.
This is handled by the {\hyperref[\detokenize{lte-design:sec-ue-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{UE RRC Measurements Model}}}}.

\end{description}

\item {} \begin{description}
\item[{Network\sphinxhyphen{}controlled}] \leavevmode
The network (i.e. the source eNodeB and the target eNodeB) decides when to
trigger the handover and oversees its execution.

\end{description}

\end{itemize}

The \sphinxstyleemphasis{handover algorithm} operates at the source eNodeB and is responsible in
making handover decisions in an “automatic” manner. It interacts with an eNodeB
RRC instance via the \sphinxstyleemphasis{Handover Management SAP} interface. These relationships
are illustrated in Figure {\hyperref[\detokenize{lte-design:fig-ue-meas-consumer}]{\sphinxcrossref{\DUrole{std,std-ref}{Relationship between UE measurements and its consumers}}}} from the previous section.

The handover algorithm interface consists of the following methods:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{AddUeMeasReportConfigForHandover}}}] \leavevmode
(Handover Algorithm \sphinxhyphen{}\textgreater{} eNodeB RRC) Used by the handover algorithm to
request measurement reports from the eNodeB RRC entity, by passing the
desired reporting configuration. The configuration will be applied to
all future attached UEs.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{ReportUeMeas}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} Handover Algorithm) Based on the UE measurements configured
earlier in \sphinxcode{\sphinxupquote{AddUeMeasReportConfigForHandover}}, UE may submit measurement
reports to the eNodeB. The eNodeB RRC entity uses the \sphinxcode{\sphinxupquote{ReportUeMeas}}
interface to forward these measurement reports to the handover algorithm.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{TriggerHandover}}}] \leavevmode
(Handover Algorithm \sphinxhyphen{}\textgreater{} eNodeB RRC) After examining the measurement reports
(but not necessarily), the handover algorithm may declare a handover. This
method is used to notify the eNodeB RRC entity about this decision, which
will then proceed to commence the handover procedure.

\end{description}

\end{itemize}

One note for the \sphinxcode{\sphinxupquote{AddUeMeasReportConfigForHandover}}. The method will return
the \sphinxcode{\sphinxupquote{measId}} (measurement identity) of the newly created measurement
configuration. Typically a handover algorithm would store this unique number. It
may be useful in the \sphinxcode{\sphinxupquote{ReportUeMeas}} method, for example when more than one
configuration has been requested and the handover algorithm needs to
differentiate incoming reports based on the configuration that triggered them.

A handover algorithm is implemented by writing a subclass of the
\sphinxcode{\sphinxupquote{LteHandoverAlgorithm}} abstract superclass and implementing each of the above
mentioned SAP interface methods. Users may develop their own handover algorithm
this way, and then use it in any simulation by following the steps outlined in
Section {\hyperref[\detokenize{lte-user:sec-x2-based-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{X2\sphinxhyphen{}based handover}}}} of the User Documentation.

Alternatively, users may choose to use one of the 3 built\sphinxhyphen{}in handover algorithms
provided by the LTE module: no\sphinxhyphen{}op, A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ, and strongest cell handover
algorithm. They are ready to be used in simulations or can be taken as an
example of implementing a handover algorithm. Each of these built\sphinxhyphen{}in algorithms
is covered in each of the following subsections.


\paragraph{No\sphinxhyphen{}op handover algorithm}
\label{\detokenize{lte-design:no-op-handover-algorithm}}
The \sphinxstyleemphasis{no\sphinxhyphen{}op handover algorithm} (\sphinxcode{\sphinxupquote{NoOpHandoverAlgorithm}} class) is the simplest
possible implementation of handover algorithm. It basically does nothing, i.e.,
does not call any of the Handover Management SAP interface methods. Users may
choose this handover algorithm if they wish to disable automatic handover
trigger in their simulation.


\paragraph{A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm}
\label{\detokenize{lte-design:a2-a4-rsrq-handover-algorithm}}
The \sphinxstyleemphasis{A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm} provides the functionality of the default
handover algorithm originally included in LENA M6 (ns\sphinxhyphen{}3.18), ported to the
Handover Management SAP interface as the \sphinxcode{\sphinxupquote{A2A4RsrqHandoverAlgorithm}} class.

As the name implies, the algorithm utilizes the Reference Signal Received
Quality (RSRQ) measurements acquired from Event A2 and Event A4. Thus, the
algorithm will add 2 measurement configuration to the corresponding eNodeB RRC
instance. Their intended use are described as follows:
\begin{itemize}
\item {} 
\sphinxstyleemphasis{Event A2} (serving cell’s RSRQ becomes worse than \sphinxtitleref{threshold}) is leveraged
to indicate that the UE is experiencing poor signal quality and may benefit
from a handover.

\item {} 
\sphinxstyleemphasis{Event A4} (neighbour cell’s RSRQ becomes better than \sphinxtitleref{threshold}) is used
to detect neighbouring cells and acquire their corresponding RSRQ from every
attached UE, which are then stored internally by the algorithm. By default,
the algorithm configures Event A4 with a very low threshold, so that the
trigger criteria are always true.

\end{itemize}

Figure {\hyperref[\detokenize{lte-design:fig-lte-legacy-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm}}}} below summarizes this procedure.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{lte-legacy-handover-algorithm}.pdf}
\caption{A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm}\label{\detokenize{lte-design:id180}}\label{\detokenize{lte-design:fig-lte-legacy-handover-algorithm}}\end{figure}

Two attributes can be set to tune the algorithm behaviour:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{ServingCellThreshold}}}] \leavevmode
The \sphinxtitleref{threshold} for Event A2, i.e. a UE must have an RSRQ lower than this
threshold to be considered for a handover.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{NeighbourCellOffset}}}] \leavevmode
The \sphinxtitleref{offset} that aims to ensure that the UE would receive better signal
quality after the handover. A neighbouring cell is considered as a target
cell for the handover only if its RSRQ is higher than the serving cell’s
RSRQ by the amount of this \sphinxtitleref{offset}.

\end{description}

\end{itemize}

The value of both attributes are expressed as RSRQ range (Section 9.1.7 of
\sphinxcite{lte-references:ts36133}), which is an integer between 0 and 34, with 0 as the lowest RSRQ.


\paragraph{Strongest cell handover algorithm}
\label{\detokenize{lte-design:strongest-cell-handover-algorithm}}
The \sphinxstyleemphasis{strongest cell handover algorithm}, or also sometimes known as the
\sphinxstyleemphasis{traditional power budget (PBGT) algorithm}, is developed using \sphinxcite{lte-references:dimou2009} as
reference. The idea is to provide each UE with the best possible Reference
Signal Received Power (RSRP). This is done by performing a handover as soon as
a better cell (i.e. with stronger RSRP) is detected.

\sphinxstyleemphasis{Event A3} (neighbour cell’s RSRP becomes better than serving cell’s RSRP) is
chosen to realize this concept. The \sphinxcode{\sphinxupquote{A3RsrpHandoverAlgorithm}} class is the
result of the implementation. Handover is triggered for the UE to the best cell
in the measurement report.

A simulation which uses this algorithm is usually more vulnerable to ping\sphinxhyphen{}pong
handover (consecutive handover to the previous source eNodeB within short period
of time), especially when the {\hyperref[\detokenize{lte-design:sec-fading-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Fading Model}}}} is enabled. This problem
is typically tackled by introducing a certain delay to the handover. The
algorithm does this by including hysteresis and time\sphinxhyphen{}to\sphinxhyphen{}trigger parameters
(Section 6.3.5 of \sphinxcite{lte-references:ts36331}) to the UE measurements configuration.

\sphinxstyleemphasis{Hysteresis} (a.k.a. handover margin) delays the handover in regard of RSRP. The
value is expressed in dB, ranges between 0 to 15 dB, and have a 0.5 dB accuracy,
e.g., an input value of 2.7 dB is rounded to 2.5 dB.

On the other hand, \sphinxstyleemphasis{time\sphinxhyphen{}to\sphinxhyphen{}trigger} delays the handover in regard of time. 3GPP
defines 16 valid values for time\sphinxhyphen{}to\sphinxhyphen{}trigger (all in milliseconds): 0, 40, 64,
80, 100, 128, 160, 256, 320, 480, 512, 640, 1024, 1280, 2560, and 5120.

The difference between hysteresis and time\sphinxhyphen{}to\sphinxhyphen{}trigger is illustrated in Figure
{\hyperref[\detokenize{lte-design:fig-lte-strongest-cell-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Effect of hysteresis and time\sphinxhyphen{}to\sphinxhyphen{}trigger in strongest cell handover algorithm}}}} below, which is taken from the
\sphinxtitleref{lena\sphinxhyphen{}x2\sphinxhyphen{}handover\sphinxhyphen{}measures} example. It depicts the perceived RSRP of serving
cell and a neighbouring cell by a UE which moves pass the border of the cells.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-strongest-cell-handover-algorithm}.pdf}
\caption{Effect of hysteresis and time\sphinxhyphen{}to\sphinxhyphen{}trigger in strongest cell handover algorithm}\label{\detokenize{lte-design:id181}}\label{\detokenize{lte-design:fig-lte-strongest-cell-handover-algorithm}}\end{figure}

By default, the algorithm uses a hysteresis of 3.0 dB and time\sphinxhyphen{}to\sphinxhyphen{}trigger of
256 ms. These values can be tuned through the \sphinxcode{\sphinxupquote{Hysteresis}} and
\sphinxcode{\sphinxupquote{TimeToTrigger}} attributes of the \sphinxcode{\sphinxupquote{A3RsrpHandoverAlgorithm}} class.


\subsubsection{Neighbour Relation}
\label{\detokenize{lte-design:neighbour-relation}}
LTE module supports a simplified \sphinxstyleemphasis{Automatic Neighbour Relation} (ANR) function.
This is handled by the \sphinxcode{\sphinxupquote{LteAnr}} class, which interacts with an eNodeB RRC
instance through the ANR SAP interface.


\paragraph{Neighbour Relation Table}
\label{\detokenize{lte-design:neighbour-relation-table}}
The ANR holds a \sphinxstyleemphasis{Neighbour Relation Table} (NRT), similar to the description in
Section 22.3.2a of \sphinxcite{lte-references:ts36300}. Each entry in the table is called a \sphinxstyleemphasis{Neighbour
Relation} (NR) and represents a detected neighbouring cell, which contains the
following boolean fields:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxtitleref{No Remove}}] \leavevmode
Indicates that the NR shall \sphinxstyleemphasis{not} be removed from the NRT. This is \sphinxtitleref{true}
by default for user\sphinxhyphen{}provided NR and \sphinxtitleref{false} otherwise.

\end{description}

\item {} \begin{description}
\item[{\sphinxtitleref{No X2}}] \leavevmode
Indicates that the NR shall \sphinxstyleemphasis{not} use an X2 interface in order to initiate
procedures towards the eNodeB parenting the target cell. This is \sphinxtitleref{false} by
default for user\sphinxhyphen{}provided NR, and \sphinxtitleref{true} otherwise.

\end{description}

\item {} \begin{description}
\item[{\sphinxtitleref{No HO}}] \leavevmode
Indicates that the NR shall \sphinxstyleemphasis{not} be used by the eNodeB for handover
reasons. This is \sphinxtitleref{true} in most cases, except when the NR is both
user\sphinxhyphen{}provided and network\sphinxhyphen{}detected.

\end{description}

\end{itemize}

Each NR entry may have at least one of the following properties:
\begin{itemize}
\item {} \begin{description}
\item[{User\sphinxhyphen{}provided}] \leavevmode
This type of NR is created as instructed by the simulation user. For
example, a NR is created automatically upon a user\sphinxhyphen{}initiated establishment
of X2 connection between 2 eNodeBs, e.g. as described in Section
{\hyperref[\detokenize{lte-user:sec-x2-based-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{X2\sphinxhyphen{}based handover}}}}. Another way to create a user\sphinxhyphen{}provided NR is
to call the \sphinxcode{\sphinxupquote{AddNeighbourRelation}} function explicitly.

\end{description}

\item {} \begin{description}
\item[{Network\sphinxhyphen{}detected}] \leavevmode
This type of NR is automatically created during the simulation as a result
of the discovery of a nearby cell.

\end{description}

\end{itemize}

In order to automatically create network\sphinxhyphen{}detected NR, ANR utilizes UE
measurements. In other words, ANR is a consumer of UE measurements, as depicted
in Figure {\hyperref[\detokenize{lte-design:fig-ue-meas-consumer}]{\sphinxcrossref{\DUrole{std,std-ref}{Relationship between UE measurements and its consumers}}}}. RSRQ and Event A4 (neighbour becomes
better than \sphinxtitleref{threshold}) are used for the reporting configuration. The default
Event A4 \sphinxtitleref{threshold} is set to the lowest possible, i.e., maximum detection
capability, but can be changed by setting the \sphinxcode{\sphinxupquote{Threshold}} attribute of
\sphinxcode{\sphinxupquote{LteAnr}} class. Note that the A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm also utilizes a
similar reporting configuration. Despite the similarity, when both ANR and this
handover algorithm are active in the eNodeB, they use separate reporting
configuration.

Also note that automatic setup of X2 interface is not supported. This is the
reason why the \sphinxtitleref{No X2} and \sphinxtitleref{No HO} fields are true in a network\sphinxhyphen{}detected but not
user\sphinxhyphen{}detected NR.


\paragraph{Role of ANR in Simulation}
\label{\detokenize{lte-design:role-of-anr-in-simulation}}
The ANR SAP interface provides the means of communication between ANR and eNodeB
RRC. Some interface functions are used by eNodeB RRC to interact with the NRT,
as shown below:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{AddNeighbourRelation}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} ANR) Add a new user\sphinxhyphen{}provided NR entry into the NRT.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{GetNoRemove}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} ANR) Get the value of \sphinxtitleref{No Remove} field of an NR entry of
the given cell ID.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{GetNoHo}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} ANR) Get the value of \sphinxtitleref{No HO} field of an NR entry of
the given cell ID.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{GetNoX2}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} ANR) Get the value of \sphinxtitleref{No X2} field of an NR entry of
the given cell ID.

\end{description}

\end{itemize}

Other interface functions exist to support the role of ANR as a UE measurements
consumer, as listed below:
\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{AddUeMeasReportConfigForAnr}}}] \leavevmode
(ANR \sphinxhyphen{}\textgreater{} eNodeB RRC) Used by the ANR to request measurement reports from the
eNodeB RRC entity, by passing the desired reporting configuration. The
configuration will be applied to all future attached UEs.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{ReportUeMeas}}}] \leavevmode
(eNodeB RRC \sphinxhyphen{}\textgreater{} ANR) Based on the UE measurements configured earlier in
\sphinxcode{\sphinxupquote{AddUeMeasReportConfigForAnr}}, UE may submit measurement reports to the
eNodeB. The eNodeB RRC entity uses the \sphinxcode{\sphinxupquote{ReportUeMeas}} interface to
forward these measurement reports to the ANR.

\end{description}

\end{itemize}

Please refer to the corresponding API documentation for \sphinxcode{\sphinxupquote{LteAnrSap}} class for
more details on the usage and the required parameters.

The ANR is utilized by the eNodeB RRC instance as a data structure to keep track
of the situation of nearby neighbouring cells. The ANR also helps the eNodeB RRC
instance to determine whether it is possible to execute a handover procedure to
a neighbouring cell. This is realized by the fact that eNodeB RRC will only
allow a handover procedure to happen if the NR entry of the target cell has both
\sphinxtitleref{No HO} and \sphinxtitleref{No X2} fields set to \sphinxtitleref{false}.

ANR is enabled by default in every eNodeB instance in the simulation. It can be
disabled by setting the \sphinxcode{\sphinxupquote{AnrEnabled}} attribute in \sphinxcode{\sphinxupquote{LteHelper}} class to
\sphinxtitleref{false}.


\subsubsection{RRC sequence diagrams}
\label{\detokenize{lte-design:rrc-sequence-diagrams}}
In this section we provide some sequence diagrams that explain the
most important RRC procedures being modeled.


\paragraph{RRC connection establishment}
\label{\detokenize{lte-design:rrc-connection-establishment}}\label{\detokenize{lte-design:sec-rrc-connection-establishment}}
Figure {\hyperref[\detokenize{lte-design:fig-rrc-connection-establishment}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the RRC Connection Establishment procedure}}}} shows how the RRC
Connection Establishment procedure is modeled, highlighting the role
of the RRC layer at both the UE and the eNB, as well as the
interaction with the other layers.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{rrc-connection-establishment}.pdf}
\caption{Sequence diagram of the RRC Connection Establishment procedure}\label{\detokenize{lte-design:id182}}\label{\detokenize{lte-design:fig-rrc-connection-establishment}}\end{figure}

There are several timeouts related to this procedure, which are listed in the
following Table {\hyperref[\detokenize{lte-design:tab-rrc-connection-establishment-timer}]{\sphinxcrossref{\DUrole{std,std-ref}{Timers in RRC connection establishment procedure}}}}. If any of these
timers expired, the RRC connection establishment procedure is terminated in
failure. At the UE side, if T300 timer has expired a consecutive
\sphinxstyleemphasis{connEstFailCount} times on the same cell it performs the cell selection again
\sphinxcite{lte-references:ts36331}. Else, the upper layer (UE NAS) will immediately attempt to retry
the procedure.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Timers in RRC connection establishment procedure}\label{\detokenize{lte-design:id183}}\label{\detokenize{lte-design:tab-rrc-connection-establishment-timer}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Location
&\sphinxstyletheadfamily 
Timer
starts
&\sphinxstyletheadfamily 
Timer
stops
&\sphinxstyletheadfamily 
Default
duration
&\sphinxstyletheadfamily 
When timer
expired
\\
\hline
Connection
request
timeout
&
eNodeB
RRC
&
New UE
context
added
&
Receive RRC
CONNECTION
REQUEST
&
15 ms
(Max)
&
Remove UE
context
\\
\hline
Connection
timeout
(T300
timer)
&
UE RRC
&
Send RRC
CONNECTION
REQUEST
&
Receive RRC
CONNECTION
SETUP or
REJECT
&
100 ms
&
Reset UE
MAC
\\
\hline
Connection
setup
timeout
&
eNodeB
RRC
&
Send RRC
CONNECTION
SETUP
&
Receive RRC
CONNECTION
SETUP
COMPLETE
&
100 ms
&
Remove UE
context
\\
\hline
Connection
rejected
timeout
&
eNodeB
RRC
&
Send RRC
CONNECTION
REJECT
&
Never
&
30 ms
&
Remove UE
context
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Note:} The value of connection request timeout timer at the eNB RRC should
not be higher than the T300 timer at UE RRC. It is to make sure that the UE
context is already removed at the eNB, once the UE will perform cell selection
upon reaching the \sphinxstyleemphasis{connEstFailCount} count. Moreover, at the time of writing
this document the {\hyperref[\detokenize{lte-design:sec-cell-selection-evaluation}]{\sphinxcrossref{\DUrole{std,std-ref}{Cell Selection Evaluation}}}} does not include
the \(Qoffset_{temp}\) parameter, thus, it is not applied while selecting
the same cell again.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Counters in RRC connection establishment procedure}\label{\detokenize{lte-design:id184}}\label{\detokenize{lte-design:tab-rrc-connection-establishment-counter}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Location
&\sphinxstyletheadfamily 
Msg
&\sphinxstyletheadfamily 
Monitored
by
&\sphinxstyletheadfamily 
Default
value
&\sphinxstyletheadfamily 
Limit not reached
&\sphinxstyletheadfamily 
Limit reached
\\
\hline
ConnEstFailCount
&
eNB MAC
&
RachConfigCommon
in SIB2, HO REQ
and HO Ack
&
UE RRC
&
1
&
Increment the local counter.
Invalided the prev SIB2 msg,
and try random access
with the same cell.
&
Reset the local
counter and perform
cell selection.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\paragraph{RRC connection reconfiguration}
\label{\detokenize{lte-design:rrc-connection-reconfiguration}}\label{\detokenize{lte-design:sec-rrc-connection-reconfiguration}}
Figure {\hyperref[\detokenize{lte-design:fig-rrc-connection-reconfiguration}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the RRC Connection Reconfiguration procedure}}}} shows how the RRC
Connection Reconfiguration procedure is modeled for the case where
MobilityControlInfo is not provided, i.e., handover is not
performed.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{rrc-connection-reconfiguration}.pdf}
\caption{Sequence diagram of the RRC Connection Reconfiguration procedure}\label{\detokenize{lte-design:id185}}\label{\detokenize{lte-design:fig-rrc-connection-reconfiguration}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-rrc-connection-reconf-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the RRC Connection Reconfiguration procedure
for the handover case}}}} shows how the RRC
Connection Reconfiguration procedure is modeled for the case where
MobilityControlInfo is provided, i.e., handover is to be performed.
As specified in \sphinxcite{lte-references:ts36331}, \sphinxstyleemphasis{After receiving the handover message,
the UE attempts to access the target cell at the first available RACH
occasion according to Random Access resource selection defined in {[}TS36321{]}\_,
i.e. the handover is asynchronous. Consequently, when
allocating a dedicated preamble for the random access in the target
cell, E\sphinxhyphen{}UTRA shall ensure it is available from the first RACH occasion
the UE may use. Upon successful completion of the handover, the UE
sends a message used to confirm the handover.} Note that the random
access procedure in this case is non\sphinxhyphen{}contention based, hence in a real
LTE system it differs slightly from the one used in RRC connection
established. Also note that the RA Preamble ID is signaled via the
Handover Command included in the X2 Handover Request ACK message sent
from the target eNB to the source eNB; in particular, the preamble is
included in the RACH\sphinxhyphen{}ConfigDedicated IE which is part of
MobilityControlInfo.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{rrc-connection-reconfiguration-handover}.pdf}
\caption{Sequence diagram of the RRC Connection Reconfiguration procedure
for the handover case}\label{\detokenize{lte-design:id186}}\label{\detokenize{lte-design:fig-rrc-connection-reconf-handover}}\end{figure}


\subsubsection{RRC protocol models}
\label{\detokenize{lte-design:rrc-protocol-models}}\label{\detokenize{lte-design:sec-rrc-protocol-models}}
As previously anticipated, we provide two different models  for the
transmission and reception of RRC messages: \sphinxstyleemphasis{Ideal}
and \sphinxstyleemphasis{Real}. Each of them is described in one of the following
subsections.


\paragraph{Ideal RRC protocol model}
\label{\detokenize{lte-design:ideal-rrc-protocol-model}}
According to this model, implemented in the classes and \sphinxtitleref{LteUeRrcProtocolIdeal} and
\sphinxtitleref{LteEnbRrcProtocolIdeal}, all RRC messages and information elements
are transmitted between the eNB and the UE in an ideal fashion,
without consuming radio resources and without errors. From an
implementation point of view, this is achieved by passing the RRC data
structure directly between the UE and eNB RRC entities, without
involving the lower layers (PDCP, RLC, MAC, scheduler).


\paragraph{Real RRC protocol model}
\label{\detokenize{lte-design:real-rrc-protocol-model}}
This model is implemented in the classes \sphinxtitleref{LteUeRrcProtocolReal} and
\sphinxtitleref{LteEnbRrcProtocolReal} and aims at modeling the transmission of RRC
PDUs as commonly performed in real LTE systems. In particular:
\begin{itemize}
\item {} 
for every RRC message being sent, a real RRC PDUs is created
following the ASN.1 encoding of RRC PDUs and information elements (IEs)
specified in \sphinxcite{lte-references:ts36331}. Some simplification are made with respect
to the IEs included in the PDU, i.e., only those IEs that are
useful for simulation purposes are included. For a detailed list,
please see the IEs defined in \sphinxtitleref{lte\sphinxhyphen{}rrc\sphinxhyphen{}sap.h} and compare with
\sphinxcite{lte-references:ts36331}.

\item {} 
the encoded RRC PDUs are sent on Signaling Radio Bearers and are
subject to the same transmission modeling used for data
communications, thus including scheduling, radio resource
consumption, channel errors, delays, retransmissions, etc.

\end{itemize}


\subparagraph{Signaling Radio Bearer model}
\label{\detokenize{lte-design:signaling-radio-bearer-model}}
We now describe the Signaling Radio Bearer model that is used for the
\sphinxstyleemphasis{Real} RRC protocol model.
\begin{itemize}
\item {} 
\sphinxstylestrong{SRB0} messages (over CCCH):
\begin{itemize}
\item {} 
\sphinxstylestrong{RrcConnectionRequest}: in real LTE systems, this is an RLC TM
SDU sent over resources specified in the UL Grant in the RAR (not
in UL DCIs); the reason is that C\sphinxhyphen{}RNTI is not known yet at this
stage. In the simulator, this is modeled as a real RLC TM RLC PDU
whose UL resources are allocated by the scheduler upon call to
SCHED\_DL\_RACH\_INFO\_REQ.

\item {} 
\sphinxstylestrong{RrcConnectionSetup}: in the simulator this is implemented as in
real LTE systems, i.e., with an RLC TM SDU sent over resources
indicated by a regular UL DCI, allocated with
SCHED\_DL\_RLC\_BUFFER\_REQ triggered by the RLC TM instance that is
mapped to LCID 0 (the CCCH).

\end{itemize}

\item {} 
\sphinxstylestrong{SRB1} messages (over DCCH):
\begin{itemize}
\item {} 
All the SRB1 messages modeled in the simulator (e.g.,
\sphinxstylestrong{RrcConnectionCompleted}) are implemented as in real LTE systems,
i.e., with a real RLC SDU sent over RLC AM using DL resources
allocated via Buffer Status Reports. See the RLC model
documentation for details.

\end{itemize}

\item {} 
\sphinxstylestrong{SRB2} messages (over DCCH):
\begin{itemize}
\item {} 
According to \sphinxcite{lte-references:ts36331}, “\sphinxstyleemphasis{SRB1 is for RRC messages (which may
include a piggybacked NAS message) as well as for NAS messages
prior to the establishment of SRB2, all using DCCH logical
channel}”, whereas “\sphinxstyleemphasis{SRB2 is for NAS messages, using DCCH
logical channel}” and “\sphinxstyleemphasis{SRB2 has a lower\sphinxhyphen{}priority than SRB1 and is
always configured by E\sphinxhyphen{}UTRAN after security
activation}”. Modeling security\sphinxhyphen{}related aspects is not a
requirement of the LTE simulation model, hence we always use
SRB1 and never activate SRB2.

\end{itemize}

\end{itemize}


\subparagraph{ASN.1 encoding of RRC IE’s}
\label{\detokenize{lte-design:asn-1-encoding-of-rrc-ie-s}}
The messages defined in RRC SAP, common to all Ue/Enb SAP Users/Providers, are transported in a transparent container to/from a Ue/Enb. The encoding format for the different Information Elements are specified in \sphinxcite{lte-references:ts36331}, using ASN.1 rules in the unaligned variant. The implementation in Ns3/Lte has been divided in the following classes:
\begin{itemize}
\item {} 
Asn1Header : Contains the encoding / decoding of basic ASN types

\item {} 
RrcAsn1Header : Inherits Asn1Header and contains the encoding / decoding of common IE’s defined in \sphinxcite{lte-references:ts36331}

\item {} 
Rrc specific messages/IEs classes : A class for each of the messages defined in RRC SAP header

\end{itemize}


\subparagraph{Asn1Header class \sphinxhyphen{} Implementation of base ASN.1 types}
\label{\detokenize{lte-design:asn1header-class-implementation-of-base-asn-1-types}}
This class implements the methods to Serialize / Deserialize the ASN.1 types being used in \sphinxcite{lte-references:ts36331}, according to the packed encoding rules in ITU\sphinxhyphen{}T X.691. The types considered are:
\begin{itemize}
\item {} 
Boolean : a boolean value uses a single bit (1=true, 0=false).

\item {} 
Integer : a constrained integer (with min and max values defined) uses the minimum amount of bits to encode its range (max\sphinxhyphen{}min+1).

\item {} 
Bitstring : a bistring will be copied bit by bit to the serialization buffer.

\item {} 
Octetstring : not being currently used.

\item {} 
Sequence : the sequence generates a preamble indicating the presence of optional and default fields. It also adds a bit indicating the presence of extension marker.

\item {} 
Sequence…Of : the sequence…of type encodes the number of elements of the sequence as an integer (the subsequent elements will need to be encoded afterwards).

\item {} 
Choice : indicates which element among the ones in the choice set is being encoded.

\item {} 
Enumeration : is serialized as an integer indicating which value is used, among the ones in the enumeration, with the number of elements in the enumeration as upper bound.

\item {} 
Null : the null value is not encoded, although its serialization function is defined to provide a clearer map between specification and implementation.

\end{itemize}

The class inherits from ns\sphinxhyphen{}3 Header, but Deserialize() function is declared pure virtual, thus inherited classes having to implement it. The reason is that deserialization will retrieve the elements in RRC messages, each of them containing different information elements.

Additionally, it has to be noted that the resulting byte length of a specific type/message can vary, according to the presence of optional fields, and due to the optimized encoding. Hence, the serialized bits will be processed using PreSerialize() function, saving the result in m\_serializationResult Buffer. As the methods to read/write in a ns3 buffer are defined in a byte basis, the serialization bits are stored into m\_serializationPendingBits attribute, until the 8 bits are set and can be written to buffer iterator. Finally, when invoking Serialize(), the contents of the m\_serializationResult attribute will be copied to Buffer::Iterator parameter


\subparagraph{RrcAsn1Header : Common IEs}
\label{\detokenize{lte-design:rrcasn1header-common-ies}}
As some Information Elements are being used for several RRC messages, this class implements the following common IE’s:
\begin{itemize}
\item {} 
SrbToAddModList

\item {} 
DrbToAddModList

\item {} 
LogicalChannelConfig

\item {} 
RadioResourceConfigDedicated

\item {} 
PhysicalConfigDedicated

\item {} 
SystemInformationBlockType1

\item {} 
SystemInformationBlockType2

\item {} 
RadioResourceConfigCommonSIB

\end{itemize}


\subparagraph{Rrc specific messages/IEs classes}
\label{\detokenize{lte-design:rrc-specific-messages-ies-classes}}
The following RRC SAP have been implemented:
\begin{itemize}
\item {} 
RrcConnectionRequest

\item {} 
RrcConnectionSetup

\item {} 
RrcConnectionSetupCompleted

\item {} 
RrcConnectionReconfiguration

\item {} 
RrcConnectionReconfigurationCompleted

\item {} 
HandoverPreparationInfo

\item {} 
RrcConnectionReestablishmentRequest

\item {} 
RrcConnectionReestablishment

\item {} 
RrcConnectionReestablishmentComplete

\item {} 
RrcConnectionReestablishmentReject

\item {} 
RrcConnectionRelease

\end{itemize}

\clearpage


\subsection{NAS}
\label{\detokenize{lte-design:nas}}\label{\detokenize{lte-design:sec-nas}}
The focus of the LTE\sphinxhyphen{}EPC model is on the NAS Active state, which corresponds to EMM Registered, ECM connected, and RRC connected. Because of this, the following simplifications are made:
\begin{itemize}
\item {} 
EMM and ECM are not modeled explicitly; instead, the NAS entity at the UE will interact directly with the MME to perform actions that are equivalent (with gross simplifications) to taking the UE to the states EMM Connected and ECM Connected;

\item {} 
the NAS also takes care of multiplexing uplink data packets coming from the upper layers into the appropriate EPS bearer by using the Traffic Flow Template classifier (TftClassifier).

\item {} 
the NAS does not support PLMN and CSG selection

\item {} 
the NAS does not support any location update/paging procedure in idle mode

\end{itemize}

Figure {\hyperref[\detokenize{lte-design:fig-nas-attach}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the attach procedure}}}} shows how the simplified NAS model
implements the attach procedure. Note that both the default and
eventual dedicated EPS bearers are activated as part of this
procedure.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nas-attach}.pdf}
\caption{Sequence diagram of the attach procedure}\label{\detokenize{lte-design:id187}}\label{\detokenize{lte-design:fig-nas-attach}}\end{figure}

\clearpage


\subsection{S1, S5 and S11}
\label{\detokenize{lte-design:s1-s5-and-s11}}

\subsubsection{S1\sphinxhyphen{}U and S5 (user plane)}
\label{\detokenize{lte-design:s1-u-and-s5-user-plane}}
The S1\sphinxhyphen{}U and S5 interfaces are modeled in a realistic way by encapsulating
data packets over GTP/UDP/IP, as done in real LTE\sphinxhyphen{}EPC systems. The
corresponding protocol stack is shown in Figure
{\hyperref[\detokenize{lte-design:fig-lte-epc-e2e-data-protocol-stack-with-split}]{\sphinxcrossref{\DUrole{std,std-ref}{LTE\sphinxhyphen{}EPC data plane protocol stack}}}}. As shown in the figure,
there are two different layers of
IP networking. The first one is the end\sphinxhyphen{}to\sphinxhyphen{}end layer, which provides end\sphinxhyphen{}to\sphinxhyphen{}end
connectivity to the users; this layer involves the UEs, the PGW and
the remote host (including eventual internet routers and hosts in
between), but does not involve the eNB and the SGW. In this version of LTE, the EPC
supports both IPv4 and IPv6 type users. The 3GPP unique 64 bit IPv6 prefix
allocation process for each UE and PGW is followed here. Each EPC is assigned
a unique 16 bit IPv4 and a 48 bit IPv6 network address from the pool of
7.0.0.0/8 and 7777:f00d::/32 respectively. In the end\sphinxhyphen{}to\sphinxhyphen{}end IP connection
between UE and PGW, all addresses are configured using these prefixes.
The PGW’s address is used by all UEs as the gateway to reach the internet.

The second layer of IP networking is the EPC local area network. This
involves all eNB nodes, SGW nodes and PGW nodes. This network is
implemented as a set of point\sphinxhyphen{}to\sphinxhyphen{}point links which connect each eNB
with its corresponding SGW node and a point\sphinxhyphen{}to\sphinxhyphen{}point link which connect
each SGW node with its corresponding PGW node;
thus, each SGW has a set of point\sphinxhyphen{}to\sphinxhyphen{}point devices, each providing
connectivity to a different eNB. By default, a 10.x.y.z/30 subnet
is assigned to each point\sphinxhyphen{}to\sphinxhyphen{}point link (a /30 subnet is the smallest
subnet that allows for two distinct host addresses).

As specified by 3GPP, the end\sphinxhyphen{}to\sphinxhyphen{}end IP
communications is tunneled over the local EPC IP network using
GTP/UDP/IP. In the following, we explain how this tunneling is
implemented in the EPC model. The explanation is done by discussing the
end\sphinxhyphen{}to\sphinxhyphen{}end flow of data packets.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{epc-data-flow-dl-with-split}.pdf}
\caption{Data flow in the downlink between the internet and the UE}\label{\detokenize{lte-design:id188}}\label{\detokenize{lte-design:fig-epc-data-flow-dl-with-split}}\end{figure}

To begin with, we consider the case of the downlink, which is depicted
in Figure {\hyperref[\detokenize{lte-design:fig-epc-data-flow-dl-with-split}]{\sphinxcrossref{\DUrole{std,std-ref}{Data flow in the downlink between the internet and the UE}}}}.
Downlink IPv4/IPv6 packets are generated from a generic remote host, and
addressed to one of the UE device. Internet routing will take care of
forwarding the packet to the generic NetDevice of the PGW node
which is connected to the internet (this is the Gi interface according
to 3GPP terminology). The PGW has a VirtualNetDevice which is
assigned the base IPv4 address of the EPC network; hence, static
routing rules will cause the incoming packet from the internet to be
routed through this VirtualNetDevice. In case of IPv6 address as destination,
a manual route towards the VirtualNetDevice is inserted in the routing table,
containing the 48 bit IPv6 prefix from which all the IPv6 addresses of the UEs
and PGW are configured. Such device starts the GTP/UDP/IP tunneling procedure,
by forwarding the packet to a dedicated application in the PGW node which
is called EpcPgwApplication. This application does the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it determines the SGW node to which it must route the traffic
for this UE, by looking at the IP destination address
(which is the address of the UE);

\item {} 
it classifies the packet using Traffic Flow Templates (TFTs) to
identify to which EPS Bearer it belongs. EPS bearers have a
one\sphinxhyphen{}to\sphinxhyphen{}one mapping to S5 Bearers, so this operation returns the
GTP\sphinxhyphen{}U Tunnel Endpoint Identifier  (TEID) to which the packet
belongs;

\item {} 
it adds the corresponding GTP\sphinxhyphen{}U protocol header to the packet;

\item {} 
finally, it sends the packet over a UDP socket to the S5
point\sphinxhyphen{}to\sphinxhyphen{}point NetDevice, addressed to the appropriate SGW.

\end{enumerate}

As a consequence, the end\sphinxhyphen{}to\sphinxhyphen{}end IP packet with newly added IP, UDP
and GTP headers is sent through one of the S5 links to the SGW, where
it is received and delivered locally (as the destination address of
the outermost IP header matches the SGW IP address). The local delivery
process will forward the packet, via an UDP socket, to a dedicated
application called EpcSgwApplication. This application then performs
the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it determines the eNB node to which the UE is attached, by looking
at the S5 TEID;

\item {} 
it maps the S5 TEID to get the S1 TEID. EPS bearers have a
one\sphinxhyphen{}to\sphinxhyphen{}one mapping to S1\sphinxhyphen{}U Bearers, so this operation returns the
S1 GTP\sphinxhyphen{}U Tunnel Endpoint Identifier (TEID) to which the packet
belongs;

\item {} 
it adds a new GTP\sphinxhyphen{}U protocol header to the packet;

\item {} 
finally, it sends the packet over a UDP socket to the S1\sphinxhyphen{}U
point\sphinxhyphen{}to\sphinxhyphen{}point NetDevice, addressed to the eNB to which the UE is
attached.

\end{enumerate}

Finally, the end\sphinxhyphen{}to\sphinxhyphen{}end IP packet with newly added IP, UDP
and GTP headers is sent through one of the S1 links to the eNB, where
it is received and delivered locally (as the destination address of
the outermost IP header matches the eNB IP address). The local delivery
process will forward the packet, via an UDP socket, to a dedicated
application called EpcEnbApplication. This application then performs
the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it removes the GTP header and retrieves the S1 TEID which is
contained in it;

\item {} 
leveraging on the one\sphinxhyphen{}to\sphinxhyphen{}one mapping between S1\sphinxhyphen{}U bearers and
Radio Bearers (which is a 3GPP requirement), it determines the
Bearer ID (BID) to which the packet belongs;

\item {} 
it records the BID in a dedicated tag called EpsBearerTag,
which is added to the packet;

\item {} 
it forwards the packet to the LteEnbNetDevice of the eNB node via
a raw packet socket

\end{enumerate}

Note that, at this point, the outmost header of the packet is the
end\sphinxhyphen{}to\sphinxhyphen{}end IP header, since the IP/UDP/GTP headers of the S1 protocol
stack have already been stripped. Upon reception of
the packet from the EpcEnbApplication, the LteEnbNetDevice will
retrieve the BID from the EpsBearerTag, and based on the BID
will determine the Radio Bearer instance (and the corresponding PDCP
and RLC protocol instances) which are then used to forward the packet
to the UE over the LTE radio interface. Finally, the LteUeNetDevice of
the UE will receive the packet, and delivery it locally to the IP
protocol stack, which will in turn delivery it to the application of
the UE, which is the end point of the downlink communication.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{epc-data-flow-ul-with-split}.pdf}
\caption{Data flow in the uplink between the UE and the internet}\label{\detokenize{lte-design:id189}}\label{\detokenize{lte-design:fig-epc-data-flow-ul-with-split}}\end{figure}

The case of the uplink is depicted in Figure {\hyperref[\detokenize{lte-design:fig-epc-data-flow-ul-with-split}]{\sphinxcrossref{\DUrole{std,std-ref}{Data flow in the uplink between the UE and the internet}}}}.
Uplink IP packets are generated by a generic application inside the UE,
and forwarded by the local TCP/IP stack to the LteUeNetDevice of the
UE. The LteUeNetDevice then performs the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it classifies the packet using TFTs and determines the
Radio Bearer to which the packet belongs (and the corresponding
RBID);

\item {} 
it identifies the corresponding PDCP protocol instance, which is
the entry point of the LTE Radio Protocol stack for this packet;

\item {} 
it sends the packet to the eNB over the LTE Radio Protocol stack.

\end{enumerate}

The eNB receives the packet via its LteEnbNetDevice. Since there is a
single PDCP and RLC protocol instance for each Radio Bearer, the
LteEnbNetDevice is able to determine the BID of the packet. This BID
is then recorded onto an EpsBearerTag, which is added to the
packet. The LteEnbNetDevice then forwards the packet to the
EpcEnbApplication via a raw packet socket.

Upon receiving the packet, the EpcEnbApplication performs the
following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it retrieves the BID from the EpsBearerTag in the packet;

\item {} 
it determines the corresponding EPS Bearer instance and GTP\sphinxhyphen{}U TEID by
leveraging on the one\sphinxhyphen{}to\sphinxhyphen{}one mapping between S1\sphinxhyphen{}U bearers and Radio
Bearers;

\item {} 
it adds a GTP\sphinxhyphen{}U header on the packet, including the TEID
determined previously;

\item {} 
it sends the packet to the SGW node via the UDP socket
connected to the S1\sphinxhyphen{}U point\sphinxhyphen{}to\sphinxhyphen{}point net device.

\end{enumerate}

At this point, the packet contains the S1\sphinxhyphen{}U IP, UDP and GTP headers in
addition to the original end\sphinxhyphen{}to\sphinxhyphen{}end IP header. When the packet is
received by the corresponding S1\sphinxhyphen{}U point\sphinxhyphen{}to\sphinxhyphen{}point NetDevice of the
SGW node, it is delivered locally (as the destination address of
the outmost IP header matches the address of the point\sphinxhyphen{}to\sphinxhyphen{}point net
device). The local delivery process will forward the packet to the
EpcSgwApplication via the corresponding UDP socket. The
EpcSgwApplication then perfoms the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
it removes the GTP header and retrieves the S1\sphinxhyphen{}U TEID;

\item {} 
it maps the S1\sphinxhyphen{}U TEID to get the S5 TEID to which the packet
belongs;

\item {} 
it determines the PGW to which it must send the packet from
the TEID mapping;

\item {} 
it add a new GTP\sphinxhyphen{}U protocol header to the packet;

\item {} 
finally, it sends the packet over a UDP socket to the S5
point\sphinxhyphen{}to\sphinxhyphen{}point NetDevice, addressed to the corresponding PGW.

\end{enumerate}

At this point, the packet contains the S5 IP, UDP and GTP headers in
addition to the original end\sphinxhyphen{}to\sphinxhyphen{}end IP header. When the packet is
received by the corresponding S5 point\sphinxhyphen{}to\sphinxhyphen{}point NetDevice of the
PGW node, it is delivered locally (as the destination address of
the outmost IP header matches the address of the point\sphinxhyphen{}to\sphinxhyphen{}point net
device). The local delivery process will forward the packet to the
EpcPgwApplication via the corresponding UDP socket. The
EpcPgwApplication then removes the GTP header and forwards the
packet to the VirtualNetDevice. At this point, the outmost header
of the packet is the end\sphinxhyphen{}to\sphinxhyphen{}end IP header. Hence, if the destination
address within this header is a remote host on the internet, the
packet is sent to the internet via the corresponding NetDevice of the
PGW. In the event that the packet is addressed to another UE, the
IP stack of the PGW will redirect the packet again to the
VirtualNetDevice, and the packet will go through the downlink delivery
process in order to reach its destination UE.

Note that the EPS Bearer QoS is not enforced on the S1\sphinxhyphen{}U and S5
links, it is assumed that the overprovisioning of the link bandwidth
is sufficient to meet the QoS requirements of all bearers.


\subsubsection{S1AP}
\label{\detokenize{lte-design:s1ap}}
The S1\sphinxhyphen{}AP interface provides control plane interaction between the eNB
and the MME. In the simulator, this interface is modeled in a realistic
fashion transmitting the encoded S1AP messages and information elements
specified in \sphinxcite{lte-references:ts36413} on the S1\sphinxhyphen{}MME link.

The S1\sphinxhyphen{}AP primitives that are modeled are:
\begin{itemize}
\item {} 
INITIAL UE MESSAGE

\item {} 
INITIAL CONTEXT SETUP REQUEST

\item {} 
INITIAL CONTEXT SETUP RESPONSE

\item {} 
PATH SWITCH REQUEST

\item {} 
PATH SWITCH REQUEST ACKNOWLEDGE

\end{itemize}


\subsubsection{S5 and S11}
\label{\detokenize{lte-design:s5-and-s11}}
The S5 interface provides control plane interaction between the SGW
and the PGW. The S11 interface provides control plane interaction between
the SGw and the MME. Both interfaces use the GPRS Tunneling Protocol (GTPv2\sphinxhyphen{}C)
to tunnel signalling messages \sphinxcite{lte-references:ts29274} and use UDP as transport protocol.
In the simulator, these interfaces and protocol are modeled in a realistic
fashion transmitting the encoded GTP\sphinxhyphen{}C messages.

The GTPv2\sphinxhyphen{}C primitives that are modeled are:
\begin{itemize}
\item {} 
CREATE SESSION REQUEST

\item {} 
CREATE SESSION RESPONSE

\item {} 
MODIFY BEARER REQUEST

\item {} 
MODIFY BEARER RESPONSE

\item {} 
DELETE SESSION REQUEST

\item {} 
DELETE SESSION RESPONSE

\item {} 
DELETE BEARER COMMAND

\item {} 
DELETE BEARER REQUEST

\item {} 
DELETE BEARER RESPONSE

\end{itemize}

Of these primitives, the first two are used upon initial UE attachment for the establishment
of the S1\sphinxhyphen{}U and S5 bearers. Section {\hyperref[\detokenize{lte-design:sec-nas}]{\sphinxcrossref{\DUrole{std,std-ref}{NAS}}}} shows the implementation of the attach
procedure. The other primitives are used during the handover to switch the S1\sphinxhyphen{}U bearers from
the source eNB to the target eNB as a consequence of the reception by the MME of a
PATH SWITCH REQUEST S1\sphinxhyphen{}AP message.

\clearpage


\subsection{X2}
\label{\detokenize{lte-design:x2}}\label{\detokenize{lte-design:sec-x2}}
The X2 interface interconnects two eNBs \sphinxcite{lte-references:ts36420}. From a logical
point of view, the X2 interface is a point\sphinxhyphen{}to\sphinxhyphen{}point interface between
the two eNBs. In a real E\sphinxhyphen{}UTRAN, the logical point\sphinxhyphen{}to\sphinxhyphen{}point interface
should be feasible even in the absence of a physical direct connection
between the two eNBs. In the X2 model implemented in the simulator,
the X2 interface is a point\sphinxhyphen{}to\sphinxhyphen{}point link between the two eNBs. A
point\sphinxhyphen{}to\sphinxhyphen{}point device is created in both eNBs and the two
point\sphinxhyphen{}to\sphinxhyphen{}point devices are attached to the point\sphinxhyphen{}to\sphinxhyphen{}point link.

For a representation of how the X2 interface fits in the overall
architecture of the LENA simulation model, the reader is referred to
the figure {\hyperref[\detokenize{lte-design:fig-epc-topology}]{\sphinxcrossref{\DUrole{std,std-ref}{Overview of the LTE\sphinxhyphen{}EPC simulation model}}}}.

The X2 interface implemented in the simulator provides detailed implementation of the following elementary procedures of the Mobility Management functionality \sphinxcite{lte-references:ts36423}:
\begin{itemize}
\item {} 
Handover Request procedure

\item {} 
Handover Request Acknowledgement procedure

\item {} 
SN Status Transfer procedure

\item {} 
UE Context Release procedure

\end{itemize}

These procedures are involved in the X2\sphinxhyphen{}based handover. You can find
the detailed description of the handover in section 10.1.2.1 of
\sphinxcite{lte-references:ts36300}. We note that the simulator model currently supports only
the \sphinxstyleemphasis{seamless handover} as defined in Section 2.6.3.1 of \sphinxcite{lte-references:sesia2009};
in particular, \sphinxstyleemphasis{lossless handover} as described in Section 2.6.3.2 of
\sphinxcite{lte-references:sesia2009} is not supported at the time of this writing.

Figure {\hyperref[\detokenize{lte-design:fig-x2-based-handover-seq-diagram}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the X2\sphinxhyphen{}based handover}}}} below shows the interaction of
the entities of the X2 model in the simulator. The shaded labels indicate the
moments when the UE or eNodeB transition to another RRC state.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-epc-x2-handover-seq-diagram}.pdf}
\caption{Sequence diagram of the X2\sphinxhyphen{}based handover}\label{\detokenize{lte-design:id190}}\label{\detokenize{lte-design:fig-x2-based-handover-seq-diagram}}\end{figure}

The figure also shows two timers within the handover procedure: the \sphinxstyleemphasis{handover
leaving timer} is maintained by the source eNodeB, while the \sphinxstyleemphasis{handover joining
timer} by the target eNodeB. The duration of the timers can be configured in
the \sphinxcode{\sphinxupquote{HandoverLeavingTimeoutDuration}} and \sphinxcode{\sphinxupquote{HandoverJoiningTimeoutDuration}}
attributes of the respective \sphinxcode{\sphinxupquote{LteEnbRrc}} instances. When one of these timers
expire, the handover procedure is considered as failed.

However, there is no proper handling of handover failure in the current version
of LTE module. Users should tune the simulation properly in order to avoid
handover failure, otherwise unexpected behaviour may occur. Please refer to
Section {\hyperref[\detokenize{lte-user:sec-tuning-handover-simulation}]{\sphinxcrossref{\DUrole{std,std-ref}{Tuning simulation with handover}}}} of the User Documentation for some
tips regarding this matter.

The X2 model is an entity that uses services from:
\begin{itemize}
\item {} 
the X2 interfaces,
\begin{itemize}
\item {} 
They are implemented as Sockets on top of the point\sphinxhyphen{}to\sphinxhyphen{}point devices.

\item {} 
They are used to send/receive X2 messages through the X2\sphinxhyphen{}C and X2\sphinxhyphen{}U interfaces (i.e. the point\sphinxhyphen{}to\sphinxhyphen{}point device attached to the point\sphinxhyphen{}to\sphinxhyphen{}point link) towards the peer eNB.

\end{itemize}

\item {} 
the S1 application.
\begin{itemize}
\item {} 
Currently, it is the EpcEnbApplication.

\item {} 
It is used to get some information needed for the Elementary Procedures of the X2 messages.

\end{itemize}

\end{itemize}

and it provides services to:
\begin{itemize}
\item {} 
the RRC entity (X2 SAP)
\begin{itemize}
\item {} 
to send/receive RRC messages. The X2 entity sends the RRC message as a transparent container in the X2 message. This RRC message is sent to the UE.

\end{itemize}

\end{itemize}

Figure {\hyperref[\detokenize{lte-design:fig-x2-entity-saps}]{\sphinxcrossref{\DUrole{std,std-ref}{Implementation Model of X2 entity and SAPs}}}} shows the implementation model of the X2 entity and its relationship with all the other entities and services in the protocol stack.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=550\sphinxpxdimen]{{lte-epc-x2-entity-saps}.pdf}
\caption{Implementation Model of X2 entity and SAPs}\label{\detokenize{lte-design:id191}}\label{\detokenize{lte-design:fig-x2-entity-saps}}\end{figure}

The RRC entity manages the initiation of the handover procedure. This is done in the Handover Management submodule of the eNB RRC entity. The target eNB may perform some Admission Control procedures. This is done in the Admission Control submodule. Initially, this submodule will accept any handover request.


\subsubsection{X2 interfaces}
\label{\detokenize{lte-design:x2-interfaces}}
The X2 model contains two interfaces:
\begin{itemize}
\item {} 
the X2\sphinxhyphen{}C interface. It is the control interface and it is used to send the X2\sphinxhyphen{}AP PDUs
(i.e. the elementary procedures).

\item {} 
the X2\sphinxhyphen{}U interface. It is used to send the bearer data when there is \sphinxtitleref{DL forwarding}.

\end{itemize}

Figure {\hyperref[\detokenize{lte-design:fig-lte-epc-x2-interface}]{\sphinxcrossref{\DUrole{std,std-ref}{X2 interface protocol stacks}}}} shows the protocol stacks of the X2\sphinxhyphen{}U interface and X2\sphinxhyphen{}C interface modeled in the simulator.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-epc-x2-interface}.pdf}
\caption{X2 interface protocol stacks}\label{\detokenize{lte-design:id192}}\label{\detokenize{lte-design:fig-lte-epc-x2-interface}}\end{figure}


\paragraph{X2\sphinxhyphen{}C}
\label{\detokenize{lte-design:x2-c}}
The X2\sphinxhyphen{}C interface is the control part of the X2 interface and it is
used to send the X2\sphinxhyphen{}AP PDUs (i.e. the elementary procedures).

In the original X2 interface control plane protocol stack, SCTP is
used as the transport protocol but currently, the SCTP protocol is not
modeled in the ns\sphinxhyphen{}3 simulator and its implementation is out\sphinxhyphen{}of\sphinxhyphen{}scope
of the project. The UDP protocol is used as the datagram oriented
protocol instead of the SCTP protocol.


\paragraph{X2\sphinxhyphen{}U}
\label{\detokenize{lte-design:x2-u}}
The X2\sphinxhyphen{}U interface is used to send the bearer data when there is \sphinxtitleref{DL
forwarding} during the execution of the X2\sphinxhyphen{}based handover
procedure. Similarly to what done for the S1\sphinxhyphen{}U interface, data packets
are encapsulated over GTP/UDP/IP when being sent over this
interface. Note that the EPS Bearer QoS is not enforced on the X2\sphinxhyphen{}U
links, it is assumed that the overprovisioning of the link bandwidth
is sufficient to meet the QoS requirements of all bearers.


\subsubsection{X2 Service Interface}
\label{\detokenize{lte-design:x2-service-interface}}
The X2 service interface is used by the RRC entity to send and receive messages of the X2 procedures. It is divided into two parts:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{EpcX2SapProvider}} part is provided by the X2 entity and used by the RRC entity and

\item {} 
the \sphinxcode{\sphinxupquote{EpcX2SapUser}} part is provided by the RRC entity and used by the RRC enity.

\end{itemize}

The primitives that are supported in our X2\sphinxhyphen{}C model are described in the following subsections.


\paragraph{X2\sphinxhyphen{}C primitives for handover execution}
\label{\detokenize{lte-design:x2-c-primitives-for-handover-execution}}
The following primitives are used for the X2\sphinxhyphen{}based
handover:
\begin{itemize}
\item {} 
HANDOVER REQUEST

\item {} 
HANDOVER REQUEST ACK

\item {} 
HANDOVER PREPARATION FAILURE

\item {} 
SN STATUS STRANSFER

\item {} 
UE CONTEXT RELEASE

\end{itemize}

all the above primitives are used by the currently implemented RRC
model during the preparation and execution of the handover
procedure. Their usage interacts with the RRC state machine;
therefore, they are not meant to be used for code customization, at
least unless it is desired to modify the RRC state machine.


\paragraph{X2\sphinxhyphen{}C SON primitives}
\label{\detokenize{lte-design:x2-c-son-primitives}}
The following primitives can be used  to implement Self\sphinxhyphen{}Organized Network (SON) functionalities:
\begin{itemize}
\item {} 
LOAD INFORMATION

\item {} 
RESOURCE STATUS UPDATE

\end{itemize}

note that the current RRC model does not actually use these
primitives, they are included in the model just to make it possible to
develop SON algorithms included in the RRC logic that make use of
them.

As a first example, we show here how the load information primitive
can be used. We assume that the LteEnbRrc has been modified to include
the following new member variables:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{UlInterferenceOverloadIndicationItem}\PYG{o}{\PYGZgt{}}
  \PYG{n}{m\PYGZus{}currentUlInterferenceOverloadIndicationList}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector} \PYG{o}{\PYGZlt{}}\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{UlHighInterferenceInformationItem}\PYG{o}{\PYGZgt{}}
  \PYG{n}{m\PYGZus{}currentUlHighInterferenceInformationList}\PYG{p}{;}
\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{RelativeNarrowbandTxBand} \PYG{n}{m\PYGZus{}currentRelativeNarrowbandTxBand}\PYG{p}{;}
\end{sphinxVerbatim}

for a detailed description of the type of these variables, we suggest
to consult the file \sphinxcode{\sphinxupquote{epc\sphinxhyphen{}x2\sphinxhyphen{}sap.h}}, the corresponding doxygen
documentation, and the references therein to the relevant sections of
3GPP TS 36.423. Now, assume that at run time these variables have been
set to meaningful values following the specifications just
mentioned. Then, you can add the following code in the LteEnbRrc class
implementation in order to send a load information primitive:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CellInformationItem} \PYG{n}{cii}\PYG{p}{;}
\PYG{n}{cii}\PYG{p}{.}\PYG{n}{sourceCellId} \PYG{o}{=} \PYG{n}{m\PYGZus{}cellId}\PYG{p}{;}
\PYG{n}{cii}\PYG{p}{.}\PYG{n}{ulInterferenceOverloadIndicationList} \PYG{o}{=} \PYG{n}{m\PYGZus{}currentUlInterferenceOverloadIndicationList}\PYG{p}{;}
\PYG{n}{cii}\PYG{p}{.}\PYG{n}{ulHighInterferenceInformationList} \PYG{o}{=} \PYG{n}{m\PYGZus{}currentUlHighInterferenceInformationList}\PYG{p}{;}
\PYG{n}{cii}\PYG{p}{.}\PYG{n}{relativeNarrowbandTxBand} \PYG{o}{=} \PYG{n}{m\PYGZus{}currentRelativeNarrowbandTxBand}\PYG{p}{;}

\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{LoadInformationParams} \PYG{n}{params}\PYG{p}{;}
\PYG{n}{params}\PYG{p}{.}\PYG{n}{targetCellId} \PYG{o}{=} \PYG{n}{cellId}\PYG{p}{;}
\PYG{n}{params}\PYG{p}{.}\PYG{n}{cellInformationList}\PYG{p}{.}\PYG{n}{push\PYGZus{}back} \PYG{p}{(}\PYG{n}{cii}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}x2SapProvider}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SendLoadInformation} \PYG{p}{(}\PYG{n}{params}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The above code allows the source eNB to send the message. The method
\sphinxcode{\sphinxupquote{LteEnbRrc::DoRecvLoadInformation}} will be called when the target
eNB receives the message. The desired processing of the load
information should therefore be implemented within that method.

In the following second example we show how the resource
status update primitive is used. We assume that the LteEnbRrc has been
modified to include the following new member variable:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CellMeasurementResultItem} \PYG{n}{m\PYGZus{}cmri}\PYG{p}{;}
\end{sphinxVerbatim}

similarly to before, we refer to \sphinxcode{\sphinxupquote{epc\sphinxhyphen{}x2\sphinxhyphen{}sap.h}} and the references
therein for detailed information about this variable type.
Again, we assume that the variable has been already set to a
meaningful value. Then, you can add the following code in order to
send a resource status update:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EpcX2Sap}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ResourceStatusUpdateParams} \PYG{n}{params}\PYG{p}{;}
\PYG{n}{params}\PYG{p}{.}\PYG{n}{targetCellId} \PYG{o}{=} \PYG{n}{cellId}\PYG{p}{;}
\PYG{n}{params}\PYG{p}{.}\PYG{n}{cellMeasurementResultList}\PYG{p}{.}\PYG{n}{push\PYGZus{}back} \PYG{p}{(}\PYG{n}{m\PYGZus{}cmri}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{m\PYGZus{}x2SapProvider}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SendResourceStatusUpdate} \PYG{p}{(}\PYG{n}{params}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The method \sphinxcode{\sphinxupquote{eEnbRrc::DoRecvResourceStatusUpdate}} will be called when
the target eNB receives the resource status update message. The
desired processing of this message should therefore be implemented
within that method.

Finally, we note that the setting and processing of the appropriate
values for the variable passed to the above described primitives is
deemed to be specific of the SON algorithm being implemented, and
hence is not covered by this documentation.


\paragraph{Unsupported primitives}
\label{\detokenize{lte-design:unsupported-primitives}}
Mobility Robustness Optimization primitives such as Radio Link Failure
indication and Handover Report are not supported at this stage.

\clearpage


\subsection{S11}
\label{\detokenize{lte-design:s11}}
The S11 interface provides control plane interaction between the SGW
and the MME using the GTPv2\sphinxhyphen{}C protocol specified in \sphinxcite{lte-references:ts29274}. In the
simulator, this interface is modeled in an ideal
fashion, with direct interaction between the SGW and the MME objects,
without actually implementing the encoding of the messages and without actually
transmitting any PDU on any link.

The S11 primitives that are modeled are:
\begin{itemize}
\item {} 
CREATE SESSION REQUEST

\item {} 
CREATE SESSION RESPONSE

\item {} 
MODIFY BEARER REQUEST

\item {} 
MODIFY BEARER RESPONSE

\end{itemize}

Of these primitives, the first two are used upon initial UE attachment
for the establishment of the S1\sphinxhyphen{}U bearers; the other two are used
during handover to switch the S1\sphinxhyphen{}U bearers from the source eNB to the
target eNB as a consequence of the reception by the MME of a PATH
SWITCH REQUEST S1\sphinxhyphen{}AP message.

\clearpage


\subsection{Power Control}
\label{\detokenize{lte-design:power-control}}
This section describes the ns\sphinxhyphen{}3 implementation of Downlink and Uplink Power Control.


\subsubsection{Downlink Power Control}
\label{\detokenize{lte-design:downlink-power-control}}
Since some of Frequency Reuse Algorithms require Downlink Power Control,
this feature was also implemented in ns\sphinxhyphen{}3.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-dl-power-control}.pdf}
\caption{Sequence diagram of Downlink Power Control}\label{\detokenize{lte-design:id193}}\label{\detokenize{lte-design:fig-lte-downlik-power-control}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-lte-downlik-power-control}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of Downlink Power Control}}}} shows the sequence diagram of
setting downlink P\_A value for UE, highlighting the interactions between
the RRC and the other entities. FR algorithm triggers RRC to change P\_A values
for UE. Then RRC starts RrcConnectionReconfiguration function to inform UE
about new configuration. After successful RrcConnectionReconfiguration, RRC
can set P\_A value for UE by calling function SetPa from CphySap, value is
saved in new map m\_paMap which contain P\_A values for each UE served by eNb.

When LteEnbPhy starts new subframe, DCI control messages are processed to get
vector of used RBs. Now also GeneratePowerAllocationMap(uint16\_t rnti, int rbId)
function is also called. This function check P\_A value for UE, generate power
for each RB and store it in m\_dlPowerAllocationMap. Then this map is used by
CreateTxPowerSpectralDensityWithPowerAllocation function to create
Ptr\textless{}SpectrumValue\textgreater{} txPsd.

PdschConfigDedicated (TS 36.331, 6.3.2 PDSCH\sphinxhyphen{}Config) was added in
LteRrcSap::PhysicalConfigDedicated struct, which is used in
RrcConnectionReconfiguration process.


\subsubsection{Uplink Power Control}
\label{\detokenize{lte-design:uplink-power-control}}
Uplink power control controls the transmit power of the different uplink physical
channels. This functionality is described in 3GPP TS 36.213 section 5.

Uplink Power Control is enabled by default, and can be disabled by attribute system:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePhy::EnableUplinkPowerControl}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Two Uplink Power Control mechanisms are implemented:
\begin{itemize}
\item {} 
Open Loop Uplink Power Control: the UE transmission power depends on estimation of
the downlink path\sphinxhyphen{}loss and channel configuration

\item {} 
Closed Loop Uplink Power Control: as in Open Loop, in addition eNB can control the UE
transmission power by means of explicit Transmit Power Control TPC commands transmitted
in the downlink.

\end{itemize}

To switch between these two mechanism types, one should change parameter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::ClosedLoop}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

By default, Closed Loop Power Control is enabled.
\begin{description}
\item[{Two modes of Closed Loop Uplink Power Control are available:}] \leavevmode\begin{itemize}
\item {} 
Absolute mode: TxPower is computed with absolute TPC values

\item {} 
Accumulative mode: TxPower is computed with accumulated TPC values

\end{itemize}

\end{description}

To switch between these two modes, one should change parameter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::AccumulationEnabled}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

By default, Accumulation Mode is enabled and TPC commands in DL\sphinxhyphen{}DCI are set by all schedulers to 1,
what is mapped to value of 0 in Accumulation Mode.


\paragraph{Uplink Power Control for PUSCH}
\label{\detokenize{lte-design:uplink-power-control-for-pusch}}\label{\detokenize{lte-design:sec-uplink-power-control-pusch}}
The setting of the UE Transmit power for a Physical Uplink Shared Channel (PUSCH) transmission
is defined as follows:
\begin{itemize}
\item {} 
If the UE transmits PUSCH without a simultaneous PUCCH for the serving cell \(c\), then the
UE transmit power \(P_{PUSCH,c}(i)\) for PUSCH transmission in subframe \(i\) for the
serving cell \(c\) is given by:
\begin{equation*}
\begin{split}P_{PUSCH,c}(i)=\min\begin{Bmatrix}
               P_{CMAX,c}(i)\\
               10\log_{10}(M_{PUSCH,c}(i))+ P_{O\_PUSCH,c}(j)
               + \alpha_{c} (j) * PL_{c} + \Delta_{TF,c}(i) + f_{c}(i)
               \end{Bmatrix} [dBm]\end{split}
\end{equation*}
\item {} 
If the UE transmits PUSCH simultaneous with PUCCH for the serving cell \(c\), then the UE
transmit power \(P_{PUSCH,c}(i)\) for the PUSCH transmission in subframe \(i\) for
the serving cell \(c\) is given by:
\begin{equation*}
\begin{split}P_{PUSCH,c}(i)=\min\begin{Bmatrix}
               10\log_{10}(\hat{P}_{CMAX,c}(i) - \hat{P}_{PUCCH}(i))\\
               10\log_{10}(M_{PUSCH,c}(i))+ P_{O\_PUSCH,c}(j)
               + \alpha_{c} (j) * PL_{c} + \Delta_{TF,c}(i) + f_{c}(i)
               \end{Bmatrix} [dBm]\end{split}
\end{equation*}
Since Uplink Power Control for PUCCH is not implemented, this case is not implemented as well.

\item {} 
If the UE is not transmitting PUSCH for the serving cell \(c\), for the accumulation of
TPC command received with DCI format 3/3A for PUSCH, the UE shall assume that the UE transmit
power \(P_{PUSCH,c}(i)\) for the PUSCH transmission in    subframe \(i\) for the serving
cell \(c\) is computed by
\begin{equation*}
\begin{split}P_{PUSCH,c}(i)=\min\begin{Bmatrix}
               {P}_{CMAX,c}(i)\\
               P_{O\_PUSCH,c}(1) + \alpha_{c} (1) * PL_{c} + f_{c}(i)
               \end{Bmatrix} [dBm]\end{split}
\end{equation*}
\end{itemize}
\begin{description}
\item[{where:}] \leavevmode\begin{itemize}
\item {} 
\(P_{CMAX,c}(i)\) is the configured UE transmit power defined in 3GPP 36.101. Table 6.2.2\sphinxhyphen{}1
in subframe \(i\) for serving cell \(c\) and \(\hat{P}_{CMAX,c}(i)\) is the linear
value of \(P_{CMAX,c}(i)\). Default value for \(P_{CMAX,c}(i)\) is 23 dBm

\item {} 
\(M_{PUSCH,c}(i)\) is the bandwidth of the PUSCH resource assignment expressed in number
of resource blocks valid for subframe \(i\) and serving cell \(c\) .

\item {} 
\(P_{O\_PUSCH,c}(j)\) is a parameter composed of the sum of a component \(P_{O\_NOMINAL\_PUSCH,c}(j)\)
provided from higher layers for \(j={0,1}\) and a component \(P_{O\_UE\_PUSCH,c}(j)\) provided by higher
layers for \(j={0,1}\) for serving cell \(c\). SIB2 message needs to be extended to carry these two
components, but currently they can be set via attribute system:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::PoNominalPusch}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{IntegerValue} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{90}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::PoUePusch}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{IntegerValue} \PYG{p}{(}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\item {} 
\(\alpha_{c} (j)\) is a 3\sphinxhyphen{}bit parameter provided by higher layers for serving cell \(c\).
For \(j=0,1\),   \(\alpha_c \in \left \{ 0, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 \right \}\)
For \(j=2\),   \(\alpha_{c} (j) = 1\).
This parameter is configurable by attribute system:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::Alpha}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{0.8}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\item {} 
\(PL_{c}\) is the downlink pathloss estimate calculated in the UE for serving cell \(c\) in dB
and \(PL_{c} = referenceSignalPower – higher layer filtered RSRP\), where \(referenceSignalPower\)
is provided by higher layers and RSRP. \(referenceSignalPower\) is provided in SIB2 message

\item {} 
\(\Delta_{TF,c}(i) = 10\log_{10}((2^{BPRE\cdot K_s}-1)\cdot\beta_{offset}^{PUSCH} )\) for \(K_{s} = 1.25\)
and \(\Delta_{TF,c}(i) = 0\) for \(K_{s} = 0\). Only second case is implemented.

\item {} 
\(f_{c}(i)\) is component of Closed Loop Power Control. It is the current PUSCH power control
adjustment state for serving cell \(c\).

If Accumulation Mode is enabled \(f_{c}(i)\) is given by:
\begin{quote}
\begin{equation*}
\begin{split}f_{c}(i) = f_{c}(i-1) + \delta_{PUSCH,c}(i - K_{PUSCH})\end{split}
\end{equation*}\end{quote}

where: \(\delta_{PUSCH,c}\) is a correction value, also referred to as a TPC command and is included
in PDCCH with DCI; \(\delta_{PUSCH,c}(i - K_{PUSCH})\) was signalled on PDCCH/EPDCCH with DCI for
serving cell \(c\) on subframe \((i - K_{PUSCH})\); \(K_{PUSCH} = 4\) for FDD.

If UE has reached \(P_{CMAX,c}(i)\) for serving cell \(c\), positive TPC commands for serving cell
\(c\) are not be accumulated. If UE has reached minimum power, negative TPC commands are not be accumulated.
Minimum UE power is defined in TS36.101 section 6.2.3.  Default value is \sphinxhyphen{}40 dBm.

If Accumulation Mode is not enabled \(f_{c}(i)\) is given by:
\begin{quote}
\begin{equation*}
\begin{split}f_{c}(i) = \delta_{PUSCH,c}(i - K_{PUSCH})\end{split}
\end{equation*}\end{quote}

where: \(\delta_{PUSCH,c}\) is a correction value, also referred to as a TPC command and is included
in PDCCH with DCI; \(\delta_{PUSCH,c}(i - K_{PUSCH})\) was signalled on PDCCH/EPDCCH with DCI for
serving cell \(c\) on subframe \((i - K_{PUSCH})\); \(K_{PUSCH} = 4\) for FDD.

Mapping of TPC Command Field in DCI format 0/3/4 to absolute and accumulated \(\delta_{PUSCH,c}\)
values is defined in TS36.231 section 5.1.1.1 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

\end{description}


\paragraph{Uplink Power Control for PUCCH}
\label{\detokenize{lte-design:uplink-power-control-for-pucch}}
Since all uplink control messages are an ideal messages and do not consume any radio resources,
Uplink Power Control for PUCCH is not needed and it is not implemented.


\paragraph{Uplink Power Control for SRS}
\label{\detokenize{lte-design:uplink-power-control-for-srs}}
The setting of the UE Transmit power \(P_{SRS}\) for the SRS transmitted on subframe \(i\)
for serving cell \(c\) is defined by
\begin{quote}
\begin{equation*}
\begin{split}P_{PUSCH,c}(i)=\min\begin{Bmatrix}
               {P}_{CMAX,c}(i)\\
               P_{SRS\_OFFSET,c}(m) + 10\log_{10}(M_{SRS,c})+
               P_{O\_PUSCH,c}(j) + \alpha_{c}(j) * PL_{c} + f_{c}(i)
               \end{Bmatrix} [dBm]\end{split}
\end{equation*}\end{quote}
\begin{description}
\item[{where:}] \leavevmode\begin{itemize}
\item {} 
\(P_{CMAX,c}(i)\) is the configured UE transmit power defined in 3GPP 36.101. Table 6.2.2\sphinxhyphen{}1.
Default value for \(P_{CMAX,c}(i)\) is 23 dBm

\item {} 
\(P_{SRS\_OFFSET,c}(m)\) is semi\sphinxhyphen{}statically configured by higher layers for \(m=0,1\) for
serving cell \(c\) . For SRS transmission given trigger type 0 then \(m=0,1\) and for SRS
transmission given trigger type 1 then \(m=1\).
For \(K_{s} = 0\) P\_Srs\_Offset\_Value is computed with equation:
\begin{equation*}
\begin{split}P_{SRS\_OFFSET,c}(m)value = -10.5 + P_{SRS\_OFFSET,c}(m) * 1.5 [dBm]\end{split}
\end{equation*}
This parameter is configurable by attribute system:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LteUePowerControl::PsrsOffset}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{IntegerValue} \PYG{p}{(}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\item {} 
\(M_{SRS,c}\) is the bandwidth of the SRS transmission in subframe \(i\) for serving
cell \(c\) expressed in number of resource blocks. In current implementation SRS is sent
over entire UL bandwidth.

\item {} 
\(f_{c}(i)\) is the current PUSCH power control adjustment state for serving cell \(c\),
as defined in    {\hyperref[\detokenize{lte-design:sec-uplink-power-control-pusch}]{\sphinxcrossref{\DUrole{std,std-ref}{Uplink Power Control for PUSCH}}}}

\item {} 
\(P_{O\_PUSCH,c}(j)\) and \(\alpha_{c}(j)\) are parameters as defined in
{\hyperref[\detokenize{lte-design:sec-uplink-power-control-pusch}]{\sphinxcrossref{\DUrole{std,std-ref}{Uplink Power Control for PUSCH}}}}, where \(j = 1\) .

\end{itemize}

\end{description}


\subsection{Fractional Frequency Reuse}
\label{\detokenize{lte-design:fractional-frequency-reuse}}

\subsubsection{Overview}
\label{\detokenize{lte-design:id134}}
This section describes the ns\sphinxhyphen{}3 support for Fractional Frequency Reuse
algorithms. All implemented algorithms are described in \sphinxcite{lte-references:ashamza2013}.
Currently 7 FR algorithms are implemented:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrNoOpAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrHardAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrStrictAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrSoftAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrSoftAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrEnhancedAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrDistributedAlgorithm}}

\end{itemize}

New LteFfrAlgorithm class was created and it is a abstract class for
Frequency Reuse algorithms implementation. Also, two new SAPs between
FR\sphinxhyphen{}Scheduler and FR\sphinxhyphen{}RRC were added.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-ffr-scheduling}.pdf}
\caption{Sequence diagram of Scheduling with FR algorithm}\label{\detokenize{lte-design:id194}}\label{\detokenize{lte-design:fig-lte-ffr-scheduling}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-lte-ffr-scheduling}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of Scheduling with FR algorithm}}}} shows the sequence diagram of
scheduling process with FR algorithm. In the beginning of scheduling
process, scheduler asks FR entity for available RBGs. According to
implementation FR returns all RBGs available in cell or filter them based
on its policy. Then when trying to assign some RBG to UE, scheduler asks FR
entity if this RBG is allowed for this UE. When FR returns true, scheduler
can assign this RBG to this UE, if not scheduler is checking another RBG
for this UE. Again, FR response depends on implementation and policy applied
to UE.


\subsubsection{Supported FR algorithms}
\label{\detokenize{lte-design:supported-fr-algorithms}}

\paragraph{No Frequency Reuse}
\label{\detokenize{lte-design:no-frequency-reuse}}
The NoOp FR algorithm (LteFrNoOpAlgorithm class) is implementation of
Full Frequency Reuse scheme, that means no frequency partitioning is performed
between eNBs of the same network (frequency reuse factor, FRF equals 1). eNBs
uses entire system bandwidth and transmit with uniform power over all RBGs. It
is the simplest scheme and is the basic way of operating an LTE network. This
scheme allows for achieving the high peak data rate. But from the other hand,
due to heavy interference levels from neighbouring cells, cell\sphinxhyphen{}edge users
performance is greatly limited.

Figure {\hyperref[\detokenize{lte-design:fig-lte-full-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Full Frequency Reuse scheme}}}} below presents frequency and
power plan for Full Frequency Reuse scheme.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-full-frequency-reuse-scheme}.pdf}
\caption{Full Frequency Reuse scheme}\label{\detokenize{lte-design:id195}}\label{\detokenize{lte-design:fig-lte-full-frequency-reuse-scheme}}\end{figure}

In ns\sphinxhyphen{}3, the NoOp FR algorithm always allows scheduler to use full bandwidth
and allows all UEs to use any RBG. It simply does nothing new (i.e. it does not
limit eNB bandwidth, FR algorithm is disabled), it is the simplest implementation
of FrAlgorithm class and is installed in eNb by default.


\paragraph{Hard Frequency Reuse}
\label{\detokenize{lte-design:hard-frequency-reuse}}\label{\detokenize{lte-design:sec-fr-hard-algorithm}}
The Hard Frequency Reuse algorithm provides the simplest scheme which allows to
reduce inter\sphinxhyphen{}cell interference level. In this scheme whole frequency bandwidth is
divided into few (typically 3, 4, or 7) disjoint sub\sphinxhyphen{}bands. Adjacent eNBs are
allocated with different sub\sphinxhyphen{}band. Frequency reuse factor equals the number
of sub\sphinxhyphen{}bands. This scheme allows to significantly reduce ICI at the cell edge,
so the performance of cell\sphinxhyphen{}users is improved. But due to the fact, that each
eNB uses only one part of whole bandwidth, peak data rate level is also reduced
by the factor equal to the reuse factor.

Figure {\hyperref[\detokenize{lte-design:fig-lte-hard-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Hard Frequency Reuse scheme}}}} below presents frequency and
power plan for Hard Frequency Reuse scheme.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-hard-frequency-reuse-scheme}.pdf}
\caption{Hard Frequency Reuse scheme}\label{\detokenize{lte-design:id196}}\label{\detokenize{lte-design:fig-lte-hard-frequency-reuse-scheme}}\end{figure}

In our implementation, the Hard FR algorithm has only vector of RBGs available
for eNB and pass it to MAC Scheduler during scheduling functions. When scheduler
ask, if RBG is allowed for specific UE it always return true.


\paragraph{Strict Frequency Reuse}
\label{\detokenize{lte-design:strict-frequency-reuse}}
Strict Frequency Reuse scheme is combination of Full and Hard Frequency Reuse
schemes. It consists of dividing the system bandwidth into two parts which will
have different frequency reuse. One common sub\sphinxhyphen{}band of the system bandwidth is
used in each cell interior (frequency reuse\sphinxhyphen{}1), while the other part of the
bandwidth is divided among the neighboring eNBs as in hard frequency reuse
(frequency reuse\sphinxhyphen{}N, N\textgreater{}1), in order to create one sub\sphinxhyphen{}band with a low inter\sphinxhyphen{}cell
interference level in each sector. Center UEs will be granted with the fully\sphinxhyphen{}reused
frequency chunks, while cell\sphinxhyphen{}edge UEs with orthogonal chunks. It means that interior
UEs from one cell do not share any spectrum with edge UEs from second cell, which
reduces interference for both. As can be noticed, Strict FR requires a total of
N + 1 sub\sphinxhyphen{}bands, and allows to achieve RFR in the middle between 1 and 3.

Figure {\hyperref[\detokenize{lte-design:fig-lte-strict-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Strict Frequency Reuse scheme}}}} below presents frequency and
power plan for Strict Frequency Reuse scheme with a cell\sphinxhyphen{}edge reuse factor of N = 3.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-strict-frequency-reuse-scheme}.pdf}
\caption{Strict Frequency Reuse scheme}\label{\detokenize{lte-design:id197}}\label{\detokenize{lte-design:fig-lte-strict-frequency-reuse-scheme}}\end{figure}

In our implementation, Strict FR algorithm has two maps, one for each sub\sphinxhyphen{}band.
If UE can be served within private sub\sphinxhyphen{}band, its RNTI is added to m\_privateSubBandUe
map. If UE can be served within common sub\sphinxhyphen{}band, its RNTI is added to
m\_commonSubBandUe map. Strict FR algorithm needs to decide within which sub\sphinxhyphen{}band
UE should be served. It uses UE measurements provided by RRB and compare them
with signal quality threshold (this parameter can be easily tuned by attribute
mechanism). Threshold has influence on interior to cell radius ratio.


\paragraph{Soft Frequency Reuse}
\label{\detokenize{lte-design:soft-frequency-reuse}}
In Soft Frequency Reuse (SFR) scheme each eNb transmits over the entire system
bandwidth, but there are two sub\sphinxhyphen{}bands, within UEs are served with different power
level. Since cell\sphinxhyphen{}center UEs share the bandwidth with neighboring cells, they
usually transmit at lower power level than the cell\sphinxhyphen{}edge UEs. SFR is more bandwidth
efficient than Strict FR, because it uses entire system bandwidth, but it also
results in more interference to both cell interior and edge users.

There are two possible versions of SFR scheme:
\begin{itemize}
\item {} 
In first version, the sub\sphinxhyphen{}band dedicated for the cell\sphinxhyphen{}edge UEs may also be used
by the cell\sphinxhyphen{}center UEs but with reduced power level and only if it is not occupied
by the cell\sphinxhyphen{}edge UEs. Cell\sphinxhyphen{}center sub\sphinxhyphen{}band is available to the centre UEs only.
Figure {\hyperref[\detokenize{lte-design:fig-lte-soft-frequency-reuse-scheme-v1}]{\sphinxcrossref{\DUrole{std,std-ref}{Soft Frequency Reuse scheme version 1}}}} below presents frequency and
power plan for this version of Soft Frequency Reuse scheme.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-soft-frequency-reuse-scheme-v1}.pdf}
\caption{Soft Frequency Reuse scheme version 1}\label{\detokenize{lte-design:id198}}\label{\detokenize{lte-design:fig-lte-soft-frequency-reuse-scheme-v1}}\end{figure}

\item {} 
In second version, cell\sphinxhyphen{}center UEs do not have access to cell\sphinxhyphen{}edge sub\sphinxhyphen{}band.
In this way, each cell can use the whole system bandwidth while reducing the
interference to the neighbors cells. From the other hand, lower ICI level at
the cell\sphinxhyphen{}edge is achieved at the expense of lower spectrum utilization.
Figure {\hyperref[\detokenize{lte-design:fig-lte-soft-frequency-reuse-scheme-v2}]{\sphinxcrossref{\DUrole{std,std-ref}{Soft Frequency Reuse scheme version 2}}}} below presents frequency
and power plan for this version of Soft Frequency Reuse scheme.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-soft-frequency-reuse-scheme-v2}.pdf}
\caption{Soft Frequency Reuse scheme version 2}\label{\detokenize{lte-design:id199}}\label{\detokenize{lte-design:fig-lte-soft-frequency-reuse-scheme-v2}}\end{figure}

\end{itemize}

SFR algorithm maintain two maps. If UE should be served with lower power level,
its RNTI is added to m\_lowPowerSubBandUe map. If UE should be served with higher
power level, its RNTI is added to m\_highPowerSubBandUe map. To decide with which
power level UE should be served SFR algorithm utilize UE measurements, and
compares them to threshold. Signal quality threshold and PdschConfigDedicated
(i.e. P\_A value) for inner and outer area can be configured by attributes system.
SFR utilizes Downlink Power Control described here.


\paragraph{Soft Fractional Frequency Reuse}
\label{\detokenize{lte-design:soft-fractional-frequency-reuse}}
Soft Fractional Frequency Reuse (SFFR) is an combination of Strict and Soft
Frequency Reuse schemes. While Strict FR do not use the subbands allocated
for outer region in the adjacent cells, soft FFR uses these subbands for the
inner UEs with low transmit power. As a result, the SFFR, like SFR, use the
subband with high transmit power level and with low transmit power level.
Unlike the Soft FR and like Strict FR, the Soft FFR uses the common sub\sphinxhyphen{}band
which can enhance the throughput of the inner users.

Figure {\hyperref[\detokenize{lte-design:fig-lte-soft-fractional-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Soft Fractional Fractional Frequency Reuse scheme}}}} below presents
frequency and power plan for Soft Fractional Frequency Reuse.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-soft-fractional-frequency-reuse-scheme}.pdf}
\caption{Soft Fractional Fractional Frequency Reuse scheme}\label{\detokenize{lte-design:id200}}\label{\detokenize{lte-design:fig-lte-soft-fractional-frequency-reuse-scheme}}\end{figure}


\paragraph{Enhanced Fractional Frequency Reuse}
\label{\detokenize{lte-design:enhanced-fractional-frequency-reuse}}
Enhanced Fractional Frequency Reuse (EFFR) described in \sphinxcite{lte-references:zxie2009} defines 3
cell\sphinxhyphen{}types for directly neighboring cells in a cellular system, and reserves
for each cell\sphinxhyphen{}type a part of the whole frequency band named \sphinxtitleref{Primary Segment},
which among different type cells should be orthogonal. The remaining subchannels
constitute the \sphinxtitleref{Secondary Segment}. The \sphinxtitleref{Primary Segment} of a cell\sphinxhyphen{}type is
at the same time a part of the \sphinxtitleref{Secondary Segments} belonging to the other two
cell\sphinxhyphen{}types. Each cell can occupy all subchannels of its \sphinxtitleref{Primary Segment} at
will, whereas only a part of subchannels in the \sphinxtitleref{Secondary Segment} can be used
by this cell in an interference\sphinxhyphen{}aware manner.The \sphinxtitleref{Primary Segment} of each cell
is divided into a reuse\sphinxhyphen{}3 part and reuse\sphinxhyphen{}1 part. The reuse\sphinxhyphen{}1 part can be reused
by all types of cells in the system, whereas reuse\sphinxhyphen{}3 part can only be exclusively
reused by other same type cells( i.e. the reuse\sphinxhyphen{}3 subchannels cannot be reused
by directly neighboring cells). On the \sphinxtitleref{Secondary Segment} cell acts as a guest,
and occupying secondary subchannels is actually reuse the primary subchannels
belonging to the directly neighboring cells, thus reuse on the \sphinxtitleref{Secondary Segment}
by each cell should conform to two rules:
\begin{itemize}
\item {} 
monitor before use

\item {} 
resource reuse based on SINR estimation

\end{itemize}

Each cell listens on every secondary subchannel all the time. And before occupation,
it makes SINR evaluation according to the gathered channel quality information (CQI)
and chooses resources with best estimation values for reuse. If CQI value for RBG is
above configured threshold for some user, transmission for this user can be performed
using this RBG.

In \sphinxcite{lte-references:zxie2009} scheduling process is described, it consist of three steps and two
scheduling polices. Since none of currently implemented schedulers allow for
this behaviour, some simplification were applied. In our implementation reuse\sphinxhyphen{}1
subchannels can be used only by cell center users. Reuse\sphinxhyphen{}3 subchannels can be used by
edge users, and only if there is no edge user, transmission for cell center users can
be served in reuse\sphinxhyphen{}3 subchannels.

Figure {\hyperref[\detokenize{lte-design:fig-lte-enhanced-fractional-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Enhanced Fractional Fractional Frequency Reuse scheme}}}} below presents
frequency and power plan for Enhanced Fractional Frequency Reuse.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{fr-enhanced-fractional-frequency-reuse-scheme}.pdf}
\caption{Enhanced Fractional Fractional Frequency Reuse scheme}\label{\detokenize{lte-design:id201}}\label{\detokenize{lte-design:fig-lte-enhanced-fractional-frequency-reuse-scheme}}\end{figure}


\paragraph{Distributed Fractional Frequency Reuse}
\label{\detokenize{lte-design:distributed-fractional-frequency-reuse}}
This Distributed Fractional Frequency Reuse Algorithm was presented in \sphinxcite{lte-references:dkimura2012}. It
automatically optimizes cell\sphinxhyphen{}edge sub\sphinxhyphen{}bands by focusing on user distribution (in particular,
receive\sphinxhyphen{}power distribution). This algorithm adaptively selects RBs for cell\sphinxhyphen{}edge sub\sphinxhyphen{}band on
basis of coordination information from adjecent cells and notifies the base stations of the
adjacent cells, which RBs it selected to use in edge sub\sphinxhyphen{}band. The base station of each cell
uses the received information and the following equation to compute cell\sphinxhyphen{}edge\sphinxhyphen{}band metric
\(A_{k}\) for each RB.
\begin{equation*}
\begin{split}A_{k} = \sum_{j\in J}w_{j}X_{j,k}\end{split}
\end{equation*}
where \(J\) is a set of neighbor cells, \(X_{j,k}=\{0,1\}\) is the RNTP from the \(j\)\sphinxhyphen{}th
neighbor cell. It takes a value of 1 when the \(k\)\sphinxhyphen{}th RB in the \(j\)\sphinxhyphen{}th neighbor cell is used
as a cell\sphinxhyphen{}edge sub\sphinxhyphen{}band and 0 otherwise. The symbol \(w_{j}\) denotes weight with respect to adjacent
cell \(j\), that is, the number of users for which the difference between the power of the signal
received from the serving cell \(i\) and the power of the signal received from the adjacent cell \(j\)
is less than a threshold value (i.e., the number of users near the cell edge in the service cell). A large
received power difference means that cell\sphinxhyphen{}edge users in the \(i\)\sphinxhyphen{}th cell suffer strong interference
from the \(j\)\sphinxhyphen{}th cell.

The RB for which metric \(A_{k}\) is smallest is considered to be least affected by interference from
another cell. Serving cell selects a configured number of RBs as cell\sphinxhyphen{}edge sub\sphinxhyphen{}band in ascending order
of \(A_{k}\). As a result, the RBs in which a small number of cell\sphinxhyphen{}edge users receive high
interference from adjacent base stations are selected.

The updated RNTP is then sent to all the neighbor cells. In order to avoid the meaningless oscillation
of cell\sphinxhyphen{}edge\sphinxhyphen{}band selection, a base station ignores an RNTP from another base station that has larger
cell ID than the base station.

Repeating this process across all cells enables the allocation of RBs to cell\sphinxhyphen{}edge areas to be optimized
over the system and to be adjusted with changes in user distribution.

Figure {\hyperref[\detokenize{lte-design:fig-lte-distributed-fractional-frequency-reuse-scheme}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of Distributed Frequency Reuse Scheme}}}} below presents
sequence diagram of Distributed Fractional Frequency Reuse Scheme.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{ffr-distributed-scheme}.pdf}
\caption{Sequence diagram of Distributed Frequency Reuse Scheme}\label{\detokenize{lte-design:id202}}\label{\detokenize{lte-design:fig-lte-distributed-fractional-frequency-reuse-scheme}}\end{figure}

\clearpage


\subsection{Carrier Aggregation}
\label{\detokenize{lte-design:carrier-aggregation}}\label{\detokenize{lte-design:sec-carrier-aggregation}}

\subsubsection{Overview}
\label{\detokenize{lte-design:id139}}
This section describes the ns\sphinxhyphen{}3 support for Carrier Aggregation.
The references in the standard are \sphinxcite{lte-references:ts36211}, \sphinxcite{lte-references:ts36213} and \sphinxcite{lte-references:ts36331}.

\sphinxstylestrong{Note:} Carrier Aggregation was introduced in release 3.27 and currently, only works in downlink.

3GPP standardizes, in release R10, the Carrier Aggregation (CA) technology.

This technology consists of the possibility, to aggregate radio resources belonging to
different carriers, in order to have more bandwidth available, and to achieve a higher
throughput. Carrier Aggregation as defined by 3GPP can be used with both TDD and FDD.
Since ns\sphinxhyphen{}3 only supports FDD LTE implementation, we will consider only this case in
this section. Each aggregated carrier is referred to as a component carrier, CC.
The component carrier can have a bandwidth of 1.4, 3, 5, 10, 15 or 20 MHz and a maximum
of five component carriers can be aggregated, hence the maximum aggregated bandwidth is
100 MHz. In FDD the number of aggregated carriers can be different in DL and UL. However,
the number of UL component carriers is always equal to or lower than the number of DL
component carriers. The individual component carriers can also be of different bandwidths.
When carrier aggregation is used there are a number of serving cells, one for each
component carrier. The coverage of the serving cells may differ, for example due to
that CCs on different frequency bands will experience different pathloss. The RRC
connection is only handled by one cell, the Primary serving cell, served by the
Primary component carrier (DL and UL PCC). It is also on the DL PCC that the UE
receives NAS information, such as security parameters.

3GPP defines three different CA bandwidth classes in releases 10 and 11 (where ATBC
is Aggregated Transmission Bandwidth Configuration):

Class A: ATBC \(\leq\) 100, maximum number of CC = 1

Class B: ATBC \(\leq\) 100, maximum number of CC = 2

Class C: 100 \(\leq\) ATBC \(\leq\) 200, maximum number of CC = 2

Figure {\hyperref[\detokenize{lte-design:fig-lte-carrier-aggregation-impact}]{\sphinxcrossref{\DUrole{std,std-ref}{CA impact on different layers of LTE protocol stack (from 3gpp.org)}}}} (from 3gpp.org) shows the main
impact of CA technology on the different layers of the LTE protocol stack.
Introduction of carrier aggregation influences mainly the MAC and new RRC messages
are introduced. In order to keep R8/R9 compatibility the protocol changes will be kept
to a minimum. Basically each component carrier is treated as an R8 carrier. However some
changes are required, such as new RRC messages in order to handle the secondary component
carrier (SCC), and MAC must be able to handle scheduling on a number of CCs. In the
following we describe the impact of the carrier aggregation implementation on the different
layers of the LTE protocol stack in ns\sphinxhyphen{}3.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{carrier-aggregation-impact}.png}
\caption{CA impact on different layers of LTE protocol stack (from 3gpp.org)}\label{\detokenize{lte-design:id203}}\label{\detokenize{lte-design:fig-lte-carrier-aggregation-impact}}\end{figure}


\paragraph{Impact on RRC layer}
\label{\detokenize{lte-design:impact-on-rrc-layer}}
The main impacts on the RRC layer are related to secondary carrier configuration and
measurements reporting. To enable these features we have enhanced the already existing
procedures for the RRC Connection Reconfiguration and UE RRC Measurements Model.

The carrier aggregation enabling procedure is shown in figure {\hyperref[\detokenize{lte-design:fig-ca-rrc-reconf}]{\sphinxcrossref{\DUrole{std,std-ref}{A schematic overview of the secondary carrier enabling procedure}}}}.
As per 3GPP definition, the secondary cell is a cell, operating on a secondary frequency,
which may be configured once an RRC connection is established and which may be used to
provide additional radio resources. Hence, the procedure starts when the UE is in the
CONNECTED\_NORMALLY state (see the RRC state machine description). This part of the procedure
is the same as in the previous architecture. In order to simplify the implementation,
the \sphinxtitleref{UE Capability Inquiry} and \sphinxtitleref{UE Capability Information} are not implemented. This
implies to assume that each UE can support the carrier aggregation, and any specific
configuration provided by the eNB to which is attached. The eNB RRC sends to the UE the
secondary carrier configuration parameters through the RRC Connection Reconfiguration
procedure. This procedure may be used for various purposes related to modifications of
the RRC connection, e.g. to establish, modify or release RBs, to perform handover, to
setup, modify or release measurements, to add, modify and release secondary cells (SCells).
At UE side, the RRC is extended to configure the lower layers, in such a way that the
SCell(s) are considered. Once the carriers are configured, the \sphinxtitleref{Reconfiguration Completed}
message is sent back to the eNB RRC, informing the eNB RRC and CCM that the secondary
carriers have been properly configured. The RRC layer at both the UE and the eNB sides
is extended to allow measurement reporting for the secondary carriers. Finally, in order
to allow the procedures for configuration and measurement reporting, the RRC is enhanced
to support serialization and deserialization of RRC message structures that carry information
related to the secondary carriers, e.g., if the \sphinxcode{\sphinxupquote{RRCConnectionReconfiguration}} message
includes \sphinxcode{\sphinxupquote{sCellToAddModList}} structure, SCell addition or modification will be performed,
or, if it contains \sphinxcode{\sphinxupquote{measConfig}} the measurement reporting will be configured. To allow
transmission of this information the following structures are implemented for the sCell:
\sphinxcode{\sphinxupquote{RadioResourceConfigCommonSCell}}, \sphinxcode{\sphinxupquote{RadioResourceConfigDedicatedSCell}} and
\sphinxcode{\sphinxupquote{PhysicalConfigDedicatedSCell}} and \sphinxcode{\sphinxupquote{NonCriticalExtensionConfiguration}}.
\sphinxcode{\sphinxupquote{RadioResourceConfigCommonSCell}} and \sphinxcode{\sphinxupquote{RadioResourceConfigDedicatedSCell}} are
used for SCell addition and modification (see TS 36.331, 5.3.10.3b).
\sphinxcode{\sphinxupquote{PhysicalConfigDedicatedSCell}} is used for physical channel reconfiguration
(see TS 36.331, 5.3.10.6). Finally, \sphinxcode{\sphinxupquote{NonCriticalExtensionConfiguration}} is used to
carry information of \sphinxcode{\sphinxupquote{sCellToAddModeList}} and \sphinxcode{\sphinxupquote{sCellToReleaseList}},
which is a modified structure comparing to TS 36.331, 6.6.2, according to which these
are directly in the root of RRCConnectionReconfiguration message. Measurement
reporting is extended with \sphinxcode{\sphinxupquote{measResultSCell}} structure to include RSRP and RSRQ
measurements for each configured SCell. However, the measurement report triggering
event A6 (neighbour becomes offset better than SCell) is not implemented yet.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{ca-rrc-reconf}.pdf}
\caption{A schematic overview of the secondary carrier enabling procedure}\label{\detokenize{lte-design:id204}}\label{\detokenize{lte-design:fig-ca-rrc-reconf}}\end{figure}


\paragraph{Impact on PCDCP layer}
\label{\detokenize{lte-design:impact-on-pcdcp-layer}}
There is no impact on PDCP layer.


\paragraph{Impact on RLC layer}
\label{\detokenize{lte-design:impact-on-rlc-layer}}
The impact on the RLC layer is relatively small. There is some impact on configuration of
the buffer and the usage of SAP interfaces between RLC and MAC. Since the capacity of the
lower layers increases with the carrier aggregation it is necessary to accordingly adjust
the size of the RLC buffer. The impact on the implementation of the RLC layer is very small
thanks to the design choice that allows the CCM manager to serve the different RLC instances
through the \sphinxcode{\sphinxupquote{LteMacSapProvider interface}}. Thanks to this design choice, the RLC is using
the same interface as in the earlier LTE module architecture, the \sphinxcode{\sphinxupquote{LteMacSapProvider}},
but the actual SAP provider in the new architecture is the CCM (some class that inherits
\sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}}). The CCM acts as a proxy, it receives function calls
that are meant for the MAC, and forwards them to the MAC of the different component
carriers. Additionally, it uses the information of the UEs and the logical channels for
its own functionalities.


\paragraph{Impact on MAC layer}
\label{\detokenize{lte-design:impact-on-mac-layer}}
The impact on the MAC layer depends on the CA scheduling scheme in use. Two different
scheduling schemes are proposed in R10 and are shown in
figure {\hyperref[\detokenize{lte-design:fig-lte-carrier-aggregation-mac-impact}]{\sphinxcrossref{\DUrole{std,std-ref}{CA scheduling schemes (from 3gpp.org)}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.9]{{carrier-aggregation-mac-impact}.png}
\caption{CA scheduling schemes (from 3gpp.org)}\label{\detokenize{lte-design:id205}}\label{\detokenize{lte-design:fig-lte-carrier-aggregation-mac-impact}}\end{figure}

The CIF (Carrier Indicator Field) on PDCCH (represented by the red area) indicates
on which carrier the scheduled resource is located. In the following we describe both
the schemes:
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{)}%
\item {} 
scheduling grant and resources on the same carrier. One PDCCH is supported per carrier.

\item {} 
cross\sphinxhyphen{}carrier scheduling: it is used to schedule resources on the secondary carrier
without PDCCH.

\end{enumerate}

Current implementation covers only option 1, so there is no cross\sphinxhyphen{}carrier scheduling.
The MAC layer of the eNodeB has suffered minor changes and they are mainly related to
addition of component carrier information in message exchange between layers.


\paragraph{Impact on PHY layer}
\label{\detokenize{lte-design:impact-on-phy-layer}}
The impact on PHY layer is minor. There is an instance of PHY layer per each component
carrier and the SAP interface functions remain unchanged. As shown
in {\hyperref[\detokenize{lte-design:fig-lte-carrier-aggregation-mac-impact}]{\sphinxcrossref{\DUrole{std,std-ref}{CA scheduling schemes (from 3gpp.org)}}}} the difference is that since there are
multiple PHY instances, there are also multiple instances of PDCCH, HARQ, ACK/NACK and
CSI per carrier. So, at the eNB PHY, the changes are related to the addition of the
component carrier id information, while at the UE PHY the information of the Component
Carrier is used for some functionalities that depend on the Component Carrier to which
the PHY instance belongs. For example, the UE PHY is extended to allow disabling of
the sounding reference signal (SRS) at the secondary carriers. This is necessary
because there is one UE PHY instance per component carrier, but according
to {\hyperref[\detokenize{lte-design:fig-lte-carrier-aggregation-mac-impact}]{\sphinxcrossref{\DUrole{std,std-ref}{CA scheduling schemes (from 3gpp.org)}}}}, only a single carrier is used
and the uplink traffic is transmitted only over the primary carrier.


\subsubsection{Code Structure Design}
\label{\detokenize{lte-design:code-structure-design}}
This section briefly introduces the software design and implementation of the
carrier aggregation functionality.

Both \sphinxcode{\sphinxupquote{LteEnbNetDevice}} and \sphinxcode{\sphinxupquote{LteUeNetDevice}} are created by the \sphinxcode{\sphinxupquote{LteHelper}}
using the method \sphinxcode{\sphinxupquote{InstallSingleEnbDevice}} and \sphinxcode{\sphinxupquote{InstallSingleUeDevice}}. These
functions are now extended to allow the carrier aggregation configuration. In the
following we explain the main differences comparing to the previous architecture.

Figure {\hyperref[\detokenize{lte-design:fig-lte-enb-net-device-changes}]{\sphinxcrossref{\DUrole{std,std-ref}{Changes in LteEnbNetDevice to support CA}}}} shows the attributes and associations
of the \sphinxcode{\sphinxupquote{LteEnbNetDevice}} that are affected by the implementation, or are created
in order to support the carrier aggregation functionality. Since \sphinxcode{\sphinxupquote{LteEnbNetDevice}}
may have several component carriers, the attributes that were formerly part of
the \sphinxcode{\sphinxupquote{LteEnbNetDevice}} and are carrier specific are migrated to the ComponentCarrier
class, e.g. physical layer configuration parameters. The attributes that are
specific for the eNB component carrier are migrated to \sphinxcode{\sphinxupquote{ComponentCarrierEnb}}, e.g.
pointers to MAC, PHY, scheduler, fractional frequency reuse instances.
\sphinxcode{\sphinxupquote{LteEnbNetDevice}} can contain pointers to several \sphinxcode{\sphinxupquote{ComponentCarrierEnb}} instances.
This architecture allows that each CC may have its own configuration for PHY, MAC,
scheduling algorithm and franctional frequency reuse algorithm.  These attributes are
currently maintained also in the \sphinxcode{\sphinxupquote{LteEnbNetDevice}} for backward compatibility purpose.
By default the \sphinxcode{\sphinxupquote{LteEnbNetDevice}} attributes are the same as the
primary carrier attributes.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.9]{{ca-lte-enb-net-device-changes}.pdf}
\caption{Changes in \sphinxcode{\sphinxupquote{LteEnbNetDevice}} to support CA}\label{\detokenize{lte-design:id206}}\label{\detokenize{lte-design:fig-lte-enb-net-device-changes}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-lte-ue-net-device-changes}]{\sphinxcrossref{\DUrole{std,std-ref}{Changes in LteUeNetDevice to support CA}}}} shows the attributes and associations
of \sphinxcode{\sphinxupquote{LteUeNetDevice}} that are affected by the carrier aggregation implementation.
Similarly, to the changes in \sphinxcode{\sphinxupquote{LteEnbNetDevice}}, pointers that are specific to UE
component carrier are migrated to the \sphinxcode{\sphinxupquote{ComponentCarrierUe}} class.
\sphinxcode{\sphinxupquote{LteUeNetDevice}} has maintained m\_dlEarfcn for initial cell selection purposes.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.9]{{ca-lte-ue-net-device-changes}.pdf}
\caption{Changes in \sphinxcode{\sphinxupquote{LteUeNetDevice}} to support CA}\label{\detokenize{lte-design:id207}}\label{\detokenize{lte-design:fig-lte-ue-net-device-changes}}\end{figure}


\paragraph{CA impact on data plane of eNodeB}
\label{\detokenize{lte-design:ca-impact-on-data-plane-of-enodeb}}
Figure {\hyperref[\detokenize{lte-design:fig-ca-enb-data-plane}]{\sphinxcrossref{\DUrole{std,std-ref}{eNB Data Plane Architecture}}}} shows the class diagram of the data plane at
the eNB.

The main impact is the insertion of the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} class
in the middle of the LTE protocol stack. During the design phase it was
decided to keep the same SAP interfaces design that existed between MAC and RLC
in order to avoid unnecessary changes in these parts of protocol stack.
To achieve this the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} implements all functions
that were previously exposed by RLC to MAC through \sphinxcode{\sphinxupquote{LteMacSapUser}} interface.
It also implements functions that were previously exposed by MAC to RLC through
the \sphinxcode{\sphinxupquote{LteMacSapProvider}} interface. In this way, the carrier aggregation is
transparent to upper and lower layers. The only difference is that the MAC
instance sees now only one \sphinxcode{\sphinxupquote{LteMacSapUser}}, whereas formerly it was seeing only
one \sphinxcode{\sphinxupquote{LteMacSapUser}} per RLC instance.

The \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} is responsible for the forwarding messages
in both directions. In the current implementation, a PDCP and a RLC instances are
activated each time a new data radio bearer is configured. The correspondence
between a new  data radio bearer and a RLC instance is one to one. In order to
maintain the same behavior, when a new logical channel is activated, the logical
channel configurations is propagated to each MAC layer object in “as is” fashion.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{ca-enb-data-plane}.pdf}
\caption{eNB Data Plane Architecture}\label{\detokenize{lte-design:id208}}\label{\detokenize{lte-design:fig-ca-enb-data-plane}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-ca-downlink-bsr}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence Diagram of downlink buffer status reporting (BSR) with CA}}}} shows a sequence diagram of downlink buffer status
reporting with a carrier aggregation implementation of only one secondary carrier.
Each time that an RLC instance sends a buffer status report (BSR), the
\sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} propagates the BSR to the MAC instances.
The \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} may modify a BSR before sending it to the
MAC instances. This modification depends on the traffic split algorithm implemented
in CCM class that inherits \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{ca-downlink-bsr}.pdf}
\caption{Sequence Diagram of downlink buffer status reporting (BSR) with CA}\label{\detokenize{lte-design:id209}}\label{\detokenize{lte-design:fig-ca-downlink-bsr}}\end{figure}


\paragraph{CA impact on control plane of eNodeB}
\label{\detokenize{lte-design:ca-impact-on-control-plane-of-enodeb}}
Figure {\hyperref[\detokenize{lte-design:fig-ca-enb-ctrl-plane}]{\sphinxcrossref{\DUrole{std,std-ref}{eNB Control Plane Architecture}}}} shows the class diagram of the control plane
at the eNB. During the design phase it was decided to maintain the same hooks as in
the former architecture. To do so, at each component carrier the PHY and the MAC are
directly associated to the RRC instance. However, the RRC instance is additionally
connected to the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}}, which is responsible for enabling
and disabling the component carriers. When the simulation starts, the number of
component carrier is fixed, but only the primary carrier component is enabled.
Depending on the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} algorithm the other carrier
components could be activated or not.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{ca-enb-ctrl-plane}.pdf}
\caption{eNB Control Plane Architecture}\label{\detokenize{lte-design:id210}}\label{\detokenize{lte-design:fig-ca-enb-ctrl-plane}}\end{figure}

Figure {\hyperref[\detokenize{lte-design:fig-ca-setup-radio-bearer}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence Diagram of Data Radio Bearer Setup}}}} shows how the Radio Bearer are configured.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.9]{{ca-setup-radio-bearer}.pdf}
\caption{Sequence Diagram of Data Radio Bearer Setup}\label{\detokenize{lte-design:id211}}\label{\detokenize{lte-design:fig-ca-setup-radio-bearer}}\end{figure}


\paragraph{CA impact on data plane of UE}
\label{\detokenize{lte-design:ca-impact-on-data-plane-of-ue}}
Figure {\hyperref[\detokenize{lte-design:fig-ca-ue-data-plane}]{\sphinxcrossref{\DUrole{std,std-ref}{UE Data Plane Architecture}}}} shows the relation between the different classes
related to the UE data plane. The UE data plane architecture is similar to the eNB data
plane implementation. The \sphinxcode{\sphinxupquote{LteUeComponentCarrierManager}} is responsible to (re)map
each \sphinxcode{\sphinxupquote{MacSapUserProvider}} to the corresponding RLC instance or to the proper MAC
instance. The channel remapping depends on algorithm used as \sphinxcode{\sphinxupquote{LteUeComponentCarrierManager}}.
A particular case is represented by the UE buffer status report (BSR) to eNB.
Since, i) the standard does not specify how the BSR has to be reported on each component
carrier and ii) it is decided to map one\sphinxhyphen{}to\sphinxhyphen{}one the logical channel to each MAC layer,
the only way to send BSRs to the eNB is through the primary carrier.
Figure {\hyperref[\detokenize{lte-design:fig-ca-uplink-bsr}]{\sphinxcrossref{\DUrole{std,std-ref}{Uplink buffer status reporting with CA}}}} shows the sequence diagram.
Each time a BSR is generated, the \sphinxcode{\sphinxupquote{LteUeComponentCarrierManager}} sends it through
the primary carrier component. When the primary component carrier at the eNB receives
the BSR, it sends it to \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}}. The latter, according to
algorithm dependent policies, forwards a BSR to component carriers. The communication
between the \sphinxcode{\sphinxupquote{LteEnbMac}} and  the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierManager}} is done through a
specific set of SAP functions which are implemented in the \sphinxcode{\sphinxupquote{LteUlCcmRrcSapUser}} and
the \sphinxcode{\sphinxupquote{LteUlCcmRrcSapProvider}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{ca-ue-data-plane}.pdf}
\caption{UE Data Plane Architecture}\label{\detokenize{lte-design:id212}}\label{\detokenize{lte-design:fig-ca-ue-data-plane}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{ca-uplink-bsr}.png}
\caption{Uplink buffer status reporting with CA}\label{\detokenize{lte-design:id213}}\label{\detokenize{lte-design:fig-ca-uplink-bsr}}\end{figure}


\paragraph{CA impact on control plane of UE}
\label{\detokenize{lte-design:ca-impact-on-control-plane-of-ue}}
Figure {\hyperref[\detokenize{lte-design:fig-ca-ue-ctrl-plane}]{\sphinxcrossref{\DUrole{std,std-ref}{UE Control Plane Architecture}}}} shows the relation between the different classes
associated to the UE control plane. The control plane implementation at the UE is basically
the same as the eNB control plane implementation. Each component carrier control SAP
(both for PHY and MAC layer objects) is linked in a one\sphinxhyphen{}to\sphinxhyphen{}one fashion directly to the RRC
instance. The Ue RRC instance is then connected to the \sphinxcode{\sphinxupquote{LteUeComponentCarrierManager}}
in the same way as in the eNB.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.9]{{ca-ue-ctrl-plane}.pdf}
\caption{UE Control Plane Architecture}\label{\detokenize{lte-design:id214}}\label{\detokenize{lte-design:fig-ca-ue-ctrl-plane}}\end{figure}

\sphinxcode{\sphinxupquote{CCHelper}} is the class that is implemented to help the configuration of the physical
layer parameters, such as uplink and downlink,bandwidth and EARFCN of each carrier.


\paragraph{CCM RRC MAC interfaces}
\label{\detokenize{lte-design:ccm-rrc-mac-interfaces}}
The Component carrier manager (CCM) is also developed by using the SAP interface design.
The following SAP interfaces are implemented for CCM and MAC:
\begin{quote}
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{LteCcmMacSapUser}} part is provided by MAC and is used by the CCM

\item {} 
the \sphinxcode{\sphinxupquote{LteCcmMacSapProvider}} part is provided by CCM and is used by the MAC layer

\end{itemize}

When the primary component carrier receives an uplink BSR it uses the \sphinxcode{\sphinxupquote{LteCcmMacSapUser}}
to forward it to the CCM, which should decide how to split the traffic corresponding to
this BSR among carriers. Once this decision is made, the CCM uses the \sphinxcode{\sphinxupquote{LteCcmMacSapProvider}}
interface to send back an uplink BSR to some of the MAC instances. Additionally,
the \sphinxcode{\sphinxupquote{LteCcmMacSapUser}} can be used by the MAC to notify about the PRB occupancy
in the downlink to the CCM. This information may be used by the CCM to decide how
to split the traffic and whether to use the secondary carriers.
\end{quote}


\paragraph{CCM RRC SAP interfaces}
\label{\detokenize{lte-design:ccm-rrc-sap-interfaces}}
The following SAP interfaces are implemented for CCM and RRC:
\begin{itemize}
\item {} 
the \sphinxcode{\sphinxupquote{LteCcmRrcSapProvider}} is provided by the CCM and is used by the RRC layer

\item {} 
the \sphinxcode{\sphinxupquote{LteCcmRrcSapUser}} is provided by RRC and is used by the CCM

\end{itemize}

By using the \sphinxcode{\sphinxupquote{LteCcmRrcSapUser}} the CCM may request a specific measurement reporting
configuration to be fulfilled by the UEs attached to the eNB. When a UE measurement
report is received, as a result of this configuration, the eNB RRC entity shall forward
this report to the CCM through the \sphinxcode{\sphinxupquote{LteCcmRrcSapProvider::ReportUeMeas}} SAP function.
Additionally, the \sphinxcode{\sphinxupquote{LteCcmRrcSapProvider}} offers different functions to the RRC that can
be used to add and remove of UEs, setup or release of radio bearer, configuration of the
signalling bearer, etc.


\paragraph{Component carrier managers}
\label{\detokenize{lte-design:component-carrier-managers}}
Currently, there are two component carrier manager implementations available. The first one
is the \sphinxcode{\sphinxupquote{NoOpComponentCarrierManager}}, which  is the default CCM choice. When this CCM is
used the carrier aggregation feature is disabled. This CCM forwards all traffic, the uplink
and the downlink, over
the primary carrier, and does not use secondary carriers.
Another implementation is the \sphinxcode{\sphinxupquote{RrComponentCarrierManager}}, which splits the traffic
equally among carriers, by diving the buffer status report among different carriers.
SRB0 and SRB1 flows will be forwarded only over primary carrier.


\subsection{Helpers}
\label{\detokenize{lte-design:helpers}}
Two helper objects are used to setup simulations and configure the
various components. These objects are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{LteHelper}}, which takes care of the configuration of the LTE radio access network,
as well as of coordinating the setup and release of EPS bearers. The \sphinxcode{\sphinxupquote{LteHelper}} class
provides both the API definition and its implementation.

\item {} 
\sphinxcode{\sphinxupquote{EpcHelper}}, which takes care of the configuration of the Evolved Packet Core. The
\sphinxcode{\sphinxupquote{EpcHelper}} class is an abstract base class, which only provides the API definition;
the implementation is delegated to the child classes in order to allow for different
EPC network models.

\end{itemize}

A third helper object is used to configure the \DUrole{xref,std,std-ref}{\_sec\sphinxhyphen{}carrier\sphinxhyphen{}aggregation} functionality:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{CcHelper}}, which takes care of the configuration of the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierMap}},
basically, it creates a user specified number of \sphinxcode{\sphinxupquote{LteEnbComponentCarrier}}.
\sphinxcode{\sphinxupquote{LteUeComponentCarrierMap}} is currently created starting from the
\sphinxcode{\sphinxupquote{LteEnbComponentCarrierMap}}. \sphinxcode{\sphinxupquote{LteHelper:InstallSingleUeDevice}},
in this implementation, is needed to invoke after the \sphinxcode{\sphinxupquote{LteHelper:InstallSingleEnbDevice}}
to ensure that the \sphinxcode{\sphinxupquote{LteEnbComponentCarrierMap}} is properly initialized.

\end{itemize}

It is possible to create a simple LTE\sphinxhyphen{}only simulations by
using the \sphinxcode{\sphinxupquote{LteHelper}} alone, or to create complete LTE\sphinxhyphen{}EPC simulations by using both
\sphinxcode{\sphinxupquote{LteHelper}} and \sphinxcode{\sphinxupquote{EpcHelper}}. When both helpers are used, they interact in a master\sphinxhyphen{}slave
fashion, with the \sphinxcode{\sphinxupquote{LteHelper}} being the Master that interacts directly with the user program,
and the \sphinxcode{\sphinxupquote{EpcHelper}} working “under the hood” to configure the EPC upon explicit methods
called by the \sphinxcode{\sphinxupquote{LteHelper}}. The exact interactions are displayed in the Figure {\hyperref[\detokenize{lte-design:fig-helpers}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the interaction between LteHelper and EpcHelper.}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{helpers}.pdf}
\caption{Sequence diagram of the interaction between \sphinxcode{\sphinxupquote{LteHelper}} and \sphinxcode{\sphinxupquote{EpcHelper}}.}\label{\detokenize{lte-design:id215}}\label{\detokenize{lte-design:fig-helpers}}\end{figure}


\section{User Documentation}
\label{\detokenize{lte-user:user-documentation}}\label{\detokenize{lte-user::doc}}

\subsection{Background}
\label{\detokenize{lte-user:background}}
We assume the reader is already familiar with how to use the ns\sphinxhyphen{}3
simulator to run generic simulation programs. If this is not the case,
we strongly recommend the reader to consult \sphinxcite{lte-references:ns3tutorial}.


\subsection{Usage Overview}
\label{\detokenize{lte-user:usage-overview}}
The ns\sphinxhyphen{}3 LTE model is a software library that allows the simulation of
LTE networks, optionally including the Evolved Packet Core (EPC).  The
process of performing such simulations typically involves the
following steps:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxstyleemphasis{Define the scenario} to be simulated

\item {} 
\sphinxstyleemphasis{Write a simulation program} that recreates the desired scenario
topology/architecture. This is done accessing the ns\sphinxhyphen{}3 LTE model
library using the \sphinxcode{\sphinxupquote{ns3::LteHelper}} API defined in \sphinxcode{\sphinxupquote{src/lte/helper/lte\sphinxhyphen{}helper.h}}.

\item {} 
\sphinxstyleemphasis{Specify configuration parameters} of the objects that are being
used for the simulation. This can be done using input files (via the
\sphinxcode{\sphinxupquote{ns3::ConfigStore}}) or directly within the simulation program.

\item {} 
\sphinxstyleemphasis{Configure the desired output} to be produced by the simulator

\item {} 
\sphinxstyleemphasis{Run} the simulation.

\end{enumerate}

All these aspects will be explained in the following sections by means
of practical examples.


\subsection{Basic simulation program}
\label{\detokenize{lte-user:basic-simulation-program}}\label{\detokenize{lte-user:sec-basic-simulation-program}}
Here is the minimal simulation program that is needed to do an LTE\sphinxhyphen{}only simulation (without EPC).
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Initial boilerplate:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}include \PYGZlt{}ns3/core\PYGZhy{}module.h\PYGZgt{}
\PYGZsh{}include \PYGZlt{}ns3/network\PYGZhy{}module.h\PYGZgt{}
\PYGZsh{}include \PYGZlt{}ns3/mobility\PYGZhy{}module.h\PYGZgt{}
\PYGZsh{}include \PYGZlt{}ns3/lte\PYGZhy{}module.h\PYGZgt{}

using namespace ns3;

int main (int argc, char *argv[])
\PYGZob{}
  // the rest of the simulation program follows
\end{sphinxVerbatim}

\item {} 
Create an \sphinxcode{\sphinxupquote{LteHelper}} object:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
\end{sphinxVerbatim}

This will instantiate some common
objects (e.g., the Channel object) and provide the methods to add
eNBs and UEs and configure them.

\item {} 
Create \sphinxcode{\sphinxupquote{Node}} objects for the eNB(s) and the UEs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NodeContainer enbNodes;
enbNodes.Create (1);
NodeContainer ueNodes;
ueNodes.Create (2);
\end{sphinxVerbatim}

Note that the above Node instances at this point still don’t have
an LTE protocol stack installed; they’re just empty nodes.

\item {} 
Configure the Mobility model for all the nodes:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
MobilityHelper mobility;
mobility.SetMobilityModel (\PYGZdq{}ns3::ConstantPositionMobilityModel\PYGZdq{});
mobility.Install (enbNodes);
mobility.SetMobilityModel (\PYGZdq{}ns3::ConstantPositionMobilityModel\PYGZdq{});
mobility.Install (ueNodes);
\end{sphinxVerbatim}

The above will place all nodes at the coordinates (0,0,0). Please
refer to the documentation of the ns\sphinxhyphen{}3 mobility model for how to
set your own position or configure node movement.

\item {} 
Install an LTE protocol stack on the eNB(s):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NetDeviceContainer enbDevs;
enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes);
\end{sphinxVerbatim}

\item {} 
Install an LTE protocol stack on the UEs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NetDeviceContainer ueDevs;
ueDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallUeDevice (ueNodes);
\end{sphinxVerbatim}

\item {} 
Attach the UEs to an eNB. This will configure each UE according to
the eNB configuration, and create an RRC connection between them:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}Attach (ueDevs, enbDevs.Get (0));
\end{sphinxVerbatim}

\item {} 
Activate a data radio bearer between each UE and the eNB it is attached to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
enum EpsBearer::Qci q = EpsBearer::GBR\PYGZus{}CONV\PYGZus{}VOICE;
EpsBearer bearer (q);
lteHelper\PYGZhy{}\PYGZgt{}ActivateDataRadioBearer (ueDevs, bearer);
\end{sphinxVerbatim}

this method will also activate two saturation traffic generators for
that bearer, one in uplink and one in downlink.

\item {} 
Set the stop time:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Simulator::Stop (Seconds (0.005));
\end{sphinxVerbatim}

This is needed otherwise the simulation will last forever, because
(among others) the start\sphinxhyphen{}of\sphinxhyphen{}subframe event is scheduled repeatedly, and the
ns\sphinxhyphen{}3 simulator scheduler will hence never run out of events.

\item {} 
Run the simulation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Simulator::Run ();
\end{sphinxVerbatim}

\item {} 
Cleanup and exit:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Simulator::Destroy ();
return 0;
\PYGZcb{}
\end{sphinxVerbatim}

\end{enumerate}

For how to compile and run simulation programs, please refer to \sphinxcite{lte-references:ns3tutorial}.


\subsection{Configuration of LTE model parameters}
\label{\detokenize{lte-user:configuration-of-lte-model-parameters}}
All the relevant LTE model parameters are managed through the ns\sphinxhyphen{}3
attribute system. Please refer to the \sphinxcite{lte-references:ns3tutorial} and \sphinxcite{lte-references:ns3manual}
for detailed information on all the possible methods to do it
(environmental variables, C++ API, GtkConfigStore…).

In the following, we just briefly summarize
how to do it using input files together with the ns\sphinxhyphen{}3 ConfigStore.
First of all, you need to put the following in your simulation
program, right after \sphinxcode{\sphinxupquote{main ()}} starts:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
COMMANDLINE (cmd);
cmd.Parse (argc, argv);
ConfigStore inputConfig;
inputConfig.ConfigureDefaults ();
// parse again so you can override default values from the command line
cmd.Parse (argc, argv);
\end{sphinxVerbatim}

for the above to work, make sure you also \sphinxcode{\sphinxupquote{\#include "ns3/config\sphinxhyphen{}store.h"}}.
Now create a text file named (for example) \sphinxcode{\sphinxupquote{input\sphinxhyphen{}defaults.txt}}
specifying the new default values that you want to use for some attributes:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
default ns3::LteHelper::Scheduler \PYGZdq{}ns3::PfFfMacScheduler\PYGZdq{}
default ns3::LteHelper::PathlossModel \PYGZdq{}ns3::FriisSpectrumPropagationLossModel\PYGZdq{}
default ns3::LteEnbNetDevice::UlBandwidth \PYGZdq{}25\PYGZdq{}
default ns3::LteEnbNetDevice::DlBandwidth \PYGZdq{}25\PYGZdq{}
default ns3::LteEnbNetDevice::DlEarfcn \PYGZdq{}100\PYGZdq{}
default ns3::LteEnbNetDevice::UlEarfcn \PYGZdq{}18100\PYGZdq{}
default ns3::LteUePhy::TxPower \PYGZdq{}10\PYGZdq{}
default ns3::LteUePhy::NoiseFigure \PYGZdq{}9\PYGZdq{}
default ns3::LteEnbPhy::TxPower \PYGZdq{}30\PYGZdq{}
default ns3::LteEnbPhy::NoiseFigure \PYGZdq{}5\PYGZdq{}
\end{sphinxVerbatim}

Supposing your simulation program is called
\sphinxcode{\sphinxupquote{src/lte/examples/lte\sphinxhyphen{}sim\sphinxhyphen{}with\sphinxhyphen{}input}}, you can now pass these
settings to the simulation program in the following way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::ConfigStore::Filename=input\PYGZhy{}defaults.txt
\PYGZhy{}\PYGZhy{}ns3::ConfigStore::Mode=Load \PYGZhy{}\PYGZhy{}ns3::ConfigStore::FileFormat=RawText\PYGZdq{}
\PYGZhy{}\PYGZhy{}run src/lte/examples/lte\PYGZhy{}sim\PYGZhy{}with\PYGZhy{}input
\end{sphinxVerbatim}

Furthermore, you can generate a template input file with the following
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::ConfigStore::Filename=input\PYGZhy{}defaults.txt
\PYGZhy{}\PYGZhy{}ns3::ConfigStore::Mode=Save \PYGZhy{}\PYGZhy{}ns3::ConfigStore::FileFormat=RawText\PYGZdq{}
\PYGZhy{}\PYGZhy{}run src/lte/examples/lte\PYGZhy{}sim\PYGZhy{}with\PYGZhy{}input
\end{sphinxVerbatim}

note that the above will put in the file \sphinxcode{\sphinxupquote{input\sphinxhyphen{}defaults.txt}} \sphinxstyleemphasis{all}
the default values that are registered in your particular build of the
simulator, including lots of non\sphinxhyphen{}LTE attributes.


\subsection{Configure LTE MAC Scheduler}
\label{\detokenize{lte-user:configure-lte-mac-scheduler}}
There are several types of LTE MAC scheduler user can choose here. User can use following codes to define scheduler type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::FdMtFfMacScheduler\PYGZdq{});    // FD\PYGZhy{}MT scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::TdMtFfMacScheduler\PYGZdq{});    // TD\PYGZhy{}MT scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::TtaFfMacScheduler\PYGZdq{});     // TTA scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::FdBetFfMacScheduler\PYGZdq{});   // FD\PYGZhy{}BET scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::TdBetFfMacScheduler\PYGZdq{});   // TD\PYGZhy{}BET scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::FdTbfqFfMacScheduler\PYGZdq{});  // FD\PYGZhy{}TBFQ scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::TdTbfqFfMacScheduler\PYGZdq{});  // TD\PYGZhy{}TBFQ scheduler
lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerType (\PYGZdq{}ns3::PssFfMacScheduler\PYGZdq{});     //PSS scheduler
\end{sphinxVerbatim}

TBFQ and PSS have more parameters than other schedulers. Users can define those parameters in following way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
* TBFQ scheduler::

 Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}DebtLimit\PYGZdq{}, IntegerValue(yourvalue)); // default value \PYGZhy{}625000 bytes (\PYGZhy{}5Mb)
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}CreditLimit\PYGZdq{}, UintegerValue(yourvalue)); // default value 625000 bytes (5Mb)
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}TokenPoolSize\PYGZdq{}, UintegerValue(yourvalue)); // default value 1 byte
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}CreditableThreshold\PYGZdq{}, UintegerValue(yourvalue)); // default value 0

* PSS scheduler::

 Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}nMux\PYGZdq{}, UIntegerValue(yourvalue)); // the maximum number of UE selected by TD scheduler
 lteHelper\PYGZhy{}\PYGZgt{}SetSchedulerAttribute(\PYGZdq{}PssFdSchedulerType\PYGZdq{}, StringValue(\PYGZdq{}CoItA\PYGZdq{})); // PF scheduler type in PSS
\end{sphinxVerbatim}

In TBFQ, default values of debt limit and credit limit are set to \sphinxhyphen{}5Mb and 5Mb respectively based on paper \sphinxcite{lte-references:fabokhari2009}.
Current implementation does not consider credit threshold (\(C\) = 0). In PSS, if user does not define nMux,
PSS will set this value to half of total UE. The default FD scheduler is PFsch.

In addition, token generation rate in TBFQ and target bit rate in PSS need to be configured by Guarantee Bit Rate (GBR) or
Maximum Bit Rate (MBR) in epc bearer QoS parameters. Users can use following codes to define GBR and MBR in both downlink and uplink:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
enum EpsBearer::Qci q = EpsBearer::yourvalue;  // define Qci type
GbrQosInformation qos;
qos.gbrDl = yourvalue; // Downlink GBR
qos.gbrUl = yourvalue; // Uplink GBR
qos.mbrDl = yourvalue; // Downlink MBR
qos.mbrUl = yourvalue; // Uplink MBR
EpsBearer bearer (q, qos);
lteHelper\PYGZhy{}\PYGZgt{}ActivateDedicatedEpsBearer (ueDevs, bearer, EpcTft::Default ());
\end{sphinxVerbatim}

In PSS, TBR is obtained from GBR in bearer level QoS parameters. In TBFQ, token generation rate is obtained from the MBR
setting in bearer level QoS parameters, which therefore needs to be configured consistently.
For constant bit rate (CBR) traffic, it is suggested to set MBR to GBR. For variance bit rate (VBR) traffic,
it is suggested to set MBR k times larger than GBR in order to cover the peak traffic rate. In current implementation, k is set to
three based on paper \sphinxcite{lte-references:fabokhari2009}. In addition, current version of TBFQ does not consider RLC header and PDCP header length in
MBR and GBR. Another parameter in TBFQ is packet arrival rate. This parameter is calculated within scheduler and equals to the past
average throughput which is used in PF scheduler.

Many useful attributes of the LTE\sphinxhyphen{}EPC model will be described in the
following subsections. Still, there are many attributes which are not
explicitly mentioned in the design or user documentation, but which
are clearly documented using the ns\sphinxhyphen{}3 attribute system. You can easily
print a list of the attributes of a given object together with their
description and default value passing \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}PrintAttributes=}} to a simulation
program, like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::LteHelper\PYGZdq{}
\end{sphinxVerbatim}

You can try also with other LTE and EPC objects, like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::LteEnbNetDevice\PYGZdq{}
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::LteEnbMac\PYGZdq{}
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::LteEnbPhy\PYGZdq{}
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::LteUePhy\PYGZdq{}
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintAttributes=ns3::PointToPointEpcHelper\PYGZdq{}
\end{sphinxVerbatim}


\subsection{Simulation Output}
\label{\detokenize{lte-user:simulation-output}}\label{\detokenize{lte-user:sec-simulation-output}}
The ns\sphinxhyphen{}3 LTE model currently supports the output to file of PHY, MAC, RLC
and PDCP level Key Performance Indicators (KPIs). You can enable it in
the following way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();

// configure all the simulation scenario here...

lteHelper\PYGZhy{}\PYGZgt{}EnablePhyTraces ();
lteHelper\PYGZhy{}\PYGZgt{}EnableMacTraces ();
lteHelper\PYGZhy{}\PYGZgt{}EnableRlcTraces ();
lteHelper\PYGZhy{}\PYGZgt{}EnablePdcpTraces ();

Simulator::Run ();
\end{sphinxVerbatim}

RLC and PDCP KPIs are calculated over a time interval and stored on ASCII
files, two for RLC KPIs and two for PDCP KPIs, in each case one for
uplink and one for downlink. The time interval duration can be controlled using the attribute
\sphinxcode{\sphinxupquote{ns3::RadioBearerStatsCalculator::EpochDuration}}.

The columns of the RLC KPI files is the following (the same
for uplink and downlink):
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
start time of measurement interval in seconds since the start of simulation

\item {} 
end time of measurement interval in seconds since the start of simulation

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
cell\sphinxhyphen{}specific UE ID (RNTI)

\item {} 
Logical Channel ID

\item {} 
Number of transmitted RLC PDUs

\item {} 
Total bytes transmitted.

\item {} 
Number of received RLC PDUs

\item {} 
Total bytes received

\item {} 
Average RLC PDU delay in seconds

\item {} 
Standard deviation of the RLC PDU delay

\item {} 
Minimum value of the RLC PDU delay

\item {} 
Maximum value of the RLC PDU delay

\item {} 
Average RLC PDU size, in bytes

\item {} 
Standard deviation of the RLC PDU size

\item {} 
Minimum RLC PDU size

\item {} 
Maximum RLC PDU size

\end{enumerate}

Similarly, the columns of the PDCP KPI files is the following (again, the same
for uplink and downlink):
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
start time of measurement interval in seconds since the start of simulation

\item {} 
end time of measurement interval in seconds since the start of simulation

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
cell\sphinxhyphen{}specific UE ID (RNTI)

\item {} 
Logical Channel ID

\item {} 
Number of transmitted PDCP PDUs

\item {} 
Total bytes transmitted.

\item {} 
Number of received PDCP PDUs

\item {} 
Total bytes received

\item {} 
Average PDCP PDU delay in seconds

\item {} 
Standard deviation of the PDCP PDU delay

\item {} 
Minimum value of the PDCP PDU delay

\item {} 
Maximum value of the PDCP PDU delay

\item {} 
Average PDCP PDU size, in bytes

\item {} 
Standard deviation of the PDCP PDU size

\item {} 
Minimum PDCP PDU size

\item {} 
Maximum PDCP PDU size

\end{enumerate}

MAC KPIs are basically a trace of the resource allocation reported by
the scheduler upon the start of every subframe. They are stored in
ASCII files. For downlink MAC KPIs the format is the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in seconds at which the allocation is indicated by the scheduler

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
Frame number

\item {} 
Subframe number

\item {} 
cell\sphinxhyphen{}specific UE ID (RNTI)

\item {} 
MCS of TB 1

\item {} 
size of TB 1

\item {} 
MCS of TB 2 (0 if not present)

\item {} 
size of TB 2 (0 if not present)

\end{enumerate}

while for uplink MAC KPIs the format is:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in seconds at which the allocation is indicated by the scheduler

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
Frame number

\item {} 
Subframe number

\item {} 
cell\sphinxhyphen{}specific UE ID (RNTI)

\item {} 
MCS of TB

\item {} 
size of TB

\end{enumerate}

The names of the files used for MAC KPI output can be customized via
the ns\sphinxhyphen{}3 attributes \sphinxcode{\sphinxupquote{ns3::MacStatsCalculator::DlOutputFilename}} and
\sphinxcode{\sphinxupquote{ns3::MacStatsCalculator::UlOutputFilename}}.

PHY KPIs are distributed in seven different files, configurable through the attributes
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::DlRsrpSinrFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::UeSinrFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::InterferenceFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::DlTxOutputFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::UlTxOutputFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::DlRxOutputFilename}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::PhyStatsCalculator::UlRxOutputFilename}}

\end{enumerate}

In the RSRP/SINR file, the following content is available:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in seconds at which the allocation is indicated by the scheduler

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
RSRP

\item {} 
Linear average over all RBs of the downlink SINR in linear units

\end{enumerate}

The contents in the UE SINR file are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in seconds at which the allocation is indicated by the scheduler

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
uplink SINR in linear units for the UE

\end{enumerate}

In the interference filename the content is:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in seconds at which the allocation is indicated by the scheduler

\item {} 
Cell ID

\item {} 
List of interference values per RB

\end{enumerate}

In UL and DL transmission files the parameters included are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in milliseconds

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
RNTI

\item {} 
Layer of transmission

\item {} 
MCS

\item {} 
size of the TB

\item {} 
Redundancy version

\item {} 
New Data Indicator flag

\end{enumerate}

And finally, in UL and DL reception files the parameters included are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Simulation time in milliseconds

\item {} 
Cell ID

\item {} 
unique UE ID (IMSI)

\item {} 
RNTI

\item {} 
Transmission Mode

\item {} 
Layer of transmission

\item {} 
MCS

\item {} 
size of the TB

\item {} 
Redundancy version

\item {} 
New Data Indicator flag

\item {} 
Correctness in the reception of the TB

\end{enumerate}

\sphinxstylestrong{Note:} The traces generated by simulating the scenarios involving the RLF
will have a discontinuity in time from the moment of the RLF event until the UE
connects again to an eNB.


\subsection{Fading Trace Usage}
\label{\detokenize{lte-user:fading-trace-usage}}
In this section we will describe how to use fading traces within LTE simulations.


\subsubsection{Fading Traces Generation}
\label{\detokenize{lte-user:fading-traces-generation}}
It is possible to generate fading traces by using a dedicated matlab script provided with the code (\sphinxcode{\sphinxupquote{/lte/model/fading\sphinxhyphen{}traces/fading\sphinxhyphen{}trace\sphinxhyphen{}generator.m}}). This script already includes the typical taps configurations for three 3GPP scenarios (i.e., pedestrian, vehicular and urban as defined in Annex B.2 of \sphinxcite{lte-references:ts36104}); however users can also introduce their specific configurations. The list of the configurable parameters is provided in the following:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{fc}} : the frequency in use (it affects the computation of the doppler speed).

\item {} 
\sphinxcode{\sphinxupquote{v\_km\_h}} : the speed of the users

\item {} 
\sphinxcode{\sphinxupquote{traceDuration}} : the duration in seconds of the total length of the trace.

\item {} 
\sphinxcode{\sphinxupquote{numRBs}} : the number of the resource block to be evaluated.

\item {} 
\sphinxcode{\sphinxupquote{tag}} : the tag to be applied to the file generated.

\end{itemize}

The file generated contains ASCII\sphinxhyphen{}formatted real values organized in a matrix fashion: every row corresponds to a different RB, and every column correspond to a different temporal fading trace sample.

It has to be noted that the ns\sphinxhyphen{}3 LTE module is able to work with any fading trace file that complies with the above described ASCII format. Hence, other external tools can be used to generate custom fading traces, such as for example other simulators or experimental devices.


\subsubsection{Fading Traces Usage}
\label{\detokenize{lte-user:fading-traces-usage}}
When using a fading trace, it is of paramount importance to specify correctly the trace parameters in the simulation, so that the fading model can load and use it correctly.
The parameters to be configured are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{TraceFilename}} : the name of the trace to be loaded (absolute path, or relative path w.r.t. the path from where the simulation program is executed);

\item {} 
\sphinxcode{\sphinxupquote{TraceLength}} : the trace duration in seconds;

\item {} 
\sphinxcode{\sphinxupquote{SamplesNum}} : the number of samples;

\item {} 
\sphinxcode{\sphinxupquote{WindowSize}} : the size of the fading sampling window in seconds;

\end{itemize}

It is important to highlight that the sampling interval of the fading trace has to be 1 ms or greater, and in the latter case it has to be an integer multiple of 1 ms in order to be correctly processed by the fading module.

The default configuration of the matlab script provides a trace 10 seconds long, made of 10,000 samples (i.e., 1 sample per TTI=1ms) and used with a windows size of 0.5 seconds amplitude. These are also the default values of the parameters above used in the simulator; therefore their settage can be avoided in case the fading trace respects them.

In order to activate the fading module (which is not active by default) the following code should be included in the simulation program:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModel(\PYGZdq{}ns3::TraceFadingLossModel\PYGZdq{});
\end{sphinxVerbatim}

And for setting the parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModelAttribute (\PYGZdq{}TraceFilename\PYGZdq{}, StringValue (\PYGZdq{}src/lte/model/fading\PYGZhy{}traces/fading\PYGZus{}trace\PYGZus{}EPA\PYGZus{}3kmph.fad\PYGZdq{}));
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModelAttribute (\PYGZdq{}TraceLength\PYGZdq{}, TimeValue (Seconds (10.0)));
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModelAttribute (\PYGZdq{}SamplesNum\PYGZdq{}, UintegerValue (10000));
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModelAttribute (\PYGZdq{}WindowSize\PYGZdq{}, TimeValue (Seconds (0.5)));
lteHelper\PYGZhy{}\PYGZgt{}SetFadingModelAttribute (\PYGZdq{}RbNum\PYGZdq{}, UintegerValue (100));
\end{sphinxVerbatim}

It has to be noted that, \sphinxcode{\sphinxupquote{TraceFilename}} does not have a default value, therefore is has to be always set explicitly.

The simulator provide natively three fading traces generated according to the configurations defined in in Annex B.2 of \sphinxcite{lte-references:ts36104}. These traces are available in the folder \sphinxcode{\sphinxupquote{src/lte/model/fading\sphinxhyphen{}traces/}}). An excerpt from these traces is represented in the following figures.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fading_pedestrian}.pdf}
\caption{Excerpt of the fading trace included in the simulator for a pedestrian scenario (speed of 3 kmph).}\label{\detokenize{lte-user:id16}}\label{\detokenize{lte-user:fig-fadingpedestriantrace}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fading_vehicular}.pdf}
\caption{Excerpt of the fading trace included in the simulator for a vehicular  scenario (speed of 60 kmph).}\label{\detokenize{lte-user:id17}}\label{\detokenize{lte-user:fig-fadingvehiculartrace}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fading_urban_3kmph}.pdf}
\caption{Excerpt of the fading trace included in the simulator for an urban  scenario (speed of 3 kmph).}\label{\detokenize{lte-user:id18}}\label{\detokenize{lte-user:fig-fadingurbantrace}}\end{figure}


\subsection{Mobility Model with Buildings}
\label{\detokenize{lte-user:mobility-model-with-buildings}}
We now explain by examples how to use the buildings model (in particular, the \sphinxcode{\sphinxupquote{MobilityBuildingInfo}} and the \sphinxcode{\sphinxupquote{BuildingPropagationModel}} classes) in an ns\sphinxhyphen{}3 simulation program to setup an LTE simulation scenario that includes buildings and indoor nodes.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Header files to be included:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}include \PYGZlt{}ns3/mobility\PYGZhy{}building\PYGZhy{}info.h\PYGZgt{}
\PYGZsh{}include \PYGZlt{}ns3/buildings\PYGZhy{}propagation\PYGZhy{}loss\PYGZhy{}model.h\PYGZgt{}
\PYGZsh{}include \PYGZlt{}ns3/building.h\PYGZgt{}
\end{sphinxVerbatim}

\item {} 
Pathloss model selection:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();

lteHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}PathlossModel\PYGZdq{}, StringValue (\PYGZdq{}ns3::BuildingsPropagationLossModel\PYGZdq{}));
\end{sphinxVerbatim}

\item {} 
EUTRA Band Selection

\end{enumerate}

The selection of the working frequency of the propagation model has to be done with the standard ns\sphinxhyphen{}3 attribute system as described in the correspond section (“Configuration of LTE model parameters”) by means of the DlEarfcn and UlEarfcn parameters, for instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}DlEarfcn\PYGZdq{}, UintegerValue (100));
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}UlEarfcn\PYGZdq{}, UintegerValue (18100));
\end{sphinxVerbatim}

It is to be noted that using other means to configure the frequency used by the propagation model (i.e., configuring the corresponding BuildingsPropagationLossModel attributes directly) might generates conflicts in the frequencies definition in the modules during the simulation, and is therefore not advised.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Mobility model selection:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
MobilityHelper mobility;
mobility.SetMobilityModel (\PYGZdq{}ns3::ConstantPositionMobilityModel\PYGZdq{});

It is to be noted that any mobility model can be used.
\end{sphinxVerbatim}

\item {} 
Building creation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
double x\PYGZus{}min = 0.0;
double x\PYGZus{}max = 10.0;
double y\PYGZus{}min = 0.0;
double y\PYGZus{}max = 20.0;
double z\PYGZus{}min = 0.0;
double z\PYGZus{}max = 10.0;
Ptr\PYGZlt{}Building\PYGZgt{} b = CreateObject \PYGZlt{}Building\PYGZgt{} ();
b\PYGZhy{}\PYGZgt{}SetBoundaries (Box (x\PYGZus{}min, x\PYGZus{}max, y\PYGZus{}min, y\PYGZus{}max, z\PYGZus{}min, z\PYGZus{}max));
b\PYGZhy{}\PYGZgt{}SetBuildingType (Building::Residential);
b\PYGZhy{}\PYGZgt{}SetExtWallsType (Building::ConcreteWithWindows);
b\PYGZhy{}\PYGZgt{}SetNFloors (3);
b\PYGZhy{}\PYGZgt{}SetNRoomsX (3);
b\PYGZhy{}\PYGZgt{}SetNRoomsY (2);
\end{sphinxVerbatim}

This will instantiate a residential building with base of 10 x 20 meters and height of 10 meters whose external walls are of concrete with windows; the building has three floors and has an internal 3 x 2  grid of rooms of equal size.

\item {} 
Node creation and positioning:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ueNodes.Create (2);
mobility.Install (ueNodes);
BuildingsHelper::Install (ueNodes);
NetDeviceContainer ueDevs;
ueDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallUeDevice (ueNodes);
Ptr\PYGZlt{}ConstantPositionMobilityModel\PYGZgt{} mm0 = enbNodes.Get (0)\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}ConstantPositionMobilityModel\PYGZgt{} ();
Ptr\PYGZlt{}ConstantPositionMobilityModel\PYGZgt{} mm1 = enbNodes.Get (1)\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}ConstantPositionMobilityModel\PYGZgt{} ();
mm0\PYGZhy{}\PYGZgt{}SetPosition (Vector (5.0, 5.0, 1.5));
mm1\PYGZhy{}\PYGZgt{}SetPosition (Vector (30.0, 40.0, 1.5));
\end{sphinxVerbatim}

\item {} 
Finalize the building and mobility model configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
BuildingsHelper::MakeMobilityModelConsistent ();
\end{sphinxVerbatim}

\end{enumerate}

See the documentation of the \sphinxstyleemphasis{buildings} module for more detailed information.


\subsection{PHY Error Model}
\label{\detokenize{lte-user:phy-error-model}}
The Physical error model consists of the data error model and the downlink control error model, both of them active by default. It is possible to deactivate them with the ns3 attribute system, in detail:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteSpectrumPhy::CtrlErrorModelEnabled\PYGZdq{}, BooleanValue (false));
Config::SetDefault (\PYGZdq{}ns3::LteSpectrumPhy::DataErrorModelEnabled\PYGZdq{}, BooleanValue (false));
\end{sphinxVerbatim}


\subsection{MIMO Model}
\label{\detokenize{lte-user:mimo-model}}
Is this subsection we illustrate how to configure the MIMO parameters. LTE defines 7 types of transmission modes:
\begin{itemize}
\item {} 
Transmission Mode 1: SISO.

\item {} 
Transmission Mode 2: MIMO Tx Diversity.

\item {} 
Transmission Mode 3: MIMO Spatial Multiplexity Open Loop.

\item {} 
Transmission Mode 4: MIMO Spatial Multiplexity Closed Loop.

\item {} 
Transmission Mode 5: MIMO Multi\sphinxhyphen{}User.

\item {} 
Transmission Mode 6: Closer loop single layer precoding.

\item {} 
Transmission Mode 7: Single antenna port 5.

\end{itemize}

According to model implemented, the simulator includes the first three transmission modes types. The default one is the Transmission Mode 1 (SISO). In order to change the default Transmission Mode to be used, the attribute \sphinxcode{\sphinxupquote{DefaultTransmissionMode}} of the \sphinxcode{\sphinxupquote{LteEnbRrc}} can be used, as shown in the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteEnbRrc::DefaultTransmissionMode\PYGZdq{}, UintegerValue (0)); // SISO
Config::SetDefault (\PYGZdq{}ns3::LteEnbRrc::DefaultTransmissionMode\PYGZdq{}, UintegerValue (1)); // MIMO Tx diversity (1 layer)
Config::SetDefault (\PYGZdq{}ns3::LteEnbRrc::DefaultTransmissionMode\PYGZdq{}, UintegerValue (2)); // MIMO Spatial Multiplexity (2 layers)
\end{sphinxVerbatim}

For changing the transmission mode of a certain user during the simulation a specific interface has been implemented in both standard schedulers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void TransmissionModeConfigurationUpdate (uint16\PYGZus{}t rnti, uint8\PYGZus{}t txMode);
\end{sphinxVerbatim}

This method can be used both for developing transmission mode decision engine (i.e., for optimizing the transmission mode according to channel condition and/or user’s requirements) and for manual switching from simulation script. In the latter case, the switching can be done as shown in the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteEnbNetDevice\PYGZgt{} lteEnbDev = enbDevs.Get (0)\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}LteEnbNetDevice\PYGZgt{} ();
PointerValue ptrval;
enbNetDev\PYGZhy{}\PYGZgt{}GetAttribute (\PYGZdq{}FfMacScheduler\PYGZdq{}, ptrval);
Ptr\PYGZlt{}RrFfMacScheduler\PYGZgt{} rrsched = ptrval.Get\PYGZlt{}RrFfMacScheduler\PYGZgt{} ();
Simulator::Schedule (Seconds (0.2), \PYGZam{}RrFfMacScheduler::TransmissionModeConfigurationUpdate, rrsched, rnti, 1);
\end{sphinxVerbatim}

Finally, the model implemented can be reconfigured according to different MIMO models by updating the gain values (the only constraints is that the gain has to be constant during simulation run\sphinxhyphen{}time and common for the layers). The gain of each Transmission Mode can be changed according to the standard ns3 attribute system, where the attributes are: \sphinxcode{\sphinxupquote{TxMode1Gain}}, \sphinxcode{\sphinxupquote{TxMode2Gain}}, \sphinxcode{\sphinxupquote{TxMode3Gain}}, \sphinxcode{\sphinxupquote{TxMode4Gain}}, \sphinxcode{\sphinxupquote{TxMode5Gain}}, \sphinxcode{\sphinxupquote{TxMode6Gain}} and \sphinxcode{\sphinxupquote{TxMode7Gain}}. By default only \sphinxcode{\sphinxupquote{TxMode1Gain}}, \sphinxcode{\sphinxupquote{TxMode2Gain}} and \sphinxcode{\sphinxupquote{TxMode3Gain}} have a meaningful value, that are the ones derived by \_{[}CatreuxMIMO{]} (i.e., respectively 0.0, 4.2 and \sphinxhyphen{}2.8 dB).


\subsection{Use of AntennaModel}
\label{\detokenize{lte-user:use-of-antennamodel}}
We now show how associate a particular AntennaModel with an eNB device
in order to model a sector of a macro eNB. For this purpose, it is
convenient to use the \sphinxcode{\sphinxupquote{CosineAntennaModel}} provided by the ns\sphinxhyphen{}3
antenna module. The configuration of the eNB is to be done via the
\sphinxcode{\sphinxupquote{LteHelper}} instance right before the creation of the
\sphinxcode{\sphinxupquote{EnbNetDevice}}, as shown in the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetEnbAntennaModelType (\PYGZdq{}ns3::CosineAntennaModel\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetEnbAntennaModelAttribute (\PYGZdq{}Orientation\PYGZdq{}, DoubleValue (0));
lteHelper\PYGZhy{}\PYGZgt{}SetEnbAntennaModelAttribute (\PYGZdq{}Beamwidth\PYGZdq{},   DoubleValue (60));
lteHelper\PYGZhy{}\PYGZgt{}SetEnbAntennaModelAttribute (\PYGZdq{}MaxGain\PYGZdq{},     DoubleValue (0.0));
\end{sphinxVerbatim}

the above code will generate an antenna model with a 60 degrees
beamwidth pointing along the X axis. The orientation is measured
in degrees from the X axis, e.g., an orientation of 90 would point
along the Y axis, and an orientation of \sphinxhyphen{}90 would point in the
negative direction along the Y axis. The beamwidth is the \sphinxhyphen{}3 dB
beamwidth, e.g, for a 60 degree beamwidth the antenna gain at an angle
of \(\pm 30\) degrees from the direction of orientation is \sphinxhyphen{}3 dB.

To create a multi\sphinxhyphen{}sector site, you need to create different ns\sphinxhyphen{}3 nodes
placed at the same position, and to configure separate \sphinxcode{\sphinxupquote{EnbNetDevice}}
with different antenna orientations to be installed on each node.


\subsection{Radio Environment Maps}
\label{\detokenize{lte-user:radio-environment-maps}}\label{\detokenize{lte-user:sec-radio-environment-maps}}
By using the class \sphinxcode{\sphinxupquote{RadioEnvironmentMapHelper}} it is possible to output
to a file a Radio Environment Map (REM), i.e., a uniform 2D grid of values
that represent the Signal\sphinxhyphen{}to\sphinxhyphen{}noise ratio in the downlink with respect
to the eNB that has the strongest signal at each point. It is possible
to specify if REM should be generated for data or control channel. Also user
can set the RbId, for which REM will be generated. Default RbId is \sphinxhyphen{}1, what
means that REM will generated with averaged Signal\sphinxhyphen{}to\sphinxhyphen{}noise ratio from all RBs.

To do this, you just need to add the following code to your simulation
program towards the end, right before the call to Simulator::Run ():

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}RadioEnvironmentMapHelper\PYGZgt{} remHelper = CreateObject\PYGZlt{}RadioEnvironmentMapHelper\PYGZgt{} ();
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}ChannelPath\PYGZdq{}, StringValue (\PYGZdq{}/ChannelList/0\PYGZdq{}));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}OutputFile\PYGZdq{}, StringValue (\PYGZdq{}rem.out\PYGZdq{}));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}XMin\PYGZdq{}, DoubleValue (\PYGZhy{}400.0));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}XMax\PYGZdq{}, DoubleValue (400.0));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}XRes\PYGZdq{}, UintegerValue (100));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}YMin\PYGZdq{}, DoubleValue (\PYGZhy{}300.0));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}YMax\PYGZdq{}, DoubleValue (300.0));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}YRes\PYGZdq{}, UintegerValue (75));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}Z\PYGZdq{}, DoubleValue (0.0));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}UseDataChannel\PYGZdq{}, BooleanValue (true));
remHelper\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}RbId\PYGZdq{}, IntegerValue (10));
remHelper\PYGZhy{}\PYGZgt{}Install ();
\end{sphinxVerbatim}

By configuring the attributes of the \sphinxcode{\sphinxupquote{RadioEnvironmentMapHelper}} object
as shown above, you can tune the parameters of the REM to be
generated. Note that each \sphinxcode{\sphinxupquote{RadioEnvironmentMapHelper}} instance can
generate only one REM; if you want to generate more REMs, you need to
create one separate instance for each REM.

Note that the REM generation is very demanding, in particular:
\begin{itemize}
\item {} 
the run\sphinxhyphen{}time memory consumption is approximately 5KB per pixel. For example,
a REM with a resolution of 500x500 would need about 1.25 GB of memory, and
a resolution of 1000x1000 would need needs about 5 GB (too much for a
regular PC at the time of this writing). To overcome this issue,
the REM is generated at successive steps, with each step evaluating
at most a number of pixels determined by the value of the
the attribute \sphinxcode{\sphinxupquote{RadioEnvironmentMapHelper::MaxPointsPerIteration}}.

\item {} 
if you generate a REM at the beginning of a simulation, it will
slow down the execution of the rest of the simulation. If you want
to generate a REM for a program and also use the same program to
get simulation result, it is recommended to add a command\sphinxhyphen{}line
switch that allows to either generate the REM or run the complete
simulation. For this purpose, note that there is an attribute
\sphinxcode{\sphinxupquote{RadioEnvironmentMapHelper::StopWhenDone}} (default: true) that
will force the simulation to stop right after the REM has been generated.

\end{itemize}

The REM is stored in an ASCII file in the following format:
\begin{itemize}
\item {} 
column 1 is the x coordinate

\item {} 
column 2 is the y coordinate

\item {} 
column 3 is the z coordinate

\item {} 
column 4 is the SINR in linear units

\end{itemize}

A minimal gnuplot script that allows you to plot the REM is given
below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
set view map;
set xlabel \PYGZdq{}X\PYGZdq{}
set ylabel \PYGZdq{}Y\PYGZdq{}
set cblabel \PYGZdq{}SINR (dB)\PYGZdq{}
unset key
plot \PYGZdq{}rem.out\PYGZdq{} using (\PYGZdl{}1):(\PYGZdl{}2):(10*log10(\PYGZdl{}4)) with image
\end{sphinxVerbatim}

As an example, here is the REM that can be obtained with the example program lena\sphinxhyphen{}dual\sphinxhyphen{}stripe, which shows a three\sphinxhyphen{}sector LTE macrocell in a co\sphinxhyphen{}channel deployment with some residential femtocells randomly deployed in two blocks of apartments.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lena-dual-stripe}.pdf}
\caption{REM obtained from the lena\sphinxhyphen{}dual\sphinxhyphen{}stripe example}\label{\detokenize{lte-user:id19}}\label{\detokenize{lte-user:fig-lena-dual-stripe}}\end{figure}

Note that the lena\sphinxhyphen{}dual\sphinxhyphen{}stripe example program also generate
gnuplot\sphinxhyphen{}compatible output files containing information about the
positions of the UE and eNB nodes as well as of the buildings,
respectively in the files \sphinxcode{\sphinxupquote{ues.txt}}, \sphinxcode{\sphinxupquote{enbs.txt}} and
\sphinxcode{\sphinxupquote{buildings.txt}}. These can be easily included when using
gnuplot. For example, assuming that your gnuplot script (e.g., the
minimal gnuplot script described above) is saved in a file named
\sphinxcode{\sphinxupquote{my\_plot\_script}}, running the following command would plot the
location of UEs, eNBs and buildings on top of the REM:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
gnuplot \PYGZhy{}p enbs.txt ues.txt buildings.txt my\PYGZus{}plot\PYGZus{}script
\end{sphinxVerbatim}


\subsection{AMC Model and CQI Calculation}
\label{\detokenize{lte-user:amc-model-and-cqi-calculation}}
The simulator provides two possible schemes for what concerns the selection of the MCSs and
correspondingly the generation of the CQIs. The first one is based on the GSoC module \sphinxcite{lte-references:piro2011}
and works per RB basis. This model can be activated with the ns3 attribute system, as presented in
the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteAmc::AmcModel\PYGZdq{}, EnumValue (LteAmc::PiroEW2010));
\end{sphinxVerbatim}

While, the solution based on the physical error model can be controlled with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteAmc::AmcModel\PYGZdq{}, EnumValue (LteAmc::MiErrorModel));
\end{sphinxVerbatim}

Finally, the required efficiency of the \sphinxcode{\sphinxupquote{PiroEW2010}} AMC module can be tuned thanks to the \sphinxcode{\sphinxupquote{Ber}} attribute (), for instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteAmc::Ber\PYGZdq{}, DoubleValue (0.00005));
\end{sphinxVerbatim}


\subsection{Evolved Packet Core (EPC)}
\label{\detokenize{lte-user:evolved-packet-core-epc}}\label{\detokenize{lte-user:sec-evolved-packet-core}}
We now explain how to write a simulation program that allows to
simulate the EPC in addition to the LTE radio access network. The use
of EPC allows to use IPv4 and IPv6 networking with LTE devices. In other words,
you will be able to use the regular ns\sphinxhyphen{}3 applications and sockets over
IPv4 and IPv6 over LTE, and also to connect an LTE network to any other IPv4 and IPv6
network you might have in your simulation.

First of all, in addition to \sphinxcode{\sphinxupquote{LteHelper}} that we already introduced
in {\hyperref[\detokenize{lte-user:sec-basic-simulation-program}]{\sphinxcrossref{\DUrole{std,std-ref}{Basic simulation program}}}}, you need to use an additional
\sphinxcode{\sphinxupquote{EpcHelper}} class, which will take care of creating the EPC entities and
network topology. Note that you can’t use \sphinxcode{\sphinxupquote{EpcHelper}} directly, as
it is an abstract base class; instead, you need to use one of its
child classes, which provide different EPC topology implementations. In
this example we will consider \sphinxcode{\sphinxupquote{PointToPointEpcHelper}}, which
implements an EPC based on point\sphinxhyphen{}to\sphinxhyphen{}point links. To use it, you need
first to insert this code in your simulation program:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
Ptr\PYGZlt{}PointToPointEpcHelper\PYGZgt{} epcHelper = CreateObject\PYGZlt{}PointToPointEpcHelper\PYGZgt{} ();
\end{sphinxVerbatim}

Then, you need to tell the LTE helper that the EPC will be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetEpcHelper (epcHelper);
\end{sphinxVerbatim}

the above step is necessary so that the LTE helper will trigger the
appropriate EPC configuration in correspondence with some important
configuration, such as when a new eNB or UE is added to the
simulation, or an EPS bearer is created. The EPC helper will
automatically take care of the necessary setup, such as S1 link
creation and S1 bearer setup. All this will be done without the
intervention of the user.

Calling \sphinxcode{\sphinxupquote{lteHelper\sphinxhyphen{}\textgreater{}SetEpcHelper (epcHelper)}} enables the use of
EPC, and has the side effect that any new \sphinxcode{\sphinxupquote{LteEnbRrc}} that is
created will have the \sphinxcode{\sphinxupquote{EpsBearerToRlcMapping}} attribute set to
\sphinxcode{\sphinxupquote{RLC\_UM\_ALWAYS}} instead of \sphinxcode{\sphinxupquote{RLC\_SM\_ALWAYS}} if the latter was
the default; otherwise, the attribute won’t be changed (e.g., if
you changed the default to \sphinxcode{\sphinxupquote{RLC\_AM\_ALWAYS}}, it won’t be touched).

It is to be noted that the \sphinxcode{\sphinxupquote{EpcHelper}} will also automatically
create the PGW node and configure it so that it can properly handle
traffic from/to the LTE radio access network.  Still,
you need to add some explicit code to connect the PGW to other
IPv4/IPv6 networks (e.g., the internet, another EPC). Here is a very
simple example about how to connect a single remote host (IPv4 type)
to the PGW via a point\sphinxhyphen{}to\sphinxhyphen{}point link:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}Node\PYGZgt{} pgw = epcHelper\PYGZhy{}\PYGZgt{}GetPgwNode ();

// Create a single RemoteHost
NodeContainer remoteHostContainer;
remoteHostContainer.Create (1);
Ptr\PYGZlt{}Node\PYGZgt{} remoteHost = remoteHostContainer.Get (0);
InternetStackHelper internet;
internet.Install (remoteHostContainer);

// Create the internet
PointToPointHelper p2ph;
p2ph.SetDeviceAttribute (\PYGZdq{}DataRate\PYGZdq{}, DataRateValue (DataRate (\PYGZdq{}100Gb/s\PYGZdq{})));
p2ph.SetDeviceAttribute (\PYGZdq{}Mtu\PYGZdq{}, UintegerValue (1500));
p2ph.SetChannelAttribute (\PYGZdq{}Delay\PYGZdq{}, TimeValue (Seconds (0.010)));
NetDeviceContainer internetDevices = p2ph.Install (pgw, remoteHost);
Ipv4AddressHelper ipv4h;
ipv4h.SetBase (\PYGZdq{}1.0.0.0\PYGZdq{}, \PYGZdq{}255.0.0.0\PYGZdq{});
Ipv4InterfaceContainer internetIpIfaces = ipv4h.Assign (internetDevices);
// interface 0 is localhost, 1 is the p2p device
Ipv4Address remoteHostAddr = internetIpIfaces.GetAddress (1);


Ipv4StaticRoutingHelper ipv4RoutingHelper;
Ptr\PYGZlt{}Ipv4StaticRouting\PYGZgt{} remoteHostStaticRouting;
remoteHostStaticRouting = ipv4RoutingHelper.GetStaticRouting (remoteHost\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}Ipv4\PYGZgt{} ());
remoteHostStaticRouting\PYGZhy{}\PYGZgt{}AddNetworkRouteTo (epcHelper\PYGZhy{}\PYGZgt{}GetEpcIpv4NetworkAddress (),
                                            Ipv4Mask (\PYGZdq{}255.255.0.0\PYGZdq{}), 1);
\end{sphinxVerbatim}

Now, you should go on and create LTE eNBs and UEs as explained in the
previous sections. You can of course configure other LTE aspects such
as pathloss and fading models. Right after you created the UEs, you
should also configure them for IP networking. This is done as
follows. We assume you have a container for UE and eNodeB nodes like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NodeContainer ueNodes;
NodeContainer enbNodes;
\end{sphinxVerbatim}

to configure an LTE\sphinxhyphen{}only simulation, you would then normally do
something like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NetDeviceContainer ueLteDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallUeDevice (ueNodes);
lteHelper\PYGZhy{}\PYGZgt{}Attach (ueLteDevs, enbLteDevs.Get (0));
\end{sphinxVerbatim}

in order to configure the UEs for IP networking, you just need to
additionally do like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
// we install the IP stack on the UEs
InternetStackHelper internet;
internet.Install (ueNodes);

// assign IP address to UEs
for (uint32\PYGZus{}t u = 0; u \PYGZlt{} ueNodes.GetN (); ++u)
  \PYGZob{}
    Ptr\PYGZlt{}Node\PYGZgt{} ue = ueNodes.Get (u);
    Ptr\PYGZlt{}NetDevice\PYGZgt{} ueLteDevice = ueLteDevs.Get (u);
    Ipv4InterfaceContainer ueIpIface;
    ueIpIface = epcHelper\PYGZhy{}\PYGZgt{}AssignUeIpv4Address (NetDeviceContainer (ueLteDevice));
    // set the default gateway for the UE
    Ptr\PYGZlt{}Ipv4StaticRouting\PYGZgt{} ueStaticRouting;
    ueStaticRouting = ipv4RoutingHelper.GetStaticRouting (ue\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}Ipv4\PYGZgt{} ());
    ueStaticRouting\PYGZhy{}\PYGZgt{}SetDefaultRoute (epcHelper\PYGZhy{}\PYGZgt{}GetUeDefaultGatewayAddress (), 1);
  \PYGZcb{}
\end{sphinxVerbatim}

The activation of bearers is done in a slightly different way with
respect to what done for an LTE\sphinxhyphen{}only simulation. First, the method
ActivateDataRadioBearer is not to be used when the EPC is
used. Second, when EPC is used, the default EPS bearer will be
activated automatically when you call \sphinxcode{\sphinxupquote{LteHelper::Attach ()}}. Third, if
you want to setup dedicated EPS bearer, you can do so using the method
\sphinxcode{\sphinxupquote{LteHelper::ActivateDedicatedEpsBearer ()}}. This method takes as a
parameter the Traffic Flow Template (TFT), which is a struct that
identifies the type of traffic that will be mapped to the dedicated
EPS bearer. Here is an example for how to setup a dedicated bearer
for an application at the UE communicating on port 1234:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}EpcTft\PYGZgt{} tft = Create\PYGZlt{}EpcTft\PYGZgt{} ();
EpcTft::PacketFilter pf;
pf.localPortStart = 1234;
pf.localPortEnd = 1234;
tft\PYGZhy{}\PYGZgt{}Add (pf);
lteHelper\PYGZhy{}\PYGZgt{}ActivateDedicatedEpsBearer (ueLteDevs,
                                       EpsBearer (EpsBearer::NGBR\PYGZus{}VIDEO\PYGZus{}TCP\PYGZus{}DEFAULT),
                                       tft);
\end{sphinxVerbatim}

you can of course use custom EpsBearer and EpcTft configurations,
please refer to the doxygen documentation for how to do it.

Finally, you can install applications on the LTE UE nodes that communicate
with remote applications over the internet. This is done following the
usual ns\sphinxhyphen{}3 procedures. Following our simple example with a single
remoteHost, here is how to setup downlink communication, with an
UdpClient application on the remote host, and a PacketSink on the LTE UE
(using the same variable names of the previous code snippets)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
uint16\PYGZus{}t dlPort = 1234;
PacketSinkHelper packetSinkHelper (\PYGZdq{}ns3::UdpSocketFactory\PYGZdq{},
                                   InetSocketAddress (Ipv4Address::GetAny (), dlPort));
ApplicationContainer serverApps = packetSinkHelper.Install (ue);
serverApps.Start (Seconds (0.01));
UdpClientHelper client (ueIpIface.GetAddress (0), dlPort);
ApplicationContainer clientApps = client.Install (remoteHost);
clientApps.Start (Seconds (0.01));
\end{sphinxVerbatim}

That’s all! You can now start your simulation as usual:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Simulator::Stop (Seconds (10.0));
Simulator::Run ();
\end{sphinxVerbatim}


\subsection{Using the EPC with emulation mode}
\label{\detokenize{lte-user:using-the-epc-with-emulation-mode}}
In the previous section we used PointToPoint links for the connection between the eNBs and the SGW (S1\sphinxhyphen{}U interface) and among eNBs (X2\sphinxhyphen{}U and X2\sphinxhyphen{}C interfaces). The LTE module supports using emulated links instead of PointToPoint links. This is achieved by just replacing the creation of \sphinxcode{\sphinxupquote{LteHelper}} and \sphinxcode{\sphinxupquote{EpcHelper}} with the following code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
Ptr\PYGZlt{}EmuEpcHelper\PYGZgt{}  epcHelper = CreateObject\PYGZlt{}EmuEpcHelper\PYGZgt{} ();
lteHelper\PYGZhy{}\PYGZgt{}SetEpcHelper (epcHelper);
epcHelper\PYGZhy{}\PYGZgt{}Initialize ();
\end{sphinxVerbatim}

The attributes \sphinxcode{\sphinxupquote{ns3::EmuEpcHelper::sgwDeviceName}} and \sphinxcode{\sphinxupquote{ns3::EmuEpcHelper::enbDeviceName}} are used to set the name of the devices used for transporting the S1\sphinxhyphen{}U, X2\sphinxhyphen{}U and X2\sphinxhyphen{}C interfaces at the SGW and eNB, respectively. We will now show how this is done in an example where we execute the example program \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}simple\sphinxhyphen{}epc\sphinxhyphen{}emu}} using two virtual ethernet interfaces.

First of all we build ns\sphinxhyphen{}3 appropriately:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} configure
./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}sudo \PYGZhy{}\PYGZhy{}enable\PYGZhy{}modules=lte,fd\PYGZhy{}net\PYGZhy{}device \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples

\PYGZsh{} build
./waf
\end{sphinxVerbatim}

Then we setup two virtual ethernet interfaces, and start wireshark to look at the traffic going through:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} note: you need to be root

\PYGZsh{} create two paired veth devices
ip link add name veth0 type veth peer name veth1
ip link show

\PYGZsh{} enable promiscuous mode
ip link set veth0 promisc on
ip link set veth1 promisc on

\PYGZsh{} bring interfaces up
ip link set veth0 up
ip link set veth1 up

\PYGZsh{} start wireshark and capture on veth0
wireshark \PYGZam{}
\end{sphinxVerbatim}

We can now run the example program with the simulated clock:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple\PYGZhy{}epc\PYGZhy{}emu \PYGZhy{}\PYGZhy{}command=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::sgwDeviceName=veth0
\PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::enbDeviceName=veth1\PYGZdq{}
\end{sphinxVerbatim}

Using wireshark, you should see ARP resolution first, then some GTP
packets exchanged both in uplink and downlink.

The default setting of the example program is 1 eNB and 1UE. You can change this via command line parameters, e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple\PYGZhy{}epc\PYGZhy{}emu \PYGZhy{}\PYGZhy{}command=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::sgwDeviceName=veth0
\PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::enbDeviceName=veth1 \PYGZhy{}\PYGZhy{}nEnbs=2 \PYGZhy{}\PYGZhy{}nUesPerEnb=2\PYGZdq{}
\end{sphinxVerbatim}

To get a list of the available parameters:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple\PYGZhy{}epc\PYGZhy{}emu \PYGZhy{}\PYGZhy{}command=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintHelp\PYGZdq{}
\end{sphinxVerbatim}

To run with the realtime clock: it turns out that the default debug
build is too slow for realtime. Softening the real time constraints
with the BestEffort mode is not a good idea: something can go wrong
(e.g., ARP can fail) and, if so, you won’t get any data packets out.
So you need a decent hardware and the optimized build with statically
linked modules:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf configure \PYGZhy{}d optimized \PYGZhy{}\PYGZhy{}enable\PYGZhy{}static \PYGZhy{}\PYGZhy{}enable\PYGZhy{}modules=lte \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples
\PYGZhy{}\PYGZhy{}enable\PYGZhy{}sudo
\end{sphinxVerbatim}

Then run the example program like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}simple\PYGZhy{}epc\PYGZhy{}emu \PYGZhy{}\PYGZhy{}command=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::sgwDeviceName=veth0
\PYGZhy{}\PYGZhy{}ns3::EmuEpcHelper::enbDeviceName=veth1
\PYGZhy{}\PYGZhy{}SimulatorImplementationType=ns3::RealtimeSimulatorImpl
\PYGZhy{}\PYGZhy{}ns3::RealtimeSimulatorImpl::SynchronizationMode=HardLimit\PYGZdq{}
\end{sphinxVerbatim}

note the HardLimit setting, which will cause the program to terminate
if it cannot keep up with real time.

The approach described in this section can be used with any type of
net device. For instance, \sphinxcite{lte-references:baldo2014} describes how it was used to
run an emulated LTE\sphinxhyphen{}EPC network over a real multi\sphinxhyphen{}layer packet\sphinxhyphen{}optical
transport network.


\subsection{Custom Backhaul}
\label{\detokenize{lte-user:custom-backhaul}}\label{\detokenize{lte-user:sec-custom-backhaul}}
In the previous sections, {\hyperref[\detokenize{lte-user:sec-evolved-packet-core}]{\sphinxcrossref{\DUrole{std,std-ref}{Evolved Packet Core (EPC)}}}}, we explained how to write a simulation
program using EPC with a predefined backhaul network between the RAN and the EPC. We used the
\sphinxcode{\sphinxupquote{PointToPointEpcHelper}}. This \sphinxcode{\sphinxupquote{EpcHelper}} creates point\sphinxhyphen{}to\sphinxhyphen{}point links between the eNBs and the SGW.

We now explain how to write a simulation program that allows the simulator user to create any kind
of backhaul network in the simulation program.

First of all, in addition to \sphinxcode{\sphinxupquote{LteHelper}}, you need to use the \sphinxcode{\sphinxupquote{NoBackhaulEpcHelper}} class, which
implements an EPC but without connecting the eNBs with the core network. It just creates the network
elements of the core network:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
Ptr\PYGZlt{}NoBackhaulEpcHelper\PYGZgt{} epcHelper = CreateObject\PYGZlt{}NoBackhaulEpcHelper\PYGZgt{} ();
\end{sphinxVerbatim}

Then, as usual, you need to tell the LTE helper that the EPC will be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetEpcHelper (epcHelper);
\end{sphinxVerbatim}

Now, you should create the backhaul network. Here we create point\sphinxhyphen{}to\sphinxhyphen{}point links as it is done
by the \sphinxcode{\sphinxupquote{PointToPointEpcHelper}}. We assume you have a container for eNB nodes like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NodeContainer enbNodes;
\end{sphinxVerbatim}

We get the SGW node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}Node\PYGZgt{} sgw = epcHelper\PYGZhy{}\PYGZgt{}GetSgwNode ();
\end{sphinxVerbatim}

And we connect every eNB from the container with the SGW with a point\sphinxhyphen{}to\sphinxhyphen{}point link. We also assign
IPv4 addresses to the interfaces of eNB and SGW with \sphinxcode{\sphinxupquote{s1uIpv4AddressHelper.Assign (sgwEnbDevices)}}
and finally we tell the EpcHelper that this \sphinxcode{\sphinxupquote{enb}} has a new S1 interface with
\sphinxcode{\sphinxupquote{epcHelper\sphinxhyphen{}\textgreater{}AddS1Interface (enb, enbS1uAddress, sgwS1uAddress)}}, where \sphinxcode{\sphinxupquote{enbS1uAddress}} and
\sphinxcode{\sphinxupquote{sgwS1uAddress}} are the IPv4 addresses of the eNB and the SGW, respectively:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ipv4AddressHelper s1uIpv4AddressHelper;

// Create networks of the S1 interfaces
s1uIpv4AddressHelper.SetBase (\PYGZdq{}10.0.0.0\PYGZdq{}, \PYGZdq{}255.255.255.252\PYGZdq{});

for (uint16\PYGZus{}t i = 0; i \PYGZlt{} enbNodes.GetN (); ++i)
  \PYGZob{}
    Ptr\PYGZlt{}Node\PYGZgt{} enb = enbNodes.Get (i);

    // Create a point to point link between the eNB and the SGW with
    // the corresponding new NetDevices on each side
    PointToPointHelper p2ph;
    DataRate s1uLinkDataRate = DataRate (\PYGZdq{}10Gb/s\PYGZdq{});
    uint16\PYGZus{}t s1uLinkMtu = 2000;
    Time s1uLinkDelay = Time (0);
    p2ph.SetDeviceAttribute (\PYGZdq{}DataRate\PYGZdq{}, DataRateValue (s1uLinkDataRate));
    p2ph.SetDeviceAttribute (\PYGZdq{}Mtu\PYGZdq{}, UintegerValue (s1uLinkMtu));
    p2ph.SetChannelAttribute (\PYGZdq{}Delay\PYGZdq{}, TimeValue (s1uLinkDelay));
    NetDeviceContainer sgwEnbDevices = p2ph.Install (sgw, enb);

    Ipv4InterfaceContainer sgwEnbIpIfaces = s1uIpv4AddressHelper.Assign (sgwEnbDevices);
    s1uIpv4AddressHelper.NewNetwork ();

    Ipv4Address sgwS1uAddress = sgwEnbIpIfaces.GetAddress (0);
    Ipv4Address enbS1uAddress = sgwEnbIpIfaces.GetAddress (1);

    // Create S1 interface between the SGW and the eNB
    epcHelper\PYGZhy{}\PYGZgt{}AddS1Interface (enb, enbS1uAddress, sgwS1uAddress);
  \PYGZcb{}
\end{sphinxVerbatim}

This is just an example how to create a custom backhaul network. In this other example, we connect
all eNBs and the SGW to the same CSMA network:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
// Create networks of the S1 interfaces
s1uIpv4AddressHelper.SetBase (\PYGZdq{}10.0.0.0\PYGZdq{}, \PYGZdq{}255.255.255.0\PYGZdq{});

NodeContainer sgwEnbNodes;
sgwEnbNodes.Add (sgw);
sgwEnbNodes.Add (enbNodes);

CsmaHelper csmah;
NetDeviceContainer sgwEnbDevices = csmah.Install (sgwEnbNodes);
Ptr\PYGZlt{}NetDevice\PYGZgt{} sgwDev = sgwEnbDevices.Get (0);

Ipv4InterfaceContainer sgwEnbIpIfaces = s1uIpv4AddressHelper.Assign (sgwEnbDevices);
Ipv4Address sgwS1uAddress = sgwEnbIpIfaces.GetAddress (0);

for (uint16\PYGZus{}t i = 0; i \PYGZlt{} enbNodes.GetN (); ++i)
  \PYGZob{}
    Ptr\PYGZlt{}Node\PYGZgt{} enb = enbNodes.Get (i);
    Ipv4Address enbS1uAddress = sgwEnbIpIfaces.GetAddress (i + 1);

    // Create S1 interface between the SGW and the eNB
    epcHelper\PYGZhy{}\PYGZgt{}AddS1Interface (enb, enbS1uAddress, sgwS1uAddress);
  \PYGZcb{}
\end{sphinxVerbatim}

As you can see, apart from how you create the backhaul network, i.e. the point\sphinxhyphen{}to\sphinxhyphen{}point links or
the CSMA network, the important point is to tell the \sphinxcode{\sphinxupquote{EpcHelper}} that an \sphinxcode{\sphinxupquote{eNB}} has a new S1 interface.

Now, you should continue configuring your simulation program as it is explained in
{\hyperref[\detokenize{lte-user:sec-evolved-packet-core}]{\sphinxcrossref{\DUrole{std,std-ref}{Evolved Packet Core (EPC)}}}} subsection. This configuration includes: the internet, installing the LTE eNBs
and possibly configuring other LTE aspects, installing the LTE UEs and configuring them as IP nodes,
activation of the dedicated EPS bearers and installing applications on the LTE UEs and on the remote hosts.


\subsection{Network Attachment}
\label{\detokenize{lte-user:network-attachment}}\label{\detokenize{lte-user:sec-network-attachment}}
As shown in the basic example in section {\hyperref[\detokenize{lte-user:sec-basic-simulation-program}]{\sphinxcrossref{\DUrole{std,std-ref}{Basic simulation program}}}},
attaching a UE to an eNodeB is done by calling \sphinxcode{\sphinxupquote{LteHelper::Attach}} function.

There are 2 possible ways of network attachment. The first method is the
\sphinxstyleemphasis{“manual”} one, while the second one has a more \sphinxstyleemphasis{“automatic”} sense on it. Each
of them will be covered in this section.


\subsubsection{Manual attachment}
\label{\detokenize{lte-user:manual-attachment}}
This method uses the \sphinxcode{\sphinxupquote{LteHelper::Attach}} function mentioned above. It has been
the only available network attachment method in earlier versions of LTE module.
It is typically invoked before the simulation begins:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}Attach (ueDevs, enbDev); // attach one or more UEs to a single eNodeB
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{LteHelper::InstallEnbDevice}} and \sphinxcode{\sphinxupquote{LteHelper::InstallUeDevice}} functions
must have been called before attaching. In an EPC\sphinxhyphen{}enabled simulation, it is also
required to have IPv4/IPv6 properly pre\sphinxhyphen{}installed in the UE.

This method is very simple, but requires you to know exactly which UE belongs to
to which eNodeB before the simulation begins. This can be difficult when the UE
initial position is randomly determined by the simulation script.

One may choose the distance between the UE and the eNodeB as a criterion for
selecting the appropriate cell. It is quite simple (at least from the
simulator’s point of view) and sometimes practical. But it is important to note
that sometimes distance does not make a single correct criterion. For instance,
the eNodeB antenna directivity should be considered as well. Besides that, one
should also take into account the channel condition, which might be fluctuating
if there is fading or shadowing in effect. In these kind of cases, network
attachment should not be based on distance alone.

In real life, UE will automatically evaluate certain criteria and select the
best cell to attach to, without manual intervention from the user. Obviously
this is not the case in this \sphinxcode{\sphinxupquote{LteHelper::Attach}} function. The other network
attachment method uses more \sphinxstyleemphasis{“automatic”} approach to network attachment, as
will be described next.


\subsubsection{Automatic attachment using Idle mode cell selection procedure}
\label{\detokenize{lte-user:automatic-attachment-using-idle-mode-cell-selection-procedure}}
The strength of the received signal is the standard criterion used for selecting
the best cell to attach to. The use of this criterion is implemented in the
\sphinxtitleref{initial cell selection} process, which can be invoked by calling another
version of the \sphinxcode{\sphinxupquote{LteHelper::Attach}} function, as shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}Attach (ueDevs); // attach one or more UEs to a strongest cell
\end{sphinxVerbatim}

The difference with the manual method is that the destination eNodeB is not
specified. The procedure will find the best cell for the UEs, based on several
criteria, including the strength of the received signal (RSRP).

After the method is called, the UE will spend some time to measure the
neighbouring cells, and then attempt to attach to the best one. More details can
be found in section {\hyperref[\detokenize{lte-design:sec-initial-cell-selection}]{\sphinxcrossref{\DUrole{std,std-ref}{Initial Cell Selection}}}} of the Design
Documentation.

It is important to note that this method only works in EPC\sphinxhyphen{}enabled simulations.
LTE\sphinxhyphen{}only simulations must resort to manual attachment method.


\subsubsection{Closed Subscriber Group}
\label{\detokenize{lte-user:closed-subscriber-group}}
An interesting use case of the initial cell selection process is to setup a
simulation environment with Closed Subscriber Group (CSG).

For example, a certain eNodeB, typically a smaller version such as femtocell,
might belong to a private owner (e.g. a household or business), allowing access
only to some UEs which have been previously registered by the owner. The eNodeB
and the registered UEs altogether form a CSG.

The access restriction can be simulated by “labeling” the CSG members with the
same CSG ID. This is done through the attributes in both eNodeB and UE, for
example using the following \sphinxcode{\sphinxupquote{LteHelper}} functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
// label the following eNodeBs with CSG identity of 1 and CSG indication enabled
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}CsgId\PYGZdq{}, UintegerValue (1));
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}CsgIndication\PYGZdq{}, BooleanValue (true));

// label one or more UEs with CSG identity of 1
lteHelper\PYGZhy{}\PYGZgt{}SetUeDeviceAttribute (\PYGZdq{}CsgId\PYGZdq{}, UintegerValue (1));

// install the eNodeBs and UEs
NetDeviceContainer csgEnbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (csgEnbNodes);
NetDeviceContainer csgUeDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallUeDevice (csgUeNodes);
\end{sphinxVerbatim}

Then enable the initial cell selection procedure on the UEs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}Attach (csgUeDevs);
\end{sphinxVerbatim}

This is necessary because the CSG restriction only works with automatic method
of network attachment, but not in the manual method.

Note that setting the CSG indication of an eNodeB as false (the default value)
will disable the restriction, i.e., any UEs can connect to this eNodeB.


\subsection{Configure UE measurements}
\label{\detokenize{lte-user:configure-ue-measurements}}\label{\detokenize{lte-user:sec-configure-ue-measurements}}
The active UE measurement configuration in a simulation is dictated by the
selected so called “consumers”, such as handover algorithm. Users may add their
own configuration into action, and there are several ways to do so:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
direct configuration in eNodeB RRC entity;

\item {} 
configuring existing handover algorithm; and

\item {} 
developing a new handover algorithm.

\end{enumerate}

This section will cover the first method only. The second method is covered in
{\hyperref[\detokenize{lte-user:sec-automatic-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{Automatic handover trigger}}}}, while the third method is explained in length in
Section {\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}} of the Design Documentation.

Direct configuration in eNodeB RRC works as follows. User begins by creating a
new \sphinxcode{\sphinxupquote{LteRrcSap::ReportConfigEutra}} instance and pass it to the
\sphinxcode{\sphinxupquote{LteEnbRrc::AddUeMeasReportConfig}} function. The function will return the
\sphinxcode{\sphinxupquote{measId}} (measurement identity) which is a unique reference of the
configuration in the eNodeB instance. This function must be called before the
simulation begins. The measurement configuration will be active in all UEs
attached to the eNodeB throughout the duration of the simulation. During the
simulation, user can capture the measurement reports produced by the UEs by
listening to the existing \sphinxcode{\sphinxupquote{LteEnbRrc::RecvMeasurementReport}} trace source.

The structure \sphinxtitleref{ReportConfigEutra} is in accord with 3GPP specification.
Definition of the structure and each member field can be found in Section 6.3.5
of \sphinxcite{lte-references:ts36331}.

The code sample below configures Event A1 RSRP measurement to every eNodeB
within the container \sphinxcode{\sphinxupquote{devs}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
LteRrcSap::ReportConfigEutra config;
config.eventId = LteRrcSap::ReportConfigEutra::EVENT\PYGZus{}A1;
config.threshold1.choice = LteRrcSap::ThresholdEutra::THRESHOLD\PYGZus{}RSRP;
config.threshold1.range = 41;
config.triggerQuantity = LteRrcSap::ReportConfigEutra::RSRP;
config.reportInterval = LteRrcSap::ReportConfigEutra::MS480;

std::vector\PYGZlt{}uint8\PYGZus{}t\PYGZgt{} measIdList;

NetDeviceContainer::Iterator it;
for (it = devs.Begin (); it != devs.End (); it++)
\PYGZob{}
  Ptr\PYGZlt{}NetDevice\PYGZgt{} dev = *it;
  Ptr\PYGZlt{}LteEnbNetDevice\PYGZgt{} enbDev = dev\PYGZhy{}\PYGZgt{}GetObject\PYGZlt{}LteEnbNetDevice\PYGZgt{} ();
  Ptr\PYGZlt{}LteEnbRrc\PYGZgt{} enbRrc = enbDev\PYGZhy{}\PYGZgt{}GetRrc ();

  uint8\PYGZus{}t measId = enbRrc\PYGZhy{}\PYGZgt{}AddUeMeasReportConfig (config);
  measIdList.push\PYGZus{}back (measId); // remember the measId created

  enbRrc\PYGZhy{}\PYGZgt{}TraceConnect (\PYGZdq{}RecvMeasurementReport\PYGZdq{},
                        \PYGZdq{}context\PYGZdq{},
                        MakeCallback (\PYGZam{}RecvMeasurementReportCallback));
\PYGZcb{}
\end{sphinxVerbatim}

Note that thresholds are expressed as range. In the example above, the range 41
for RSRP corresponds to \sphinxhyphen{}100 dBm. The conversion from and to the range format is
due to Section 9.1.4 and 9.1.7 of \sphinxcite{lte-references:ts36133}. The \sphinxcode{\sphinxupquote{EutranMeasurementMapping}}
class has several static functions that can be used for this purpose.

The corresponding callback function would have a definition similar as below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void
RecvMeasurementReportCallback (std::string context,
                               uint64\PYGZus{}t imsi,
                               uint16\PYGZus{}t cellId,
                               uint16\PYGZus{}t rnti,
                               LteRrcSap::MeasurementReport measReport);
\end{sphinxVerbatim}

This method will register the callback function as a consumer of UE
measurements. In the case where there are more than one consumers in the
simulation (e.g. handover algorithm), the measurements intended for other
consumers will also be captured by this callback function. Users may utilize the
the \sphinxcode{\sphinxupquote{measId}} field, contained within the \sphinxcode{\sphinxupquote{LteRrcSap::MeasurementReport}}
argument of the callback function, to tell which measurement configuration has
triggered the report.

In general, this mechanism prevents one consumer to unknowingly intervene with
another consumer’s reporting configuration.

Note that only the reporting configuration part (i.e.
\sphinxcode{\sphinxupquote{LteRrcSap::ReportConfigEutra}}) of the UE measurements parameter is open for
consumers to configure, while the other parts are kept hidden. The
intra\sphinxhyphen{}frequency limitation is the main motivation behind this API implementation
decision:
\begin{itemize}
\item {} 
there is only one, unambiguous and definitive \sphinxstyleemphasis{measurement object}, thus
there is no need to configure it;

\item {} 
\sphinxstyleemphasis{measurement identities} are kept hidden because of the fact that there is
one\sphinxhyphen{}to\sphinxhyphen{}one mapping between reporting configuration and measurement identity,
thus a new measurement identity is set up automatically when a new reporting
configuration is created;

\item {} 
\sphinxstyleemphasis{quantity configuration} is configured elsewhere, see
{\hyperref[\detokenize{lte-design:sec-performing-measurements}]{\sphinxcrossref{\DUrole{std,std-ref}{Performing measurements}}}}; and

\item {} 
\sphinxstyleemphasis{measurement gaps} are not supported, because it is only applicable for
inter\sphinxhyphen{}frequency settings;

\end{itemize}


\subsection{X2\sphinxhyphen{}based handover}
\label{\detokenize{lte-user:x2-based-handover}}\label{\detokenize{lte-user:sec-x2-based-handover}}
As defined by 3GPP, handover is a procedure for changing the serving cell of a
UE in CONNECTED mode. The two eNodeBs involved in the process are typically
called the \sphinxstyleemphasis{source eNodeB} and the \sphinxstyleemphasis{target eNodeB}.

In order to enable the execution of X2\sphinxhyphen{}based handover in simulation, there are
two requirements that must be met. Firstly, EPC must be enabled in the
simulation (see {\hyperref[\detokenize{lte-user:sec-evolved-packet-core}]{\sphinxcrossref{\DUrole{std,std-ref}{Evolved Packet Core (EPC)}}}}).

Secondly, an X2 interface must be configured between the two eNodeBs, which
needs to be done explicitly within the simulation program:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}AddX2Interface (enbNodes);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{enbNodes}} is a \sphinxcode{\sphinxupquote{NodeContainer}} that contains the two eNodeBs between
which the X2 interface is to be configured. If the container has more than two
eNodeBs, the function will create an X2 interface between every pair of eNodeBs
in the container.

Lastly, the target eNodeB must be configured as “open” to X2 HANDOVER REQUEST.
Every eNodeB is open by default, so no extra instruction is needed in most
cases. However, users may set the eNodeB to “closed” by setting the boolean
attribute \sphinxcode{\sphinxupquote{LteEnbRrc::AdmitHandoverRequest}} to \sphinxtitleref{false}. As an example, you can
run the \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}x2\sphinxhyphen{}handover}} program and setting the attribute in this way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NS\PYGZus{}LOG=EpcX2:LteEnbRrc ./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}x2\PYGZhy{}handover \PYGZhy{}\PYGZhy{}command=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}ns3::LteEnbRrc::AdmitHandoverRequest=false\PYGZdq{}
\end{sphinxVerbatim}

After the above three requirements are fulfilled, the handover procedure can be
triggered manually or automatically. Each will be presented in the following
subsections.


\subsubsection{Manual handover trigger}
\label{\detokenize{lte-user:manual-handover-trigger}}
Handover event can be triggered “manually” within the simulation program by
scheduling an explicit handover event. The \sphinxcode{\sphinxupquote{LteHelper}} object provides a
convenient method for the scheduling of a handover event. As an example, let us
assume that \sphinxcode{\sphinxupquote{ueLteDevs}} is a \sphinxcode{\sphinxupquote{NetDeviceContainer}} that contains the UE that
is to be handed over, and that \sphinxcode{\sphinxupquote{enbLteDevs}} is another \sphinxcode{\sphinxupquote{NetDeviceContainer}}
that contains the source and the target eNB. Then, a handover at 0.1s can be
scheduled like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}HandoverRequest (Seconds (0.100),
                            ueLteDevs.Get (0),
                            enbLteDevs.Get (0),
                            enbLteDevs.Get (1));
\end{sphinxVerbatim}

Note that the UE needs to be already connected to the source eNB, otherwise the
simulation will terminate with an error message.

For an example with full source code, please refer to the \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}x2\sphinxhyphen{}handover}}
example program.


\subsubsection{Automatic handover trigger}
\label{\detokenize{lte-user:automatic-handover-trigger}}\label{\detokenize{lte-user:sec-automatic-handover}}
Handover procedure can also be triggered “automatically” by the serving eNodeB
of the UE. The logic behind the trigger depends on the handover algorithm
currently active in the eNodeB RRC entity. Users may select and configure the
handover algorithm that will be used in the simulation, which will be explained
shortly in this section. Users may also opt to write their own implementation of
handover algorithm, as described in Section {\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}} of the
Design Documentation.

Selecting a handover algorithm is done via the \sphinxcode{\sphinxupquote{LteHelper}} object and its
\sphinxcode{\sphinxupquote{SetHandoverAlgorithmType}} method as shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmType (\PYGZdq{}ns3::A2A4RsrqHandoverAlgorithm\PYGZdq{});
\end{sphinxVerbatim}

The selected handover algorithm may also provide several configurable
attributes, which can be set as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmAttribute (\PYGZdq{}ServingCellThreshold\PYGZdq{},
                                          UintegerValue (30));
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmAttribute (\PYGZdq{}NeighbourCellOffset\PYGZdq{},
                                          UintegerValue (1));
\end{sphinxVerbatim}

Three options of handover algorithm are included in the LTE module. The
\sphinxstyleemphasis{A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ} handover algorithm (named as \sphinxcode{\sphinxupquote{ns3::A2A4RsrqHandoverAlgorithm}}) is
the default option, and the usage has already been shown above.

Another option is the \sphinxstyleemphasis{strongest cell} handover algorithm (named as
\sphinxcode{\sphinxupquote{ns3::A3RsrpHandoverAlgorithm}}), which can be selected and configured by the
following code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmType (\PYGZdq{}ns3::A3RsrpHandoverAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmAttribute (\PYGZdq{}Hysteresis\PYGZdq{},
                                          DoubleValue (3.0));
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmAttribute (\PYGZdq{}TimeToTrigger\PYGZdq{},
                                          TimeValue (MilliSeconds (256)));
\end{sphinxVerbatim}

The last option is a special one, called the \sphinxstyleemphasis{no\sphinxhyphen{}op} handover algorithm, which
basically disables automatic handover trigger. This is useful for example in
cases where manual handover trigger need an exclusive control of all handover
decision. It does not have any configurable attributes. The usage is as
follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetHandoverAlgorithmType (\PYGZdq{}ns3::NoOpHandoverAlgorithm\PYGZdq{});
\end{sphinxVerbatim}

For more information on each handover algorithm’s decision policy and their
attributes, please refer to their respective subsections in Section
{\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}} of the Design Documentation.

Finally, the \sphinxcode{\sphinxupquote{InstallEnbDevice}} function of \sphinxcode{\sphinxupquote{LteHelper}} will instantiate one
instance of the selected handover algorithm for each eNodeB device. In other
words, make sure to select the right handover algorithm before finalizing it in
the following line of code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NetDeviceContainer enbLteDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes);
\end{sphinxVerbatim}

Example with full source code of using automatic handover trigger can be found
in the \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}x2\sphinxhyphen{}handover\sphinxhyphen{}measures}} example program.


\subsubsection{Tuning simulation with handover}
\label{\detokenize{lte-user:tuning-simulation-with-handover}}\label{\detokenize{lte-user:sec-tuning-handover-simulation}}
As mentioned in the Design Documentation, the current implementation of handover
model may produce unpredicted behaviour when handover failure occurs. This
subsection will focus on the steps that should be taken into account by users
if they plan to use handover in their simulations.

The major cause of handover failure that we will tackle is the error in
transmitting handover\sphinxhyphen{}related signaling messages during the execution of a
handover procedure. As apparent from the Figure
{\hyperref[\detokenize{lte-design:fig-x2-based-handover-seq-diagram}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram of the X2\sphinxhyphen{}based handover}}}} from the Design Documentation, there
are many of them and they use different interfaces and protocols. For the sake
of simplicity, we can safely assume that the X2 interface (between the source
eNodeB and the target eNodeB) and the S1 interface (between the target eNodeB
and the SGW/PGW) are quite stable. Therefore we will focus our attention to the
RRC protocol (between the UE and the eNodeBs) and the Random Access procedure,
which are normally transmitted through the air and susceptible to degradation of
channel condition.

A general tips to reduce transmission error is to \sphinxstyleemphasis{ensure high enough SINR}
level in every UE. This can be done by a proper planning of the network topology
that \sphinxstyleemphasis{minimizes network coverage hole}. If the topology has a known coverage
hole, then the UE should be configured not to venture to that area.

Another approach to keep in mind is to \sphinxstyleemphasis{avoid too\sphinxhyphen{}late handovers}. In other
words, handover should happen before the UE’s SINR becomes too low, otherwise
the UE may fail to receive the handover command from the source eNodeB. Handover
algorithms have the means to control how early or late a handover decision is
made. For example, A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm can be configured with a higher
threshold to make it decide a handover earlier. Similarly, smaller hysteresis
and/or shorter time\sphinxhyphen{}to\sphinxhyphen{}trigger in the strongest cell handover algorithm
typically results in earlier handovers. In order to find the right values for
these parameters, one of the factors that should be considered is the UE
movement speed. Generally, a faster moving UE requires the handover to be
executed earlier. Some research work have suggested recommended values, such as
in \sphinxcite{lte-references:lee2010}.

The above tips should be enough in normal simulation uses, but in the case some
special needs arise then an extreme measure can be taken into consideration.
For instance, users may consider \sphinxstyleemphasis{disabling the channel error models}. This will
ensure that all handover\sphinxhyphen{}related signaling messages will be transmitted
successfully, regardless of distance and channel condition. However, it will
also affect all other data or control packets not related to handover, which may
be an unwanted side effect. Otherwise, it can be done as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteSpectrumPhy::CtrlErrorModelEnabled\PYGZdq{}, BooleanValue (false));
Config::SetDefault (\PYGZdq{}ns3::LteSpectrumPhy::DataErrorModelEnabled\PYGZdq{}, BooleanValue (false));
\end{sphinxVerbatim}

By using the above code, we disable the error model in both control and data
channels and in both directions (downlink and uplink). This is necessary because
handover\sphinxhyphen{}related signaling messages are transmitted using these channels. An
exception is when the simulation uses the ideal RRC protocol. In this case, only
the Random Access procedure is left to be considered. The procedure consists of
control messages, therefore we only need to disable the control channel’s error
model.


\subsubsection{Handover traces}
\label{\detokenize{lte-user:handover-traces}}\label{\detokenize{lte-user:sec-handover-traces}}
The RRC model, in particular the \sphinxcode{\sphinxupquote{LteEnbRrc}} and \sphinxcode{\sphinxupquote{LteUeRrc}}
objects, provide some useful traces which can be hooked up to some
custom functions so that they are called upon start and end of the
handover execution phase at both the UE and eNB side. As an example,
in your simulation program you can declare the following methods:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void
NotifyHandoverStartUe (std::string context,
                       uint64\PYGZus{}t imsi,
                       uint16\PYGZus{}t cellId,
                       uint16\PYGZus{}t rnti,
                       uint16\PYGZus{}t targetCellId)
\PYGZob{}
  std::cout \PYGZlt{}\PYGZlt{} Simulator::Now ().GetSeconds () \PYGZlt{}\PYGZlt{} \PYGZdq{} \PYGZdq{} \PYGZlt{}\PYGZlt{} context
            \PYGZlt{}\PYGZlt{} \PYGZdq{} UE IMSI \PYGZdq{} \PYGZlt{}\PYGZlt{} imsi
            \PYGZlt{}\PYGZlt{} \PYGZdq{}: previously connected to CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} cellId
            \PYGZlt{}\PYGZlt{} \PYGZdq{} with RNTI \PYGZdq{} \PYGZlt{}\PYGZlt{} rnti
            \PYGZlt{}\PYGZlt{} \PYGZdq{}, doing handover to CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} targetCellId
            \PYGZlt{}\PYGZlt{} std::endl;
\PYGZcb{}

void
NotifyHandoverEndOkUe (std::string context,
                       uint64\PYGZus{}t imsi,
                       uint16\PYGZus{}t cellId,
                       uint16\PYGZus{}t rnti)
\PYGZob{}
  std::cout \PYGZlt{}\PYGZlt{} Simulator::Now ().GetSeconds () \PYGZlt{}\PYGZlt{} \PYGZdq{} \PYGZdq{} \PYGZlt{}\PYGZlt{} context
            \PYGZlt{}\PYGZlt{} \PYGZdq{} UE IMSI \PYGZdq{} \PYGZlt{}\PYGZlt{} imsi
            \PYGZlt{}\PYGZlt{} \PYGZdq{}: successful handover to CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} cellId
            \PYGZlt{}\PYGZlt{} \PYGZdq{} with RNTI \PYGZdq{} \PYGZlt{}\PYGZlt{} rnti
            \PYGZlt{}\PYGZlt{} std::endl;
\PYGZcb{}

void
NotifyHandoverStartEnb (std::string context,
                        uint64\PYGZus{}t imsi,
                        uint16\PYGZus{}t cellId,
                        uint16\PYGZus{}t rnti,
                        uint16\PYGZus{}t targetCellId)
\PYGZob{}
  std::cout \PYGZlt{}\PYGZlt{} Simulator::Now ().GetSeconds () \PYGZlt{}\PYGZlt{} \PYGZdq{} \PYGZdq{} \PYGZlt{}\PYGZlt{} context
            \PYGZlt{}\PYGZlt{} \PYGZdq{} eNB CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} cellId
            \PYGZlt{}\PYGZlt{} \PYGZdq{}: start handover of UE with IMSI \PYGZdq{} \PYGZlt{}\PYGZlt{} imsi
            \PYGZlt{}\PYGZlt{} \PYGZdq{} RNTI \PYGZdq{} \PYGZlt{}\PYGZlt{} rnti
            \PYGZlt{}\PYGZlt{} \PYGZdq{} to CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} targetCellId
            \PYGZlt{}\PYGZlt{} std::endl;
\PYGZcb{}

void
NotifyHandoverEndOkEnb (std::string context,
                        uint64\PYGZus{}t imsi,
                        uint16\PYGZus{}t cellId,
                        uint16\PYGZus{}t rnti)
\PYGZob{}
  std::cout \PYGZlt{}\PYGZlt{} Simulator::Now ().GetSeconds () \PYGZlt{}\PYGZlt{} \PYGZdq{} \PYGZdq{} \PYGZlt{}\PYGZlt{} context
            \PYGZlt{}\PYGZlt{} \PYGZdq{} eNB CellId \PYGZdq{} \PYGZlt{}\PYGZlt{} cellId
            \PYGZlt{}\PYGZlt{} \PYGZdq{}: completed handover of UE with IMSI \PYGZdq{} \PYGZlt{}\PYGZlt{} imsi
            \PYGZlt{}\PYGZlt{} \PYGZdq{} RNTI \PYGZdq{} \PYGZlt{}\PYGZlt{} rnti
            \PYGZlt{}\PYGZlt{} std::endl;
\PYGZcb{}
\end{sphinxVerbatim}

Then, you can hook up these methods to the corresponding trace sources
like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::Connect (\PYGZdq{}/NodeList/*/DeviceList/*/LteEnbRrc/HandoverStart\PYGZdq{},
                 MakeCallback (\PYGZam{}NotifyHandoverStartEnb));
Config::Connect (\PYGZdq{}/NodeList/*/DeviceList/*/LteUeRrc/HandoverStart\PYGZdq{},
                 MakeCallback (\PYGZam{}NotifyHandoverStartUe));
Config::Connect (\PYGZdq{}/NodeList/*/DeviceList/*/LteEnbRrc/HandoverEndOk\PYGZdq{},
                 MakeCallback (\PYGZam{}NotifyHandoverEndOkEnb));
Config::Connect (\PYGZdq{}/NodeList/*/DeviceList/*/LteUeRrc/HandoverEndOk\PYGZdq{},
                 MakeCallback (\PYGZam{}NotifyHandoverEndOkUe));
\end{sphinxVerbatim}

The example program \sphinxcode{\sphinxupquote{src/lte/examples/lena\sphinxhyphen{}x2\sphinxhyphen{}handover.cc}}
illustrates how the all above instructions can be integrated in a
simulation program. You can run the program like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}x2\PYGZhy{}handover
\end{sphinxVerbatim}

and it will output the messages printed by the custom handover trace
hooks. In order additionally visualize some meaningful logging
information, you can run the program like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
NS\PYGZus{}LOG=LteEnbRrc:LteUeRrc:EpcX2 ./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}x2\PYGZhy{}handover
\end{sphinxVerbatim}


\subsection{Frequency Reuse Algorithms}
\label{\detokenize{lte-user:frequency-reuse-algorithms}}
In this section we will describe how to use Frequency Reuse Algorithms
in eNb within LTE simulations.
There are two possible ways of configuration. The first approach is the
“manual” one, it requires more parameters to be configured, but allow user
to configure FR algorithm as he/she needs. The second approach is more
“automatic”. It is very convenient, because is the same for each FR algorithm,
so user can switch FR algorithm very quickly by changing only type of FR
algorithm. One drawback is that “automatic” approach uses only limited set
of configurations for each algorithm, what make it less flexible, but is
sufficient for most of cases.

These two approaches will be described more in following sub\sphinxhyphen{}section.

If user do not configure Frequency Reuse algorithm, default one
(i.e. LteFrNoOpAlgorithm) is installed in eNb. It acts as if FR
algorithm was disabled.

One thing that should be mentioned is that most of implemented FR algorithms work with
cell bandwidth greater or equal than 15 RBs. This limitation is caused by requirement
that at least three continuous RBs have to be assigned to UE for transmission.


\subsubsection{Manual configuration}
\label{\detokenize{lte-user:manual-configuration}}
Frequency reuse algorithm can be configured “manually” within the simulation
program by setting type of FR algorithm and all its attributes. Currently,
seven FR algorithms are implemented:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrNoOpAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrHardAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrStrictAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFrSoftAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrSoftAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrEnhancedAlgorithm}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::LteFfrDistributedAlgorithm}}

\end{itemize}

Selecting a FR algorithm is done via the \sphinxcode{\sphinxupquote{LteHelper}} object and
its \sphinxcode{\sphinxupquote{SetFfrAlgorithmType}} method as shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ptr\PYGZlt{}LteHelper\PYGZgt{} lteHelper = CreateObject\PYGZlt{}LteHelper\PYGZgt{} ();
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType (\PYGZdq{}ns3::LteFrHardAlgorithm\PYGZdq{});
\end{sphinxVerbatim}

Each implemented FR algorithm provide several configurable attributes. Users do
not have to care about UL and DL bandwidth configuration, because it is done
automatically during cell configuration. To change bandwidth for FR algorithm,
configure required values for \sphinxcode{\sphinxupquote{LteEnbNetDevice}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
uint8\PYGZus{}t bandwidth = 100;
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}DlBandwidth\PYGZdq{}, UintegerValue (bandwidth));
lteHelper\PYGZhy{}\PYGZgt{}SetEnbDeviceAttribute (\PYGZdq{}UlBandwidth\PYGZdq{}, UintegerValue (bandwidth));
\end{sphinxVerbatim}

Now, each FR algorithms configuration will be described.


\paragraph{Hard Frequency Reuse Algorithm}
\label{\detokenize{lte-user:hard-frequency-reuse-algorithm}}
As described in Section {\hyperref[\detokenize{lte-design:sec-fr-hard-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Hard Frequency Reuse}}}} of the Design Documentation
\sphinxcode{\sphinxupquote{ns3::LteFrHardAlgorithm}} uses one sub\sphinxhyphen{}band. To configure this sub\sphinxhyphen{}band user need
to specify offset and bandwidth for DL and UL in number of RBs.

Hard Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{DlSubBandOffset}}: Downlink Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlSubBandwidth}}: Downlink Transmission SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlSubBandOffset}}: Uplink Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlSubBandwidth}}: Uplink Transmission SubBandwidth Configuration in number of Resource Block Groups

\end{itemize}

Example configuration of LteFrHardAlgorithm can be done in following way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType (\PYGZdq{}ns3::LteFrHardAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlSubBandOffset\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlSubBandwidth\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlSubBandOffset\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlSubBandwidth\PYGZdq{}, UintegerValue (8));
NetDeviceContainer enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes.Get(0));
\end{sphinxVerbatim}

Above example allow eNB to use only RBs from 8 to 16 in DL and UL, while entire cell
bandwidth is 25.


\paragraph{Strict Frequency Reuse Algorithm}
\label{\detokenize{lte-user:strict-frequency-reuse-algorithm}}
Strict Frequency Reuse Algorithm uses two sub\sphinxhyphen{}bands: one common for each cell and one
private. There is also RSRQ threshold, which is needed to decide within which sub\sphinxhyphen{}band
UE should be served. Moreover the power transmission in these sub\sphinxhyphen{}bands can be different.

Strict Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{UlCommonSubBandwidth}}: Uplink Common SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandOffset}}: Uplink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandwidth}}: Uplink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlCommonSubBandwidth}}: Downlink Common SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandOffset}}: Downlink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandwidth}}: Downlink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{RsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{CenterPowerOffset}}: PdschConfigDedicated::Pa value for center sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgePowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in center area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in edge area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

Example below allow eNB to use RBs from 0 to 6 as common sub\sphinxhyphen{}band and from 12 to 18 as
private sub\sphinxhyphen{}band in DL and UL, RSRQ threshold is 20 dB, power in center area equals
\sphinxcode{\sphinxupquote{LteEnbPhy::TxPower \sphinxhyphen{} 3dB}}, power in edge area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 3dB}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType (\PYGZdq{}ns3::LteFrStrictAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlCommonSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlCommonSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandOffset\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandOffset\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}RsrqThreshold\PYGZdq{}, UintegerValue (20));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterPowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB\PYGZus{}3));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgePowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB3));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterAreaTpc\PYGZdq{}, UintegerValue (1));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgeAreaTpc\PYGZdq{}, UintegerValue (2));
NetDeviceContainer enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes.Get(0));
\end{sphinxVerbatim}


\paragraph{Soft Frequency Reuse Algorithm}
\label{\detokenize{lte-user:soft-frequency-reuse-algorithm}}
With Soft Frequency Reuse Algorithm, eNb uses entire cell bandwidth, but there are two
sub\sphinxhyphen{}bands, within UEs are served with different power level.

Soft Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandOffset}}: Uplink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandwidth}}: Uplink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandOffset}}: Downlink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandwidth}}: Downlink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{AllowCenterUeUseEdgeSubBand}}: If true center UEs can receive on edge sub\sphinxhyphen{}band RBGs, otherwise
edge sub\sphinxhyphen{}band is allowed only for edge UEs, default value is true

\item {} 
\sphinxcode{\sphinxupquote{RsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{CenterPowerOffset}}: PdschConfigDedicated::Pa value for center sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgePowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in center area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in edge area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

Example below configures RBs from 8 to 16 to be used by cell edge UEs and this sub\sphinxhyphen{}band
is not available for cell center users. RSRQ threshold is 20 dB, power in center area
equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower}}, power in edge area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 3dB}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType (\PYGZdq{}ns3::LteFrSoftAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandOffset\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandwidth\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandOffset\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandwidth\PYGZdq{}, UintegerValue (8));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}AllowCenterUeUseEdgeSubBand\PYGZdq{}, BooleanValue (false));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}RsrqThreshold\PYGZdq{}, UintegerValue (20));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterPowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgePowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB3));
NetDeviceContainer enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes.Get(0));
\end{sphinxVerbatim}


\paragraph{Soft Fractional Frequency Reuse Algorithm}
\label{\detokenize{lte-user:soft-fractional-frequency-reuse-algorithm}}
Soft Fractional Frequency Reuse (SFFR) uses three sub\sphinxhyphen{}bands: center, medium (common)
and edge. User have to configure only two of them: common and edge. Center sub\sphinxhyphen{}band
will be composed from the remaining bandwidth. Each sub\sphinxhyphen{}band can be served with
different transmission power. Since there are three sub\sphinxhyphen{}bands, two RSRQ thresholds needs to
be configured.

Soft Fractional Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{UlCommonSubBandwidth}}: Uplink Common SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandOffset}}: Uplink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlEdgeSubBandwidth}}: Uplink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlCommonSubBandwidth}}: Downlink Common SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandOffset}}: Downlink Edge SubBand Offset in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlEdgeSubBandwidth}}: Downlink Edge SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{CenterRsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in medium sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{EdgeRsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaPowerOffset}}: PdschConfigDedicated::Pa value for center sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{MediumAreaPowerOffset}}: PdschConfigDedicated::Pa value for medium sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaPowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in center area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{MediumAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in medium area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in edge area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

In example below RBs from 0 to 6 will be used as common (medium) sub\sphinxhyphen{}band,
RBs from 6 to 12 will be used as edge sub\sphinxhyphen{}band and RBs from 12 to 24 will be used as
center sub\sphinxhyphen{}band (it is composed with remaining RBs). RSRQ threshold between center
and medium area is 28 dB, RSRQ threshold between medium and edge area is 18 dB.
Power in center area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower \sphinxhyphen{} 3dB}}, power in medium area equals
\sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 3dB}}, power in edge area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 3dB}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType (\PYGZdq{}ns3::LteFfrSoftAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlCommonSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlCommonSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandOffset\PYGZdq{}, UintegerValue (0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}DlEdgeSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandOffset\PYGZdq{}, UintegerValue (0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}UlEdgeSubBandwidth\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterRsrqThreshold\PYGZdq{}, UintegerValue (28));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgeRsrqThreshold\PYGZdq{}, UintegerValue (18));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterAreaPowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB\PYGZus{}3));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}MediumAreaPowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgeAreaPowerOffset\PYGZdq{},
                      UintegerValue (LteRrcSap::PdschConfigDedicated::dB3));
NetDeviceContainer enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes.Get(0));
\end{sphinxVerbatim}


\paragraph{Enhanced Fractional Frequency Reuse Algorithm}
\label{\detokenize{lte-user:enhanced-fractional-frequency-reuse-algorithm}}
Enhanced Fractional Frequency Reuse (EFFR) reserve part of system bandwidth for each cell
(typically there are 3 cell types and each one gets 1/3 of system bandwidth). Then part of
this subbandwidth it used as \sphinxtitleref{Primary Segment} with reuse factor 3 and as \sphinxtitleref{Secondary Segment}
with reuse factor 1. User has to configure (for DL and UL) offset of the cell subbandwidth
in number of RB, number of RB which will be used as \sphinxtitleref{Primary Segment} and number of RB which
will be used as \sphinxtitleref{Secondary Segment}. \sphinxtitleref{Primary Segment} is used by cell at will, but RBs from
\sphinxtitleref{Secondary Segment} can be assigned to UE only is CQI feedback from this UE have higher value
than configured CQI threshold. UE is considered as edge UE when its RSRQ is lower than \sphinxcode{\sphinxupquote{RsrqThreshold}}.

Since each eNb needs to know where are Primary and Secondary of other cell types,
it will calculate them assuming configuration is the same for each cell and only subbandwidth offsets
are different. So it is important to divide available system bandwidth equally to each cell and apply
the same configuration of Primary and Secondary Segments to them.

Enhanced Fractional Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{UlSubBandOffset}}: Uplink SubBand Offset for this cell in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlReuse3SubBandwidth}}: Uplink Reuse 3 SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{UlReuse1SubBandwidth}}: Uplink Reuse 1 SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlSubBandOffset}}: Downlink SubBand Offset for this cell in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlReuse3SubBandwidth}}: Downlink Reuse 3 SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{DlReuse1SubBandwidth}}: Downlink Reuse 1 SubBandwidth Configuration in number of Resource Block Groups

\item {} 
\sphinxcode{\sphinxupquote{RsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaPowerOffset}}: PdschConfigDedicated::Pa value for center sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaPowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{DlCqiThreshold}}: If the DL\sphinxhyphen{}CQI for RBG of is higher than this threshold, transmission on RBG is possible

\item {} 
\sphinxcode{\sphinxupquote{UlCqiThreshold}}: If the UL\sphinxhyphen{}CQI for RBG of is higher than this threshold, transmission on RBG is possible

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in center area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in edge area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

In example below offset in DL and UL is 0 RB, 4 RB will be used in \sphinxtitleref{Primary Segment} and
\sphinxtitleref{Secondary Segment}. RSRQ threshold between center and edge area is 25 dB. DL and UL CQI
thresholds are set to value of 10. Power in center area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower \sphinxhyphen{} 6dB}},
power in edge area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 0dB}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType(\PYGZdq{}ns3::LteFfrEnhancedAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}RsrqThreshold\PYGZdq{}, UintegerValue (25));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}DlCqiThreshold\PYGZdq{}, UintegerValue (10));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}UlCqiThreshold\PYGZdq{}, UintegerValue (10));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}CenterAreaPowerOffset\PYGZdq{},
               UintegerValue (LteRrcSap::PdschConfigDedicated::dB\PYGZus{}6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}EdgeAreaPowerOffset\PYGZdq{},
               UintegerValue (LteRrcSap::PdschConfigDedicated::dB0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}UlSubBandOffset\PYGZdq{}, UintegerValue (0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}UlReuse3SubBandwidth\PYGZdq{}, UintegerValue (4));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}UlReuse1SubBandwidth\PYGZdq{}, UintegerValue (4));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}DlSubBandOffset\PYGZdq{}, UintegerValue (0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}DlReuse3SubBandwidth\PYGZdq{}, UintegerValue (4));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}DlReuse1SubBandwidth\PYGZdq{}, UintegerValue (4));
\end{sphinxVerbatim}


\paragraph{Distributed Fractional Frequency Reuse Algorithm}
\label{\detokenize{lte-user:distributed-fractional-frequency-reuse-algorithm}}
Distributed Fractional Frequency Reuse requires X2 interface between all eNB to be installed.
X2 interfaces can be installed only when EPC is configured, so this FFR scheme can be used only with
EPC scenarios.

With Distributed Fractional Frequency Reuse  Algorithm, eNb uses entire cell bandwidth and there can
be two sub\sphinxhyphen{}bands: center sub\sphinxhyphen{}band and edge sub\sphinxhyphen{}band . Within these sub\sphinxhyphen{}bands UEs can be served with
different power level. Algorithm adaptively selects RBs for cell\sphinxhyphen{}edge sub\sphinxhyphen{}band on basis of
coordination information (i.e. RNTP) from adjecent cells and notifies the base stations of the adjacent cells,
which RBs it selected to use in edge sub\sphinxhyphen{}band. If there are no UE classified as edge UE in cell,
eNB will not use any RBs as edge sub\sphinxhyphen{}band.

Distributed Fractional Frequency Reuse Algorithm provides following attributes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{CalculationInterval}}: Time interval between calculation of Edge sub\sphinxhyphen{}band, Default value 1 second

\item {} 
\sphinxcode{\sphinxupquote{RsrqThreshold}}: If the RSRQ of is worse than this threshold, UE should be served in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{RsrpDifferenceThreshold}}: If the difference between the power of the signal received by UE from
the serving cell and the power of the signal received from the adjacent cell is less than a
RsrpDifferenceThreshold value, the cell weight is incremented

\item {} 
\sphinxcode{\sphinxupquote{CenterPowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgePowerOffset}}: PdschConfigDedicated::Pa value for edge sub\sphinxhyphen{}band, default value dB0

\item {} 
\sphinxcode{\sphinxupquote{EdgeRbNum}}: Number of RB that can be used in edge sub\sphinxhyphen{}band

\item {} 
\sphinxcode{\sphinxupquote{CenterAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in center area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\item {} 
\sphinxcode{\sphinxupquote{EdgeAreaTpc}}: TPC value which will be set in DL\sphinxhyphen{}DCI for UEs in edge area,
Absolute mode is used, default value 1 is mapped to \sphinxhyphen{}1 according to TS36.213 Table 5.1.1.1\sphinxhyphen{}2

\end{itemize}

In example below calculation interval is 500 ms. RSRQ threshold between center and edge area is 25.
RSRP Difference Threshold is set to be 5. In DL and UL 6 RB will be used by each cell in edge sub\sphinxhyphen{}band.
Power in center area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower \sphinxhyphen{} 0dB}}, power in edge area equals \sphinxcode{\sphinxupquote{LteEnbPhy::TxPower + 3dB}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType(\PYGZdq{}ns3::LteFfrDistributedAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}CalculationInterval\PYGZdq{}, TimeValue(MilliSeconds(500)));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}RsrqThreshold\PYGZdq{}, UintegerValue (25));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}RsrpDifferenceThreshold\PYGZdq{}, UintegerValue (5));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgeRbNum\PYGZdq{}, UintegerValue (6));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}CenterPowerOffset\PYGZdq{},
                UintegerValue (LteRrcSap::PdschConfigDedicated::dB0));
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute (\PYGZdq{}EdgePowerOffset\PYGZdq{},
                UintegerValue (LteRrcSap::PdschConfigDedicated::dB3));
\end{sphinxVerbatim}


\subsubsection{Automatic configuration}
\label{\detokenize{lte-user:automatic-configuration}}
Frequency Reuse algorithms can also be configured in more “automatic” way by setting
only the bandwidth and FrCellTypeId. During initialization of FR instance, configuration
for set bandwidth and FrCellTypeId will be taken from configuration table. It is important
that only sub\sphinxhyphen{}bands will be configured, thresholds and transmission power will be set
to default values. If one wants, he/she can change thresholds and transmission power
as show in previous sub\sphinxhyphen{}section.

There are three FrCellTypeId : \sphinxcode{\sphinxupquote{1, 2, 3}}, which correspond to three different
configurations for each bandwidth. Three configurations allow to have different
configurations in neighbouring cells in hexagonal eNB layout. If user needs to have
more different configuration for neighbouring cells, he/she need to use manual
configuration.

Example below show automatic FR algorithm configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmType(\PYGZdq{}ns3::LteFfrSoftAlgorithm\PYGZdq{});
lteHelper\PYGZhy{}\PYGZgt{}SetFfrAlgorithmAttribute(\PYGZdq{}FrCellTypeId\PYGZdq{}, UintegerValue (1));
NetDeviceContainer enbDevs = lteHelper\PYGZhy{}\PYGZgt{}InstallEnbDevice (enbNodes.Get(0));
\end{sphinxVerbatim}


\subsection{Uplink Power Control}
\label{\detokenize{lte-user:uplink-power-control}}
Uplink Power Control functionality is enabled by default. User can disable it by setting
the boolean attribute \sphinxcode{\sphinxupquote{ns3::LteUePhy::EnableUplinkPowerControl}} to true.

User can switch between Open Loop Power Control and Closed Loop Power Control mechanisms
by setting the boolean attribute \sphinxcode{\sphinxupquote{ns3::LteUePowerControl::ClosedLoop}}.
By default Closed Loop Power Control with Accumulation Mode is enabled.

Path\sphinxhyphen{}loss is key component of Uplink Power Control. It is computed as difference between
filtered RSRP and ReferenceSignalPower parameter. ReferenceSignalPower is
sent with SIB2.

Attributes available in Uplink Power Control:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ClosedLoop}}: if true Closed Loop Uplink Power Control mode is enabled and Open Loop
Power Control otherwise, default value is false

\item {} 
\sphinxcode{\sphinxupquote{AccumulationEnabled}}: if true Accumulation Mode is enabled and Absolute mode otherwise,
default value is false

\item {} 
\sphinxcode{\sphinxupquote{Alpha}}: the path loss compensation factor, default value is 1.0

\item {} 
\sphinxcode{\sphinxupquote{Pcmin}}: minimal UE TxPower, default value is \sphinxhyphen{}40 dBm

\item {} 
\sphinxcode{\sphinxupquote{Pcmax}}: maximal UE TxPower, default value is 23 dBm

\item {} 
\sphinxcode{\sphinxupquote{PoNominalPusch}}: this parameter should be set by higher layers, but currently
it needs to be configured by attribute system, possible values are
integers in range (\sphinxhyphen{}126 … 24), Default value is \sphinxhyphen{}80

\item {} 
\sphinxcode{\sphinxupquote{PoUePusch}}: this parameter should be set by higher layers, but currently
it needs to be configured by attribute system, possible values are
integers in range (\sphinxhyphen{}8 … 7), Default value is 0

\item {} 
\sphinxcode{\sphinxupquote{PsrsOffset}}: this parameter should be set by higher layers, but currently
it needs to be configured by attribute system, possible values are
integers in range (0 … 15), Default value is 7, what gives P\_Srs\_Offset\_Value = 0

\end{itemize}
\begin{description}
\item[{Traced values in Uplink Power Control:}] \leavevmode\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ReportPuschTxPower}}: Current UE TxPower for PUSCH

\item {} 
\sphinxcode{\sphinxupquote{ReportPucchTxPower}}: Current UE TxPower for PUCCH

\item {} 
\sphinxcode{\sphinxupquote{ReportSrsTxPower}}: Current UE TxPower for SRS

\end{itemize}

\end{description}

Example configuration is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteUePhy::EnableUplinkPowerControl\PYGZdq{}, BooleanValue (true));
Config::SetDefault (\PYGZdq{}ns3::LteEnbPhy::TxPower\PYGZdq{}, DoubleValue (30));
Config::SetDefault (\PYGZdq{}ns3::LteUePowerControl::ClosedLoop\PYGZdq{}, BooleanValue (true));
Config::SetDefault (\PYGZdq{}ns3::LteUePowerControl::AccumulationEnabled\PYGZdq{}, BooleanValue (true));
\end{sphinxVerbatim}

As an example, user can take a look and run the lena\sphinxhyphen{}uplink\sphinxhyphen{}power\sphinxhyphen{}control program.


\subsection{Examples Programs}
\label{\detokenize{lte-user:examples-programs}}
The directory \sphinxcode{\sphinxupquote{src/lte/examples/}} contains some example simulation programs that
show how to simulate different LTE scenarios.


\subsection{Reference scenarios}
\label{\detokenize{lte-user:reference-scenarios}}
There is a vast amount of reference LTE simulation scenarios which can
be found in the literature. Here we list some of them:
\begin{itemize}
\item {} 
The system simulation scenarios mentioned in section A.2 of \sphinxcite{lte-references:tr36814}.

\item {} 
The dual stripe model \sphinxcite{lte-references:r4-092042}, which is partially implemented in the
example program \sphinxcode{\sphinxupquote{src/lte/examples/lena\sphinxhyphen{}dual\sphinxhyphen{}stripe.cc}}. This example
program features a lot of configurable parameters which can be customized by
changing the corresponding global variables. To get a list of all these
global variables, you can run this command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run lena\PYGZhy{}dual\PYGZhy{}stripe \PYGZhy{}\PYGZhy{}command\PYGZhy{}template=\PYGZdq{}\PYGZpc{}s \PYGZhy{}\PYGZhy{}PrintGlobals\PYGZdq{}
\end{sphinxVerbatim}

The following subsection presents an example of running a simulation
campaign using this example program.

\end{itemize}


\subsubsection{Handover simulation campaign}
\label{\detokenize{lte-user:handover-simulation-campaign}}
In this subsection, we will demonstrate an example of running a simulation
campaign using the LTE module of \sphinxstyleemphasis{ns\sphinxhyphen{}3}. The objective of the campaign is to
compare the effect of each built\sphinxhyphen{}in handover algorithm of the LTE module.

The campaign will use the \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} example program. First, we have
to modify the example program to produce the output that we need. In this
occasion, we want to produce the number of handovers, user average throughput,
and average SINR.

The number of handovers can be obtained by counting the number of times the
\sphinxtitleref{HandoverEndOk} {\hyperref[\detokenize{lte-user:sec-handover-traces}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover traces}}}} is fired. Then the user average
throughput can be obtained by enabling the RLC {\hyperref[\detokenize{lte-user:sec-simulation-output}]{\sphinxcrossref{\DUrole{std,std-ref}{Simulation Output}}}}.
Finally, SINR can be obtained by enabling the PHY simulation output. The
following sample code snippet shows one possible way to obtain the above:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void
NotifyHandoverEndOkUe (std::string context, uint64\PYGZus{}t imsi,
                       uint16\PYGZus{}t cellId, uint16\PYGZus{}t rnti)
\PYGZob{}
  std::cout \PYGZlt{}\PYGZlt{} \PYGZdq{}Handover IMSI \PYGZdq{} \PYGZlt{}\PYGZlt{} imsi \PYGZlt{}\PYGZlt{} std::endl;
\PYGZcb{}

int
main (int argc, char *argv[])
\PYGZob{}
  /*** SNIP ***/

  Config::Connect (\PYGZdq{}/NodeList/*/DeviceList/*/LteUeRrc/HandoverEndOk\PYGZdq{},
                   MakeCallback (\PYGZam{}NotifyHandoverEndOkUe));

  lteHelper\PYGZhy{}\PYGZgt{}EnablePhyTraces ();
  lteHelper\PYGZhy{}\PYGZgt{}EnableRlcTraces ();
  Ptr\PYGZlt{}RadioBearerStatsCalculator\PYGZgt{} rlcStats = lteHelper\PYGZhy{}\PYGZgt{}GetRlcStats ();
  rlcStats\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}StartTime\PYGZdq{}, TimeValue (Seconds (0)));
  rlcStats\PYGZhy{}\PYGZgt{}SetAttribute (\PYGZdq{}EpochDuration\PYGZdq{}, TimeValue (Seconds (simTime)));

  Simulator::Run ();
  Simulator::Destroy ();
  return 0;
\PYGZcb{}
\end{sphinxVerbatim}

Then we have to configure the parameters of the program to suit our simulation
needs. We are looking for the following assumptions in our simulation:
\begin{itemize}
\item {} 
7 sites of tri\sphinxhyphen{}sectored macro eNodeBs (i.e. 21 macrocells) deployed in
hexagonal layout with 500 m inter\sphinxhyphen{}site distance.

\item {} 
Although \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} is originally intended for a two\sphinxhyphen{}tier
(macrocell and femtocell) simulation, we will simplify our simulation to
one\sphinxhyphen{}tier (macrocell) simulation only.

\item {} 
UEs are randomly distributed around the sites and attach to the network
automatically using Idle mode cell selection. After that, UE will roam the
simulation environment with 60 kmph movement speed.

\item {} 
50 seconds simulation duration, so UEs would have traveled far enough to
trigger some handovers.

\item {} 
46 dBm macrocell Tx power and 10 dBm UE Tx power.

\item {} 
EPC mode will be used because the X2 handover procedure requires it to be
enabled.

\item {} 
Full\sphinxhyphen{}buffer downlink and uplink traffic, both in 5 MHz bandwidth, using TCP
protocol and Proportional Fair scheduler.

\item {} 
Ideal RRC protocol.

\end{itemize}

Table {\hyperref[\detokenize{lte-user:tab-handover-campaign-program-parameter}]{\sphinxcrossref{\DUrole{std,std-ref}{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe parameter configuration for handover campaign}}}} below shows how we
configure the parameters of \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} to achieve the above
assumptions.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{\sphinxstyleliteralintitle{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} parameter configuration for handover campaign}\label{\detokenize{lte-user:id20}}\label{\detokenize{lte-user:tab-handover-campaign-program-parameter}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Parameter name
&\sphinxstyletheadfamily 
Value
&\sphinxstyletheadfamily 
Description
\\
\hline
simTime
&
50
&
50 seconds simulation duration
\\
\hline
nBlocks
&
0
&
Disabling apartment buildings and femtocells
\\
\hline
nMacroEnbSites
&
7
&
Number of macrocell sites (each site has 3
cells)
\\
\hline
nMacroEnbSitesX
&
2
&
The macrocell sites will be positioned in a
2\sphinxhyphen{}3\sphinxhyphen{}2 formation
\\
\hline
interSiteDistance
&
500
&
500 m distance between adjacent macrocell sites
\\
\hline
macroEnbTxPowerDbm
&
46
&
46 dBm Tx power for each macrocell
\\
\hline
epc
&
1
&
Enable EPC mode
\\
\hline
epcDl
&
1
&
Enable full\sphinxhyphen{}buffer DL traffic
\\
\hline
epcUl
&
1
&
Enable full\sphinxhyphen{}buffer UL traffic
\\
\hline
useUdp
&
0
&
Disable UDP traffic and enable TCP instead
\\
\hline
macroUeDensity
&
0.00002
&
Determines number of UEs (translates to 48 UEs
in our simulation)
\\
\hline
outdoorUeMinSpeed
&
16.6667
&
Minimum UE movement speed in m/s (60 kmph)
\\
\hline
outdoorUeMaxSpeed
&
16.6667
&
Maximum UE movement speed in m/s (60 kmph)
\\
\hline
macroEnbBandwidth
&
25
&
5 MHz DL and UL bandwidth
\\
\hline
generateRem
&
1
&
(Optional) For plotting the Radio Environment
Map
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Some of the required assumptions are not available as parameters of
\sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}}. In this case, we override the default attributes, as
shown in Table {\hyperref[\detokenize{lte-user:tab-handover-campaign-default-values}]{\sphinxcrossref{\DUrole{std,std-ref}{Overriding default attributes for handover campaign}}}} below.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Overriding default attributes for handover campaign}\label{\detokenize{lte-user:id21}}\label{\detokenize{lte-user:tab-handover-campaign-default-values}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Default value name
&\sphinxstyletheadfamily 
Value
&\sphinxstyletheadfamily 
Description
\\
\hline
ns3::LteHelper::HandoverAlgorithm
&
\sphinxtitleref{ns3::NoOpHandoverAlgorithm},
\sphinxtitleref{ns3::A3RsrpHandoverAlgorithm}, or
\sphinxtitleref{ns3::A2A4RsrqHandoverAlgorithm}
&
Choice of handover algorithm
\\
\hline
ns3::LteHelper::Scheduler
&
\sphinxtitleref{ns3::PfFfMacScheduler}
&
Proportional Fair scheduler
\\
\hline
ns3::LteHelper::UseIdealRrc
&
1
&
Ideal RRC protocol
\\
\hline
ns3::RadioBearerStatsCalculator::DlRlcOutputFilename
&
\sphinxtitleref{\textless{}run\textgreater{}}\sphinxhyphen{}DlRlcStats.txt
&
File name for DL RLC trace output
\\
\hline
ns3::RadioBearerStatsCalculator::UlRlcOutputFilename
&
\sphinxtitleref{\textless{}run\textgreater{}}\sphinxhyphen{}UlRlcStats.txt
&
File name for UL RLC trace output
\\
\hline
ns3::PhyStatsCalculator::DlRsrpSinrFilename
&
\sphinxtitleref{\textless{}run\textgreater{}}\sphinxhyphen{}DlRsrpSinrStats.txt
&
File name for DL PHY RSRP/SINR trace output
\\
\hline
ns3::PhyStatsCalculator::UlSinrFilename
&
\sphinxtitleref{\textless{}run\textgreater{}}\sphinxhyphen{}UlSinrStats.txt
&
File name for UL PHY SINR trace output
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstyleemphasis{ns\sphinxhyphen{}3} provides many ways for passing configuration values into a simulation. In
this example, we will use the command line arguments. It is basically done by
appending the parameters and their values to the \sphinxcode{\sphinxupquote{waf}} call when starting each
individual simulation. So the \sphinxcode{\sphinxupquote{waf}} calls for invoking our 3 simulations would
look as below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run=\PYGZdq{}lena\PYGZhy{}dual\PYGZhy{}stripe
  \PYGZhy{}\PYGZhy{}simTime=50 \PYGZhy{}\PYGZhy{}nBlocks=0 \PYGZhy{}\PYGZhy{}nMacroEnbSites=7 \PYGZhy{}\PYGZhy{}nMacroEnbSitesX=2
  \PYGZhy{}\PYGZhy{}epc=1 \PYGZhy{}\PYGZhy{}useUdp=0 \PYGZhy{}\PYGZhy{}outdoorUeMinSpeed=16.6667 \PYGZhy{}\PYGZhy{}outdoorUeMaxSpeed=16.6667
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::HandoverAlgorithm=ns3::NoOpHandoverAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::DlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}DlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::UlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}UlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::DlRsrpSinrFilename=no\PYGZhy{}op\PYGZhy{}DlRsrpSinrStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::UlSinrFilename=no\PYGZhy{}op\PYGZhy{}UlSinrStats.txt
  \PYGZhy{}\PYGZhy{}RngRun=1\PYGZdq{} \PYGZgt{} no\PYGZhy{}op.txt

\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run=\PYGZdq{}lena\PYGZhy{}dual\PYGZhy{}stripe
  \PYGZhy{}\PYGZhy{}simTime=50 \PYGZhy{}\PYGZhy{}nBlocks=0 \PYGZhy{}\PYGZhy{}nMacroEnbSites=7 \PYGZhy{}\PYGZhy{}nMacroEnbSitesX=2
  \PYGZhy{}\PYGZhy{}epc=1 \PYGZhy{}\PYGZhy{}useUdp=0 \PYGZhy{}\PYGZhy{}outdoorUeMinSpeed=16.6667 \PYGZhy{}\PYGZhy{}outdoorUeMaxSpeed=16.6667
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::HandoverAlgorithm=ns3::A3RsrpHandoverAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::DlRlcOutputFilename=a3\PYGZhy{}rsrp\PYGZhy{}DlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::UlRlcOutputFilename=a3\PYGZhy{}rsrp\PYGZhy{}UlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::DlRsrpSinrFilename=a3\PYGZhy{}rsrp\PYGZhy{}DlRsrpSinrStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::UlSinrFilename=a3\PYGZhy{}rsrp\PYGZhy{}UlSinrStats.txt
  \PYGZhy{}\PYGZhy{}RngRun=1\PYGZdq{} \PYGZgt{} a3\PYGZhy{}rsrp.txt

\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run=\PYGZdq{}lena\PYGZhy{}dual\PYGZhy{}stripe
  \PYGZhy{}\PYGZhy{}simTime=50 \PYGZhy{}\PYGZhy{}nBlocks=0 \PYGZhy{}\PYGZhy{}nMacroEnbSites=7 \PYGZhy{}\PYGZhy{}nMacroEnbSitesX=2
  \PYGZhy{}\PYGZhy{}epc=1 \PYGZhy{}\PYGZhy{}useUdp=0 \PYGZhy{}\PYGZhy{}outdoorUeMinSpeed=16.6667 \PYGZhy{}\PYGZhy{}outdoorUeMaxSpeed=16.6667
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::HandoverAlgorithm=ns3::A2A4RsrqHandoverAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::DlRlcOutputFilename=a2\PYGZhy{}a4\PYGZhy{}rsrq\PYGZhy{}DlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::UlRlcOutputFilename=a2\PYGZhy{}a4\PYGZhy{}rsrq\PYGZhy{}UlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::DlRsrpSinrFilename=a2\PYGZhy{}a4\PYGZhy{}rsrq\PYGZhy{}DlRsrpSinrStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::UlSinrFilename=a2\PYGZhy{}a4\PYGZhy{}rsrq\PYGZhy{}UlSinrStats.txt
  \PYGZhy{}\PYGZhy{}RngRun=1\PYGZdq{} \PYGZgt{} a2\PYGZhy{}a4\PYGZhy{}rsrq.txt
\end{sphinxVerbatim}

Some notes on the execution:
\begin{itemize}
\item {} 
Notice that some arguments are not specified because they are already the
same as the default values. We also keep the handover algorithms on each own
default settings.

\item {} 
Note the file names of simulation output, e.g. RLC traces and PHY traces,
because we have to make sure that they are not overwritten by the next
simulation run. In this example, we specify the names one by one using the
command line arguments.

\item {} 
The \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}RngRun=1}} argument at the end is used for setting the run number
used by the random number generator used in the simulation. We re\sphinxhyphen{}run the
same simulations with different \sphinxtitleref{RngRun} values, hence creating several
independent replications of the same simulations. Then we average the
results obtained from these replications to achieve some statistical
confidence.

\item {} 
We can add a \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}generateRem=1}} argument to generate the files necessary for
generating the Radio Environment Map (REM) of the simulation. The result is
Figure {\hyperref[\detokenize{lte-user:fig-lte-handover-campaign-rem}]{\sphinxcrossref{\DUrole{std,std-ref}{REM obtained from a simulation in handover campaign}}}} below, which can be produced by
following the steps described in Section {\hyperref[\detokenize{lte-user:sec-radio-environment-maps}]{\sphinxcrossref{\DUrole{std,std-ref}{Radio Environment Maps}}}}.
This figure also shows the position of eNodeBs and UEs at the beginning of a
simulation using \sphinxcode{\sphinxupquote{RngRun = 1}}. Other values of \sphinxtitleref{RngRun} may produce
different UE position.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-handover-campaign-rem}.pdf}
\caption{REM obtained from a simulation in handover campaign}\label{\detokenize{lte-user:id22}}\label{\detokenize{lte-user:fig-lte-handover-campaign-rem}}\end{figure}

After hours of running, the simulation campaign will eventually end. Next we
will perform some post\sphinxhyphen{}processing on the produced simulation output to obtain
meaningful information out of it.

In this example, we use GNU Octave to assist the processing of throughput and
SINR data, as demonstrated in a sample GNU Octave script below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{} RxBytes is the 10th column
DlRxBytes = load (\PYGZdq{}no\PYGZhy{}op\PYGZhy{}DlRlcStats.txt\PYGZdq{}) (:,10);
DlAverageThroughputKbps = sum (DlRxBytes) * 8 / 1000 / 50

\PYGZpc{} RxBytes is the 10th column
UlRxBytes = load (\PYGZdq{}no\PYGZhy{}op\PYGZhy{}UlRlcStats.txt\PYGZdq{}) (:,10);
UlAverageThroughputKbps = sum (UlRxBytes) * 8 / 1000 / 50

\PYGZpc{} Sinr is the 6th column
DlSinr = load (\PYGZdq{}no\PYGZhy{}op\PYGZhy{}DlRsrpSinrStats.txt\PYGZdq{}) (:,6);
\PYGZpc{} eliminate NaN values
idx = isnan (DlSinr);
DlSinr (idx) = 0;
DlAverageSinrDb = 10 * log10 (mean (DlSinr)) \PYGZpc{} convert to dB

\PYGZpc{} Sinr is the 5th column
UlSinr = load (\PYGZdq{}no\PYGZhy{}op\PYGZhy{}UlSinrStats.txt\PYGZdq{}) (:,5);
\PYGZpc{} eliminate NaN values
idx = isnan (UlSinr);
UlSinr (idx) = 0;
UlAverageSinrDb = 10 * log10 (mean (UlSinr)) \PYGZpc{} convert to dB
\end{sphinxVerbatim}

As for the number of handovers, we can use simple shell scripting to count the
number of occurrences of string “Handover” in the log file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} grep \PYGZdq{}Handover\PYGZdq{} no\PYGZhy{}op.txt | wc \PYGZhy{}l
\end{sphinxVerbatim}

Table {\hyperref[\detokenize{lte-user:tab-handover-campaign-results}]{\sphinxcrossref{\DUrole{std,std-ref}{Results of handover campaign}}}} below shows the complete statistics
after we are done with post\sphinxhyphen{}processing on every individual simulation run. The
values shown are the average of the results obtained from \sphinxcode{\sphinxupquote{RngRun}} of 1, 2, 3,
and 4.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Results of handover campaign}\label{\detokenize{lte-user:id23}}\label{\detokenize{lte-user:tab-handover-campaign-results}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Statistics
&\sphinxstyletheadfamily 
No\sphinxhyphen{}op
&\sphinxstyletheadfamily 
A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ
&\sphinxstyletheadfamily 
Strongest cell
\\
\hline
Average DL system throughput
&
6 615 kbps
&
20 509 kbps
&
19 709 kbps
\\
\hline
Average UL system throughput
&
4 095 kbps
&
5 705 kbps
&
6 627 kbps
\\
\hline
Average DL SINR
&
\sphinxhyphen{}0.10 dB
&
5.19 dB
&
5.24 dB
\\
\hline
Average UL SINR
&
9.54 dB
&
81.57 dB
&
79.65 dB
\\
\hline
Number of handovers per UE per second
&
0
&
0.05694
&
0.04771
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The results show that having a handover algorithm in a mobility simulation
improves both user throughput and SINR significantly. There is little difference
between the two handover algorithms in this campaign scenario. It would be
interesting to see their performance in different scenarios, such as scenarios
with home eNodeBs deployment.


\subsubsection{Frequency Reuse examples}
\label{\detokenize{lte-user:frequency-reuse-examples}}
There are two examples showing Frequency Reuse Algorithms functionality.

\sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} is simple example with 3 eNBs in triangle layout.
There are 3 cell edge UEs, which are located in the center of this triangle and
3 cell center UEs (one near each eNB). User can also specify the number of randomly
located UEs. FR algorithm is installed in eNBs and each eNB has different FrCellTypeId,
what means each eNB uses different FR configuration. User can run \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}}
with 6 different FR algorithms: NoOp, Hard FR, Strict FR, Soft FR, Soft FFR and Enhanced FFR.
To run scenario with Distributed FFR algorithm, user should use \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}distributed\sphinxhyphen{}ffr}}.
These two examples are very similar, but they were split because Distributed FFR requires
EPC to be used, and other algorithms do not.

To run \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} with different Frequency Reuse algorithms, user needs to specify
FR algorithm by overriding the default attribute \sphinxcode{\sphinxupquote{ns3::LteHelper::FfrAlgorithm}}.
Example command to run \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} with Soft FR algorithm is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}frequency\PYGZhy{}reuse \PYGZhy{}\PYGZhy{}ns3::LteHelper::FfrAlgorithm=ns3::LteFrSoftAlgorithm\PYGZdq{}
\end{sphinxVerbatim}

In these examples functionality to generate REM and spectrum analyzer trace was added.
User can enable generation of it by setting \sphinxcode{\sphinxupquote{generateRem}} and \sphinxcode{\sphinxupquote{generateSpectrumTrace}}
attributes.

Command to generate REM for RB 1 in data channel from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} scenario
with Soft FR algorithm is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}frequency\PYGZhy{}reuse \PYGZhy{}\PYGZhy{}ns3::LteHelper::FfrAlgorithm=ns3::LteFrSoftAlgorithm
  \PYGZhy{}\PYGZhy{}generateRem=true \PYGZhy{}\PYGZhy{}remRbId=1\PYGZdq{}
\end{sphinxVerbatim}

Radio Environment Map for Soft FR is presented in Figure {\hyperref[\detokenize{lte-user:fig-lte-soft-fr-1-rem}]{\sphinxcrossref{\DUrole{std,std-ref}{REM for RB 1 obtained from lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse example with Soft FR
algorithm enabled}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-fr-soft-1-rem}.pdf}
\caption{REM for RB 1 obtained from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} example with Soft FR
algorithm enabled}\label{\detokenize{lte-user:id24}}\label{\detokenize{lte-user:fig-lte-soft-fr-1-rem}}\end{figure}

Command to generate spectrum trace from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} scenario
with Soft FFR algorithm is presented below (Spectrum Analyzer position needs to be configured
inside script):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}frequency\PYGZhy{}reuse \PYGZhy{}\PYGZhy{}ns3::LteHelper::FfrAlgorithm=ns3::LteFfrSoftAlgorithm
  \PYGZhy{}\PYGZhy{}generateSpectrumTrace=true\PYGZdq{}
\end{sphinxVerbatim}

Example spectrum analyzer trace is presented in figure {\hyperref[\detokenize{lte-user:fig-lte-soft-ffr-2-spectrum-trace}]{\sphinxcrossref{\DUrole{std,std-ref}{Spectrum Analyzer trace obtained from lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse example
with Soft FFR algorithm enabled. Spectrum Analyzer was located need eNB
with FrCellTypeId 2.}}}}.
As can be seen, different data channel subbands are sent with different power level
(according to configuration), while control channel is transmitted with uniform power
along entire system bandwidth.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-ffr-soft-2-spectrum-trace}.pdf}
\caption{Spectrum Analyzer trace obtained from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} example
with Soft FFR algorithm enabled. Spectrum Analyzer was located need eNB
with FrCellTypeId 2.}\label{\detokenize{lte-user:id25}}\label{\detokenize{lte-user:fig-lte-soft-ffr-2-spectrum-trace}}\end{figure}

\sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} can be also run with Frequency Reuse algorithms installed in all macro eNB.
User needs to specify FR algorithm by overriding the default attribute \sphinxcode{\sphinxupquote{ns3::LteHelper::FfrAlgorithm}}.
Example command to run \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} with Hard FR algorithm is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run=\PYGZdq{}lena\PYGZhy{}dual\PYGZhy{}stripe
  \PYGZhy{}\PYGZhy{}simTime=50 \PYGZhy{}\PYGZhy{}nBlocks=0 \PYGZhy{}\PYGZhy{}nMacroEnbSites=7 \PYGZhy{}\PYGZhy{}nMacroEnbSitesX=2
  \PYGZhy{}\PYGZhy{}epc=1 \PYGZhy{}\PYGZhy{}useUdp=0 \PYGZhy{}\PYGZhy{}outdoorUeMinSpeed=16.6667 \PYGZhy{}\PYGZhy{}outdoorUeMaxSpeed=16.6667
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::HandoverAlgorithm=ns3::NoOpHandoverAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::FfrAlgorithm=ns3::LteFrHardAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::DlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}DlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::UlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}UlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::DlRsrpSinrFilename=no\PYGZhy{}op\PYGZhy{}DlRsrpSinrStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::UlSinrFilename=no\PYGZhy{}op\PYGZhy{}UlSinrStats.txt
  \PYGZhy{}\PYGZhy{}RngRun=1\PYGZdq{} \PYGZgt{} no\PYGZhy{}op.txt
\end{sphinxVerbatim}

Example command to generate REM for RB 1 in data channel from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} scenario
with Hard FR algorithm is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run=\PYGZdq{}lena\PYGZhy{}dual\PYGZhy{}stripe
  \PYGZhy{}\PYGZhy{}simTime=50 \PYGZhy{}\PYGZhy{}nBlocks=0 \PYGZhy{}\PYGZhy{}nMacroEnbSites=7 \PYGZhy{}\PYGZhy{}nMacroEnbSitesX=2
  \PYGZhy{}\PYGZhy{}epc=0 \PYGZhy{}\PYGZhy{}useUdp=0 \PYGZhy{}\PYGZhy{}outdoorUeMinSpeed=16.6667 \PYGZhy{}\PYGZhy{}outdoorUeMaxSpeed=16.6667
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::HandoverAlgorithm=ns3::NoOpHandoverAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::LteHelper::FfrAlgorithm=ns3::LteFrHardAlgorithm
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::DlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}DlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::RadioBearerStatsCalculator::UlRlcOutputFilename=no\PYGZhy{}op\PYGZhy{}UlRlcStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::DlRsrpSinrFilename=no\PYGZhy{}op\PYGZhy{}DlRsrpSinrStats.txt
  \PYGZhy{}\PYGZhy{}ns3::PhyStatsCalculator::UlSinrFilename=no\PYGZhy{}op\PYGZhy{}UlSinrStats.txt
  \PYGZhy{}\PYGZhy{}RngRun=1 \PYGZhy{}\PYGZhy{}generateRem=true \PYGZhy{}\PYGZhy{}remRbId=1\PYGZdq{} \PYGZgt{} no\PYGZhy{}op.txt
\end{sphinxVerbatim}

Radio Environment Maps for RB 1, 10 and 20 generated from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}}
scenario with Hard Frequency Reuse algorithm are presented in the figures
below. These RB were selected because each one is used by different FR cell type.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-fr-hard-1-rem}.pdf}
\caption{REM for RB 1 obtained from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} simulation with Hard FR algorithm enabled}\label{\detokenize{lte-user:id26}}\label{\detokenize{lte-user:fig-lte-hard-fr-1-rem}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-fr-hard-2-rem}.pdf}
\caption{REM for RB 10 obtained from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} simulation with Hard FR algorithm enabled}\label{\detokenize{lte-user:id27}}\label{\detokenize{lte-user:fig-lte-hard-fr-2-rem}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-fr-hard-3-rem}.pdf}
\caption{REM for RB 20 obtained from \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}dual\sphinxhyphen{}stripe}} simulation with Hard FR algorithm enabled}\label{\detokenize{lte-user:id28}}\label{\detokenize{lte-user:fig-lte-hard-fr-3-rem}}\end{figure}


\subsection{Carrier aggregation examples}
\label{\detokenize{lte-user:carrier-aggregation-examples}}
The carrier aggregation feature is not enabled by default. The user can enable it by setting the boolean attribute
\sphinxcode{\sphinxupquote{ns3::LteHelper::UseCa}} to true. The number of component carriers to be used in carrier aggregation can
be configured by setting the attribute \sphinxcode{\sphinxupquote{ns3::LteHelper::NumberOfComponentCarriers}}. Currently the
maximum number is 5. Additionally, the component carrier manager needs to be configured. By default
the \sphinxcode{\sphinxupquote{NoOpComponentCarrierManager}} is selected, which means that only the primary carrier is enabled. The Component
carrier manager (CCM) implementation that uses all the available carriers is \sphinxcode{\sphinxupquote{RrComponentCarrierManager}}.
The CCM can be configured by using the attribute \sphinxcode{\sphinxupquote{LteHelper::EnbComponentCarrierManager}}.

An example configuration is presented below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteHelper::UseCa\PYGZdq{}, BooleanValue (useCa));
Config::SetDefault (\PYGZdq{}ns3::LteHelper::NumberOfComponentCarriers\PYGZdq{}, UintegerValue (2));
Config::SetDefault (\PYGZdq{}ns3::LteHelper::EnbComponentCarrierManager\PYGZdq{}, StringValue (\PYGZdq{}ns3::RrComponentCarrierManager\PYGZdq{}));
\end{sphinxVerbatim}

As an example, the user can take a look and run the \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}simple}} and \sphinxcode{\sphinxupquote{lena\sphinxhyphen{}simple\sphinxhyphen{}epc}} programs and enable LTE traces
to check the performance. A new column is added to PHY and MAC traces to indicate the component carrier.

The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}carrier\sphinxhyphen{}aggregation}} is also a test program that can be used as an example as it can be run in a mode to write results
to output files by setting the \sphinxcode{\sphinxupquote{s\_writeResults}} boolean static variable to true. The test can be run by using a \sphinxtitleref{test\sphinxhyphen{}runner}:
\begin{quote}

./waf \textendash{}run ‘test\sphinxhyphen{}runner \textendash{}suite=lte\sphinxhyphen{}carrier\sphinxhyphen{}aggregation’
\end{quote}

To plot the test results, a file has to be created in the root folder of the ns\sphinxhyphen{}3 repository, and added to it with the following content :
\begin{quote}

set terminal png
set xlabel “Number of users”
set ylabel “Throughput per UE {[}Mbps{]}”
set key top right

downlink\_results=”carrier\_aggregation\_results\_dl.txt”
uplink\_results=”carrier\_aggregation\_results\_ul.txt”

set output “ca\sphinxhyphen{}test\sphinxhyphen{}example\sphinxhyphen{}dl.png”
set title “Downlink performance”
\begin{description}
\item[{plot downlink\_results using 1:(\$2==1 ? \$3/1000000}] \leavevmode{[}1/0) w lp t ‘NO SDL’, {]}
downlink\_results using 1:(\$2==2 ? \$3/1000000 : 1/0) w lp t ‘RR SDL 1’, downlink\_results using 1:(\$2==3 ? \$3/1000000 : 1/0) w lp t ‘RR SDL 2’

\end{description}

set output “ca\sphinxhyphen{}test\sphinxhyphen{}example\sphinxhyphen{}ul.png”
set title “Uplink performance”
\begin{description}
\item[{plot uplink\_results using 1:(\$2==1 ? \$3/1000000}] \leavevmode{[}1/0) w lp t ‘NO SDL’, {]}
uplink\_results using 1:(\$2==2 ? \$3/1000000 : 1/0) w lp t ‘RR SDL 1’, uplink\_results using 1:(\$2==3 ? \$3/1000000 : 1/0) w lp t ‘RR SDL 2’

\end{description}
\end{quote}

\sphinxcode{\sphinxupquote{gnuplot}} can be run by providing the file name, so that in the ns\sphinxhyphen{}3 root directory
figures are generated. An example to run this test suite is shown in figures:
\sphinxtitleref{fig\sphinxhyphen{}ca\sphinxhyphen{}test\sphinxhyphen{}example\sphinxhyphen{}ul} and \sphinxtitleref{fig\sphinxhyphen{}ca\sphinxhyphen{}test\sphinxhyphen{}example\sphinxhyphen{}dl}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{ca-test-example-ul}.png}
\caption{Example of CA test performance in the uplink}\label{\detokenize{lte-user:id29}}\label{\detokenize{lte-user:fig-ca-test-example-ul}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{ca-test-example-dl}.png}
\caption{Example of CA test performance in the downlink}\label{\detokenize{lte-user:id30}}\label{\detokenize{lte-user:fig-ca-test-example-dl}}\end{figure}


\subsection{Radio link failure example}
\label{\detokenize{lte-user:radio-link-failure-example}}
The example \sphinxstyleemphasis{lena\sphinxhyphen{}radio\sphinxhyphen{}link\sphinxhyphen{}failure.cc} is an example to simulate the RLF
functionality. In particular, it simulates only one moving UE using \sphinxstyleemphasis{Ideal} or \sphinxstyleemphasis{Real}
RRC protocol with EPC performing downlink and uplink communication in two
scenarios shown in {\hyperref[\detokenize{lte-user:lena-radio-link-failure-one-enb}]{\sphinxcrossref{\DUrole{std,std-ref}{Scenario A: Radio link failure example with one eNB}}}} and
{\hyperref[\detokenize{lte-user:lena-radio-link-failure-two-enb}]{\sphinxcrossref{\DUrole{std,std-ref}{Scenario B: Radio link failure example with two eNBs}}}}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lena-radio-link-failure-one-enb}.pdf}
\caption{Scenario A: Radio link failure example with one eNB}\label{\detokenize{lte-user:id31}}\label{\detokenize{lte-user:lena-radio-link-failure-one-enb}}\end{figure}

We note that, the RLF detection is enabled by default, which can be disabled by
configuring the \sphinxcode{\sphinxupquote{LteUePhy::EnableRlfDetection}} to false, e.g.,:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Config::SetDefault (\PYGZdq{}ns3::LteUePhy::EnableRlfDetection\PYGZdq{}, BooleanValue (false));
\end{sphinxVerbatim}

In this example, to study the impact of a RLF on the user’s quality of experience,
we compute an instantaneous (i.e., every 200 ms) DL throughput of the UE, and
writes it into a file for plotting purposes. For example, to simulate the “Scenario
A” with \sphinxstyleemphasis{Ideal} and \sphinxstyleemphasis{Real} RRC protocol a user can use the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ideal RRC:
./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}radio\PYGZhy{}link\PYGZhy{}failure
\PYGZhy{}\PYGZhy{}numberOfEnbs=1 \PYGZhy{}\PYGZhy{}useIdealRrc=1
\PYGZhy{}\PYGZhy{}interSiteDistance=1200 \PYGZhy{}\PYGZhy{}n310=1 \PYGZhy{}\PYGZhy{}n311=1
\PYGZhy{}\PYGZhy{}t310=1 \PYGZhy{}\PYGZhy{}enableCtrlErrorModel=1
\PYGZhy{}\PYGZhy{}enableDataErrorModel=1 \PYGZhy{}\PYGZhy{}simTime=25\PYGZdq{}

Real RRC:
./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}radio\PYGZhy{}link\PYGZhy{}failure
\PYGZhy{}\PYGZhy{}numberOfEnbs=1 \PYGZhy{}\PYGZhy{}useIdealRrc=0
\PYGZhy{}\PYGZhy{}interSiteDistance=1200 \PYGZhy{}\PYGZhy{}n310=1 \PYGZhy{}\PYGZhy{}n311=1
\PYGZhy{}\PYGZhy{}t310=1 \PYGZhy{}\PYGZhy{}enableCtrlErrorModel=1
\PYGZhy{}\PYGZhy{}enableDataErrorModel=1 \PYGZhy{}\PYGZhy{}simTime=25\PYGZdq{}
\end{sphinxVerbatim}

After running the above two commands, we can use a simple gnuplot script to plot
the throughput as shown in the Figure {\hyperref[\detokenize{lte-user:fig-lena-radio-link-failure-one-enb-thrput}]{\sphinxcrossref{\DUrole{std,std-ref}{Downlink instantaneous throughput of UE in scenario A}}}}
, e.g.,

\begin{sphinxVerbatim}[commandchars=\\\{\}]
set terminal png
set output  \PYGZdq{}lena\PYGZhy{}radio\PYGZhy{}link\PYGZhy{}failure\PYGZhy{}one\PYGZhy{}enb\PYGZhy{}thrput.png\PYGZdq{}
set multiplot
set xlabel \PYGZdq{}Time [s]\PYGZdq{}
set ylabel \PYGZdq{}Instantaneous throughput UE [Mbps]\PYGZdq{}
set grid
set title \PYGZdq{}LTE RLF example 1 eNB DL instantaneous throughput\PYGZdq{}
plot \PYGZdq{}rlf\PYGZus{}dl\PYGZus{}thrput\PYGZus{}1\PYGZus{}eNB\PYGZus{}ideal\PYGZus{}rrc\PYGZdq{} using (\PYGZdl{}1):(\PYGZdl{}2) with linespoints
title \PYGZsq{}Ideal RRC\PYGZsq{} linestyle 1 lw 2 lc rgb \PYGZsq{}blue\PYGZsq{}, \PYGZdq{}rlf\PYGZus{}dl\PYGZus{}thrput\PYGZus{}1\PYGZus{}eNB\PYGZus{}real\PYGZus{}rrc\PYGZdq{}
using (\PYGZdl{}1):(\PYGZdl{}2) with linespoints title \PYGZsq{}Real RRC\PYGZsq{} linestyle 2 lw 2 lc rgb \PYGZsq{}red\PYGZsq{}

unset multiplot
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lena-radio-link-failure-one-enb-thrput}.png}
\caption{Downlink instantaneous throughput of UE in scenario A}\label{\detokenize{lte-user:id32}}\label{\detokenize{lte-user:fig-lena-radio-link-failure-one-enb-thrput}}\end{figure}

In this scenario, when using the \sphinxstyleemphasis{Ideal} RRC the UE after the RLF will connect
and disconnect from the eNB several times. This is because it can
synchronize (i.e., start reading system information) with an eNB at a low
RSRP level, which is default to \sphinxhyphen{}140 dBm (see QRxLevMin attribute of eNB RRC).
It enables the UE to start the random access procedure with the eNB. With the
\sphinxstyleemphasis{Ideal} RRC, the UE can complete the random access without any errors, since
all the RRC messages are exchanged ideally between the eNB and the UE.
However, soon after the connection establishment, it ends up in RLF due to the
poor channel quality. On the other hand, with the \sphinxstyleemphasis{Real} RRC the UE after the RLF
will not be able to complete the random access procedure due to the poor channel
conditions, thus, will not be able to establish the connection with the eNB.
Therefore, in both the cases the UE throughput drops to zero as shown in the
Figure {\hyperref[\detokenize{lte-user:fig-lena-radio-link-failure-one-enb-thrput}]{\sphinxcrossref{\DUrole{std,std-ref}{Downlink instantaneous throughput of UE in scenario A}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lena-radio-link-failure-two-enb}.pdf}
\caption{Scenario B: Radio link failure example with two eNBs}\label{\detokenize{lte-user:id33}}\label{\detokenize{lte-user:lena-radio-link-failure-two-enb}}\end{figure}

Similarly, to simulate the “Scenario B” with \sphinxstyleemphasis{Ideal} and \sphinxstyleemphasis{Real} RRC protocol
following commands can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Ideal RRC:
./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}radio\PYGZhy{}link\PYGZhy{}failure
\PYGZhy{}\PYGZhy{}numberOfEnbs=2 \PYGZhy{}\PYGZhy{}useIdealRrc=1
\PYGZhy{}\PYGZhy{}interSiteDistance=1200 \PYGZhy{}\PYGZhy{}n310=1 \PYGZhy{}\PYGZhy{}n311=1
\PYGZhy{}\PYGZhy{}t310=1 \PYGZhy{}\PYGZhy{}enableCtrlErrorModel=1
\PYGZhy{}\PYGZhy{}enableDataErrorModel=1 \PYGZhy{}\PYGZhy{}simTime=25\PYGZdq{}

Real RRC:
./waf \PYGZhy{}\PYGZhy{}run \PYGZdq{}lena\PYGZhy{}radio\PYGZhy{}link\PYGZhy{}failure
\PYGZhy{}\PYGZhy{}numberOfEnbs=2 \PYGZhy{}\PYGZhy{}useIdealRrc=0
\PYGZhy{}\PYGZhy{}interSiteDistance=1200 \PYGZhy{}\PYGZhy{}n310=1 \PYGZhy{}\PYGZhy{}n311=1
\PYGZhy{}\PYGZhy{}t310=1 \PYGZhy{}\PYGZhy{}enableCtrlErrorModel=1
\PYGZhy{}\PYGZhy{}enableDataErrorModel=1 \PYGZhy{}\PYGZhy{}simTime=25\PYGZdq{}
\end{sphinxVerbatim}

Figure {\hyperref[\detokenize{lte-user:fig-lena-radio-link-failure-two-enb-thrput}]{\sphinxcrossref{\DUrole{std,std-ref}{Downlink instantaneous throughput of UE in scenario B}}}}, shows the throughput
in “Scenario B”. We note that in this scenario the handover algorithm is not used.
As expected, with \sphinxstyleemphasis{Ideal} RRC protocol the UE after the RLF can complete
the random access procedure with the second eNB. Interestingly, the DL SINR after
the connection establishment is not low enough to trigger the RLF, but it is
low enough to impact the DL control reception for some TBs, which in turn causes
loss of data. It can be observed from the slightly unstable throughput of the UE
after connecting to the second eNB. On the other hand, with \sphinxstyleemphasis{Real} RRC the UE faces
problems in connection establishment phase due to the loss of RRC messages, in
particular, the RRC connection request from the UE. This is the reason why the
UE throughput after the RLF remains zero for a more extended period as compared
to the \sphinxstyleemphasis{ideal} RRC protocol.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lena-radio-link-failure-two-enb-thrput}.png}
\caption{Downlink instantaneous throughput of UE in scenario B}\label{\detokenize{lte-user:id34}}\label{\detokenize{lte-user:fig-lena-radio-link-failure-two-enb-thrput}}\end{figure}


\subsection{Troubleshooting and debugging tips}
\label{\detokenize{lte-user:troubleshooting-and-debugging-tips}}
Many users post on the ns\sphinxhyphen{}3\sphinxhyphen{}users mailing list asking, for example,
why they do not get any traffic in their simulation, or maybe only
uplink but no downlink traffic is generated, etc. In most of the cases,
this is a bug in the user simulation program. Here the reader can find some
tips to debug the program and find out the cause of the problem.

The general approach is to selectively and incrementally enable the logging
of relevant LTE module components, verifying upon each activation that the
output is as expected. In detail:
\begin{itemize}
\item {} 
first check the control plane, in particular the RRC connection
establishment procedure, by enabling the log components LteUeRrc and LteEnbRrc

\item {} 
then check packet transmissions on the data plane, starting by
enabling the log components LteUeNetDevice and the
EpcSgwApplication, EpcPgwApplication and EpcEnbApplication, then moving down the
LTE radio stack (PDCP, RLC, MAC, and finally PHY). All this until
you find where packets stop being processed / forwarded.

\end{itemize}


\section{Testing Documentation}
\label{\detokenize{lte-testing:testing-documentation}}\label{\detokenize{lte-testing::doc}}

\subsection{Overview}
\label{\detokenize{lte-testing:overview}}
To test and validate the ns\sphinxhyphen{}3 LTE module, several test suites are provided which are integrated with the ns\sphinxhyphen{}3 test framework.
To run them, you need to have configured the build of the simulator in this way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}enable\PYGZhy{}modules\PYG{o}{=}lte \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples
\PYGZdl{} ./test.py
\end{sphinxVerbatim}

The above will run not only the test suites belonging to the LTE module, but also those belonging to all the other ns\sphinxhyphen{}3 modules on which the LTE module depends. See the ns\sphinxhyphen{}3 manual for generic information on the testing framework.

You can get a more detailed report in HTML format in this way:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}w results.html
\end{sphinxVerbatim}

After the above command has run, you can view the detailed result for each test by opening the file \sphinxcode{\sphinxupquote{results.html}} with a web browser.

You can run each test suite separately using this command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}s test\PYGZhy{}suite\PYGZhy{}name
\end{sphinxVerbatim}

For more details about \sphinxcode{\sphinxupquote{test.py}} and the ns\sphinxhyphen{}3 testing framework, please refer to the ns\sphinxhyphen{}3 manual.


\subsection{Description of the test suites}
\label{\detokenize{lte-testing:description-of-the-test-suites}}

\subsubsection{Unit Tests}
\label{\detokenize{lte-testing:unit-tests}}

\paragraph{SINR calculation in the Downlink}
\label{\detokenize{lte-testing:sinr-calculation-in-the-downlink}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}downlink\sphinxhyphen{}sinr}}
checks that the SINR calculation in
downlink is performed correctly. The SINR in the downlink is calculated for each
RB assigned to data transmissions by dividing the power of the
intended signal from the considered eNB by the sum of the noise power plus all
the transmissions on the same RB coming from other eNBs (the interference
signals):
\begin{equation*}
\begin{split}\gamma = \frac{ P_\mathrm{signal} }{ P_\mathrm{noise} + \sum P_\mathrm{interference} }\end{split}
\end{equation*}
In general, different signals can be active during different periods
of time. We define a \sphinxstyleemphasis{chunk} as the time interval between any two
events of type either start or end of a waveform. In other words, a
chunk identifies a time interval during which the set of active
waveforms does not change. Let \(i\) be the generic chunk,
\(T_i\) its duration and \(\mathrm{SINR_i}\) its SINR,
calculated with the above equation. The calculation of the average
SINR \(\overline{\gamma}\) to be used for CQI feedback reporting
uses the following formula:
\begin{equation*}
\begin{split}\overline{\gamma} = \frac{ \sum_i {\gamma}_i  T_i }{ \sum_i T_{i} }\end{split}
\end{equation*}
The test suite checks that the above calculation is performed
correctly in the simulator. The test vectors are obtained offline by
an Octave script that implements the above equation, and that
recreates a number of random transmitted signals and interference
signals that mimic a scenario where an UE is trying to decode a signal
from an eNB while facing interference from other eNBs. The test passes
if the calculated values are equal to the test vector within a
tolerance of \(10^{-7}\). The tolerance is meant to account for
the approximation errors typical of floating point arithmetic.


\paragraph{SINR calculation in the Uplink}
\label{\detokenize{lte-testing:sinr-calculation-in-the-uplink}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}uplink\sphinxhyphen{}sinr}} checks that the SINR calculation in
uplink is performed correctly. This test suite is identical to
\sphinxcode{\sphinxupquote{lte\sphinxhyphen{}downlink\sphinxhyphen{}sinr}} described in the previous section, with the
difference than both the signal and the interference now refer to
transmissions by the UEs, and reception is performed by the eNB.
This test suite recreates a number of random transmitted signals and
interference signals to mimic a scenario where an eNB is trying to
decode the signal from several UEs simultaneously (the ones in the
cell of the eNB) while facing interference from other UEs (the ones
belonging to other cells).

The test vectors are obtained by a dedicated Octave script. The test
passes if the calculated values are equal to the test vector within a
tolerance of \(10^{-7}\) which, as for the downlink SINR test,
deals with floating point arithmetic approximation issues.


\paragraph{E\sphinxhyphen{}UTRA Absolute Radio Frequency Channel Number (EARFCN)}
\label{\detokenize{lte-testing:e-utra-absolute-radio-frequency-channel-number-earfcn}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}earfcn}} checks that the carrier frequency used
by the LteSpectrumValueHelper class (which implements the LTE spectrum
model) is done in compliance with \sphinxcite{lte-references:ts36101}, where the E\sphinxhyphen{}UTRA
Absolute Radio Frequency Channel Number (EARFCN) is defined. The test
vector for this test suite comprises a set of EARFCN values and the
corresponding carrier frequency calculated by hand following the
specification of \sphinxcite{lte-references:ts36101}. The test passes if the carrier frequency
returned by LteSpectrumValueHelper is the same as the known value for
each element in the test vector.


\subsubsection{System Tests}
\label{\detokenize{lte-testing:system-tests}}

\paragraph{Dedicated Bearer Deactivation Tests}
\label{\detokenize{lte-testing:dedicated-bearer-deactivation-tests}}
The test suite ‘lte\sphinxhyphen{}test\sphinxhyphen{}deactivate\sphinxhyphen{}bearer’ creates test case with single EnodeB and Three UE’s.
Each UE consists of one Default and one Dedicated EPS bearer with same bearer specification but with different ARP.
Test Case Flow is as follows:
Attach UE \sphinxhyphen{}\textgreater{} Create Default+Dedicated Bearer \sphinxhyphen{}\textgreater{} Deactivate one of the Dedicated bearer

Test case further deactivates dedicated bearer having bearer ID 2(LCID=BearerId+2) of First UE (UE\_ID=1)
User can schedule bearer deactivation after specific time delay using Simulator::Schedule () method.

Once the test case execution ends it will create \sphinxcode{\sphinxupquote{DlRlcStats.txt}} and \sphinxcode{\sphinxupquote{UlRlcStats.txt}}. Key fields that need to be checked in statistics are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{|}Start \PYG{p}{|} end \PYG{p}{|} Cell ID \PYG{p}{|} IMSI \PYG{p}{|} RNTI \PYG{p}{|} LCID \PYG{p}{|} TxBytes \PYG{p}{|} RxBytes \PYG{p}{|}
\end{sphinxVerbatim}

Test case executes in three epochs:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
In first Epoch (0.04s\sphinxhyphen{}1.04s) All UE’s and corresponding bearers gets attached and packet flow over the dedicated bearers activated.

\item {} 
In second Epoch (1.04s\sphinxhyphen{}2.04s), bearer deactivation is instantiated, hence User can see relatively less number of TxBytes on UE\_ID=1 and LCID=4 as compared to other bearers.

\item {} 
In third Epoch (2.04s\sphinxhyphen{}3.04s) since bearer deactivation of UE\_ID=1 and LCID=4 is completed, user will not see any logging related to LCID=4.

\end{enumerate}

Test case passes if and only if
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
IMSI=1 and LCID=4 completely removed in third epoch

\item {} 
No packets seen in TxBytes and RxBytes corresponding to IMSI=1 and LCID=4

\end{enumerate}

If above criteria do not match, the test case is considered to be failed


\paragraph{Adaptive Modulation and Coding Tests}
\label{\detokenize{lte-testing:adaptive-modulation-and-coding-tests}}\label{\detokenize{lte-testing:sec-lte-amc-tests}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}link\sphinxhyphen{}adaptation}} provides system tests recreating a
scenario with a single eNB and a single UE. Different test cases are created
corresponding to different SNR values perceived by the UE. The aim of the test
is to check that in each test case the chosen MCS corresponds to some known
reference values. These reference values are obtained by
re\sphinxhyphen{}implementing in Octave (see \sphinxtitleref{src/lte/test/reference/lte\_amc.m}) the
model described in Section {\hyperref[\detokenize{lte-design:sec-lte-amc}]{\sphinxcrossref{\DUrole{std,std-ref}{Adaptive Modulation and Coding}}}} for the calculation of the
spectral efficiency, and determining the corresponding MCS index
by manually looking up the tables in \sphinxcite{lte-references:r1-081483}. The resulting test vector is
represented in Figure {\hyperref[\detokenize{lte-testing:fig-lte-mcs-index}]{\sphinxcrossref{\DUrole{std,std-ref}{Test vector for Adaptive Modulation and Coding}}}}.

The MCS which is used by the simulator is measured by
obtaining the tracing output produced by the scheduler after 4ms (this
is needed to account for the initial delay in CQI reporting). The SINR
which is calculated by the simulator is also obtained using the
\sphinxcode{\sphinxupquote{LteChunkProcessor}} interface. The test
passes if both the following conditions are satisfied:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
the SINR calculated by the simulator correspond to the SNR
of the test vector within an absolute tolerance of \(10^{-7}\);

\item {} 
the MCS index used by the simulator exactly corresponds to
the one in the test vector.

\end{enumerate}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-mcs-index}.pdf}
\caption{Test vector for Adaptive Modulation and Coding}\label{\detokenize{lte-testing:id12}}\label{\detokenize{lte-testing:fig-lte-mcs-index}}\end{figure}


\paragraph{Inter\sphinxhyphen{}cell Interference Tests}
\label{\detokenize{lte-testing:inter-cell-interference-tests}}
The test suite \sphinxtitleref{lte\sphinxhyphen{}interference} provides system tests recreating an
inter\sphinxhyphen{}cell interference scenario with two eNBs, each having a single
UE attached to it and employing Adaptive Modulation and Coding both in
the downlink and in the uplink. The topology of the scenario
is depicted in Figure {\hyperref[\detokenize{lte-testing:fig-lte-interference-test-scenario}]{\sphinxcrossref{\DUrole{std,std-ref}{Topology for the inter\sphinxhyphen{}cell interference test}}}}. The
\(d_1\) parameter represents the distance of each UE to the eNB it
is attached to, whereas the \(d_2\) parameter represent the
interferer distance. We note that the scenario topology is such that
the interferer distance is the same for uplink and downlink; still,
the actual interference power perceived will be different, because of
the different propagation loss in the uplink and downlink
bands. Different test cases are obtained by varying the \(d_1\)
and \(d_2\) parameters.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-interference-test-scenario}.pdf}
\caption{Topology for the inter\sphinxhyphen{}cell interference test}\label{\detokenize{lte-testing:id13}}\label{\detokenize{lte-testing:fig-lte-interference-test-scenario}}\end{figure}

The test vectors are obtained by use of a dedicated octave script
(available in
\sphinxtitleref{src/lte/test/reference/lte\_link\_budget\_interference.m}), which does
the link budget calculations (including interference) corresponding to the topology of each
test case, and outputs the resulting SINR and spectral efficiency. The
latter is then used to determine (using the same procedure adopted for
{\hyperref[\detokenize{lte-testing:sec-lte-amc-tests}]{\sphinxcrossref{\DUrole{std,std-ref}{Adaptive Modulation and Coding Tests}}}}. We note that the test vector
contains separate values for uplink and downlink.


\paragraph{UE Measurements Tests}
\label{\detokenize{lte-testing:ue-measurements-tests}}
The test suite \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements} provides system tests recreating an
inter\sphinxhyphen{}cell interference scenario identical of the one defined for
\sphinxtitleref{lte\sphinxhyphen{}interference} test\sphinxhyphen{}suite. However, in this test the quantities to be
tested are represented by RSRP and RSRQ measurements performed by the UE in two
different points of the stack: the source, which is UE PHY layer, and the
destination, that is the eNB RRC.

The test vectors are obtained by the use of a dedicated octave script (available
in \sphinxtitleref{src/lte/test/reference/lte\sphinxhyphen{}ue\sphinxhyphen{}measurements.m}), which does the link budget
calculations (including interference) corresponding to the topology of each
test case, and outputs the resulting RSRP and RSRQ. The obtained values are then
used for checking the correctness of the UE Measurements at PHY layer. After
that, they have to be converted according to 3GPP formatting for the purpose of
checking their correctness at eNB RRC level.


\paragraph{UE measurement configuration tests}
\label{\detokenize{lte-testing:ue-measurement-configuration-tests}}
Besides the previously mentioned test suite, there are 3 other test suites for
testing UE measurements: \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}piecewise\sphinxhyphen{}1},
\sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}piecewise\sphinxhyphen{}2}, and \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}handover}. These
test suites are more focused on the reporting trigger procedure, i.e. the
correctness of the implementation of the event\sphinxhyphen{}based triggering criteria is
verified here.

In more specific, the tests verify the \sphinxstyleemphasis{timing} and the \sphinxstyleemphasis{content} of each
measurement reports received by eNodeB. Each test case is an stand\sphinxhyphen{}alone LTE
simulation and the test case will pass if measurement report(s) only occurs at
the prescribed time and shows the correct level of RSRP (RSRQ is not verified at
the moment).


\subparagraph{Piecewise configuration}
\label{\detokenize{lte-testing:piecewise-configuration}}
The piecewise configuration aims to test a particular UE measurements
configuration. The simulation script will setup the corresponding measurements
configuration to the UE, which will be active throughout the simulation.

Since the reference values are precalculated by hands, several assumptions are
made to simplify the simulation. Firstly, the channel is only affected by path
loss model (in this case, Friis model is used). Secondly, the ideal RRC protocol
is used, and layer 3 filtering is disabled. Finally, the UE moves in a
predefined motion pattern between 4 distinct spots, as depicted in Figure
{\hyperref[\detokenize{lte-testing:fig-ue-meas-piecewise-motion}]{\sphinxcrossref{\DUrole{std,std-ref}{UE movement trace throughout the simulation in piecewise configuration}}}} below. Therefore the fluctuation of the
measured RSRP can be determined more easily.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{ue-meas-piecewise-motion}.pdf}
\caption{UE movement trace throughout the simulation in piecewise configuration}\label{\detokenize{lte-testing:id14}}\label{\detokenize{lte-testing:fig-ue-meas-piecewise-motion}}\end{figure}

The motivation behind the \sphinxstyleemphasis{“teleport”} between the predefined spots is to
introduce drastic change of RSRP level, which will guarantee the triggering of
entering or leaving condition of the tested event. By performing drastic
changes, the test can be run within shorter amount of time.

Figure {\hyperref[\detokenize{lte-testing:fig-ue-meas-piecewise-a1}]{\sphinxcrossref{\DUrole{std,std-ref}{Measured RSRP trace of an example Event A1 test case in piecewise
configuration}}}} below shows the measured RSRP after
layer 1 filtering by the PHY layer during the simulation with a piecewise
configuration. Because layer 3 filtering is disabled, these are the exact values
used by the UE RRC instance to evaluate reporting trigger procedure. Notice that
the values are refreshed every 200 ms, which is the default filtering period of
PHY layer measurements report. The figure also shows the time when entering and
leaving conditions of an example instance of Event A1 (serving cell becomes
better than threshold) occur during the simulation.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{ue-meas-piecewise-a1}.pdf}
\caption{Measured RSRP trace of an example Event A1 test case in piecewise
configuration}\label{\detokenize{lte-testing:id15}}\label{\detokenize{lte-testing:fig-ue-meas-piecewise-a1}}\end{figure}

Each reporting criterion is tested several times with different threshold/offset
parameters. Some test scenarios also take hysteresis and time\sphinxhyphen{}to\sphinxhyphen{}trigger into
account. Figure {\hyperref[\detokenize{lte-testing:fig-ue-meas-piecewise-a1-hys}]{\sphinxcrossref{\DUrole{std,std-ref}{Measured RSRP trace of an example Event A1 with hysteresis test case in
piecewise configuration}}}} depicts the effect of
hysteresis in another example of Event A1 test.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{ue-meas-piecewise-a1-hys}.pdf}
\caption{Measured RSRP trace of an example Event A1 with hysteresis test case in
piecewise configuration}\label{\detokenize{lte-testing:id16}}\label{\detokenize{lte-testing:fig-ue-meas-piecewise-a1-hys}}\end{figure}

Piecewise configuration is used in two test suites of UE measurements. The first
one is \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}piecewise\sphinxhyphen{}1}, henceforth Piecewise test \#1, which
simulates 1 UE and 1 eNodeB. The other one is \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}piecewise\sphinxhyphen{}2},
which has 1 UE and 2 eNodeBs in the simulation.

Piecewise test \#1 is intended to test the event\sphinxhyphen{}based criteria which are not
dependent on the existence of a neighboring cell. These criteria include Event
A1 and A2. The other events are also briefly tested to verify that they are
still working correctly (albeit not reporting anything) in the absence of any
neighboring cell. Table {\hyperref[\detokenize{lte-testing:tab-ue-meas-piecewise-1}]{\sphinxcrossref{\DUrole{std,std-ref}{UE measurements test scenarios using piecewise configuration \#1}}}} below lists the
scenarios tested in piecewise test \#1.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{UE measurements test scenarios using piecewise configuration \#1}\label{\detokenize{lte-testing:id17}}\label{\detokenize{lte-testing:tab-ue-meas-piecewise-1}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Test \#
&\sphinxstyletheadfamily 
Reporting Criteria
&\sphinxstyletheadfamily 
Threshold/Offset
&\sphinxstyletheadfamily 
Hysteresis
&\sphinxstyletheadfamily 
Time\sphinxhyphen{}to\sphinxhyphen{}Trigger
\\
\hline
1
&
Event A1
&
Low
&
No
&
No
\\
\hline
2
&
Event A1
&
Normal
&
No
&
No
\\
\hline
3
&
Event A1
&
Normal
&
No
&
Short
\\
\hline
4
&
Event A1
&
Normal
&
No
&
Long
\\
\hline
5
&
Event A1
&
Normal
&
No
&
Super
\\
\hline
6
&
Event A1
&
Normal
&
Yes
&
No
\\
\hline
7
&
Event A1
&
High
&
No
&
No
\\
\hline
8
&
Event A2
&
Low
&
No
&
No
\\
\hline
9
&
Event A2
&
Normal
&
No
&
No
\\
\hline
10
&
Event A2
&
Normal
&
No
&
Short
\\
\hline
11
&
Event A2
&
Normal
&
No
&
Long
\\
\hline
12
&
Event A2
&
Normal
&
No
&
Super
\\
\hline
13
&
Event A2
&
Normal
&
Yes
&
No
\\
\hline
14
&
Event A2
&
High
&
No
&
No
\\
\hline
15
&
Event A3
&
Zero
&
No
&
No
\\
\hline
16
&
Event A4
&
Normal
&
No
&
No
\\
\hline
17
&
Event A5
&
Normal\sphinxhyphen{}Normal
&
No
&
No
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Other events such as Event A3, A4, and A5 depend on measurements of neighbouring
cell, so they are more thoroughly tested in Piecewise test \#2. The simulation
places the nodes on a straight line and instruct the UE to \sphinxstyleemphasis{“jump”} in a similar
manner as in Piecewise test \#1. Handover is disabled in the simulation, so the
role of serving and neighbouring cells do not switch during the simulation.
Table {\hyperref[\detokenize{lte-testing:tab-ue-meas-piecewise-2}]{\sphinxcrossref{\DUrole{std,std-ref}{UE measurements test scenarios using piecewise configuration \#2}}}} below lists the scenarios tested in
Piecewise test \#2.


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{|l|l|l|l|l|}
\sphinxthelongtablecaptionisattop
\caption{UE measurements test scenarios using piecewise configuration \#2\strut}\label{\detokenize{lte-testing:id18}}\label{\detokenize{lte-testing:tab-ue-meas-piecewise-2}}\\*[\sphinxlongtablecapskipadjust]
\hline
\sphinxstyletheadfamily 
Test \#
&\sphinxstyletheadfamily 
Reporting Criteria
&\sphinxstyletheadfamily 
Threshold/Offset
&\sphinxstyletheadfamily 
Hysteresis
&\sphinxstyletheadfamily 
Time\sphinxhyphen{}to\sphinxhyphen{}Trigger
\\
\hline
\endfirsthead

\multicolumn{5}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline
\sphinxstyletheadfamily 
Test \#
&\sphinxstyletheadfamily 
Reporting Criteria
&\sphinxstyletheadfamily 
Threshold/Offset
&\sphinxstyletheadfamily 
Hysteresis
&\sphinxstyletheadfamily 
Time\sphinxhyphen{}to\sphinxhyphen{}Trigger
\\
\hline
\endhead

\hline
\multicolumn{5}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

1
&
Event A1
&
Low
&
No
&
No
\\
\hline
2
&
Event A1
&
Normal
&
No
&
No
\\
\hline
3
&
Event A1
&
Normal
&
Yes
&
No
\\
\hline
4
&
Event A1
&
High
&
No
&
No
\\
\hline
5
&
Event A2
&
Low
&
No
&
No
\\
\hline
6
&
Event A2
&
Normal
&
No
&
No
\\
\hline
7
&
Event A2
&
Normal
&
Yes
&
No
\\
\hline
8
&
Event A2
&
High
&
No
&
No
\\
\hline
9
&
Event A3
&
Positive
&
No
&
No
\\
\hline
10
&
Event A3
&
Zero
&
No
&
No
\\
\hline
11
&
Event A3
&
Zero
&
No
&
Short
\\
\hline
12
&
Event A3
&
Zero
&
No
&
Super
\\
\hline
13
&
Event A3
&
Zero
&
Yes
&
No
\\
\hline
14
&
Event A3
&
Negative
&
No
&
No
\\
\hline
15
&
Event A4
&
Low
&
No
&
No
\\
\hline
16
&
Event A4
&
Normal
&
No
&
No
\\
\hline
17
&
Event A4
&
Normal
&
No
&
Short
\\
\hline
18
&
Event A4
&
Normal
&
No
&
Super
\\
\hline
19
&
Event A4
&
Normal
&
Yes
&
No
\\
\hline
20
&
Event A4
&
High
&
No
&
No
\\
\hline
21
&
Event A5
&
Low\sphinxhyphen{}Low
&
No
&
No
\\
\hline
22
&
Event A5
&
Low\sphinxhyphen{}Normal
&
No
&
No
\\
\hline
23
&
Event A5
&
Low\sphinxhyphen{}High
&
No
&
No
\\
\hline
24
&
Event A5
&
Normal\sphinxhyphen{}Low
&
No
&
No
\\
\hline
25
&
Event A5
&
Normal\sphinxhyphen{}Normal
&
No
&
No
\\
\hline
26
&
Event A5
&
Normal\sphinxhyphen{}Normal
&
No
&
Short
\\
\hline
27
&
Event A5
&
Normal\sphinxhyphen{}Normal
&
No
&
Super
\\
\hline
28
&
Event A5
&
Normal\sphinxhyphen{}Normal
&
Yes
&
No
\\
\hline
29
&
Event A5
&
Normal\sphinxhyphen{}High
&
No
&
No
\\
\hline
30
&
Event A5
&
High\sphinxhyphen{}Low
&
No
&
No
\\
\hline
31
&
Event A5
&
High\sphinxhyphen{}Normal
&
No
&
No
\\
\hline
32
&
Event A5
&
High\sphinxhyphen{}High
&
No
&
No
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}

One note about the tests with time\sphinxhyphen{}to\sphinxhyphen{}trigger, they are tested using 3 different
values of time\sphinxhyphen{}to\sphinxhyphen{}trigger: \sphinxstyleemphasis{short} (shorter than report interval), \sphinxstyleemphasis{long}
(shorter than the filter measurement period of 200 ms), and \sphinxstyleemphasis{super} (longer than
200 ms). The first two ensure that time\sphinxhyphen{}to\sphinxhyphen{}trigger evaluation always use the
latest measurement reports received from PHY layer. While the last one is
responsible for verifying time\sphinxhyphen{}to\sphinxhyphen{}trigger cancellation, for example when a
measurement report from PHY shows that the entering/leaving condition is no
longer true before the first trigger is fired.


\subparagraph{Handover configuration}
\label{\detokenize{lte-testing:handover-configuration}}
The purpose of the handover configuration is to verify whether UE measurement
configuration is updated properly after a successful handover takes place. For
this purpose, the simulation will construct 2 eNodeBs with different UE
measurement configuration, and the UE will perform handover from one cell to
another. The UE will be located on a straight line between the 2 eNodeBs, and
the handover will be invoked manually. The duration of each simulation is
2 seconds (except the last test case) and the handover is triggered exactly at
halfway of simulation.

The \sphinxtitleref{lte\sphinxhyphen{}ue\sphinxhyphen{}measurements\sphinxhyphen{}handover} test suite covers various types of
configuration differences. The first one is the difference in report interval,
e.g. the first eNodeB is configured with 480 ms report interval, while the
second eNodeB is configured with 240 ms report interval. Therefore, when the UE
performed handover to the second cell, the new report interval must take effect.
As in piecewise configuration, the timing and the content of each measurement
report received by the eNodeB will be verified.

Other types of differences covered by the test suite are differences in event
and differences in threshold/offset. Table {\hyperref[\detokenize{lte-testing:tab-ue-meas-handover}]{\sphinxcrossref{\DUrole{std,std-ref}{UE measurements test scenarios using handover configuration}}}} below
lists the tested scenarios.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{UE measurements test scenarios using handover configuration}\label{\detokenize{lte-testing:id19}}\label{\detokenize{lte-testing:tab-ue-meas-handover}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Test \#
&\sphinxstyletheadfamily 
Test Subject
&\sphinxstyletheadfamily 
Initial Configuration
&\sphinxstyletheadfamily 
Post\sphinxhyphen{}Handover Configuration
\\
\hline
1
&
Report interval
&
480 ms
&
240 ms
\\
\hline
2
&
Report interval
&
120 ms
&
640 ms
\\
\hline
3
&
Event
&
Event A1
&
Event A2
\\
\hline
4
&
Event
&
Event A2
&
Event A1
\\
\hline
5
&
Event
&
Event A3
&
Event A4
\\
\hline
6
&
Event
&
Event A4
&
Event A3
\\
\hline
7
&
Event
&
Event A2
&
Event A3
\\
\hline
8
&
Event
&
Event A3
&
Event A2
\\
\hline
9
&
Event
&
Event A4
&
Event A5
\\
\hline
10
&
Event
&
Event A5
&
Event A4
\\
\hline
11
&
Threshold/offset
&
RSRP range 52 (Event A1)
&
RSRP range 56 (Event A1)
\\
\hline
12
&
Threshold/offset
&
RSRP range 52 (Event A2)
&
RSRP range 56 (Event A2)
\\
\hline
13
&
Threshold/offset
&
A3 offset \sphinxhyphen{}30 (Event A3)
&
A3 offset +30 (Event A3)
\\
\hline
14
&
Threshold/offset
&
RSRP range 52 (Event A4)
&
RSRP range 56 (Event A4)
\\
\hline
15
&
Threshold/offset
&
RSRP range 52\sphinxhyphen{}52 (Event A5)
&
RSRP range 56\sphinxhyphen{}56 (Event A5)
\\
\hline
16
&
Time\sphinxhyphen{}to\sphinxhyphen{}trigger
&
1024 ms
&
100 ms
\\
\hline
17
&
Time\sphinxhyphen{}to\sphinxhyphen{}trigger
&
1024 ms
&
640 ms
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\paragraph{Round Robin scheduler performance}
\label{\detokenize{lte-testing:round-robin-scheduler-performance}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}rr\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} creates different test cases with
a single eNB and several UEs, all having the same Radio Bearer specification. In
each test case, the UEs see the same SINR from the eNB; different test cases are
implemented by using different distance among UEs and the eNB (i.e., therefore
having different SINR values) and different numbers of UEs. The test consists on
checking that the obtained throughput performance is equal among users and
matches a reference throughput value obtained according to the SINR perceived
within a given tolerance.

The test vector is obtained according to the values of transport block
size reported in table 7.1.7.2.1\sphinxhyphen{}1 of \sphinxcite{lte-references:ts36213}, considering an
equal distribution of the physical resource block among the users
using Resource Allocation Type 0 as defined in Section 7.1.6.1 of
\sphinxcite{lte-references:ts36213}.  Let \(\tau\) be the TTI duration, \(N\) be the
number of UEs, \(B\) the transmission bandwidth configuration in
number of RBs, \(G\) the RBG size, \(M\) the modulation and
coding scheme in use at the given SINR and \(S(M, B)\) be the
transport block size in bits as defined by 3GPP TS 36.213. We first
calculate the number \(L\) of RBGs allocated to each user as
\begin{equation*}
\begin{split}L = \left\lfloor \frac{B}{NG} \right\rfloor\end{split}
\end{equation*}
The reference throughput \(T\) in bit/s achieved by each UE is then calculated as
\begin{equation*}
\begin{split}T =  \frac{S(M, L G)}{8 \; \tau}\end{split}
\end{equation*}
The test passes if the measured throughput matches with the reference throughput
within a relative tolerance of 0.1. This tolerance is needed to account for the
transient behavior at the beginning of the simulation (e.g., CQI feedback is
only available after a few subframes) as well as for the accuracy of the
estimator of the average throughput performance over the chosen simulation time
(0.4s). This choice of the simulation time is justified by the need to
follow the ns\sphinxhyphen{}3 guidelines of keeping the total execution time of the test
suite low, in spite of the high number of test cases. In any case, we note that
a lower value of the tolerance can be used when longer simulations are
run.

In Figure {\hyperref[\detokenize{lte-testing:fig-lenathrtestcase1}]{\sphinxcrossref{fig\sphinxhyphen{}lenaThrTestCase1}}}, the curves labeled “RR” represent the test values
calculated for the RR scheduler test, as a function of the number of UEs and of
the MCS index being used in each test case.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lenaThrTestCase1}.pdf}
\caption{Test vectors for the RR and PF Scheduler in the downlink in a
scenario where all UEs use the same MCS.}\label{\detokenize{lte-testing:id20}}\label{\detokenize{lte-testing:fig-lenathrtestcase1}}\end{figure}


\paragraph{Proportional Fair scheduler performance}
\label{\detokenize{lte-testing:proportional-fair-scheduler-performance}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}pf\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} creates different test cases with
a single eNB, using the Proportional Fair (PF) scheduler, and several UEs, all
having the same Radio Bearer specification. The test cases are grouped in two
categories in order to evaluate the performance both in terms of the adaptation
to the channel condition and from a fairness perspective.

In the first category of test cases, the UEs are all placed at the
same distance from the eNB, and hence all placed in order to have the
same SINR. Different test cases are implemented by using a different
SINR value and a different number of UEs. The test consists on
checking that the obtained throughput performance matches with the
known reference throughput up to a given tolerance. The expected
behavior of the PF scheduler when all UEs have the same SNR is that
each UE should get an equal fraction of the throughput obtainable by a
single UE when using all the resources. We calculate the reference
throughput value by dividing the throughput achievable by a single UE
at the given SNR by the total number of UEs.
Let \(\tau\) be the TTI duration, \(B\) the transmission
bandwidth configuration in number of RBs, \(M\) the modulation and
coding scheme in use at the given SINR and \(S(M, B)\) be the
transport block size as defined in \sphinxcite{lte-references:ts36213}. The reference
throughput \(T\) in bit/s achieved by each UE is calculated as
\begin{equation*}
\begin{split}T = \frac{S(M,B)}{\tau N}\end{split}
\end{equation*}
The curves labeled “PF” in Figure {\hyperref[\detokenize{lte-testing:fig-lenathrtestcase1}]{\sphinxcrossref{fig\sphinxhyphen{}lenaThrTestCase1}}} represent the test values
calculated for the PF scheduler tests of the first category, that we just described.

The second category of tests aims at verifying the fairness of the PF
scheduler in a more realistic simulation scenario where the UEs have a
different SINR (constant for the whole simulation). In these conditions, the PF
scheduler will give to each user a share of the system bandwidth that is
proportional to the capacity achievable by a single user alone considered its
SINR. In detail, let \(M_i\) be the modulation and coding scheme being used by
each UE (which is a deterministic function of the SINR of the UE, and is hence
known in this scenario). Based on the MCS, we determine the achievable
rate \(R_i\) for each user \(i\) using the
procedure described in Section\textasciitilde{}ref\{sec:pfs\}. We then define the
achievable rate ratio \(\rho_{R,i}\) of each user \(i\) as
\begin{equation*}
\begin{split}\rho_{R,i} = \frac{R_i}{\sum_{j=1}^N R_j}\end{split}
\end{equation*}
Let now \(T_i\) be the throughput actually achieved by the UE \(i\) , which
is obtained as part of the simulation output. We define the obtained throughput
ratio \(\rho_{T,i}\) of UE \(i\) as
\begin{equation*}
\begin{split}\rho_{T,i} = \frac{T_i}{\sum_{j=1}^N T_j}\end{split}
\end{equation*}
The test consists of checking that the following condition is verified:
\begin{equation*}
\begin{split}\rho_{R,i} = \rho_{T,i}\end{split}
\end{equation*}
if so, it means that the throughput obtained by each UE over the whole
simulation matches with the steady\sphinxhyphen{}state throughput expected by the PF scheduler
according to the theory. This test can be derived from \sphinxcite{lte-references:holtzman2000}
as follows. From Section 3 of \sphinxcite{lte-references:holtzman2000}, we know that
\begin{equation*}
\begin{split}\frac{T_i}{R_i} = c, \, \forall i\end{split}
\end{equation*}
where \(c\) is a constant. By substituting the above into the
definition of \(\rho_{T,i}\) given previously, we get
\begin{equation*}
\begin{split}\frac{T_i}{\sum_{j=1}^N T_j} &=  \frac{c R_i}{\sum_{j=1}^N c R_j} \\
                             &=  \frac{c R_i}{c \sum_{j=1}^N  R_j} \\
                             &=  \frac{R_i}{\sum_{j=1}^N  R_j}\end{split}
\end{equation*}
which is exactly the expression being used in the test.

Figure {\hyperref[\detokenize{lte-testing:fig-lenathrtestcase2}]{\sphinxcrossref{\DUrole{std,std-ref}{Throughput ratio evaluation for the PF scheduler in a scenario
where the UEs have MCS index 28, 24, 16, 12, 6}}}} presents the results obtained in a test case with
UEs \(i=1,\dots,5\) that are located at a distance from the base
station such that they will use respectively the MCS index \(28, 24, 16, 12,
6\). From the figure, we note that, as expected, the obtained throughput is
proportional to the achievable rate. In other words, the PF scheduler assign
more resources to the users that use a higher MCS index.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lenaThrTestCase2}.pdf}
\caption{Throughput ratio evaluation for the PF scheduler in a scenario
where the UEs have MCS index \(28, 24, 16, 12, 6\)}\label{\detokenize{lte-testing:id21}}\label{\detokenize{lte-testing:fig-lenathrtestcase2}}\end{figure}


\paragraph{Maximum Throughput scheduler performance}
\label{\detokenize{lte-testing:maximum-throughput-scheduler-performance}}
Test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}fdmt\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} and \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}tdmt\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}}
create different test cases with a single eNB and several UEs, all having the same
Radio Bearer specification, using the Frequency Domain Maximum Throughput (FDMT)
scheduler and Time Domain Maximum Throughput (TDMT) scheduler respectively.
In other words, UEs are all placed at the
same distance from the eNB, and hence all placed in order to have the
same SNR. Different test cases are implemented by using a different
SNR values and a different number of UEs. The test consists on
checking that the obtained throughput performance matches with the
known reference throughput up to a given tolerance.The expected
behavior of both FDMT and TDMT scheduler when all UEs have the same SNR is that
scheduler allocates all RBGs to the first UE defined in script. This is because
the current FDMT and TDMT implementation always select the first UE to serve when there are
multiple UEs having the same SNR value. We calculate the reference
throughput value for first UE by the throughput achievable of a single UE
at the given SNR, while reference throughput value for other UEs by zero.
Let \(\tau\) be the TTI duration, \(B\) the transmission
bandwidth configuration in number of RBs, \(M\) the modulation and
coding scheme in use at the given SNR and \(S(M, B)\) be the
transport block size as defined in \sphinxcite{lte-references:ts36213}. The reference
throughput \(T\) in bit/s achieved by each UE is calculated as
\begin{equation*}
\begin{split}T = \frac{S(M,B)}{\tau}\end{split}
\end{equation*}

\paragraph{Throughput to Average scheduler performance}
\label{\detokenize{lte-testing:throughput-to-average-scheduler-performance}}
Test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}tta\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}}
create different test cases with a single eNB and several UEs, all having the same
Radio Bearer specification using TTA scheduler. Network topology and configurations in
TTA test case are as the same as the test for MT scheduler. More complex test case needs to be
developed to show the fairness feature of TTA scheduler.


\paragraph{Blind Average Throughput scheduler performance}
\label{\detokenize{lte-testing:blind-average-throughput-scheduler-performance}}
Test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}tdbet\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} and \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}fdbet\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} create different
test cases with a single eNB and several UEs, all having the same Radio Bearer specification.

In the first test case of \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}tdbet\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} and \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}fdbet\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}},
the UEs are all placed at the same distance from the eNB, and hence all placed in order to
have the same SNR. Different test cases are implemented by using a different SNR value and
a different number of UEs. The test consists on checking that the obtained throughput performance
matches with the known reference throughput up to a given tolerance. In long term, the expected
behavior of both TD\sphinxhyphen{}BET and FD\sphinxhyphen{}BET when all UEs have the same SNR is that each UE should get an
equal throughput. However, the exact throughput value of TD\sphinxhyphen{}BET and FD\sphinxhyphen{}BET in this test case is not
the same.

When all UEs have the same SNR, TD\sphinxhyphen{}BET can be seen as a specific case of PF where achievable rate equals
to 1. Therefore, the throughput obtained by TD\sphinxhyphen{}BET is equal to that of PF. On the other hand, FD\sphinxhyphen{}BET performs
very similar to the round robin (RR) scheduler in case of that all UEs have the same SNR and the number of UE( or RBG)
is an integer multiple of the number of RBG( or UE). In this case, FD\sphinxhyphen{}BET always allocate the same number of RBGs
to each UE. For example, if eNB has 12 RBGs and there are 6 UEs, then each UE will get 2 RBGs in each TTI.
Or if eNB has 12 RBGs and there are 24 UEs, then each UE will get 2 RBGs per two TTIs. When the number of
UE (RBG) is not an integer multiple of the number of RBG (UE), FD\sphinxhyphen{}BET will not follow the RR behavior because
it will assigned different number of RBGs to some UEs, while the throughput of each UE is still the same.

The second category of tests aims at verifying the fairness of the both TD\sphinxhyphen{}BET and FD\sphinxhyphen{}BET schedulers in a more realistic
simulation scenario where the UEs have a different SNR (constant for the whole simulation). In this case,
both scheduler should give the same amount of averaged throughput to each user.

Specifically, for TD\sphinxhyphen{}BET, let \(F_i\) be the fraction of time allocated to user i in total simulation time,
\(R^{fb}_i\) be the full bandwidth achievable rate for user i and \(T_i\) be the achieved throughput of
user i. Then we have:
\begin{equation*}
\begin{split}T_i = F_i R^{fb}_i\end{split}
\end{equation*}
In TD\sphinxhyphen{}BET, the sum of \(F_i\) for all user equals one. In long term, all UE has the same \(T_i\) so that we replace
\(T_i\) by \(T\).  Then we have:
\begin{equation*}
\begin{split}T = \frac{1}{ \sum_{i=1}^{N} \frac{1}{R^{fb}_i} }\end{split}
\end{equation*}

\paragraph{Token Band Fair Queue scheduler performance}
\label{\detokenize{lte-testing:token-band-fair-queue-scheduler-performance}}
Test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}fdtbfq\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} and \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}tdtbfq\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} create different
test cases for testing three key features of TBFQ scheduler: traffic policing, fairness and traffic
balance. Constant Bit Rate UDP traffic is used in both downlink and uplink in all test cases.
The packet interval is set to 1ms to keep the RLC buffer non\sphinxhyphen{}empty. Different traffic rate is
achieved by setting different packet size. Specifically, two classes of flows are created in the
test suites:
\begin{itemize}
\item {} 
Homogeneous flow: flows with the same token generation rate and packet arrival rate

\item {} 
Heterogeneous flow: flows with different packet arrival rate, but with the same token generation rate

\end{itemize}

In test case 1 verifies traffic policing and fairness features for the scenario that all UEs are
placed at the same distance from the eNB. In this case, all Ues have the same SNR value. Different
test cases are implemented by using a different SNR value and a different number of UEs. Because each
flow have the same traffic rate and token generation rate, TBFQ scheduler will guarantee the same
throughput among UEs without the constraint of token generation rate. In addition, the exact value
of UE throughput is depended on the total traffic rate:
\begin{itemize}
\item {} 
If total traffic rate \textless{}= maximum throughput, UE throughput = traffic rate

\item {} 
If total traffic rate \textgreater{} maximum throughput,  UE throughput = maximum throughput / N

\end{itemize}

Here, N is the number of UE connected to eNodeB. The maximum throughput in this case equals to the rate
that all RBGs are assigned to one UE(e.g., when distance equals 0, maximum throughput is 2196000 byte/sec).
When the traffic rate is smaller than max bandwidth, TBFQ can police the traffic by token generation rate
so that the UE throughput equals its actual traffic rate (token generation rate is set to traffic
generation rate); On the other hand, when total traffic rate is bigger than the max throughput, eNodeB
cannot forward all traffic to UEs. Therefore, in each TTI, TBFQ will allocate all RBGs to one UE due to
the large packets buffered in RLC buffer. When  a UE is scheduled in current TTI, its token counter is decreased
so that it will not be scheduled in the next TTI. Because each UE has the same traffic generation rate,
TBFQ will serve each UE in turn and only serve one UE in each TTI (both in TD TBFQ and FD TBFQ).
Therefore, the UE throughput in the second condition equals to the evenly share of maximum throughput.

Test case 2 verifies traffic policing and fairness features for the scenario that each UE is placed at
the different distance from the eNB. In this case, each UE has the different SNR value. Similar to test
case 1, UE throughput in test case 2 is also depended on the total traffic rate but with a different
maximum throughput. Suppose all UEs have a high traffic load. Then the traffic will saturate the RLC buffer
in eNodeB. In each TTI, after selecting one UE with highest metric, TBFQ will allocate all RBGs to this
UE due to the large RLC buffer size. On the other hand, once RLC buffer is saturated, the total throughput
of all UEs cannot increase any more. In addition, as we discussed in test case 1, for homogeneous flows
which have the same t\_i and r\_i, each UE will achieve the same throughput in long term. Therefore, we
can use the same method in TD BET to calculate the maximum throughput:
\begin{equation*}
\begin{split}T = \frac{N}{ \sum_{i=1}^{N} \frac{1}{R^{fb}_i} }\end{split}
\end{equation*}
Here, \(T\) is the maximum throughput. \(R^{fb}_i\) be the full bandwidth achievable rate
for user i. \(N\) is the number of UE.

When the total traffic rate is bigger than \(T\), the UE throughput equals to \(\frac{T}{N}\) . Otherwise, UE throughput
equals to its traffic generation rate.

In test case 3, three flows with different traffic rate are created. Token generation rate for each
flow is the same and equals to the average traffic rate of three flows. Because TBFQ use a shared token
bank, tokens contributed by UE with lower traffic load can be utilized by UE with higher traffic load.
In this way, TBFQ can guarantee the traffic rate for each flow. Although we use heterogeneous flow here,
the calculation of maximum throughput is as same as that in test case 2. In calculation max throughput
of test case 2, we assume that all UEs suffer high traffic load so that scheduler always assign all RBGs
to one UE in each TTI. This assumes is also true in heterogeneous flow case. In other words, whether
those flows have the same traffic rate and token generation rate, if their traffic rate is bigger enough,
TBFQ performs as same as it in test case 2. Therefore, the maximum bandwidth in test case 3 is as
same as it in test case 2.

In test case 3, in some flows, token generate rate does not equal to MBR, although all flows are CBR
traffic. This is not accorded with our parameter setting rules. Actually, the traffic balance feature
is used in VBR traffic. Because different UE’s peak rate may occur in different time, TBFQ use shared
token bank to balance the traffic among those VBR traffics. Test case 3 use CBR traffic to verify this
feature. But in the real simulation, it is recommended to set token generation rate to MBR.


\paragraph{Priority Set scheduler performance}
\label{\detokenize{lte-testing:priority-set-scheduler-performance}}
Test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}pss\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}} create different test cases with a single eNB and several UEs.
In all test cases, we select PFsch in FD scheduler. Same testing results can also be obtained by using CoItA
scheduler. In addition, all test cases do not define nMux so that TD scheduler in PSS will always select half
of total UE.

In the first class test case of \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}pss\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}}, the UEs are all placed at the same distance from
the eNB, and hence all placed in order to have the same SNR. Different test cases are implemented
by using a different TBR for each UEs. In each test cases, all UEs have the same
Target Bit Rate configured by GBR in EPS bear setting. The expected behavior of PSS is to guarantee that
each UE’s throughput at least equals its TBR if the total flow rate is blow maximum throughput. Similar
to TBFQ, the maximum throughput in this case equals to the rate that all RBGs are assigned to one UE.
When the traffic rate is smaller than max bandwidth, the UE throughput equals its actual traffic rate;
On the other hand, UE throughput equals to the evenly share of the maximum throughput.

In the first class of test cases, each UE has the same SNR. Therefore, the priority metric in PF scheduler will be
determined by past average throughput \(T_{j}(t)\) because each UE has the same achievable throughput
\(R_{j}(k,t)\) in PFsch or same \(CoI[k,n]\) in CoItA. This means that PSS will performs like a
TD\sphinxhyphen{}BET which allocates all RBGs to one UE in each TTI. Then the maximum value of UE throughput equals to
the achievable rate that all RBGs are allocated to this UE.

In the second class of test case of \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}pss\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}}, the UEs are all placed at the same distance from
the eNB, and hence all placed in order to have the same SNR. Different TBR values are assigned to each UE.
There also exist an maximum throughput in this case. Once total traffic rate is bigger than this threshold,
there will be some UEs that cannot achieve their TBR. Because there is no fading, subband CQIs for each
RBGs frequency are the same. Therefore, in FD scheduler,in each TTI, priority metrics of UE for all RBGs
are the same. This means that FD scheduler will always allocate all RBGs to one user. Therefore, in the
maximum throughput case, PSS performs like a TD\sphinxhyphen{}BET. Then we have:
\begin{equation*}
\begin{split}T = \frac{N}{ \sum_{i=1}^N \frac{1}{R^{fb}_i} }\end{split}
\end{equation*}
Here, \(T\) is the maximum throughput. \(R^{fb}_i\) be the full bandwidth achievable rate
for user i. \(N\) is the number of UE.


\paragraph{Channel and QoS aware scheduler performance}
\label{\detokenize{lte-testing:channel-and-qos-aware-scheduler-performance}}
The performance of the Channel and QoS aware scheduler can be tested in the similar way to performance of
Priority Set scheduler when GBR flows are not delay sensitive by measuring if the achieved throughput at
RLC layer is close to the TBR. Having this in mind, the performance of the CQA scheduler is tested by using
the same test cases as the \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}pss\sphinxhyphen{}ff\sphinxhyphen{}mac\sphinxhyphen{}scheduler}}. Additionally, in \sphinxcite{lte-references:bbojovic2014} can be found performance
evaluation of CQA scheduler when the GBR flows are delay sensitive by considering different QoE metrics.


\paragraph{Building Propagation Loss Model}
\label{\detokenize{lte-testing:building-propagation-loss-model}}
The aim of the system test is to verify the integration of the
BuildingPathlossModel with the lte module. The test exploits a set of
three pre calculated losses for generating the expected SINR at the
receiver counting the transmission and the noise powers. These SINR
values are compared with the results obtained from a LTE
simulation that uses the BuildingPathlossModel. The reference loss values are
calculated off\sphinxhyphen{}line with an Octave script
(/test/reference/lte\_pathloss.m). Each test case passes if the
reference loss value is equal to the value calculated by the simulator
within a tolerance of \(0.001\) dB, which accounts for numerical
errors in the calculations.


\paragraph{Physical Error Model}
\label{\detokenize{lte-testing:physical-error-model}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}phy\sphinxhyphen{}error\sphinxhyphen{}model}} generates different test cases for
evaluating both data and control error models. For what concern the data, the
test consists of six test cases with single eNB and a various number of UEs,
all having the same Radio Bearer specification. Each test is designed for
evaluating the error rate perceived by a specific TB size in order to verify
that it corresponds to the expected values according to the BLER generated for
CB size analog to the TB size. This means that, for instance, the test will
check that the performance of a TB of \(N\) bits is analogous to the one of
a CB size of \(N\) bits by collecting the performance of a user which has
been forced the generation of a such TB size according to the distance to eNB.
In order to significantly test the BLER at MAC level, we configured the Adaptive
Modulation and Coding (AMC) module, the \sphinxcode{\sphinxupquote{LteAmc}} class, for making it less
robust to channel conditions by using the PiroEW2010 AMC model and configuring
it to select the MCS considering a target BER of 0.03 (instead of the default
value of 0.00005). We note that these values do not reflect the actual BER,
since they come from an analytical bound which does not consider all the
transmission chain aspects; therefore the BER and BLER actually experienced at
the reception of a TB is in general different.

The parameters of the six test cases are reported in the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
4 UEs placed 1800 meters far from the eNB, which implies the use of MCS 2
(SINR of \sphinxhyphen{}5.51 dB) and a TB of 256 bits, that in turns produce a BLER of 0.33
(see point A in figure {\hyperref[\detokenize{lte-testing:fig-mcs-2-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for tests 1, 2, 3.}}}}).

\item {} 
2 UEs placed 1800 meters far from the eNB, which implies the use of MCS 2
(SINR of \sphinxhyphen{}5.51 dB) and a TB of 528 bits, that in turns produce a BLER of 0.11
(see point B in figure {\hyperref[\detokenize{lte-testing:fig-mcs-2-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for tests 1, 2, 3.}}}}).

\item {} 
1 UE placed 1800 meters far from the eNB, which implies the use of MCS 2
(SINR of \sphinxhyphen{}5.51 dB) and a TB of 1088 bits, that in turns produce a BLER of
0.02 (see point C in figure {\hyperref[\detokenize{lte-testing:fig-mcs-2-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for tests 1, 2, 3.}}}}).

\item {} 
1 UE placed 600 meters far from the eNB, which implies the use of MCS 12
(SINR of 4.43 dB) and a TB of 4800 bits, that in turns produce a BLER of 0.3
(see point D in figure {\hyperref[\detokenize{lte-testing:fig-mcs-12-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for tests 4, 5.}}}}).

\item {} 
3 UEs placed 600 meters far from the eNB, which implies the use of MCS 12
(SINR of 4.43 dB) and a TB of 1632 bits, that in turns produce a BLER of 0.55
(see point E in figure {\hyperref[\detokenize{lte-testing:fig-mcs-12-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for tests 4, 5.}}}}).

\item {} 
1 UE placed 470 meters far from the eNB, which implies the use of MCS 16
(SINR of 8.48 dB) and a TB of 7272 bits (segmented in 2 CBs of 3648 and 3584
bits), that in turns produce a BLER of 0.14, since each CB has CBLER equal to
0.075 (see point F in figure {\hyperref[\detokenize{lte-testing:fig-mcs-14-test}]{\sphinxcrossref{\DUrole{std,std-ref}{BLER for test 6.}}}}).

\end{enumerate}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_2_test}.pdf}
\caption{BLER for tests 1, 2, 3.}\label{\detokenize{lte-testing:id22}}\label{\detokenize{lte-testing:fig-mcs-2-test}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_12_test}.pdf}
\caption{BLER for tests 4, 5.}\label{\detokenize{lte-testing:id23}}\label{\detokenize{lte-testing:fig-mcs-12-test}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{MCS_16_test}.pdf}
\caption{BLER for test 6.}\label{\detokenize{lte-testing:id24}}\label{\detokenize{lte-testing:fig-mcs-14-test}}\end{figure}

The test condition verifies that in each test case the expected number of
packets received correctly corresponds to a Bernoulli distribution with a
confidence interval of 99\%, where the probability of success in each trail is
\(p=1-BER\) and \(n\) is the total number of packets sent.

The error model of PCFICH\sphinxhyphen{}PDCCH channels consists of 4 test cases with a single
UE and several eNBs, where the UE is connected to only one eNB in order to have
the remaining acting as interfering ones. The errors on data are disabled in
order to verify only the ones due to erroneous decodification of PCFICH\sphinxhyphen{}PDCCH.
As before, the system has been forced on working in a less conservative fashion
in the AMC module for appreciating the results in border situations. The
parameters of the 4 tests cases are reported in the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
2 eNBs placed 1078 meters far from the UE, which implies a SINR of \sphinxhyphen{}2.00 dB
and a TB of 217 bits, that in turns produce a BLER of 0.007.

\item {} 
3 eNBs placed 1040 meters far from the UE, which implies a SINR of \sphinxhyphen{}4.00 dB
and a TB of 217 bits, that in turns produce a BLER of 0.045.

\item {} 
4 eNBs placed 1250 meters far from the UE, which implies a SINR of \sphinxhyphen{}6.00 dB
and a TB of 133 bits, that in turns produce a BLER of 0.206.

\item {} 
5 eNBs placed 1260 meters far from the UE, which implies a SINR of \sphinxhyphen{}7.00 dB
and a TB of 81 bits, that in turns produce a BLER of 0.343.

\end{enumerate}

The test condition verifies that in each test case the expected number
of packets received correct corresponds to a Bernoulli distribution
with a confidence interval of 99.8\%, where the probability of success
in each trail is \(p=1-BER\) and \(n\) is the total number of
packet sent. The larger confidence interval is due to the errors that
might be produced in quantizing the MI and the error curve.


\paragraph{HARQ Model}
\label{\detokenize{lte-testing:harq-model}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}harq}} includes two tests for evaluating the HARQ model and the related extension in the error model. The test consists on checking whether the amount of bytes received during the simulation corresponds to the expected ones according to the values of transport block and the HARQ dynamics. In detail, the test checks whether the throughput obtained after one HARQ retransmission is the expected one. For evaluating the expected throughput the expected TB delivering time has been evaluated according to the following formula:
\begin{equation*}
\begin{split}\mathrm{T} = P_s^1 \times 1 + P_s^2 \times 2 + (1-P_s^2) \times 3\end{split}
\end{equation*}
where \(P_s^i\) is the probability of receiving with success the HARQ block at the attempt \(i\) (i.e., the RV with 3GPP naming). According to the scenarios, in the test we always have \(P_s^1\) equal to 0.0, while \(P_s^2\) varies in the two tests, in detail:
\begin{align*}\!\begin{aligned}
\mathrm{T_{test-1}} = 0.0 \times 1 + 0.926 \times 2 + 0.074 \times 3 = 2.074\\
\mathrm{T_{test-2}} = 0.0 \times 1 + 0.752 \times 2 + 0.248 \times 3 = 2.248\\
\end{aligned}\end{align*}
The expected throughput is calculted by counting the number of transmission slots available during the simulation (e.g., the number of TTIs) and the size of the TB in the simulation, in detail:
\begin{equation*}
\begin{split}\mathrm{Thr_{test-i}} = \frac{TTI_{NUM}}{T_{test-i}} TB_{size} = \left\{ \begin{array}{lll} \dfrac{1000}{2.074}66 = 31822\mbox{ bps} & \mbox{ for test-1} \\ & \\ \dfrac{1000}{2.248}472 = 209964\mbox{ bps} & \mbox{ for test-2}\end{array} \right.\end{split}
\end{equation*}
where \(TTI_{NUM}\) is the total number of TTIs in 1 second.
The test is performed both for Round Robin scheduler. The test passes if the measured throughput matches with the reference throughput within a relative tolerance of 0.1. This tolerance is needed to account for the transient behavior at the beginning of the simulation and the on\sphinxhyphen{}fly blocks at the end of the simulation.


\paragraph{MIMO Model}
\label{\detokenize{lte-testing:mimo-model}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}mimo}} aims at verifying both the effect of the gain considered for each Transmission Mode on the system performance and the Transmission Mode switching through the scheduler interface. The test consists on checking whether the amount of bytes received during a certain window of time (0.1 seconds in our case) corresponds to the expected ones according to the values of transport block
size reported in table 7.1.7.2.1\sphinxhyphen{}1 of \sphinxcite{lte-references:ts36213}, similarly to what done for the tests of the schedulers.

The test is performed both for Round Robin and Proportional Fair schedulers. The test passes if the measured throughput matches with the reference throughput within a relative tolerance of 0.1. This tolerance is needed to account for the
transient behavior at the beginning of the simulation and the transition phase between the Transmission Modes.


\paragraph{Antenna Model integration}
\label{\detokenize{lte-testing:antenna-model-integration}}
The test suite \sphinxtitleref{lte\sphinxhyphen{}antenna} checks that the AntennaModel integrated
with the LTE model works correctly. This test suite recreates a
simulation scenario with one eNB node at coordinates (0,0,0) and one
UE node at coordinates (x,y,0). The eNB node is configured with an
CosineAntennaModel having given orientation and beamwidth. The UE
instead uses the default IsotropicAntennaModel. The test
checks that the received power both in uplink and downlink account for
the correct value of the antenna gain, which is determined
offline; this is implemented by comparing the uplink and downlink SINR
and checking that both match with the reference value up to a
tolerance of \(10^{-6}\) which accounts for numerical errors.
Different test cases are provided by varying the x and y coordinates
of the UE,  and the beamwidth and the orientation of the antenna of
the eNB.


\paragraph{RLC}
\label{\detokenize{lte-testing:rlc}}
Two test suites \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}rlc\sphinxhyphen{}um\sphinxhyphen{}transmitter}} and
\sphinxcode{\sphinxupquote{lte\sphinxhyphen{}rlc\sphinxhyphen{}am\sphinxhyphen{}transmitter}} check that the UM RLC and the AM RLC
implementation work correctly. Both these suites work by testing RLC
instances connected to special test entities that play the role of the
MAC and of the PDCP, implementing respectively the LteMacSapProvider
and LteRlcSapUser interfaces. Different test cases (i.e., input test
vector consisting of series of primitive calls by the MAC and the
PDCP) are provided that check the behavior in the following cases:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
one SDU, one PDU: the MAC notifies a TX opportunity causes the creation of a PDU which exactly
contains a whole SDU

\item {} 
segmentation: the MAC notifies multiple TX opportunities that are smaller than the SDU
size stored in the transmission buffer, which is then to be fragmented and hence
multiple PDUs are generated;

\item {} 
concatenation: the MAC notifies a TX opportunity that is bigger than the SDU, hence
multiple SDUs are concatenated in the same PDU

\item {} 
buffer status report: a series of new SDUs notifications by the
PDCP is inteleaved with a series of TX opportunity notification in
order to verify that the buffer status report procedure is
correct.

\end{enumerate}

In all these cases, an output test vector is determine manually from
knowledge of the input test vector and knowledge of the expected
behavior. These test vector are specialized for UM RLC and
AM RLC due to their different behavior. Each test case passes if the
sequence of primitives triggered by the RLC instance being tested is
exactly equal to the output test vector. In particular, for each PDU
transmitted by the RLC instance, both the size and the content of the
PDU are verified to check for an exact match with the test vector.

The AM RLC implementation features an additional test suite,
\sphinxcode{\sphinxupquote{lte\sphinxhyphen{}rlc\sphinxhyphen{}am\sphinxhyphen{}e2e}}, which test the correct retransmission of RLC PDUs
in presence of channel losses. The test instantiates an RLC AM
transmitter and a receiver, and interposes a channel that randomly
drops packet according to a fixed loss probability. Different test
cases are instantiated using different \sphinxcode{\sphinxupquote{RngRun}} values and different
loss probability values. Each test case passes if at the end of the
simulation all SDUs are correctly delivered to the upper layers of the
receiving RLC AM entity.


\paragraph{RRC}
\label{\detokenize{lte-testing:rrc}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}rrc}} tests the correct functionality of the following aspects:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
MAC Random Access

\item {} 
RRC System Information Acquisition

\item {} 
RRC Connection Establishment

\item {} 
RRC Reconfiguration

\end{enumerate}

The test suite considers a type of scenario with four eNBs aligned in a square
layout with 100\sphinxhyphen{}meter edges. Multiple UEs are located at a specific spot on the
diagonal of the square and are instructed to connect to the first eNB. Each test
case implements an instance of this scenario with specific values of the
following parameters:
\begin{itemize}
\item {} 
number of UEs

\item {} 
number of Data Radio Bearers to be activated for each UE

\item {} 
time \(t^c_0\) at which the first UE is instructed to start connecting to the eNB

\item {} 
time interval \(d^i\) between the start of connection of UE \(n\) and UE \(n+1\); the time at which user \(n\) connects is thus determined as \(t^c_n = t^c_0 + n d^i\) sdf

\item {} 
the relative position of the UEs on the diagonal of the square, where higher
values indicate larger distance from the serving eNodeB, i.e., higher
interference from the other eNodeBs

\item {} 
a boolean flag indicating whether the ideal or the real RRC protocol model is used

\end{itemize}

Each test cases passes if a number of test conditions are positively evaluated for each UE after a delay \(d^e\) from the time it started connecting to the eNB. The delay \(d^e\) is determined as
\begin{equation*}
\begin{split}d^e = d^{si} + d^{ra} + d^{ce} + d^{cr}\end{split}
\end{equation*}
where:
\begin{itemize}
\item {} 
\(d^{si}\) is the max delay necessary for the acquisition of System Information. We set it to 90ms accounting for 10ms for the MIB acquisition and 80ms for the subsequent SIB2 acquisition

\item {} 
\(d^{ra}\) is the delay for the MAC Random Access (RA)
procedure. This depends on preamble collisions as well as on the
availability of resources for the UL grant allocation. The total amount of
necessary RA attempts depends on preamble collisions and failures
to allocate the UL grant because of lack of resources. The number
of collisions depends on the number of UEs that try to access
simultaneously; we estimated that for a \(0.99\) RA success
probability, 5 attempts are sufficient for up to 20 UEs, and  10 attempts for up
to 50 UEs.
For the UL grant, considered the system bandwidth and the
default MCS used for the UL grant (MCS 0), at most 4 UL grants can
be assigned in a TTI; so for \(n\) UEs trying to
do RA simultaneously the max number of attempts due to the UL grant
issue is \(\lceil n/4 \rceil\). The time for
a RA attempt  is determined by 3ms + the value of
LteEnbMac::RaResponseWindowSize, which defaults to 3ms, plus 1ms
for the scheduling of the new transmission.

\item {} 
\(d^{ce}\) is the delay required for the transmission of RRC CONNECTION
SETUP + RRC CONNECTION SETUP COMPLETED. We consider a round trip
delay of 10ms plus \(\lceil 2n/4 \rceil\) considering that 2
RRC packets have to be transmitted and that at most 4 such packets
can be transmitted per TTI. In cases where interference is high, we
accommodate one retry attempt by the UE, so we double the \(d^{ce}\)
value and then add \(d^{si}\) on top of it (because the timeout has
reset the previously received SIB2).

\item {} 
\(d^{cr}\) is the delay required for eventually needed RRC
CONNECTION RECONFIGURATION transactions. The number of transactions needed is
1 for each bearer activation. Similarly to what done for
\(d^{ce}\), for each transaction we consider a round trip
delay of 10ms plus \(\lceil 2n/4 \rceil\).
delay of 20ms.

\end{itemize}

The base version of the test \sphinxcode{\sphinxupquote{LteRrcConnectionEstablishmentTestCase}}
tests for correct RRC connection establishment in absence of channel
errors. The conditions that are evaluated for this test case to pass
are, for each UE:
\begin{itemize}
\item {} 
the RRC state at the UE is CONNECTED\_NORMALLY

\item {} 
the UE is configured with the CellId, DlBandwidth, UlBandwidth,
DlEarfcn and UlEarfcn of the eNB

\item {} 
the IMSI of the UE stored at the eNB is correct

\item {} 
the number of active Data Radio Bearers is the expected one, both
at the eNB and at the UE

\item {} 
for each Data Radio Bearer, the following identifiers match between
the UE and the eNB: EPS bearer id, DRB id, LCID

\end{itemize}

The test variant \sphinxcode{\sphinxupquote{LteRrcConnectionEstablishmentErrorTestCase}} is
similar except for the presence of errors in the transmission of a
particular RRC message of choice during the first connection
attempt. The error is obtained by temporarily moving the UE to a far
away location; the time of movement has been determined empirically
for each instance of the test case based on the message that it was
desired to be in error. The test case checks that at least one of the following
conditions is false at the time right before the UE is moved back to
the original location:
\begin{itemize}
\item {} 
the RRC state at the UE is CONNECTED\_NORMALLY

\item {} 
the UE context at the eNB is present

\item {} 
the RRC state of the UE Context at the eNB is CONNECTED\_NORMALLY

\end{itemize}


\paragraph{Initial cell selection}
\label{\detokenize{lte-testing:initial-cell-selection}}
The test suite \sphinxtitleref{lte\sphinxhyphen{}cell\sphinxhyphen{}selection} is responsible for verifying the
{\hyperref[\detokenize{lte-design:sec-initial-cell-selection}]{\sphinxcrossref{\DUrole{std,std-ref}{Initial Cell Selection}}}} procedure. The test is a simulation of a small
network of 2 non\sphinxhyphen{}CSG cells and 2 non\sphinxhyphen{}CSG cells. Several static UEs are then
placed at predefined locations. The UEs enter the simulation without being
attached to any cell. Initial cell selection is enabled for these UEs, so each
UE will find the best cell and attach to it by themselves.

At predefined check points time during the simulation, the test verifies that
every UE is attached to the right cell. Moreover, the test also ensures that the
UE is properly connected, i.e., its final state is \sphinxtitleref{CONNECTED\_NORMALLY}. Figure
{\hyperref[\detokenize{lte-testing:fig-lte-cell-selection-scenario}]{\sphinxcrossref{\DUrole{std,std-ref}{Sample result of cell selection test}}}} depicts the network layout and the
expected result. When a UE is depicted as having 2 successful cell selections
(e.g., UE \#3 and \#4), any of them is accepted by the test case.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-cell-selection-scenario}.pdf}
\caption{Sample result of cell selection test}\label{\detokenize{lte-testing:id25}}\label{\detokenize{lte-testing:fig-lte-cell-selection-scenario}}\end{figure}

The figure shows that CSG members may attach to either CSG or non\sphinxhyphen{}CSG cells, and
simply choose the stronger one. On the other hand, non\sphinxhyphen{}members can only attach
to non\sphinxhyphen{}CSG cells, even when they are actually receiving stronger signal from a
CSG cell.

For reference purpose, Table {\hyperref[\detokenize{lte-testing:tab-cell-selection-error-rate}]{\sphinxcrossref{\DUrole{std,std-ref}{UE error rate in Initial Cell Selection test}}}} shows the
error rate of each UE when receiving transmission from the control channel.
Based on this information, the check point time for UE \#3 is done at a later
time than the others to compensate for its higher risk of failure.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{UE error rate in Initial Cell Selection test}\label{\detokenize{lte-testing:id26}}\label{\detokenize{lte-testing:tab-cell-selection-error-rate}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
UE \#
&\sphinxstyletheadfamily 
Error rate
\\
\hline
1
&
0.00\%
\\
\hline
2
&
1.44\%
\\
\hline
3
&
12.39\%
\\
\hline
4
&
0.33\%
\\
\hline
5
&
0.00\%
\\
\hline
6
&
0.00\%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The test uses the default Friis path loss model and without any channel fading
model.


\paragraph{GTP\sphinxhyphen{}U protocol}
\label{\detokenize{lte-testing:gtp-u-protocol}}
The unit test suite \sphinxcode{\sphinxupquote{epc\sphinxhyphen{}gtpu}} checks that the encoding and decoding of the GTP\sphinxhyphen{}U
header is done correctly. The test fills in a header with a set of
known values, adds the header to a packet, and then removes the header
from the packet. The test fails if, upon removing, any of the fields
in the GTP\sphinxhyphen{}U header is not decoded correctly. This is detected by
comparing the decoded value from the known value.


\paragraph{S1\sphinxhyphen{}U interface}
\label{\detokenize{lte-testing:s1-u-interface}}
Two test suites (\sphinxcode{\sphinxupquote{epc\sphinxhyphen{}s1u\sphinxhyphen{}uplink}} and \sphinxcode{\sphinxupquote{epc\sphinxhyphen{}s1u\sphinxhyphen{}downlink}}) make
sure that the S1\sphinxhyphen{}U interface implementation works correctly in
isolation. This is achieved by creating a set of simulation scenarios
where the EPC model alone is used, without the LTE model (i.e.,
without the LTE radio protocol stack, which is replaced by simple CSMA
devices). This checks that the
interoperation between multiple EpcEnbApplication instances in
multiple eNBs and the EpcSgwPgwApplication instance in the SGW/PGW
node works correctly in a variety of scenarios, with varying numbers
of end users (nodes with a CSMA device installed), eNBs, and different
traffic patterns (packet sizes and number of total packets).
Each test case works by injecting the chosen traffic pattern in the
network (at the considered UE or at the remote host for in the uplink or the
downlink test suite respectively) and checking that at the receiver
(the remote host or each  considered UE, respectively) that exactly the same
traffic patterns is received. If any mismatch in the transmitted and
received traffic pattern is detected for any UE, the test fails.


\paragraph{TFT classifier}
\label{\detokenize{lte-testing:tft-classifier}}
The test suite \sphinxcode{\sphinxupquote{epc\sphinxhyphen{}tft\sphinxhyphen{}classifier}} checks in isolation that the
behavior of the EpcTftClassifier class is correct. This is performed
by creating different classifier instances where different TFT
instances are activated, and testing for each classifier that an
heterogeneous set of packets (including IP and TCP/UDP headers) is
classified correctly. Several test cases are provided that check the
different matching aspects of a TFT (e.g. local/remote IP address, local/remote port) both for uplink and
downlink traffic.  Each test case corresponds to a specific packet and
a specific classifier instance with a given set of TFTs. The test case
passes if the bearer identifier returned by the classifier exactly
matches with the one that is expected for the considered packet.


\paragraph{End\sphinxhyphen{}to\sphinxhyphen{}end LTE\sphinxhyphen{}EPC data plane functionality}
\label{\detokenize{lte-testing:end-to-end-lte-epc-data-plane-functionality}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}epc\sphinxhyphen{}e2e\sphinxhyphen{}data}} ensures the correct end\sphinxhyphen{}to\sphinxhyphen{}end
functionality of the LTE\sphinxhyphen{}EPC data plane. For each test case in this
suite, a complete LTE\sphinxhyphen{}EPC simulation
scenario is created with the following characteristics:
\begin{itemize}
\item {} 
a given number of eNBs

\item {} 
for each eNB, a given number of UEs

\item {} 
for each UE, a given number of active EPS bearers

\item {} 
for each active EPS bearer, a given traffic pattern (number of UDP
packets to be transmitted and packet size)

\end{itemize}

Each test is executed by transmitting the given traffic pattern both
in the uplink and in the downlink, at subsequent time intervals. The
test passes if all the following conditions are satisfied:
\begin{itemize}
\item {} 
for each active EPS bearer, the transmitted and received traffic
pattern (respectively  at the UE and the remote host for uplink,
and vice versa for downlink) is exactly the same

\item {} 
for each active EPS bearer and each direction (uplink or downlink),
exactly the expected number of packet flows over the corresponding
RadioBearer instance

\end{itemize}


\paragraph{X2 handover}
\label{\detokenize{lte-testing:x2-handover}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}x2\sphinxhyphen{}handover}} checks the correct functionality of the X2 handover procedure. The scenario being tested is a topology with two eNBs connected by an X2 interface. Each test case is a particular instance of this scenario defined by the following parameters:
\begin{itemize}
\item {} 
the number of UEs that are initially attached to the first eNB

\item {} 
the number of EPS bearers activated for each UE

\item {} 
a list of handover events to be triggered, where each event is defined by:
+ the start time of the handover trigger
+ the index of the UE doing the handover
+ the index of the source eNB
+ the index of the target eNB

\item {} 
a boolean flag indicating whether the target eNB admits the handover or not

\item {} 
a boolean flag indicating whether the ideal RRC protocol is to be used instead of the real RRC protocol

\item {} 
the type of scheduler to be used (RR or PF)

\end{itemize}

Each test case passes if the following conditions are true:
\begin{itemize}
\item {} 
at time 0.06s, the test CheckConnected verifies that each UE is connected to the first eNB

\item {} 
for each event in the handover list:
\begin{itemize}
\item {} 
at the indicated event start time, the indicated UE is connected to the indicated source eNB

\item {} 
0.1s after the start time, the indicated UE is connected to the indicated target eNB

\item {} 
0.6s after the start time, for each active EPS bearer, the uplink and downlink sink applications of the indicated UE have achieved a number of bytes which is at least half the number of bytes transmitted by the corresponding source applications

\end{itemize}

\end{itemize}

The condition “UE is connected to eNB” is evaluated positively if and only if all the following conditions are met:
\begin{itemize}
\item {} 
the eNB has the context of the UE (identified by the RNTI value
retrieved from the UE RRC)

\item {} 
the RRC state of the UE at the eNB is CONNECTED\_NORMALLY

\item {} 
the RRC state at the UE is CONNECTED\_NORMALLY

\item {} 
the UE is configured with the CellId, DlBandwidth, UlBandwidth,
DlEarfcn and UlEarfcn of the eNB

\item {} 
the IMSI of the UE stored at the eNB is correct

\item {} 
the number of active Data Radio Bearers is the expected one, both
at the eNB and at the UE

\item {} 
for each Data Radio Bearer, the following identifiers match between
the UE and the eNB: EPS bearer id, DRB id, LCID

\end{itemize}


\paragraph{Automatic X2 handover}
\label{\detokenize{lte-testing:automatic-x2-handover}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}x2\sphinxhyphen{}handover\sphinxhyphen{}measures}} checks the correct functionality of the handover
algorithm. The scenario being tested is a topology with two, three or four eNBs connected by
an X2 interface. The eNBs are located in a straight line in the X\sphinxhyphen{}axes. A UE moves along the
X\sphinxhyphen{}axes going from the neighborhood of one eNB to the next eNB. Each test case is a particular
instance of this scenario defined by the following parameters:
\begin{itemize}
\item {} 
the number of eNBs in the X\sphinxhyphen{}axes

\item {} 
the number of UEs

\item {} 
the number of EPS bearers activated for the UE

\item {} 
a list of check point events to be triggered, where each event is defined by:
+ the time of the first check point event
+ the time of the last check point event
+ interval time between two check point events
+ the index of the UE doing the handover
+ the index of the eNB where the UE must be connected

\item {} 
a boolean flag indicating whether UDP traffic is to be used instead of TCP traffic

\item {} 
the type of scheduler to be used

\item {} 
the type of handover algorithm to be used

\item {} 
a boolean flag indicating whether handover is admitted by default

\item {} 
a boolean flag indicating whether the ideal RRC protocol is to be used instead of the
real RRC protocol

\end{itemize}

The test suite consists of many test cases. In fact, it has been one of the most
time\sphinxhyphen{}consuming test suite in ns\sphinxhyphen{}3. The test cases run with \sphinxstyleemphasis{some} combination of
the following variable parameters:
\begin{itemize}
\item {} 
number of eNBs: 2, 3, 4;

\item {} 
number of EPS bearers: 0, 1, 2;

\item {} 
RRC: ideal, real (see {\hyperref[\detokenize{lte-design:sec-rrc-protocol-models}]{\sphinxcrossref{\DUrole{std,std-ref}{RRC protocol models}}}});

\item {} 
MAC scheduler: round robin, proportional fair (see {\hyperref[\detokenize{lte-design:sec-ff-mac-scheduler}]{\sphinxcrossref{\DUrole{std,std-ref}{The FemtoForum MAC Scheduler Interface}}}}); and

\item {} 
handover algorithm: A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ, strongest cell (see {\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}}).

\end{itemize}

Each test case passes if the following conditions are true:
\begin{itemize}
\item {} 
at time 0.08s, the test CheckConnected verifies that each UE is connected to the first eNB

\item {} 
for each event in the check point list:
\begin{itemize}
\item {} 
at the indicated check point time, the indicated UE is connected to the indicated eNB

\item {} 
0.5s after the check point, for each active EPS bearer, the uplink and downlink sink
applications of the UE have achieved a number of bytes which is at least half the number
of bytes transmitted by the corresponding source applications

\end{itemize}

\end{itemize}

The condition “UE is connected to eNB” is evaluated positively if and only if all the following conditions are met:
\begin{itemize}
\item {} 
the eNB has the context of the UE (identified by the RNTI value
retrieved from the UE RRC)

\item {} 
the RRC state of the UE at the eNB is CONNECTED\_NORMALLY

\item {} 
the RRC state at the UE is CONNECTED\_NORMALLY

\item {} 
the UE is configured with the CellId, DlBandwidth, UlBandwidth,
DlEarfcn and UlEarfcn of the eNB

\item {} 
the IMSI of the UE stored at the eNB is correct

\item {} 
the number of active Data Radio Bearers is the expected one, both
at the eNB and at the UE

\item {} 
for each Data Radio Bearer, the following identifiers match between
the UE and the eNB: EPS bearer id, DRB id, LCID

\end{itemize}


\paragraph{Handover delays}
\label{\detokenize{lte-testing:handover-delays}}
Handover procedure consists of several message exchanges between UE, source
eNodeB, and target eNodeB over both RRC protocol and X2 interface. Test suite
\sphinxcode{\sphinxupquote{lte\sphinxhyphen{}handover\sphinxhyphen{}delay}} verifies that this procedure consistently spends the
same amount of time.

The test suite will run several handover test cases. Each test case is an
individual simulation featuring a handover at a specified time in simulation.
For example, the handover in the first test case is invoked at time +0.100s,
while in the second test case it is at +0.101s. There are 10 test cases, each
testing a different subframe in LTE. Thus the last test case has the handover
at +0.109s.

The simulation scenario in the test cases is as follow:
\begin{itemize}
\item {} 
EPC is enabled

\item {} 
2 eNodeBs with circular (isotropic) antenna, separated by 1000 meters

\item {} 
1 static UE positioned exactly in the center between the eNodeBs

\item {} 
no application installed

\item {} 
no channel fading

\item {} 
default path loss model (Friis)

\item {} 
0.300s simulation duration

\end{itemize}

The test case runs as follow. At the beginning of the simulation, the UE is
attached to the first eNodeB. Then at the time specified by the test case input
argument, a handover request will be explicitly issued to the second eNodeB.
The test case will then record the starting time, wait until the handover is
completed, and then record the completion time. If the difference between the
completion time and starting time is less than a predefined threshold, then the
test passes.

A typical handover in the current ns\sphinxhyphen{}3 implementation takes 4.2141 ms when using
Ideal RRC protocol model, and 19.9283 ms when using Real RRC protocol model.
Accordingly, the test cases use 5 ms and 20 ms as the maximum threshold values.
The test suite runs 10 test cases with Ideal RRC protocol model and 10 test
cases with Real RRC protocol model. More information regarding these models can
be found in Section {\hyperref[\detokenize{lte-design:sec-rrc-protocol-models}]{\sphinxcrossref{\DUrole{std,std-ref}{RRC protocol models}}}}.

The motivation behind using subframes as the main test parameters is the fact
that subframe index is one of the factors for calculating RA\sphinxhyphen{}RNTI, which is used
by Random Access during the handover procedure. The test cases verify this
computation, utilizing the fact that the handover will be delayed when this
computation is broken. In the default simulation configuration, the handover
delay observed because of a broken RA\sphinxhyphen{}RNTI computation is typically 6 ms.


\paragraph{Selection of target cell in handover algorithm}
\label{\detokenize{lte-testing:selection-of-target-cell-in-handover-algorithm}}
eNodeB may utilize {\hyperref[\detokenize{lte-design:sec-handover-algorithm}]{\sphinxcrossref{\DUrole{std,std-ref}{Handover algorithm}}}} to automatically create
handover decisions during simulation. The decision includes the UE which should
do the handover and the target cell where the UE should perform handover to.

The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}handover\sphinxhyphen{}target}} verifies that the handover algorithm is
making the right decision, in particular, in choosing the right target cell. It
consists of several short test cases for different network topology (2×2 grid
and 3×2 grid) and types of handover algorithm (the A2\sphinxhyphen{}A4\sphinxhyphen{}RSRQ handover algorithm
and the strongest cell handover algorithm).

Each test case is a simulation of a micro\sphinxhyphen{}cell environment with the following
parameter:
\begin{itemize}
\item {} 
EPC is enabled

\item {} 
several circular (isotropic antenna) micro\sphinxhyphen{}cell eNodeBs in a rectangular grid
layout, with 130 m distance between each adjacent point

\item {} 
1 static UE, positioned close to and attached to the source cell

\item {} 
no control channel error model

\item {} 
no application installed

\item {} 
no channel fading

\item {} 
default path loss model (Friis)

\item {} 
1s simulation duration

\end{itemize}

To trigger a handover, the test case “shutdowns” the source cell at +0.5s
simulation time. Figure {\hyperref[\detokenize{lte-testing:fig-lte-handover-target-scenario}]{\sphinxcrossref{\DUrole{std,std-ref}{lte\sphinxhyphen{}handover\sphinxhyphen{}target test scenario in a 2×2 grid}}}} below
illustrates the process. This is done by setting the source cell’s Tx power to
a very low value. As a result, the handover algorithm notices that the UE
deserves a handover and several neighboring cells become candidates of target
cell at the same time.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{lte-handover-target-scenario}.pdf}
\caption{\sphinxcode{\sphinxupquote{lte\sphinxhyphen{}handover\sphinxhyphen{}target}} test scenario in a 2×2 grid}\label{\detokenize{lte-testing:id27}}\label{\detokenize{lte-testing:fig-lte-handover-target-scenario}}\end{figure}

The test case then verifies that the handover algorithm, when faced with more
than one options of target cells, is able to choose the right one.


\paragraph{Downlink Power Control}
\label{\detokenize{lte-testing:downlink-power-control}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}downlink\sphinxhyphen{}power\sphinxhyphen{}control}} checks correctness of Downlink
Power Control in three different ways:
\begin{itemize}
\item {} 
LteDownlinkPowerControlSpectrumValue test case   check if
\sphinxcode{\sphinxupquote{LteSpectrumValueHelper::CreateTxPowerSpectralDensity}} is creating correct
spectrum value for PSD for downlink transmission. The test vector contain EARFCN,
system bandwidth, TX power, TX power for each RB, active RBs, and expected TxPSD.
The test passes if TxPDS generated by
\sphinxcode{\sphinxupquote{LteSpectrumValueHelper::CreateTxPowerSpectralDensity}} is equal to expected TxPSD.

\item {} 
LteDownlinkPowerControlTestCase test case check if TX power difference between
data and control channel is equal to configured PdschConfigDedicated::P\_A value.
TX power of control channel is measured by \sphinxcode{\sphinxupquote{LteTestSinrChunkProcessor}} added
to \sphinxcode{\sphinxupquote{RsPowerChunkProcessor}} list in UE DownlinkSpectrumPhy. Tx power of data
channel is measured in similar way, but it had to be implemented. Now
\sphinxcode{\sphinxupquote{LteTestSinrChunkProcessor}} is added to \sphinxcode{\sphinxupquote{DataPowerChunkProcessor}} list in UE
DownlinkSpectrumPhy. Test vector contain a set of all available P\_A values. Test
pass if power difference equals P\_A value.

\item {} 
LteDownlinkPowerControlRrcConnectionReconfiguration test case check if
RrcConnectionReconfiguration is performed correctly. When FR entity gets UE
measurements, it immediately calls function to change P\_A value for this UE and also
triggers callback connected with this event. Then, test check if UE gets
RrcConnectionReconfiguration message (it trigger callback). Finally, it checks if eNB
receive RrcConnectionReconfigurationCompleted message, what also trigger callback.
The test passes if all event have occurred. The test is performed two times, with
IdealRrcProtocol and with RealRrcProtocol.

\end{itemize}


\paragraph{Uplink Power Control Tests}
\label{\detokenize{lte-testing:uplink-power-control-tests}}
UE uses Uplink Power Control to automatically change Tx Power level for Uplink
Physical Channels. Tx Power is computed based on path\sphinxhyphen{}loss, number of RB used for transmission,
some configurable parameters and TPC command from eNB.

The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}uplink\sphinxhyphen{}power\sphinxhyphen{}control}} verifies if Tx Power is computed correctly.
There are three different test cases:
\begin{itemize}
\item {} 
LteUplinkOpenLoopPowerControlTestCase test case checks Uplink Power Control functionality
in Open Loop mechanism. UE is attached to eNB and is transmitting data in Downlink and
Uplink. Uplink Power Control with Open Loop mechanism is enabled and UE changes position
each 100 ms. In each position Uplink Power Control entity is calculating new Tx Power level
for all uplink channels. These values are traced and test passes if Uplink Tx Power for
PUSCH, PUCCH and SRS in each UE position are equal to expected values.

\item {} 
LteUplinkClosedLoopPowerControlAbsoluteModeTestCase test case checks Uplink Power Control
functionality with Closed Loop mechanism and Absolute Mode enabled.
UE is attached to eNB and is transmitting data in Downlink and Uplink. Uplink Power Control
with Closed Loop mechanism and Absolute Mode is enabled. UE is located 100 m from eNB and
is not changing its position. LteFfrSimple algorithm is used on eNB side to set TPC values in
DL\sphinxhyphen{}DCI messages. TPC configuration in eNB is changed every 100 ms, so every 100 ms Uplink
Power Control entity in UE should calculate different Tx Power level for all uplink channels.
These values are traced and test passes if Uplink Tx Power for PUSCH, PUCCH and SRS
computed with all TCP values are equal to expected values.

\item {} 
LteUplinkClosedLoopPowerControlAccumulatedModeTestCase test case checks Closed Loop Uplink
Power Control functionality with Closed Loop mechanism and Accumulative Mode enabled.
UE is attached to eNB and is transmitting data in Downlink and Uplink. Uplink Power Control
with Closed Loop mechanism and Accumulative Mode is enabled. UE is located 100 m from eNB and
is not changing its position. As in above test case, LteFfrSimple algorithm is used on eNB
side to set TPC values in DL\sphinxhyphen{}DCI messages, but in this case TPC command are set in DL\sphinxhyphen{}DCI
only configured number of times, and after that TPC is set to be 1, what is mapped to value
of 0 in Accumulative Mode (TS36.213 Table 5.1.1.1\sphinxhyphen{}2). TPC configuration in eNB is changed
every 100 ms. UE is accumulating these values and calculates Tx Power levels for all uplink
channels based on accumulated value. If computed Tx Power level is lower than minimal
UE Tx Power, UE should transmit with its minimal Tx Power. If computed Tx Power level is
higher than maximal UE Tx Power, UE should transmit with its maximal Tx Power.
Tx Power levels for PUSCH, PUCCH and SRS are traced and test passes if they are equal to
expected values.

\end{itemize}


\paragraph{Frequency Reuse Algorithms}
\label{\detokenize{lte-testing:frequency-reuse-algorithms}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}frequency\sphinxhyphen{}reuse}} contain two types of test cases.

First type of test cases check if RBGs are used correctly according to FR algorithm
policy. We are testing if scheduler use only RBGs allowed by FR configuration. To
check which RBGs are used \sphinxcode{\sphinxupquote{LteSimpleSpectrumPhy}} is attached to Downlink Channel.
It notifies when data downlink channel transmission has occurred and pass signal
TxPsd spectrum value to check which RBs were used for transmission. The test vector
comprise a set of configuration for Hard and Strict FR algorithms (there is no point
to check other FR algorithms in this way because they use entire cell bandwidth).
Test passes if none of not allowed RBGs are used.

Second type of test cases check if UE is served within proper sub\sphinxhyphen{}band and with proper
transmission power. In this test scenario, there are two eNBs.There are also two UEs
and each eNB is serving one.  One uses Frequency Reuse algorithm and second one does not.
Second eNB is responsible for generating interferences in whole system bandwidth.
UE served by first eNB is changing position each few second (rather slow because time is
needed to report new UE Measurements). To check which RBGs are used for this UE
\sphinxcode{\sphinxupquote{LteSimpleSpectrumPhy}} is attached to Downlink Channel. It notifies when data
downlink channel transmission in cell 1 has occurred and pass signal TxPsd spectrum value
to check which RBs were used for transmission and their power level.
The same approach is applied in Uplink direction and second \sphinxcode{\sphinxupquote{LteSimpleSpectrumPhy}}
is attached to Uplink Channel. Test passes if UE served by eNB with FR algorithm
is served in DL and UL with expected RBs and with expected power level.
Test vector comprise a configuration for Strict FR, Soft FR, Soft FFR, Enhanced FFR.
Each FR algorithm is tested with all schedulers, which support FR (i.e. PF, PSS, CQA,
TD\sphinxhyphen{}TBFQ, FD\sphinxhyphen{}TBFQ). (Hard FR do not use UE measurements, so there is no point to perform
this type of test for Hard FR).

Test case for Distributed FFR algorithm is quite similar to above one, but since eNBs need
to exchange some information, scenario with EPC enabled and X2 interfaces is considered.
Moreover, both eNB are using Distributed FFR algorithm. There are 2 UE in first cell,
and 1 in second cell. Position of each UE is changed (rather slow because time is
needed to report new UE Measurements), to obtain different result from calculation in
Distributed FFR algorithm entities. To check which RBGs are used for UE transmission
\sphinxcode{\sphinxupquote{LteSimpleSpectrumPhy}} is attached to Downlink Channel. It notifies when data
downlink channel transmission has occurred and pass signal TxPsd spectrum value
to check which RBs were used for transmission and their power level.
The same approach is applied in Uplink direction and second \sphinxcode{\sphinxupquote{LteSimpleSpectrumPhy}}
is attached to Uplink Channel.
Test passes if UE served by eNB in cell 2, is served in DL and UL with expected RBs
and with expected power level. Test vector comprise a configuration for Distributed FFR.
Test is performed with all schedulers, which support FR (i.e. PF, PSS, CQA,
TD\sphinxhyphen{}TBFQ, FD\sphinxhyphen{}TBFQ).


\paragraph{Inter\sphinxhyphen{}cell Interference with FR algorithms Tests}
\label{\detokenize{lte-testing:inter-cell-interference-with-fr-algorithms-tests}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}interference\sphinxhyphen{}fr}} is very similar to \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}interference}}.
Topology (Figure {\hyperref[\detokenize{lte-testing:fig-lte-interference-test-scenario}]{\sphinxcrossref{\DUrole{std,std-ref}{Topology for the inter\sphinxhyphen{}cell interference test}}}}) is the same and test checks
interference level. The difference is that, in this test case Frequency Reuse algorithms
are enabled and we are checking interference level on different RBGs (not only on one).
For example, when we install Hard FR algorithm in eNbs, and first half of system bandwidth
is assigned to one eNb, and second half to second eNb, interference level should be much
lower compared to legacy scenario. The test vector comprise a set of configuration for
all available Frequency Reuse Algorithms. Test passes if calculated SINR on specific
RBs is equal to these obtained by Octave script.


\paragraph{Carrier aggregation test}
\label{\detokenize{lte-testing:carrier-aggregation-test}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}carrier\sphinxhyphen{}aggregation}} is a system test program that creates different test
cases with a single eNB and several UEs, all having the same radio bearer specification. Different
test cases are implemented by using different SINR values and different numbers of UEs. eNBs and UEs
are configured to use the secondary carrier and the component carrier manager is configured to
split the data uniformly between primary and secondary carrier. The test consists of checking that
the throughput obtained over the different carriers are equal considering a given tolerance. For more
details about this test, see the section Carrier aggregation usage example.


\paragraph{Carrier aggregation test for eNB and UE configuration}
\label{\detokenize{lte-testing:carrier-aggregation-test-for-enb-and-ue-configuration}}
The test suite \sphinxcode{\sphinxupquote{carrier\sphinxhyphen{}aggregation\sphinxhyphen{}config\sphinxhyphen{}test}} is a system test program, which verifies the
following two cases:
\begin{itemize}
\item {} 
When carrier aggregation is enabled and UE carriers configuration is different than the default
configuration done in LteHelper, we check that the UE(s) is configured properly once it receives
RRC Connection Reconfiguration message from eNB.

\item {} 
A user can configure 2 or more eNBs and UEs with different configuration parameters, i.e.,
each eNB and UE can have different EARFCN and Bandwidths and a UE connects to an eNB with similar DL EARFCN.
In this test, we check with CA enabled but the end results will be the same if carrier aggregation is not
enabled and we have more than one eNBs and UEs with different configurations.

\end{itemize}

Since, we do not need EPC to test the configuration, this test only simulates the LTE radio access with RLC SM.
There are two test cases, Test 1 tests that the UE is configured properly after receiving RRC Connection Reconfiguration
message from the eNB, which will overwrite UE default configuration done in LteHelper for the sake of
creating PHY and MAC instances equal to the number of component carriers. Test 2 tests that every eNB or UE in a
simulation scenario can be configured with different EARFCNs and Bandwidths. For both test cases, it also counts
the number of times the hooked trace source \sphinxcode{\sphinxupquote{SCarrierConfigured}} get triggered. As, it reflects how many UEs
got attached to their respective eNB. If the count is not equal to the number of UEs in the scenario, the test fails,
which could be the result of improper UE configuration.


\paragraph{Radio link failure Test}
\label{\detokenize{lte-testing:radio-link-failure-test}}
The test suite \sphinxcode{\sphinxupquote{lte\sphinxhyphen{}radio\sphinxhyphen{}link\sphinxhyphen{}failure}} is a system test, which tests the
radio link failure functionality using Ideal and Real RRC protocols.
In particular, it tests the following to verify the Radio link
Failure (RLF) implementation.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
The state and the configuration of the UE while it is connected to the eNB.

\item {} 
The state of the UE while T310 timer is running at the UE.

\item {} 
The number of out\sphinxhyphen{}of\sphinxhyphen{}sync and in\sphinxhyphen{}synch indications received.

\item {} 
The state of the UE before the simulation end.

\item {} 
The UE context existence at the eNB before the simulation end.

\end{enumerate}

This test simulates only one static UE with EPC performing downlink and uplink
communication in the following two scenarios:


\subparagraph{One eNB using Ideal and Real RRC}
\label{\detokenize{lte-testing:one-enb-using-ideal-and-real-rrc}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-test-rlf-one-enb}.pdf}
\caption{RLF scenario with one eNB}\label{\detokenize{lte-testing:id28}}\label{\detokenize{lte-testing:fig-lte-test-rlf-one-enb}}\end{figure}

In this scenario, the UE is initially placed near to the eNB, and on the
following instances above conditions are verified against the expected outcome.

\sphinxstylestrong{At 0.3 sec:}  It verifies that the UE is well connected, i.e., it is in
“CONNECTED\_NORMALLY” state, and is attached to the eNB with cell id 1. It also
checks for the match between the configuration of the UE and the UE context at
the eNB, e.g., IMSI, bandwidth, D/UL EARFCN, number of bearers and the bearer IDs.
The miss match would result in the test suite failure.

\sphinxstylestrong{At 0.4 sec:} The UE jumps far away from the eNB, which causes the DL SINR at
the UE to fall below \sphinxhyphen{}5 dB. In result, the UE PHY after monitoring the SINR for
20 consecutive frames will send a notification to the UE RRC. In this test, the
N310 counter is set to 1; thus, the UE RRC will start the T310 (set to 1 sec)
timer upon the first notification from the PHY layer.

\sphinxstylestrong{At 1 sec:} At this stage, it is expected that the T310 timer is still running,
and the UE is connected to the eNB.

\sphinxstylestrong{Upon RLF:} It is expected that the UE RRC will start the T310 timer upon reaching
the configured, i.e., N310 = 1 number of notification from the eNB. The RRC will
receive no in\sphinxhyphen{}sync indication since the UE stays at far away position.

\sphinxstylestrong{Before the end of simulation:}  The expected behavior is that the UE state
will be in “IDLE\_CELL\_SEARCH” since there is no eNB available where it has jumped.
Moreover, the deletion of the UE context from the eNB is also verified.


\subparagraph{Two eNBs using Ideal and Real RRC}
\label{\detokenize{lte-testing:two-enbs-using-ideal-and-real-rrc}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lte-test-rlf-two-enb}.pdf}
\caption{RLF scenario with two eNBs}\label{\detokenize{lte-testing:id29}}\label{\detokenize{lte-testing:fig-lte-test-rlf-two-enb}}\end{figure}

In this scenario, the only difference is the addition of a second eNB near the
position where the UE jumps away. Therefore, except the outcome before the end
of the simulation, all the outcomes are similar to that we expected in the first
scenario.

\sphinxstylestrong{Before the end of simulation:}  It is expected that the UE after the RLF will
connect to the second eNB, i.e., it will be in “CONNECTED\_NORMALLY” state, and
its context exists in the second eNB.


\section{Profiling Documentation}
\label{\detokenize{lte-profiling:profiling-documentation}}\label{\detokenize{lte-profiling::doc}}

\subsection{Overview and objectives}
\label{\detokenize{lte-profiling:overview-and-objectives}}
The main objective of the profiling carried out is to assess the simulator performance on a broad set of scenarios. This evaluation provides reference values for simulation running times and memory consumption figures. It also helps to identify potential performance improvements and to check for scalability problems when increasing the number of eNodeB and UEs attached to those.

In the following sections, a detailed description of the general profiling framework employed to perform the study is introduced. It also includes details on the main performed tests and its results evaluation.


\subsection{Framework description}
\label{\detokenize{lte-profiling:framework-description}}

\subsubsection{Simulation scripts}
\label{\detokenize{lte-profiling:simulation-scripts}}
The simulation script used for all the E\sphinxhyphen{}UTRAN results showed in this documentation is located at \sphinxcode{\sphinxupquote{src/lte/examples/lena\sphinxhyphen{}profiling.cc}}. It uses the complete PHY and MAC UE/eNodeB implementation with a simplified RLC implementation on top. This script generates a squared grid topology, placing a eNodeB at the centre of each square. UEs attached to this node are scattered randomly across the square (using a random uniform distribution along X and Y axis). If \sphinxstyleemphasis{BuildingPropagationModel} is used, the squares are replaced by rooms. To generate the UL and DL traffic, the RLC implementation always report data to be transferred.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{eutran-profiling-scenario}.pdf}
\caption{E\sphinxhyphen{}UTRAN}\label{\detokenize{lte-profiling:id3}}\label{\detokenize{lte-profiling:fig-eutranprofilingscenario}}\end{figure}

For the EPC results, the script is \sphinxcode{\sphinxupquote{src/lte/examples/lena\sphinxhyphen{}simple\sphinxhyphen{}epc.cc}}. It uses a complete E\sphinxhyphen{}UTRAN implementation (PHY+MAC+RLC/UM+PDCP) and the most relevant EPC user plane entities the PGW and SGW, including GTP\sphinxhyphen{}U tunneling. This script generates a given number of eNodeBs, distributed across a line and attaches a single UE to every eNodeB. It also creates an EPC network and an external host connected to it through the Internet. Each UE sends and receives data to and from the remote host. In addition, each UE is also sending data to the UE camped in the adjacent eNodeB.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{epc-profiling-scenario}.pdf}
\caption{Propagation Model}\label{\detokenize{lte-profiling:id4}}\label{\detokenize{lte-profiling:fig-epcprofilingscenario}}\end{figure}

RLC and MAC traces are enabled for all UEs and all eNodeBs and those traces are written to disk directly. The MAC scheduler used is \sphinxstyleemphasis{round robin}.


\paragraph{Simulation input parameters}
\label{\detokenize{lte-profiling:simulation-input-parameters}}
The \sphinxstyleemphasis{lena\sphinxhyphen{}profiling} simulation script accepts the following input parameters:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{simTime}}: time to simulate (in seconds)

\item {} 
\sphinxcode{\sphinxupquote{nUe}}: number of UEs attached to each eNodeB

\item {} 
\sphinxcode{\sphinxupquote{nEnb}}: number of eNodeB composing the grid per floor

\item {} 
\sphinxcode{\sphinxupquote{nFloors}}: number of floors, 0 for \sphinxstyleemphasis{Friis propagation model} (no walls), 1 or greater for \sphinxstyleemphasis{Building propagation model} generating a nFloors\sphinxhyphen{}storey building.

\item {} 
\sphinxcode{\sphinxupquote{traceDirectory}}: destination directory where simulation traces will be stored

\end{itemize}

The \sphinxstyleemphasis{lena\sphinxhyphen{}simple\sphinxhyphen{}epc} script accepts those other parameters:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{simTime}}: time to simulate (in seconds)

\item {} 
\sphinxcode{\sphinxupquote{numberOfNodes}}: number of eNodeB + UE pairs created

\end{itemize}


\subsubsection{Time measurement}
\label{\detokenize{lte-profiling:time-measurement}}
Running time is measured using default Linux shell command \sphinxstylestrong{time}. This command counts how much user time the execution of a program takes.


\subsubsection{Perl script}
\label{\detokenize{lte-profiling:perl-script}}
To simplify the process of running the profiling script for a wide range of values and collecting its timing data, a simple Perl script to automate the complete process is provided. It is placed in \sphinxcode{\sphinxupquote{src/lte/test/lte\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}time.pl}} for \sphinxstyleemphasis{lena\sphinxhyphen{}profiling} and in \sphinxcode{\sphinxupquote{src/lte/epc\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}time.pl}} for \sphinxstyleemphasis{lena\sphinxhyphen{}simple\sphinxhyphen{}epc}. It simply runs a batch of simulations with a range of parameters and stores the timing results in a CSV file called \sphinxstyleemphasis{lteTimes.csv} and \sphinxstyleemphasis{epcTimes.csv} respectively. The range of values each parameter sweeps can be modified editing the corresponding script.


\paragraph{Requirements}
\label{\detokenize{lte-profiling:requirements}}\begin{description}
\item[{The following Perl modules are required to use the provided script, all of them available from CPAN:}] \leavevmode\begin{itemize}
\item {} 
IO::CaptureOutput

\item {} 
Statistics::Descriptive

\end{itemize}

\end{description}

For installing the modules, simply use the following command:

\sphinxcode{\sphinxupquote{perl \sphinxhyphen{}MCPAN \sphinxhyphen{}e \textquotesingle{}install moduleName\textquotesingle{}}}


\paragraph{Plotting results}
\label{\detokenize{lte-profiling:plotting-results}}
To plot the results obtained from running the Perl scripts, two gnuplot scripts are provided, in \sphinxcode{\sphinxupquote{src/lte/test/lte\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}plot}} and \sphinxcode{\sphinxupquote{src/lte/test/epc\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}plot}}. Most of the plots available in this documentation can be reproduced with those, typing the commands \sphinxcode{\sphinxupquote{gnuplot \textless{} src/lte/test/lte\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}plot}}  and  \sphinxcode{\sphinxupquote{gnuplot \textless{} src/lte/test/epc\sphinxhyphen{}test\sphinxhyphen{}run\sphinxhyphen{}plot}}.


\subsubsection{Reference software and equipment}
\label{\detokenize{lte-profiling:reference-software-and-equipment}}
All timing tests had been run in a Intel Pentium IV 3.00 GHz machine with 512 Mb of RAM memory running Fedora Core 10 with a 2.6.27.41\sphinxhyphen{}170.2.117 kernel, storing the traces directly to the hard disk.

Also, as a reference configuration, the build has been configured static and optimized. The exact \sphinxcode{\sphinxupquote{waf}} command issued is:

\sphinxcode{\sphinxupquote{CXXFLAGS="\sphinxhyphen{}O3 \sphinxhyphen{}w" ./waf \sphinxhyphen{}d optimized configure \sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}static \sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}examples \sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}modules=lte}}


\subsection{Results}
\label{\detokenize{lte-profiling:results}}

\subsubsection{E\sphinxhyphen{}UTRAN}
\label{\detokenize{lte-profiling:e-utran}}
The following results and figures had been obtained with LENA \sphinxstylestrong{changeset 2c5b0d697717}.


\paragraph{Running time}
\label{\detokenize{lte-profiling:running-time}}
This scenario, evaluates the running time for a fixed simulation time (10s) and Friis propagation mode increasing the number of UEs attached to each eNodeB and the number of planted eNodeBs in the scenario.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{runningTime10s}.pdf}
\caption{Running time}\label{\detokenize{lte-profiling:id5}}\label{\detokenize{lte-profiling:fig-runtime}}\end{figure}

The figure shows the expected behaviour, since it increases linearly respect the number of UEs per eNodeB and quadratically respect the total number of eNodeBs.


\paragraph{Propagation model}
\label{\detokenize{lte-profiling:propagation-model}}
The objective of this scenario is to evaluate the impact of the propagation model complexity in the overall run time figures. Therefore, the same scenario is simulated twice: once using the more simple Friis model, once with the more complex Building model. The rest of the parameters (e.g. number of eNodeB and of UE attached per eNodeB) were maintained. The timing results for both models are compared in the following figure.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{propagationModel}.pdf}
\caption{Propagation Model}\label{\detokenize{lte-profiling:id6}}\label{\detokenize{lte-profiling:fig-propagationmodel}}\end{figure}

In this situation, results are also coherent with what is expected. The more complex the model, the higher the running time. Moreover, as the number of computed path losses increases (i.e. more UEs per eNodeB or more eNodeBs) the extra complexity of the propagation model drives the running time figures further apart.


\paragraph{Simulation time}
\label{\detokenize{lte-profiling:simulation-time}}
In this scenario, for a fixed set of UEs per eNodeB, different simulation times had been run. As the simulation time increases, running time should also increase linearly, i.e. for a given scenario, simulate four seconds should take twice times what it takes to simulate two seconds. The slope of this line is a function of the complexity of the scenario: the more eNodeB / UEs placed, the higher the slope of the line.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{simulationTime}.pdf}
\caption{Simulation time}\label{\detokenize{lte-profiling:id7}}\label{\detokenize{lte-profiling:fig-simulationtime}}\end{figure}


\paragraph{Memory usage}
\label{\detokenize{lte-profiling:memory-usage}}
Massif tool to profile memory consumption

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{profiling-memory}.pdf}
\caption{Memory profile}\label{\detokenize{lte-profiling:id8}}\label{\detokenize{lte-profiling:fig-profilingmemory}}\end{figure}


\subsubsection{EPC}
\label{\detokenize{lte-profiling:epc}}
The following results and figures had been obtained with LENA \sphinxstylestrong{changeset e8b3ccdf6673}. The rationale behind the two scenarios profiled on this section is the same than for the E\sphinxhyphen{}UTRA part.


\paragraph{Running time}
\label{\detokenize{lte-profiling:id1}}
Running time evolution is quadratic since we increase at the same time the number of eNodeB and the number of UEs.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{epcRunningTime}.pdf}
\caption{Running time}\label{\detokenize{lte-profiling:id9}}\label{\detokenize{lte-profiling:fig-epcruntime}}\end{figure}

To estimate the additional complexity of the upper LTE Radio Protocol Stack model and the EPC model, we compare two scenarios using the simplified E\sphinxhyphen{}UTRAN version (using only PHY, MAC and the simplified RLC/SM, with no EPC and no ns\sphinxhyphen{}3 applications) against the complete E\sphinxhyphen{}UTRAN + EPC (with UM RLC, PDCP, end\sphinxhyphen{}to\sphinxhyphen{}end IP networking and regular ns\sphinxhyphen{}3 applications). Both configuration have been tested with the same number of UEs per eNodeB, the same number of eNodeBs, and approximately the same volume of transmitted data (an exact match was not possible due to the different ways in which packets are generated in the two configurations).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{epcEutranRunningTime}.pdf}
\caption{EPC E\sphinxhyphen{}UTRAN running time}\label{\detokenize{lte-profiling:id10}}\label{\detokenize{lte-profiling:fig-epceutranruntime}}\end{figure}

From the figure, it is evident that the additional complexity of using the upper LTE stack plus the EPC model translates approximately into a doubling of the execution time of the simulations. We believe that, considered all the new features that have been added, this figure is acceptable.


\paragraph{Simulation time}
\label{\detokenize{lte-profiling:id2}}
Finally, again the linearity of the running time as the simulation time increases gets validated through a set of experiments, as the following figure shows.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{epcSimulationTime}.pdf}
\caption{Simulation time}\label{\detokenize{lte-profiling:id11}}\label{\detokenize{lte-profiling:fig-epcsimtime}}\end{figure}


\section{References}
\label{\detokenize{lte-references:references}}\label{\detokenize{lte-references::doc}}

\chapter{Wi\sphinxhyphen{}Fi Mesh Module Documentation}
\label{\detokenize{mesh:wi-fi-mesh-module-documentation}}\label{\detokenize{mesh::doc}}

\section{Design Documentation}
\label{\detokenize{mesh-design:design-documentation}}\label{\detokenize{mesh-design::doc}}

\subsection{Overview}
\label{\detokenize{mesh-design:overview}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} \sphinxtitleref{mesh} module extends the \sphinxstyleemphasis{ns\sphinxhyphen{}3} \sphinxtitleref{wifi} module to provide mesh
networking capabilities according to the IEEE 802.11s standard \sphinxcite{mesh-references:ieee80211s}.

The basic purpose of IEEE 802.11s is to define a mode of operation for
Wi\sphinxhyphen{}Fi that permits frames to be forwarded over multiple radio hops
transparent to higher layer protocols such as IP.  To accomplish this,
mesh\sphinxhyphen{}capable stations form a \sphinxtitleref{Mesh Basic Service Set} (MBSS) by running
a pair\sphinxhyphen{}wise peering protocol to establish forwarding associations, and
by running a routing protocol to find paths through the network.  A
special gateway device called a \sphinxtitleref{mesh gate} allows a MBSS to interconnect
with a Distribution System (DS).

The basic enhancements defined by IEEE 802.11s include:
\begin{itemize}
\item {} 
discovery services

\item {} 
peering management

\item {} 
security

\item {} 
beaconing and synchronization

\item {} 
the Mesh Coordination Function (MCF)

\item {} 
power management

\item {} 
channel switching

\item {} 
extended frame formats

\item {} 
path selection and forwarding

\item {} 
interworking (proxy mesh gateways)

\item {} 
intra\sphinxhyphen{}mesh congestion control, and

\item {} 
emergency service support.

\end{itemize}

The \sphinxstyleemphasis{ns\sphinxhyphen{}3} models implement only a subset of the above service extensions,
focusing mainly on those items related to peering and routing/forwarding
of data frames through the mesh.

The Mesh NetDevice based on 802.11s D3.0 draft standard
was added in \sphinxstyleemphasis{ns\sphinxhyphen{}3.6} and includes the Mesh Peering Management Protocol and
HWMP (routing) protocol implementations. An overview
presentation by Kirill Andreev was published at the Workshop on ns\sphinxhyphen{}3
in 2009 \sphinxcite{mesh-references:and09}.  An overview paper is available at \sphinxcite{mesh-references:and10}.

As of ns\sphinxhyphen{}3.23 release, the model has been updated to the 802.11s\sphinxhyphen{}2012
standard \sphinxcite{mesh-references:ieee80211s} with regard to packet formats, based on the
contribution in \sphinxcite{mesh-references:hep15}.

These changes include:
\begin{itemize}
\item {} 
Category codes and the categories compliant to IEEE\sphinxhyphen{}802.11\sphinxhyphen{}2012 Table 8\sphinxhyphen{}38—Category values.

\item {} 
Information Elements (An adjustment of the element ID values was needed according to Table 8\sphinxhyphen{}54 of IEEE\sphinxhyphen{}802.11\sphinxhyphen{}2012).

\item {} 
Mesh Peering Management element format changed according to IEEE\sphinxhyphen{}802.11\sphinxhyphen{}2012 Figure 8\sphinxhyphen{}370.

\item {} 
Mesh Configuration element format changed according to IEEE\sphinxhyphen{}802.11\sphinxhyphen{}2012 Figure 8\sphinxhyphen{}363.

\item {} 
PERR element format changed according to IEEE\sphinxhyphen{}802.11\sphinxhyphen{}2012 Figure 8\sphinxhyphen{}394.

\end{itemize}

With these changes the messages of the Peering Management Protocol and Hybrid Wireless Mesh Protocol will be transmitted compliant to IEEE802.11\sphinxhyphen{}2012 and the resulting pcap trace files can be analyzed by Wireshark.

The multi\sphinxhyphen{}interface mesh points are supported as an extension of IEEE draft version 3.0. Note that corresponding \sphinxstyleemphasis{ns\sphinxhyphen{}3} mesh device helper creates a single interface station by default.


\subsubsection{Overview of IEEE 802.11s}
\label{\detokenize{mesh-design:overview-of-ieee-802-11s}}
The implementation of the 802.11s extension consists of two main parts: the Peer Management Protocol (PMP) and Hybrid Wireless Mesh Protocol (HWMP).

The tasks of the peer management protocol are the following:
\begin{itemize}
\item {} 
opening links, detecting beacons, and starting peer link finite state machine, and

\item {} 
closing peer links due to transmission failures or beacon loss.

\end{itemize}

If a peer link between the sender and receiver does not exist, a frame will be
dropped. So, the plug\sphinxhyphen{}in to the peer management protocol (PMP) is the first
in the list of \sphinxcode{\sphinxupquote{ns3::MeshWifiInterfaceMacPlugins}} to be used.


\paragraph{Peer management protocol}
\label{\detokenize{mesh-design:peer-management-protocol}}
The peer management protocol consists of three main parts:
\begin{itemize}
\item {} 
the protocol itself, \sphinxcode{\sphinxupquote{ns3::dot11s::PeerManagementProtocol}}, which keeps all active peer links on interfaces, handles all changes of their states and notifies the routing protocol about link failures.

\item {} 
the MAC plug\sphinxhyphen{}in, \sphinxcode{\sphinxupquote{ns3::dot11s::PeerManagementProtocolMac}}, which drops frames if there is no peer link, and peeks all needed information from management frames and information elements from beacons.

\item {} 
the peer link, \sphinxcode{\sphinxupquote{ns3::dot11s::PeerLink}}, which keeps finite state machine of each peer link, keeps beacon loss counter and counter of successive transmission failures.

\end{itemize}

The procedure of closing a peer link is not described in detail in the
standard, so in the model the link may be closed by:
\begin{itemize}
\item {} 
beacon loss (see an appropriate attribute of ns3::dot11s::PeerLink class)

\item {} 
transmission failure \textendash{} when a predefined number of successive packets have failed to transmit, the link will be closed.

\end{itemize}

The peer management protocol is also responsible for beacon collision avoidance, because it keeps beacon timing elements from all neighbours. Note that the PeerManagementProtocol is not attached to the MeshPointDevice as a routing protocol, but the structure is similar: the upper tier of the protocol is
\sphinxcode{\sphinxupquote{ns3::dot11s::PeerManagementProtocol}} and its plug\sphinxhyphen{}in is
\sphinxcode{\sphinxupquote{ns3::dot11s::PeerManagementProtocolMac}}.


\paragraph{Hybrid Wireless Mesh Protocol}
\label{\detokenize{mesh-design:hybrid-wireless-mesh-protocol}}
HWMP is implemented in both modes, reactive and proactive, although path maintenance is not implemented (so active routes may time out and need to be rebuilt, causing packet loss). Also the model implements an ability to transmit broadcast data and management frames as unicasts (see appropriate attributes). This feature is disabled at a station when the number of neighbors of the station is more than a threshold value.


\subsection{Scope and Limitations}
\label{\detokenize{mesh-design:scope-and-limitations}}

\subsubsection{Supported features}
\label{\detokenize{mesh-design:supported-features}}\begin{itemize}
\item {} 
Peering Management Protocol (PMP), including link close heuristics and beacon collision avoidance.

\item {} 
Hybrid Wireless Mesh Protocol (HWMP), including proactive and reactive modes, unicast/broadcast propagation of management traffic, multi\sphinxhyphen{}radio extensions.

\item {} 
802.11e compatible airtime link metric.

\end{itemize}


\subsubsection{Verification}
\label{\detokenize{mesh-design:verification}}\begin{itemize}
\item {} 
Comes with the custom Wireshark dissector.

\item {} 
Linux kernel mac80211 layer compatible message formats.

\end{itemize}


\subsubsection{Unsupported features}
\label{\detokenize{mesh-design:unsupported-features}}\begin{itemize}
\item {} 
Mesh Coordinated Channel Access (MCCA).

\item {} 
Internetworking: mesh access point and mesh portal.

\item {} 
Security.

\item {} 
Power save.

\item {} 
Path maintenance (sending PREQ proactively before a path expires)

\item {} 
Though multi\sphinxhyphen{}radio operation is supported, no channel assignment protocol is proposed for now. (Correct channel switching is not implemented)

\end{itemize}


\subsubsection{Models yet to be created}
\label{\detokenize{mesh-design:models-yet-to-be-created}}\begin{itemize}
\item {} 
Mesh access point (QoS + non\sphinxhyphen{}QoS?)

\item {} 
Mesh portal (QoS + non\sphinxhyphen{}QoS?)

\end{itemize}


\subsubsection{Open issues}
\label{\detokenize{mesh-design:open-issues}}
A bug exists in the Wi\sphinxhyphen{}Fi module that manifests itself as performance
degradation in large mesh networks, due to incorrect duplicate frame
detection for QoS data frames (bug 2326).

Mesh does not work for 802.11n/ac stations (bug 2276).

Energy module can not be used on mesh devices (bug 2265).

IE11S\_MESH\_PEERING\_PROTOCOL\_VERSION should be removed as per standard.
Protocol ID should actually be part of the Mesh Peering Management IE (bug 2600).

Node packet processing times are not modeled; some evaluation of the impact
of packet processing delays is discussed in \sphinxcite{mesh-references:hep16}.


\section{User Documentation}
\label{\detokenize{mesh-user:user-documentation}}\label{\detokenize{mesh-user::doc}}

\subsection{Using the MeshNetDevice}
\label{\detokenize{mesh-user:using-the-meshnetdevice}}

\section{Testing Documentation}
\label{\detokenize{mesh-testing:testing-documentation}}\label{\detokenize{mesh-testing::doc}}

\section{References}
\label{\detokenize{mesh-references:references}}\label{\detokenize{mesh-references::doc}}

\chapter{MPI for Distributed Simulation}
\label{\detokenize{distributed:mpi-for-distributed-simulation}}\label{\detokenize{distributed::doc}}
Parallel and distributed discrete event simulation allows the execution of a
single simulation program on multiple processors. By splitting up the simulation
into logical processes, LPs, each LP can be executed by a different processor.
This simulation methodology enables very large\sphinxhyphen{}scale simulations by leveraging
increased processing power and memory availability. In order to ensure proper
execution of a distributed simulation, message passing between LPs is required.
To support distributed simulation in \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the standard Message Passing
Interface (MPI) is used, along with a new distributed simulator class.
Currently, dividing a simulation for distributed purposes in \sphinxstyleemphasis{ns\sphinxhyphen{}3} can only occur
across point\sphinxhyphen{}to\sphinxhyphen{}point links.


\section{Current Implementation Details}
\label{\detokenize{distributed:current-implementation-details}}\label{\detokenize{distributed:id1}}
During the course of a distributed simulation, many packets must cross simulator
boundaries. In other words, a packet that originated on one LP is destined for a
different LP, and in order to make this transition, a message containing the
packet contents must be sent to the remote LP. Upon receiving this message, the
remote LP can rebuild the packet and proceed as normal. The process of sending
an receiving messages between LPs is handled easily by the new MPI interface in
\sphinxstyleemphasis{ns\sphinxhyphen{}3}.

Along with simple message passing between LPs, a distributed simulator is used
on each LP to determine which events to process. It is important to process
events in time\sphinxhyphen{}stamped order to ensure proper simulation execution. If a LP
receives a message containing an event from the past, clearly this is an issue,
since this event could change other events which have already been executed. To
address this problem, two conservative synchronization algorithm with lookahead are
used in \sphinxstyleemphasis{ns\sphinxhyphen{}3}. For more information on different synchronization approaches and
parallel and distributed simulation in general, please refer to “Parallel and
Distributed Simulation Systems” by Richard Fujimoto.

The default parallel synchronization strategy implemented in the
DistributedSimulatorImpl class is based on a globally synchronized
algorithm using an MPI collective operation to synchronize simulation
time across all LPs.  A second synchronization strategy based on local
communication and null messages is implemented in the
NullMessageSimulatorImpl class, For the null message strategy the
global all to all gather is not required; LPs only need to
communication with LPs that have shared point\sphinxhyphen{}to\sphinxhyphen{}point links.  The
algorithm to use is controlled by which the \sphinxstyleemphasis{ns\sphinxhyphen{}3} global value
SimulatorImplementationType.

The best algorithm to use is dependent on the communication and event
scheduling pattern for the application.  In general, null message
synchronization algorithms will scale better due to local
communication scaling better than a global all\sphinxhyphen{}to\sphinxhyphen{}all gather that is
required by DistributedSimulatorImpl.  There are two known cases where
the global synchronization performs better.  The first is when most
LPs have point\sphinxhyphen{}to\sphinxhyphen{}point link with most other LPs, in other words the
LPs are nearly fully connected.  In this case the null message
algorithm will generate more message passing traffic than the
all\sphinxhyphen{}to\sphinxhyphen{}all gather.  A second case where the global all\sphinxhyphen{}to\sphinxhyphen{}all gather
is more efficient is when there are long periods of simulation time
when no events are occurring.  The all\sphinxhyphen{}to\sphinxhyphen{}all gather algorithm is able
to quickly determine then next event time globally.  The nearest
neighbor behavior of the null message algorithm will require more
communications to propagate that knowledge; each LP is only aware of
neighbor next event times.


\subsection{Remote point\sphinxhyphen{}to\sphinxhyphen{}point links}
\label{\detokenize{distributed:remote-point-to-point-links}}
As described in the introduction, dividing a simulation for distributed purposes
in \sphinxstyleemphasis{ns\sphinxhyphen{}3} currently can only occur across point\sphinxhyphen{}to\sphinxhyphen{}point links; therefore, the
idea of remote point\sphinxhyphen{}to\sphinxhyphen{}point links is very important for distributed simulation
in \sphinxstyleemphasis{ns\sphinxhyphen{}3}. When a point\sphinxhyphen{}to\sphinxhyphen{}point link is installed, connecting two nodes, the
point\sphinxhyphen{}to\sphinxhyphen{}point helper checks the system id, or rank, of both nodes. The rank
should be assigned during node creation for distributed simulation and is
intended to signify on which LP a node belongs. If the two nodes are on the same
rank, a regular point\sphinxhyphen{}to\sphinxhyphen{}point link is created. If, however, the two nodes are
on different ranks, then these nodes are intended for different LPs, and a
remote point\sphinxhyphen{}to\sphinxhyphen{}point link is used. If a packet is to be sent across a remote
point\sphinxhyphen{}to\sphinxhyphen{}point link, MPI is used to send the message to the remote LP.


\subsection{Distributing the topology}
\label{\detokenize{distributed:distributing-the-topology}}
Currently, the full topology is created on each rank, regardless of the
individual node system ids. Only the applications are specific to a rank. For
example, consider node 1 on LP 1 and node 2 on LP 2, with a traffic generator on
node 1. Both node 1 and node 2 will be created on both LP1 and LP2; however, the
traffic generator will only be installed on LP1. While this is not optimal for
memory efficiency, it does simplify routing, since all current routing
implementations in \sphinxstyleemphasis{ns\sphinxhyphen{}3} will work with distributed simulation.


\section{Running Distributed Simulations}
\label{\detokenize{distributed:running-distributed-simulations}}

\subsection{Prerequisites}
\label{\detokenize{distributed:prerequisites}}
Ensure that MPI is installed, as well as mpic++. In Ubuntu repositories,
these are openmpi\sphinxhyphen{}bin, openmpi\sphinxhyphen{}common, openmpi\sphinxhyphen{}doc, libopenmpi\sphinxhyphen{}dev. In
Fedora, these are openmpi and openmpi\sphinxhyphen{}devel.

Note:

There is a conflict on some Fedora systems between libotf and openmpi. A
possible “quick\sphinxhyphen{}fix” is to yum remove libotf before installing openmpi.
This will remove conflict, but it will also remove emacs. Alternatively,
these steps could be followed to resolve the conflict:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{)}%
\item {} 
Rename the tiny otfdump which emacs says it needs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mv /usr/bin/otfdump /usr/bin/otfdump.emacs\PYGZhy{}version
\end{sphinxVerbatim}

\item {} 
Manually resolve openmpi dependencies:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo yum install libgfortran libtorque numactl
\end{sphinxVerbatim}

\item {} 
Download rpm packages:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
openmpi\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm
openmpi\PYGZhy{}devel\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm
openmpi\PYGZhy{}libs\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm
openmpi\PYGZhy{}vt\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm
\end{sphinxVerbatim}

from \sphinxurl{http://mirrors.kernel.org/fedora/releases/11/Everything/i386/os/Packages/}

\item {} 
Force the packages in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo rpm \PYGZhy{}ivh \PYGZhy{}\PYGZhy{}force \PYG{l+s+se}{\PYGZbs{}}
openmpi\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm \PYG{l+s+se}{\PYGZbs{}}
openmpi\PYGZhy{}libs\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm \PYG{l+s+se}{\PYGZbs{}}
openmpi\PYGZhy{}devel\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm \PYG{l+s+se}{\PYGZbs{}}
openmpi\PYGZhy{}vt\PYGZhy{}1.3.1\PYGZhy{}1.fc11.i586.rpm
\end{sphinxVerbatim}

\end{enumerate}

Also, it may be necessary to add the openmpi bin directory to PATH in order to
execute mpic++ and mpirun from the command line. Alternatively, the full path to
these executables can be used. Finally, if openmpi complains about the inability
to open shared libraries, such as libmpi\_cxx.so.0, it may be necessary to add
the openmpi lib directory to LD\_LIBRARY\_PATH.

Here is an example of setting up PATH and LD\_LIBRARY\_PATH using a bash shell:
\begin{quote}
\begin{itemize}
\item {} 
For a 32\sphinxhyphen{}bit Linux distribution:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{export} \PYG{n+nv}{PATH}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}PATH}:/usr/lib/openmpi/bin
\PYGZdl{} \PYG{n+nb}{export} \PYG{n+nv}{LD\PYGZus{}LIBRARY\PYGZus{}PATH}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}LD\PYGZus{}LIBRARY\PYGZus{}PATH}:/usr/lib/openmpi/lib
\end{sphinxVerbatim}

\end{itemize}
\begin{quote}

For a 64\sphinxhyphen{}bit Linux distribution:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nb}{export} \PYG{n+nv}{PATH}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}PATH}:/usr/lib64/openmpi/bin
\PYGZdl{} \PYG{n+nb}{export} \PYG{n+nv}{LD\PYGZus{}LIBRARY\PYGZus{}PATH}\PYG{o}{=}\PYG{n+nv}{\PYGZdl{}LD\PYGZus{}LIBRARY\PYGZus{}PATH}:/usr/lib64/openmpi/lib
\end{sphinxVerbatim}
\end{quote}
\end{quote}

These lines can be added into \textasciitilde{}/.bash\_profile or \textasciitilde{}/.bashrc to avoid having to
retype them when a new shell is opened.


\subsection{Building and Running Examples}
\label{\detokenize{distributed:building-and-running-examples}}
If you already built \sphinxstyleemphasis{ns\sphinxhyphen{}3} without MPI enabled, you must re\sphinxhyphen{}build:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf distclean
\end{sphinxVerbatim}

Configure \sphinxstyleemphasis{ns\sphinxhyphen{}3} with the \textendash{}enable\sphinxhyphen{}mpi option:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}d debug configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}enable\PYGZhy{}mpi
\end{sphinxVerbatim}

Ensure that MPI is enabled by checking the optional features shown from the
output of configure.

Next, build \sphinxstyleemphasis{ns\sphinxhyphen{}3}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf
\end{sphinxVerbatim}

After building \sphinxstyleemphasis{ns\sphinxhyphen{}3} with mpi enabled, the example programs are now
ready to run with mpirun. Here are a few examples (from the root \sphinxstyleemphasis{ns\sphinxhyphen{}3}
directory):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mpirun \PYGZhy{}np \PYG{l+m}{2} ./waf \PYGZhy{}\PYGZhy{}run simple\PYGZhy{}distributed
\PYGZdl{} mpirun \PYGZhy{}np \PYG{l+m}{4} \PYGZhy{}machinefile mpihosts ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s1}{\PYGZsq{}nms\PYGZhy{}udp\PYGZhy{}nix \PYGZhy{}\PYGZhy{}LAN=2 \PYGZhy{}\PYGZhy{}CN=4 \PYGZhy{}\PYGZhy{}nix=1\PYGZsq{}}
\end{sphinxVerbatim}

An examle using the null message synchronization algorithm:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} mpirun \PYGZhy{}np \PYG{l+m}{2} ./waf \PYGZhy{}\PYGZhy{}run simple\PYGZhy{}distributed \PYGZhy{}\PYGZhy{}nullmsg
\end{sphinxVerbatim}

The np switch is the number of logical processors to use. The machinefile switch
is which machines to use. In order to use machinefile, the target file must
exist (in this case mpihosts). This can simply contain something like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
localhost
localhost
localhost
...
\end{sphinxVerbatim}

Or if you have a cluster of machines, you can name them.

NOTE: Some users have experienced issues using mpirun and waf together. An
alternative way to run distributed examples is shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf shell
\PYGZdl{} \PYG{n+nb}{cd} build/debug
\PYGZdl{} mpirun \PYGZhy{}np \PYG{l+m}{2} src/mpi/examples/simple\PYGZhy{}distributed
\end{sphinxVerbatim}


\subsection{Setting synchronization algorithm to use}
\label{\detokenize{distributed:setting-synchronization-algorithm-to-use}}
The global value SimulatorImplementationType is used to set the
synchronization algorithm to use.  This value must be set before the
MpiInterface::Enable method is invoked if the default
DistributedSimulatorImpl is not used.  Here is an example code snippet
showing how to add a command line argument to control the
synchronization algorithm choice::

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cmd.AddValue \PYG{o}{(}\PYG{l+s+s2}{\PYGZdq{}nullmsg\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}Enable the use of null\PYGZhy{}message synchronization\PYGZdq{}}, nullmsg\PYG{o}{)}\PYG{p}{;}
\PYG{k}{if}\PYG{o}{(}nullmsg\PYG{o}{)}
  \PYG{o}{\PYGZob{}}
    GlobalValue::Bind \PYG{o}{(}\PYG{l+s+s2}{\PYGZdq{}SimulatorImplementationType\PYGZdq{}},
                       StringValue \PYG{o}{(}\PYG{l+s+s2}{\PYGZdq{}ns3::NullMessageSimulatorImpl\PYGZdq{}}\PYG{o}{)}\PYG{o}{)}\PYG{p}{;}
  \PYG{o}{\PYGZcb{}}
\PYG{k}{else}
  \PYG{o}{\PYGZob{}}
    GlobalValue::Bind \PYG{o}{(}\PYG{l+s+s2}{\PYGZdq{}SimulatorImplementationType\PYGZdq{}},
                       StringValue \PYG{o}{(}\PYG{l+s+s2}{\PYGZdq{}ns3::DistributedSimulatorImpl\PYGZdq{}}\PYG{o}{)}\PYG{o}{)}\PYG{p}{;}
  \PYG{o}{\PYGZcb{}}

// Enable parallel simulator with the \PYG{n+nb}{command} line arguments
MpiInterface::Enable \PYG{o}{(}\PYG{p}{\PYGZam{}}argc, \PYG{p}{\PYGZam{}}argv\PYG{o}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Creating custom topologies}
\label{\detokenize{distributed:creating-custom-topologies}}
The example programs in src/mpi/examples give a good idea of how to create different
topologies for distributed simulation. The main points are assigning system ids
to individual nodes, creating point\sphinxhyphen{}to\sphinxhyphen{}point links where the simulation should
be divided, and installing applications only on the LP associated with the
target node.

Assigning system ids to nodes is simple and can be handled two different ways.
First, a NodeContainer can be used to create the nodes and assign system ids:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{nodes}\PYG{p}{;}
\PYG{n}{nodes}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Creates 5 nodes with system id 1.}
\end{sphinxVerbatim}

Alternatively, nodes can be created individually, assigned system ids, and added
to a NodeContainer. This is useful if a NodeContainer holds nodes with different
system ids:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{nodes}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node1} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Create node1 with system id 0}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node2} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Create node2 with system id 1}
\PYG{n}{nodes}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{node1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{nodes}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{node2}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Next, where the simulation is divided is determined by the placement of
point\sphinxhyphen{}to\sphinxhyphen{}point links. If a point\sphinxhyphen{}to\sphinxhyphen{}point link is created between two
nodes with different system ids, a remote point\sphinxhyphen{}to\sphinxhyphen{}point link is created,
as described in {\hyperref[\detokenize{distributed:current-implementation-details}]{\sphinxcrossref{\DUrole{std,std-ref}{Current Implementation Details}}}}.

Finally, installing applications only on the LP associated with the target node
is very important. For example, if a traffic generator is to be placed on node
0, which is on LP0, only LP0 should install this application.  This is easily
accomplished by first checking the simulator system id, and ensuring that it
matches the system id of the target node before installing the application.


\section{Tracing During Distributed Simulations}
\label{\detokenize{distributed:tracing-during-distributed-simulations}}
Depending on the system id (rank) of the simulator, the information traced will
be different, since traffic originating on one simulator is not seen by another
simulator until it reaches nodes specific to that simulator. The easiest way to
keep track of different traces is to just name the trace files or pcaps
differently, based on the system id of the simulator. For example, something
like this should work well, assuming all of these local variables were
previously defined:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{MpiInterface}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetSystemId} \PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{pointToPoint}\PYG{p}{.}\PYG{n}{EnablePcapAll} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{phy}\PYG{p}{.}\PYG{n}{EnablePcap} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{apDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{csma}\PYG{p}{.}\PYG{n}{EnablePcap} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{csmaDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{k}{else} \PYG{k}{if} \PYG{p}{(}\PYG{n}{MpiInterface}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetSystemId} \PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{pointToPoint}\PYG{p}{.}\PYG{n}{EnablePcapAll} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{phy}\PYG{p}{.}\PYG{n}{EnablePcap} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{apDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{csma}\PYG{p}{.}\PYG{n}{EnablePcap} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{distributed\PYGZhy{}rank1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{csmaDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\chapter{Mobility}
\label{\detokenize{mobility:mobility}}\label{\detokenize{mobility:id1}}\label{\detokenize{mobility::doc}}
The mobility support in \sphinxstyleemphasis{ns\sphinxhyphen{}3} includes:
\begin{itemize}
\item {} 
a set of mobility models which are used to track and maintain the \sphinxstyleemphasis{current} cartesian position and speed of an object.

\item {} 
a “course change notifier” trace source which can be used to register listeners to the course changes of a mobility model

\item {} 
a number of helper classes which are used to place nodes and setup mobility models (including parsers for some mobility definition formats).

\end{itemize}


\section{Model Description}
\label{\detokenize{mobility:model-description}}
The source code for mobility lives in the directory \sphinxcode{\sphinxupquote{src/mobility}}.


\subsection{Design}
\label{\detokenize{mobility:design}}
The design includes mobility models, position allocators, and helper
functions.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, special \sphinxcode{\sphinxupquote{MobilityModel}} objects track the evolution of position
with respect to a (cartesian) coordinate system.  The mobility model
is typically aggregated to an \sphinxcode{\sphinxupquote{ns3::Node}} object and queried using
\sphinxcode{\sphinxupquote{GetObject\textless{}MobilityModel\textgreater{} ()}}. The base class \sphinxcode{\sphinxupquote{ns3::MobilityModel}}
is subclassed for different motion behaviors.

The initial position of objects is typically set with a PositionAllocator.
These types of objects will lay out the position on a notional canvas.
Once the simulation starts, the position allocator may no longer be
used, or it may be used to pick future mobility “waypoints” for such
mobility models.

Most users interact with the mobility system using mobility helper
classes.  The MobilityHelper combines a mobility model and position
allocator, and can be used with a node container to install mobility
capability on a set of nodes.

We first describe the coordinate system and issues
surrounding multiple coordinate systems.


\subsubsection{Coordinate system}
\label{\detokenize{mobility:coordinate-system}}
There are many possible coordinate systems and possible translations between
them.  \sphinxstyleemphasis{ns\sphinxhyphen{}3} uses the Cartesian coordinate system only, at present.

The question has arisen as to how to use the mobility models (supporting
Cartesian coordinates) with different coordinate systems.  This is possible
if the user performs conversion between the \sphinxstyleemphasis{ns\sphinxhyphen{}3} Cartesian and the
other coordinate system.  One possible library to assist is
the proj4 \sphinxurl{http://trac.osgeo.org/proj/} library for projections and reverse
projections.

If we support converting between coordinate systems, we must adopt a
reference.  It has been suggested to use the geocentric Cartesian coordinate
system as a reference.  Contributions are welcome in this regard.

The question has arisen about adding a new mobility model whose motion
is natively implemented in a different coordinate system (such as an
orbital mobility model implemented using spherical coordinate system).
We advise to create a subclass with the APIs desired
(such as Get/SetSphericalPosition), and new position allocators, and
implement the motion however desired, but must also support the conversion to
cartesian (by supporting the cartesian Get/SetPosition).


\subsubsection{Coordinates}
\label{\detokenize{mobility:coordinates}}
The base class for a coordinate is called \sphinxcode{\sphinxupquote{ns3::Vector}}.  While
positions are normally described as coordinates and not vectors in
the literature, it is possible to reuse the same data structure to
represent position (x,y,z) and velocity (magnitude and direction
from the current position).  \sphinxstyleemphasis{ns\sphinxhyphen{}3} uses class Vector for both.

There are also some additional related structures used to support
mobility models.
\begin{itemize}
\item {} 
Rectangle

\item {} 
Box

\item {} 
Waypoint

\end{itemize}


\subsubsection{MobilityModel}
\label{\detokenize{mobility:mobilitymodel}}
Describe base class
\begin{itemize}
\item {} 
GetPosition ()

\item {} 
Position and Velocity attributes

\item {} 
GetDistanceFrom ()

\item {} 
CourseChangeNotification

\end{itemize}


\subsubsection{MobilityModel Subclasses}
\label{\detokenize{mobility:mobilitymodel-subclasses}}\begin{itemize}
\item {} 
ConstantPosition

\item {} 
ConstantVelocity

\item {} 
ConstantAcceleration

\item {} 
GaussMarkov

\item {} 
Hierarchical

\item {} 
RandomDirection2D

\item {} 
RandomWalk2D

\item {} 
RandomWaypoint

\item {} 
SteadyStateRandomWaypoint

\item {} 
Waypoint

\end{itemize}


\subsubsection{PositionAllocator}
\label{\detokenize{mobility:positionallocator}}
Position allocators usually used only at beginning, to lay out the nodes
initial position.  However, some mobility models (e.g. RandomWaypoint) will
use a position allocator to pick new waypoints.
\begin{itemize}
\item {} 
ListPositionAllocator

\item {} 
GridPositionAllocator

\item {} 
RandomRectanglePositionAllocator

\item {} 
RandomBoxPositionAllocator

\item {} 
RandomDiscPositionAllocator

\item {} 
UniformDiscPositionAllocator

\end{itemize}


\subsubsection{Helper}
\label{\detokenize{mobility:helper}}
A special mobility helper is provided that is mainly aimed at supporting
the installation of mobility to a Node container (when using containers
at the helper API level).  The MobilityHelper class encapsulates
a MobilityModel factory object and a PositionAllocator used for
initial node layout.


\subsubsection{ns\sphinxhyphen{}2 MobilityHelper}
\label{\detokenize{mobility:ns-2-mobilityhelper}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}2} mobility format is a widely used mobility trace format.  The
documentation is available at: \sphinxurl{http://www.isi.edu/nsnam/ns/doc/node172.html}

Valid trace files use the following ns2 statements:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} X\PYGZus{} x1
\PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} Y\PYGZus{} y1
\PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} Z\PYGZus{} z1
\PYG{n+nv}{\PYGZdl{}ns} at \PYG{n+nv}{\PYGZdl{}time} \PYG{n+nv}{\PYGZdl{}node} setdest x2 y2 speed
\PYG{n+nv}{\PYGZdl{}ns} at \PYG{n+nv}{\PYGZdl{}time} \PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} X\PYGZus{} x1
\PYG{n+nv}{\PYGZdl{}ns} at \PYG{n+nv}{\PYGZdl{}time} \PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} Y\PYGZus{} Y1
\PYG{n+nv}{\PYGZdl{}ns} at \PYG{n+nv}{\PYGZdl{}time} \PYG{n+nv}{\PYGZdl{}node} \PYG{n+nb}{set} Z\PYGZus{} Z1
\end{sphinxVerbatim}

In the above, the initial positions are set using the \sphinxcode{\sphinxupquote{set}} statements.
Also, this \sphinxcode{\sphinxupquote{set}} can be specified for a future time, such as in the
last three statements above.

The command \sphinxcode{\sphinxupquote{setdest}} instructs the simulation to start moving the
specified node towards the coordinate (x2, y2) at the specified time.
Note that the node may never get to the destination, but will
proceed towards the destination at the specified speed until it
either reaches the destination (where it will pause), is set to
a new position (via \sphinxcode{\sphinxupquote{set}}), or sent on another course change
(via \sphinxcode{\sphinxupquote{setdest}}).

Note that in \sphinxstyleemphasis{ns\sphinxhyphen{}3}, movement along the Z dimension is not supported.

Some examples of external tools that can export in this format include:
\begin{itemize}
\item {} 
\sphinxhref{http://net.cs.uni-bonn.de/wg/cs/applications/bonnmotion/}{BonnMotion}
\begin{itemize}
\item {} 
\sphinxhref{http://www.nsnam.org/wiki/HOWTO\_use\_ns-3\_with\_BonnMotion\_mobility\_generator\_and\_analysis\_tool}{Installation instructions} and

\item {} 
\sphinxhref{http://www.ida.liu.se/~rikno/files/mobility\_generation.pdf}{Documentation} for using BonnMotion with \sphinxstyleemphasis{ns\sphinxhyphen{}3}

\end{itemize}

\item {} 
\sphinxhref{http://sourceforge.net/apps/mediawiki/sumo/index.php?title=Main\_Page}{SUMO}

\item {} 
\sphinxhref{http://trans.epfl.ch/}{TraNS}

\item {} 
\sphinxstyleemphasis{ns\sphinxhyphen{}2} \sphinxhref{http://www.winlab.rutgers.edu/~zhibinwu/html/ns2\_wireless\_scene.htm}{setdest} utility

\end{itemize}

A special Ns2MobilityHelper object can be used to parse these files
and convert the statements into \sphinxstyleemphasis{ns\sphinxhyphen{}3} mobility events.  The underlying
ConstantVelocityMobilityModel is used to model these movements.

See below for additional usage instructions on this helper.


\subsection{Scope and Limitations}
\label{\detokenize{mobility:scope-and-limitations}}\begin{itemize}
\item {} 
only cartesian coordinates are presently supported

\end{itemize}


\subsection{References}
\label{\detokenize{mobility:references}}
TBD


\section{Usage}
\label{\detokenize{mobility:usage}}
Most \sphinxstyleemphasis{ns\sphinxhyphen{}3} program authors typically interact with the mobility system
only at configuration time.  However, various \sphinxstyleemphasis{ns\sphinxhyphen{}3} objects interact
with mobility objects repeatedly during runtime, such as a propagation
model trying to determine the path loss between two mobile nodes.


\subsection{Helper}
\label{\detokenize{mobility:id2}}
A typical usage pattern can be found in the \sphinxcode{\sphinxupquote{third.cc}} program in the
tutorial.

First, the user instantiates a \sphinxcode{\sphinxupquote{MobilityHelper}} object and sets some
\sphinxcode{\sphinxupquote{Attributes}} controlling the “position allocator” functionality.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}

\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetPositionAllocator} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::GridPositionAllocator}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MinX}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MinY}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DeltaX}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{5.0}\PYG{p}{)}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DeltaY}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{10.0}\PYG{p}{)}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{GridWidth}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{LayoutType}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{RowFirst}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This code tells the mobility helper to use a two\sphinxhyphen{}dimensional grid to initially
place the nodes.  The first argument is an \sphinxstyleemphasis{ns\sphinxhyphen{}3} TypeId specifying the
type of mobility model; the remaining attribute/value pairs configure
this position allocator.

Next, the user typically sets the MobilityModel subclass; e.g.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetMobilityModel} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RandomWalk2dMobilityModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Bounds}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{RectangleValue} \PYG{p}{(}\PYG{n}{Rectangle} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once the helper is configured, it is typically passed a container, such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiStaNodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

A MobilityHelper object may be reconfigured and reused for different
NodeContainers during the configuration of an \sphinxstyleemphasis{ns\sphinxhyphen{}3} scenario.


\subsection{Ns2MobilityHelper}
\label{\detokenize{mobility:ns2mobilityhelper}}
Two example programs are provided demonstrating the use of the
\sphinxstyleemphasis{ns\sphinxhyphen{}2} mobility helper:
\begin{itemize}
\item {} 
ns2\sphinxhyphen{}mobility\sphinxhyphen{}trace.cc

\item {} 
bonnmotion\sphinxhyphen{}ns2\sphinxhyphen{}example.cc

\end{itemize}


\subsubsection{ns2\sphinxhyphen{}mobility\sphinxhyphen{}trace}
\label{\detokenize{mobility:ns2-mobility-trace}}
The \sphinxcode{\sphinxupquote{ns2\sphinxhyphen{}mobility\sphinxhyphen{}trace.cc}} program is an example of loading an
\sphinxstyleemphasis{ns\sphinxhyphen{}2} trace file that specifies the movements of two nodes over 100
seconds of simulation time.  It is paired with the file
\sphinxcode{\sphinxupquote{default.ns\_movements}}.

The program behaves as follows:
\begin{itemize}
\item {} 
a Ns2MobilityHelper object is created, with the specified trace file.

\item {} 
A log file is created, using the log file name argument.

\item {} 
A node container is created with the number of nodes specified in the command line.  For this particular trace file, specify the value 2 for this argument.

\item {} 
the Install() method of Ns2MobilityHelper to set mobility to nodes. At this moment, the file is read line by line, and the movement is scheduled in the simulator.

\item {} 
A callback is configured, so each time a node changes its course a log message is printed.

\end{itemize}

The example prints out messages generated by each read line from the ns2 movement trace file.   For each line, it shows if the line is correct, or of it has errors and in this case it will be ignored.

Example usage:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}ns2\PYGZhy{}mobility\PYGZhy{}trace \PYGZbs{}}
\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}traceFile=src/mobility/examples/default.ns\PYGZus{}movements \PYGZbs{}}
\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}nodeNum=2 \PYGZbs{}}
\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}duration=100.0 \PYGZbs{}}
\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}logFile=ns2\PYGZhy{}mob.log\PYGZdq{}}
\end{sphinxVerbatim}

Sample log file output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+0.0ns POS: x=150, y=93.986, z=0; VEL:0, y=50.4038, z=0
+0.0ns POS: x=195.418, y=150, z=0; VEL:50.1186, y=0, z=0
+104727357.0ns POS: x=200.667, y=150, z=0; VEL:50.1239, y=0, z=0
+204480076.0ns POS: x=205.667, y=150, z=0; VEL:0, y=0, z=0
\end{sphinxVerbatim}


\subsubsection{bonnmotion\sphinxhyphen{}ns2\sphinxhyphen{}example}
\label{\detokenize{mobility:bonnmotion-ns2-example}}
The \sphinxcode{\sphinxupquote{bonnmotion\sphinxhyphen{}ns2\sphinxhyphen{}example.cc}} program, which models the movement of
a single mobile node for 1000 seconds of simulation time, has a few
associated files:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bonnmotion.ns\_movements}} is the \sphinxstyleemphasis{ns\sphinxhyphen{}2}\sphinxhyphen{}formatted mobility trace

\item {} 
\sphinxcode{\sphinxupquote{bonnmotion.params}} is a BonnMotion\sphinxhyphen{}generated file with some metadata about the mobility trace

\item {} 
\sphinxcode{\sphinxupquote{bonnmotion.ns\_params}} is another BonnMotion\sphinxhyphen{}generated file with ns\sphinxhyphen{}2\sphinxhyphen{}related metadata.

\end{itemize}

Neither of the latter two files is used by \sphinxstyleemphasis{ns\sphinxhyphen{}3}, although they are generated
as part of the BonnMotion process to output ns\sphinxhyphen{}2\sphinxhyphen{}compatible traces.

The program \sphinxcode{\sphinxupquote{bonnmotion\sphinxhyphen{}ns2\sphinxhyphen{}example.cc}} will output the following to stdout:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
At 0.00 node 0: Position(329.82, 66.06, 0.00);   Speed(0.53, \PYGZhy{}0.22, 0.00)
At 100.00 node 0: Position(378.38, 45.59, 0.00);   Speed(0.00, 0.00, 0.00)
At 200.00 node 0: Position(304.52, 123.66, 0.00);   Speed(\PYGZhy{}0.92, 0.97, 0.00)
At 300.00 node 0: Position(274.16, 131.67, 0.00);   Speed(\PYGZhy{}0.53, \PYGZhy{}0.46, 0.00)
At 400.00 node 0: Position(202.11, 123.60, 0.00);   Speed(\PYGZhy{}0.98, 0.35, 0.00)
At 500.00 node 0: Position(104.60, 158.95, 0.00);   Speed(\PYGZhy{}0.98, 0.35, 0.00)
At 600.00 node 0: Position(31.92, 183.87, 0.00);   Speed(0.76, \PYGZhy{}0.51, 0.00)
At 700.00 node 0: Position(107.99, 132.43, 0.00);   Speed(0.76, \PYGZhy{}0.51, 0.00)
At 800.00 node 0: Position(184.06, 80.98, 0.00);   Speed(0.76, \PYGZhy{}0.51, 0.00)
At 900.00 node 0: Position(250.08, 41.76, 0.00);   Speed(0.60, \PYGZhy{}0.05, 0.00)
\end{sphinxVerbatim}

The motion of the mobile node is sampled every 100 seconds, and its position
and speed are printed out.  This output may be compared to the output of
a similar \sphinxstyleemphasis{ns\sphinxhyphen{}2} program (found in the \sphinxstyleemphasis{ns\sphinxhyphen{}2} \sphinxcode{\sphinxupquote{tcl/ex/}} directory of \sphinxstyleemphasis{ns\sphinxhyphen{}2})
running from the same mobility trace.

The next file is generated from \sphinxstyleemphasis{ns\sphinxhyphen{}2} (users will have to download and
install \sphinxstyleemphasis{ns\sphinxhyphen{}2} and run this Tcl program to see this output).
The output of the \sphinxstyleemphasis{ns\sphinxhyphen{}2} \sphinxcode{\sphinxupquote{bonnmotion\sphinxhyphen{}example.tcl}} program is shown below
for comparison (file \sphinxcode{\sphinxupquote{bonnmotion\sphinxhyphen{}example.tr}}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
M 0.00000 0 (329.82, 66.06, 0.00), (378.38, 45.59), 0.57
M 100.00000 0 (378.38, 45.59, 0.00), (378.38, 45.59), 0.57
M 119.37150 0 (378.38, 45.59, 0.00), (286.69, 142.52), 1.33
M 200.00000 0 (304.52, 123.66, 0.00), (286.69, 142.52), 1.33
M 276.35353 0 (286.69, 142.52, 0.00), (246.32, 107.57), 0.70
M 300.00000 0 (274.16, 131.67, 0.00), (246.32, 107.57), 0.70
M 354.65589 0 (246.32, 107.57, 0.00), (27.38, 186.94), 1.04
M 400.00000 0 (202.11, 123.60, 0.00), (27.38, 186.94), 1.04
M 500.00000 0 (104.60, 158.95, 0.00), (27.38, 186.94), 1.04
M 594.03719 0 (27.38, 186.94, 0.00), (241.02, 42.45), 0.92
M 600.00000 0 (31.92, 183.87, 0.00), (241.02, 42.45), 0.92
M 700.00000 0 (107.99, 132.43, 0.00), (241.02, 42.45), 0.92
M 800.00000 0 (184.06, 80.98, 0.00), (241.02, 42.45), 0.92
M 884.77399 0 (241.02, 42.45, 0.00), (309.59, 37.22), 0.60
M 900.00000 0 (250.08, 41.76, 0.00), (309.59, 37.22), 0.60
\end{sphinxVerbatim}

The output formatting is slightly different, and the course change
times are additionally plotted, but it can be seen that the position
vectors are the same between the two traces at intervals of 100 seconds.

The mobility computations performed on the \sphinxstyleemphasis{ns\sphinxhyphen{}2} trace file are slightly
different in \sphinxstyleemphasis{ns\sphinxhyphen{}2} and \sphinxstyleemphasis{ns\sphinxhyphen{}3}, and floating\sphinxhyphen{}point arithmetic is used,
so there is a chance that the position in \sphinxstyleemphasis{ns\sphinxhyphen{}2} may be slightly
different than the respective position when using the trace file
in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.


\subsection{Use of Random Variables}
\label{\detokenize{mobility:use-of-random-variables}}
A typical use case is to evaluate protocols on a mobile topology that
involves some randomness in the motion or initial position allocation.
To obtain random motion and positioning that is not affected by
the configuration of the rest of the scenario, it is recommended to
use the “AssignStreams” facility of the random number system.

Class \sphinxcode{\sphinxupquote{MobilityModel}} and class \sphinxcode{\sphinxupquote{PositionAllocator}} both have public
API to assign streams to underlying random variables:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * Assign a fixed random variable stream number to the random variables}
\PYG{c+cm}{ * used by this model. Return the number of streams (possibly zero) that}
\PYG{c+cm}{ * have been assigned.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}param stream first stream index to use}
\PYG{c+cm}{ * \PYGZbs{}return the number of stream indices assigned by this model}
\PYG{c+cm}{ */}
\PYG{k+kt}{int64\PYGZus{}t} \PYG{n+nf}{AssignStreams} \PYG{p}{(}\PYG{k+kt}{int64\PYGZus{}t} \PYG{n}{stream}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The class \sphinxcode{\sphinxupquote{MobilityHelper}} also provides this API.  The typical usage
pattern when using the helper is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{int64\PYGZus{}t} \PYG{n}{streamIndex} \PYG{o}{=} \PYG{c+cm}{/*some positive integer */}
\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.} \PYG{p}{(}\PYG{n}{configure} \PYG{n}{mobility}\PYG{p}{)}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiStaNodes}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{int64\PYGZus{}t} \PYG{n}{streamsUsed} \PYG{o}{=} \PYG{n}{mobility}\PYG{p}{.}\PYG{n}{AssignStreams} \PYG{p}{(}\PYG{n}{wifiStaNodes}\PYG{p}{,} \PYG{n}{streamIndex}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

If AssignStreams is called before Install, it will not have any effect.


\subsection{Advanced Usage}
\label{\detokenize{mobility:advanced-usage}}
A number of external tools can be used to generate traces read by
the Ns2MobilityHelper.


\subsubsection{ns\sphinxhyphen{}2 scengen}
\label{\detokenize{mobility:ns-2-scengen}}
TBD


\subsubsection{BonnMotion}
\label{\detokenize{mobility:id3}}
\sphinxurl{http://net.cs.uni-bonn.de/wg/cs/applications/bonnmotion/}


\subsubsection{SUMO}
\label{\detokenize{mobility:id4}}
\sphinxurl{http://sourceforge.net/apps/mediawiki/sumo/index.php?title=Main\_Page}


\subsubsection{TraNS}
\label{\detokenize{mobility:id5}}
\sphinxurl{http://trans.epfl.ch/}


\subsection{Examples}
\label{\detokenize{mobility:examples}}\begin{itemize}
\item {} 
main\sphinxhyphen{}random\sphinxhyphen{}topology.cc

\item {} 
main\sphinxhyphen{}random\sphinxhyphen{}walk.cc

\item {} 
main\sphinxhyphen{}grid\sphinxhyphen{}topology.cc

\item {} 
ns2\sphinxhyphen{}mobility\sphinxhyphen{}trace.cc

\item {} 
ns2\sphinxhyphen{}bonnmotion.cc

\end{itemize}


\section{Validation}
\label{\detokenize{mobility:validation}}
TBD


\chapter{Network Module}
\label{\detokenize{network:network-module}}\label{\detokenize{network::doc}}

\section{Packets}
\label{\detokenize{packets:packets}}\label{\detokenize{packets::doc}}
The design of the Packet framework of \sphinxstyleemphasis{ns} was heavily guided by a few
important use\sphinxhyphen{}cases:
\begin{itemize}
\item {} 
avoid changing the core of the simulator to introduce new types of packet
headers or trailers

\item {} 
maximize the ease of integration with real\sphinxhyphen{}world code and systems

\item {} 
make it easy to support fragmentation, defragmentation, and, concatenation
which are important, especially in wireless systems.

\item {} 
make memory management of this object efficient

\item {} 
allow actual application data or dummy application bytes for emulated
applications

\end{itemize}

Each network packet contains a byte buffer, a set of byte tags, a set of packet
tags, and metadata.

The byte buffer stores the serialized content of the headers and trailers added
to a packet. The serialized representation of these headers is expected to match
that of real network packets bit for bit (although nothing forces you to do
this) which means that the content of a packet buffer is expected to be that of
a real packet.

Fragmentation and defragmentation are quite natural to implement within this
context: since we have a buffer of real bytes, we can split it in multiple
fragments and re\sphinxhyphen{}assemble these fragments. We expect that this choice will make
it really easy to wrap our Packet data structure within Linux\sphinxhyphen{}style skb or
BSD\sphinxhyphen{}style mbuf to integrate real\sphinxhyphen{}world kernel code in the simulator. We also
expect that performing a real\sphinxhyphen{}time plug of the simulator to a real\sphinxhyphen{}world network
will be easy.

One problem that this design choice raises is that it is difficult to
pretty\sphinxhyphen{}print the packet headers without context. The packet metadata describes
the type of the headers and trailers which were serialized in the byte buffer.
The maintenance of metadata is optional and disabled by default. To enable it,
you must call Packet::EnablePrinting() and this will allow you to get non\sphinxhyphen{}empty
output from Packet::Print and Packet::Print.

Also, developers often want to store data in packet objects that is not found
in the real packets (such as timestamps or flow\sphinxhyphen{}ids). The Packet class
deals with this requirement by storing a set of tags (class Tag).
We have found two classes of use cases for these tags, which leads to
two different types of tags. So\sphinxhyphen{}called ‘byte’ tags are used to tag a subset of
the bytes in the packet byte buffer while ‘packet’ tags are used to tag the
packet itself. The main difference between these two kinds of tags is what
happens when packets are copied, fragmented, and reassembled: ‘byte’ tags follow
bytes while ‘packet’ tags follow packets. Another important difference between
these two kinds of tags is that byte tags cannot be removed and are expected to
be written once, and read many times, while packet tags are expected to be
written once, read many times, and removed exactly once. An example of a ‘byte’
tag is a FlowIdTag which contains a flow id and is set by the application
generating traffic. An example of a ‘packet’ tag is a cross\sphinxhyphen{}layer QoS class id
set by an application and processed by a lower\sphinxhyphen{}level MAC layer.

Memory management of Packet objects is entirely automatic and extremely
efficient: memory for the application\sphinxhyphen{}level payload can be modeled by a virtual
buffer of zero\sphinxhyphen{}filled bytes for which memory is never allocated unless
explicitly requested by the user or unless the packet is fragmented or
serialized out to a real network device. Furthermore, copying, adding, and,
removing headers or trailers to a packet has been optimized to be virtually free
through a technique known as Copy On Write.

Packets (messages) are fundamental objects in the simulator and
their design is important from a performance and resource management
perspective. There are various ways to design the simulation packet, and
tradeoffs among the different approaches. In particular, there is a tension
between ease\sphinxhyphen{}of\sphinxhyphen{}use, performance, and safe interface design.


\subsection{Packet design overview}
\label{\detokenize{packets:packet-design-overview}}
Unlike \sphinxstyleemphasis{ns\sphinxhyphen{}2}, in which Packet objects contain a buffer of C++
structures corresponding to protocol headers, each network packet in
\sphinxstyleemphasis{ns\sphinxhyphen{}3} contains a byte Buffer, a list of byte Tags, a list of
packet Tags, and a PacketMetadata object:
\begin{itemize}
\item {} 
The byte buffer stores the serialized content of the chunks added to a packet.
The serialized representation of these chunks is expected to match that of
real network packets bit for bit (although nothing forces you to do this)
which means that the content of a packet buffer is expected to be that of a
real packet.  Packets can also be created with an arbitrary zero\sphinxhyphen{}filled
payload for which no real memory is allocated.

\item {} 
Each list of tags stores an arbitrarily large set of arbitrary user\sphinxhyphen{}provided
data structures in the packet.  Each Tag is uniquely identified by its type;
only one instance of each type of data structure is allowed in a list of tags.
These tags typically contain per\sphinxhyphen{}packet cross\sphinxhyphen{}layer information or flow
identifiers (i.e., things that you wouldn’t find in the bits on the wire).

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{packet}.pdf}
\caption{Implementation overview of Packet class.}\label{\detokenize{packets:id2}}\label{\detokenize{packets:id1}}\end{figure}

Figure {\hyperref[\detokenize{packets:id1}]{\sphinxcrossref{\DUrole{std,std-ref}{Implementation overview of Packet class.}}}} is a high\sphinxhyphen{}level overview of the Packet implementation;
more detail on the byte Buffer implementation is provided later in Figure
{\hyperref[\detokenize{packets:buffer}]{\sphinxcrossref{\DUrole{std,std-ref}{Implementation overview of a packet’s byte Buffer.}}}}. In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the Packet byte buffer is analogous to a Linux skbuff
or BSD mbuf; it is a serialized representation of the actual data in the packet.
The tag lists are containers for extra items useful for simulation convenience;
if a Packet is converted to an emulated packet and put over an actual network,
the tags are stripped off and the byte buffer is copied directly into a real
packet.

Packets are reference counted objects. They are handled with smart pointer (Ptr)
objects like many of the objects in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} system.  One small difference you
will see is that class Packet does not inherit from class Object or class
RefCountBase, and implements the Ref() and Unref() methods directly. This was
designed to avoid the overhead of a vtable in class Packet.

The Packet class is designed to be copied cheaply; the overall design
is based on Copy on Write (COW).  When there are multiple references
to a packet object, and there is an operation on one of them, only
so\sphinxhyphen{}called “dirty” operations will trigger a deep copy of the packet:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Packet::AddHeader()}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Packet::AddTrailer()}}

\item {} 
\sphinxcode{\sphinxupquote{both versions of ns3::Packet::AddAtEnd()}}

\item {} 
\sphinxcode{\sphinxupquote{Packet::RemovePacketTag()}}

\end{itemize}

The fundamental classes for adding to and removing from the byte buffer are
\sphinxcode{\sphinxupquote{class Header}} and \sphinxcode{\sphinxupquote{class Trailer}}. Headers are more common but the below
discussion also largely applies to protocols using trailers. Every protocol
header that needs to be inserted and removed from a Packet instance should
derive from the abstract Header base class and implement the private pure
virtual methods listed below:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::Header::SerializeTo()}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Header::DeserializeFrom()}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Header::GetSerializedSize()}}

\item {} 
\sphinxcode{\sphinxupquote{ns3::Header::PrintTo()}}

\end{itemize}

Basically, the first three functions are used to serialize and deserialize
protocol control information to/from a Buffer. For example, one may define
\sphinxcode{\sphinxupquote{class TCPHeader : public Header}}. The TCPHeader object will typically
consist of some private data (like a sequence number) and public interface
access functions (such as checking the bounds of an input). But the underlying
representation of the TCPHeader in a Packet Buffer is 20 serialized bytes (plus
TCP options). The TCPHeader::SerializeTo() function would therefore be designed
to write these 20 bytes properly into the packet, in network byte order. The
last function is used to define how the Header object prints itself onto an
output stream.

Similarly, user\sphinxhyphen{}defined Tags can be appended to the packet. Unlike Headers,
Tags are not serialized into a contiguous buffer but are stored in lists. Tags
can be flexibly defined to be any type, but there can only be one instance of
any particular object type in the Tags buffer at any time.


\subsection{Using the packet interface}
\label{\detokenize{packets:using-the-packet-interface}}
This section describes how to create and use the \sphinxcode{\sphinxupquote{ns3::Packet}} object.


\subsubsection{Creating a new packet}
\label{\detokenize{packets:creating-a-new-packet}}
The following command will create a new packet with a new unique Id.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{pkt} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

What is the Uid (unique Id)?  It is an internal id that the system uses to
identify packets.  It can be fetched via the following method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{uid} \PYG{o}{=} \PYG{n}{pkt}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetUid} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

But please note the following. This uid is an internal uid and cannot be counted
on to provide an accurate counter of how many “simulated packets” of a
particular protocol are in the system. It is not trivial to make this uid into
such a counter, because of questions such as what should the uid be when the
packet is sent over broadcast media, or when fragmentation occurs. If a user
wants to trace actual packet counts, he or she should look at e.g. the IP ID
field or transport sequence numbers, or other packet or frame counters at other
protocol layers.

We mentioned above that it is possible to create packets with zero\sphinxhyphen{}filled
payloads that do not actually require a memory allocation (i.e., the packet may
behave, when delays such as serialization or transmission delays are computed,
to have a certain number of payload bytes, but the bytes will only be allocated
on\sphinxhyphen{}demand when needed).  The command to do this is, when the packet is
created:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{pkt} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where N is a positive integer.

The packet now has a size of N bytes, which can be verified by the GetSize()
method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}returns the size in bytes of the packet (including the zero\PYGZhy{}filled}
\PYG{c+cm}{ *          initial payload)}
\PYG{c+cm}{ */}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{GetSize} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

You can also initialize a packet with a character buffer. The input
data is copied and the input buffer is untouched. The constructor
applied is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Packet} \PYG{p}{(}\PYG{k+kt}{uint8\PYGZus{}t} \PYG{k}{const} \PYG{o}{*}\PYG{n}{buffer}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{size}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Here is an example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{pkt1} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{k}{reinterpret\PYGZus{}cast}\PYG{o}{\PYGZlt{}}\PYG{k}{const} \PYG{k+kt}{uint8\PYGZus{}t}\PYG{o}{*}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hello}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Packets are freed when there are no more references to them, as with all \sphinxstyleemphasis{ns\sphinxhyphen{}3}
objects referenced by the Ptr class.


\subsubsection{Adding and removing Buffer data}
\label{\detokenize{packets:adding-and-removing-buffer-data}}
After the initial packet creation (which may possibly create some fake initial
bytes of payload), all subsequent buffer data is added by adding objects of
class Header or class Trailer. Note that, even if you are in the application
layer, handling packets, and want to write application data, you write it as an
ns3::Header or ns3::Trailer. If you add a Header, it is prepended to the
packet, and if you add a Trailer, it is added to the end of the packet. If you
have no data in the packet, then it makes no difference whether you add a Header
or Trailer. Since the APIs and classes for header and trailer are pretty much
identical, we’ll just look at class Header here.

The first step is to create a new header class. All new Header classes
must inherit from class Header, and implement the following methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Serialize ()}}

\item {} 
\sphinxcode{\sphinxupquote{Deserialize ()}}

\item {} 
\sphinxcode{\sphinxupquote{GetSerializedSize ()}}

\item {} 
\sphinxcode{\sphinxupquote{Print ()}}

\end{itemize}

To see a simple example of how these are done, look at the UdpHeader class
headers src/internet/model/udp\sphinxhyphen{}header.cc. There are many other examples within
the source code.

Once you have a header (or you have a preexisting header), the following
Packet API can be used to add or remove such headers.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * Add header to this packet. This method invokes the}
\PYG{c+cm}{ * Header::GetSerializedSize and Header::Serialize}
\PYG{c+cm}{ * methods to reserve space in the buffer and request the}
\PYG{c+cm}{ * header to serialize itself in the packet buffer.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}param header a reference to the header to add to this packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{AddHeader} \PYG{p}{(}\PYG{k}{const} \PYG{n}{Header} \PYG{o}{\PYGZam{}} \PYG{n}{header}\PYG{p}{)}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * Deserialize and remove the header from the internal buffer.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * This method invokes Header::Deserialize (begin) and should be used for}
\PYG{c+cm}{ * fixed\PYGZhy{}length headers.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}param header a reference to the header to remove from the internal buffer.}
\PYG{c+cm}{ * \PYGZbs{}returns the number of bytes removed from the packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{RemoveHeader} \PYG{p}{(}\PYG{n}{Header} \PYG{o}{\PYGZam{}}\PYG{n}{header}\PYG{p}{)}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * Deserialize but does \PYGZus{}not\PYGZus{} remove the header from the internal buffer.}
\PYG{c+cm}{ * This method invokes Header::Deserialize.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}param header a reference to the header to read from the internal buffer.}
\PYG{c+cm}{ * \PYGZbs{}returns the number of bytes read from the packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{PeekHeader} \PYG{p}{(}\PYG{n}{Header} \PYG{o}{\PYGZam{}}\PYG{n}{header}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

For instance, here are the typical operations to add and remove a UDP header.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// add header}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{packet} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{UdpHeader} \PYG{n}{udpHeader}\PYG{p}{;}
\PYG{c+c1}{// Fill out udpHeader fields appropriately}
\PYG{n}{packet}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddHeader} \PYG{p}{(}\PYG{n}{udpHeader}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\PYG{c+c1}{// remove header}
\PYG{n}{UdpHeader} \PYG{n}{udpHeader}\PYG{p}{;}
\PYG{n}{packet}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{RemoveHeader} \PYG{p}{(}\PYG{n}{udpHeader}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// Read udpHeader fields as needed}
\end{sphinxVerbatim}

If the header is variable\sphinxhyphen{}length, then another variant of RemoveHeader() is
needed:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}brief Deserialize and remove the header from the internal buffer.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * This method invokes Header::Deserialize (begin, end) and should be}
\PYG{c+cm}{ * used for variable\PYGZhy{}length headers (where the size is determined somehow}
\PYG{c+cm}{ * by the caller).}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}param header a reference to the header to remove from the internal buffer.}
\PYG{c+cm}{ * \PYGZbs{}param size number of bytes to deserialize}
\PYG{c+cm}{ * \PYGZbs{}returns the number of bytes removed from the packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n+nf}{RemoveHeader} \PYG{p}{(}\PYG{n}{Header} \PYG{o}{\PYGZam{}}\PYG{n}{header}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{size}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In this case, the caller must figure out and provide the right ‘size’ as
an argument (the Deserialization routine may not know when to stop).  An
example of this type of header would be a series of Type\sphinxhyphen{}Length\sphinxhyphen{}Value (TLV)
information elements, where the ending point of the series of TLVs can
be deduced from the packet length.


\subsubsection{Adding and removing Tags}
\label{\detokenize{packets:adding-and-removing-tags}}
There is a single base class of Tag that all packet tags must derive from. They
are used in two different tag lists in the packet; the lists have different
semantics and different expected use cases.

As the names imply, ByteTags follow bytes and PacketTags follow packets. What
this means is that when operations are done on packets, such as fragmentation,
concatenation, and appending or removing headers, the byte tags keep track of
which packet bytes they cover. For instance, if a user creates a TCP segment,
and applies a ByteTag to the segment, each byte of the TCP segment will be
tagged. However, if the next layer down inserts an IPv4 header, this ByteTag
will not cover those bytes.  The converse is true for the PacketTag; it covers a
packet despite the operations on it.

PacketTags are limited in size to 20 bytes. This is a modifiable compile\sphinxhyphen{}time
constant in \sphinxcode{\sphinxupquote{src/network/model/packet\sphinxhyphen{}tag\sphinxhyphen{}list.h}}. ByteTags have no such restriction.

Each tag type must subclass \sphinxcode{\sphinxupquote{ns3::Tag}}, and only one instance of
each Tag type may be in each tag list. Here are a few differences in the
behavior of packet tags and byte tags.
\begin{itemize}
\item {} 
\sphinxstylestrong{Fragmentation:}  As mentioned above, when a packet is fragmented, each
packet fragment (which is a new packet) will get a copy of all packet tags,
and byte tags will follow the new packet boundaries (i.e. if the fragmented
packets fragment across a buffer region covered by the byte tag, both packet
fragments will still have the appropriate buffer regions byte tagged).

\item {} 
\sphinxstylestrong{Concatenation:} When packets are combined, two different buffer regions
will become one. For byte tags, the byte tags simply follow the respective
buffer regions. For packet tags, only the tags on the first packet survive
the merge.

\item {} 
\sphinxstylestrong{Finding and Printing:} Both classes allow you to iterate over all of the
tags and print them.

\item {} 
\sphinxstylestrong{Removal:} Users can add and remove the same packet tag multiple times on a
single packet (AddPacketTag () and RemovePacketTag ()). The packet However,
once a byte tag is added, it can only be removed by stripping all byte tags
from the packet. Removing one of possibly multiple byte tags is not supported
by the current API.

\end{itemize}

As of \sphinxstyleemphasis{ns\sphinxhyphen{}3.5} and later, Tags are not serialized and deserialized to a buffer when
\sphinxcode{\sphinxupquote{Packet::Serialize ()}} and \sphinxcode{\sphinxupquote{Packet::Deserialize ()}} are called; this is an
open bug.

If a user wants to take an existing packet object and reuse it as a new packet,
he or she should remove all byte tags and packet tags before doing so. An
example is the UdpEchoServer class, which takes the received packet and “turns
it around” to send back to the echo client.

The Packet API for byte tags is given below.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param tag the new tag to add to this packet}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Tag each byte included in this packet with the}
\PYG{c+cm}{ * new tag.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Note that adding a tag is a const operation which is pretty}
\PYG{c+cm}{ * un\PYGZhy{}intuitive. The rationale is that the content and behavior of}
\PYG{c+cm}{ * a packet is \PYGZus{}not\PYGZus{} changed when a tag is added to a packet: any}
\PYG{c+cm}{ * code which was not aware of the new tag is going to work just}
\PYG{c+cm}{ * the same if the new tag is added. The real reason why adding a}
\PYG{c+cm}{ * tag was made a const operation is to allow a trace sink which gets}
\PYG{c+cm}{ * a packet to tag the packet, even if the packet is const (and most}
\PYG{c+cm}{ * trace sources should use const packets because it would be}
\PYG{c+cm}{ * totally evil to allow a trace sink to modify the content of a}
\PYG{c+cm}{ * packet).}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{AddByteTag} \PYG{p}{(}\PYG{k}{const} \PYG{n}{Tag} \PYG{o}{\PYGZam{}}\PYG{n}{tag}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}returns an iterator over the set of byte tags included in this packet.}
\PYG{c+cm}{ */}
\PYG{n}{ByteTagIterator} \PYG{n+nf}{GetByteTagIterator} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param tag the tag to search in this packet}
\PYG{c+cm}{ * \PYGZbs{}returns true if the requested tag type was found, false otherwise.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * If the requested tag type is found, it is copied in the user\PYGZsq{}s}
\PYG{c+cm}{ * provided tag instance.}
\PYG{c+cm}{ */}
\PYG{k+kt}{bool} \PYG{n+nf}{FindFirstMatchingByteTag} \PYG{p}{(}\PYG{n}{Tag} \PYG{o}{\PYGZam{}}\PYG{n}{tag}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}

\PYG{c+cm}{/**}
\PYG{c+cm}{ * Remove all the tags stored in this packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{RemoveAllByteTags} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)}\PYG{p}{;}

\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param os output stream in which the data should be printed.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Iterate over the tags present in this packet, and}
\PYG{c+cm}{ * invoke the Print method of each tag stored in the packet.}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{PrintByteTags} \PYG{p}{(}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ostream} \PYG{o}{\PYGZam{}}\PYG{n}{os}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

The Packet API for packet tags is given below.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param tag the tag to store in this packet}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Add a tag to this packet. This method calls the}
\PYG{c+cm}{ * Tag::GetSerializedSize and, then, Tag::Serialize.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Note that this method is const, that is, it does not}
\PYG{c+cm}{ * modify the state of this packet, which is fairly}
\PYG{c+cm}{ * un\PYGZhy{}intuitive.}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{AddPacketTag} \PYG{p}{(}\PYG{k}{const} \PYG{n}{Tag} \PYG{o}{\PYGZam{}}\PYG{n}{tag}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param tag the tag to remove from this packet}
\PYG{c+cm}{ * \PYGZbs{}returns true if the requested tag is found, false}
\PYG{c+cm}{ *          otherwise.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Remove a tag from this packet. This method calls}
\PYG{c+cm}{ * Tag::Deserialize if the tag is found.}
\PYG{c+cm}{ */}
\PYG{k+kt}{bool} \PYG{n+nf}{RemovePacketTag} \PYG{p}{(}\PYG{n}{Tag} \PYG{o}{\PYGZam{}}\PYG{n}{tag}\PYG{p}{)}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param tag the tag to search in this packet}
\PYG{c+cm}{ * \PYGZbs{}returns true if the requested tag is found, false}
\PYG{c+cm}{ *          otherwise.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Search a matching tag and call Tag::Deserialize if it is found.}
\PYG{c+cm}{ */}
\PYG{k+kt}{bool} \PYG{n+nf}{PeekPacketTag} \PYG{p}{(}\PYG{n}{Tag} \PYG{o}{\PYGZam{}}\PYG{n}{tag}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\PYG{c+cm}{/**}
\PYG{c+cm}{ * Remove all packet tags.}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{RemoveAllPacketTags} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)}\PYG{p}{;}

\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}param os the stream in which we want to print data.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * Print the list of \PYGZsq{}packet\PYGZsq{} tags.}
\PYG{c+cm}{ *}
\PYG{c+cm}{ * \PYGZbs{}sa Packet::AddPacketTag, Packet::RemovePacketTag, Packet::PeekPacketTag,}
\PYG{c+cm}{ *  Packet::RemoveAllPacketTags}
\PYG{c+cm}{ */}
\PYG{k+kt}{void} \PYG{n+nf}{PrintPacketTags} \PYG{p}{(}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ostream} \PYG{o}{\PYGZam{}}\PYG{n}{os}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}

\PYG{c+cm}{/**}
\PYG{c+cm}{ * \PYGZbs{}returns an object which can be used to iterate over the list of}
\PYG{c+cm}{ *  packet tags.}
\PYG{c+cm}{ */}
\PYG{n}{PacketTagIterator} \PYG{n+nf}{GetPacketTagIterator} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

Here is a simple example illustrating the use of tags from the
code in \sphinxcode{\sphinxupquote{src/internet/model/udp\sphinxhyphen{}socket\sphinxhyphen{}impl.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{p}\PYG{p}{;}  \PYG{c+c1}{// pointer to a pre\PYGZhy{}existing packet}
\PYG{n}{SocketIpTtlTag} \PYG{n}{tag}
\PYG{n}{tag}\PYG{p}{.}\PYG{n}{SetTtl} \PYG{p}{(}\PYG{n}{m\PYGZus{}ipMulticastTtl}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Convey the TTL from UDP layer to IP layer}
\PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddPacketTag} \PYG{p}{(}\PYG{n}{tag}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This tag is read at the IP layer, then stripped (\sphinxcode{\sphinxupquote{src/internet/model/ipv4\sphinxhyphen{}l3\sphinxhyphen{}protocol.cc}}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{uint8\PYGZus{}t} \PYG{n}{ttl} \PYG{o}{=} \PYG{n}{m\PYGZus{}defaultTtl}\PYG{p}{;}
\PYG{n}{SocketIpTtlTag} \PYG{n}{tag}\PYG{p}{;}
\PYG{k+kt}{bool} \PYG{n}{found} \PYG{o}{=} \PYG{n}{packet}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{RemovePacketTag} \PYG{p}{(}\PYG{n}{tag}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{if} \PYG{p}{(}\PYG{n}{found}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
    \PYG{n}{ttl} \PYG{o}{=} \PYG{n}{tag}\PYG{p}{.}\PYG{n}{GetTtl} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsubsection{Fragmentation and concatenation}
\label{\detokenize{packets:fragmentation-and-concatenation}}
Packets may be fragmented or merged together.  For example, to fragment a packet
\sphinxcode{\sphinxupquote{p}} of 90 bytes into two packets, one containing the first 10 bytes and the
other containing the remaining 80, one may call the following code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{frag0} \PYG{o}{=} \PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateFragment} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{frag1} \PYG{o}{=} \PYG{n}{p}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{CreateFragment} \PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{90}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

As discussed above, the packet tags from \sphinxcode{\sphinxupquote{p}} will follow to both packet
fragments, and the byte tags will follow the byte ranges as needed.

Now, to put them back together:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{frag0}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddAtEnd} \PYG{p}{(}\PYG{n}{frag1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Now frag0 should be equivalent to the original packet \sphinxcode{\sphinxupquote{p}}.  If, however, there
were operations on the fragments before being reassembled (such as tag
operations or header operations), the new packet will not be the same.


\subsubsection{Enabling metadata}
\label{\detokenize{packets:enabling-metadata}}
We mentioned above that packets, being on\sphinxhyphen{}the\sphinxhyphen{}wire representations of byte
buffers, present a problem to print out in a structured way unless the printing
function has access to the context of the header.  For instance, consider a
tcpdump\sphinxhyphen{}like printer that wants to pretty\sphinxhyphen{}print the contents of a packet.

To enable this usage, packets may have metadata enabled (disabled by default for
performance reasons). This class is used by the Packet class to record every
operation performed on the packet’s buffer, and provides an implementation of
\sphinxcode{\sphinxupquote{Packet::Print ()}} method that uses the metadata to analyze the content of the
packet’s buffer.

The metadata is also used to perform extensive sanity checks at runtime when
performing operations on a Packet. For example, this metadata is used to verify
that when you remove a header from a packet, this same header was actually
present at the front of the packet. These errors will be detected and will abort
the program.

To enable this operation, users will typically insert one or both of these
statements at the beginning of their programs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Packet}\PYG{o}{:}\PYG{o}{:}\PYG{n}{EnablePrinting} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Packet}\PYG{o}{:}\PYG{o}{:}\PYG{n}{EnableChecking} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Sample programs}
\label{\detokenize{packets:sample-programs}}
See \sphinxcode{\sphinxupquote{src/network/examples/main\sphinxhyphen{}packet\sphinxhyphen{}header.cc}} and \sphinxcode{\sphinxupquote{src/network/examples/main\sphinxhyphen{}packet\sphinxhyphen{}tag.cc}}.


\subsection{Implementation details}
\label{\detokenize{packets:implementation-details}}

\subsubsection{Private member variables}
\label{\detokenize{packets:private-member-variables}}
A Packet object’s interface provides access to some private data:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Buffer} \PYG{n}{m\PYGZus{}buffer}\PYG{p}{;}
\PYG{n}{ByteTagList} \PYG{n}{m\PYGZus{}byteTagList}\PYG{p}{;}
\PYG{n}{PacketTagList} \PYG{n}{m\PYGZus{}packetTagList}\PYG{p}{;}
\PYG{n}{PacketMetadata} \PYG{n}{m\PYGZus{}metadata}\PYG{p}{;}
\PYG{k}{mutable} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}refCount}\PYG{p}{;}
\PYG{k}{static} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}globalUid}\PYG{p}{;}
\end{sphinxVerbatim}

Each Packet has a Buffer and two Tags lists, a PacketMetadata object, and a ref
count. A static member variable keeps track of the UIDs allocated. The actual
uid of the packet is stored in the PacketMetadata.

Note:
that real network packets do not have a UID; the UID is therefore an instance of
data that normally would be stored as a Tag in the packet. However, it was felt
that a UID is a special case that is so often used in simulations that it would
be more convenient to store it in a member variable.


\subsubsection{Buffer implementation}
\label{\detokenize{packets:buffer-implementation}}
Class Buffer represents a buffer of bytes. Its size is automatically adjusted to
hold any data prepended or appended by the user. Its implementation is optimized
to ensure that the number of buffer resizes is minimized, by creating new
Buffers of the maximum size ever used.  The correct maximum size is learned at
runtime during use by recording the maximum size of each packet.

Authors of new Header or Trailer classes need to know the public API of the
Buffer class.  (add summary here)

The byte buffer is implemented as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{struct} \PYG{n}{BufferData} \PYG{p}{\PYGZob{}}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}count}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}size}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}initialStart}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}dirtyStart}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}dirtySize}\PYG{p}{;}
    \PYG{k+kt}{uint8\PYGZus{}t} \PYG{n}{m\PYGZus{}data}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\PYG{k}{struct} \PYG{n}{BufferData} \PYG{o}{*}\PYG{n}{m\PYGZus{}data}\PYG{p}{;}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}zeroAreaSize}\PYG{p}{;}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}start}\PYG{p}{;}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}size}\PYG{p}{;}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_count}}: reference count for BufferData structure

\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_size}}: size of data buffer stored in BufferData structure

\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_initialStart}}: offset from start of data buffer where data
was first inserted

\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_dirtyStart}}: offset from start of buffer where every Buffer
which holds a reference to this BufferData instance have written data so far

\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_dirtySize}}: size of area where data has been written so far

\item {} 
\sphinxcode{\sphinxupquote{BufferData::m\_data}}: pointer to data buffer

\item {} 
\sphinxcode{\sphinxupquote{Buffer::m\_zeroAreaSize}}: size of zero area which extends before
\sphinxcode{\sphinxupquote{m\_initialStart}}

\item {} 
\sphinxcode{\sphinxupquote{Buffer::m\_start}}: offset from start of buffer to area used by this buffer

\item {} 
\sphinxcode{\sphinxupquote{Buffer::m\_size}}: size of area used by this Buffer in its BufferData
structure

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{buffer}.pdf}
\caption{Implementation overview of a packet’s byte Buffer.}\label{\detokenize{packets:id3}}\label{\detokenize{packets:buffer}}\end{figure}

This data structure is summarized in Figure {\hyperref[\detokenize{packets:buffer}]{\sphinxcrossref{\DUrole{std,std-ref}{Implementation overview of a packet’s byte Buffer.}}}}. Each Buffer holds a
pointer to an instance of a BufferData. Most Buffers should be able to share the
same underlying BufferData and thus simply increase the BufferData’s reference
count. If they have to change the content of a BufferData inside the Dirty Area,
and if the reference count is not one, they first create a copy of the
BufferData and then complete their state\sphinxhyphen{}changing operation.


\subsubsection{Tags implementation}
\label{\detokenize{packets:tags-implementation}}
(XXX revise me)

Tags are implemented by a single pointer which points to the start of a
linked list ofTagData data structures. Each TagData structure points
to the next TagData in the list (its next pointer contains zero to
indicate the end of the linked list). Each TagData contains an integer
unique id which identifies the type of the tag stored in the TagData.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{struct} \PYG{n}{TagData} \PYG{p}{\PYGZob{}}
    \PYG{k}{struct} \PYG{n}{TagData} \PYG{o}{*}\PYG{n}{m\PYGZus{}next}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}id}\PYG{p}{;}
    \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{m\PYGZus{}count}\PYG{p}{;}
    \PYG{k+kt}{uint8\PYGZus{}t} \PYG{n}{m\PYGZus{}data}\PYG{p}{[}\PYG{n}{Tags}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SIZE}\PYG{p}{]}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\PYG{k}{class} \PYG{n+nc}{Tags} \PYG{p}{\PYGZob{}}
    \PYG{k}{struct} \PYG{n}{TagData} \PYG{o}{*}\PYG{n}{m\PYGZus{}next}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\end{sphinxVerbatim}

Adding a tag is a matter of inserting a new TagData at the head of the linked
list. Looking at a tag requires you to find the relevant TagData in the linked
list and copy its data into the user data structure. Removing a tag and updating
the content of a tag requires a deep copy of the linked list before performing
this operation.  On the other hand, copying a Packet and its tags is a matter of
copying the TagData head pointer and incrementing its reference count.

Tags are found by the unique mapping between the Tag type and
its underlying id. This is why at most one instance of any Tag
can be stored in a packet. The mapping between Tag type and
underlying id is performed by a registration as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/* A sample Tag implementation}
\PYG{c+cm}{ */}
\PYG{k}{struct} \PYG{n}{MyTag} \PYG{p}{\PYGZob{}}
    \PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{m\PYGZus{}streamId}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Memory management}
\label{\detokenize{packets:memory-management}}
\sphinxstyleemphasis{Describe dataless vs. data\sphinxhyphen{}full packets.}


\subsubsection{Copy\sphinxhyphen{}on\sphinxhyphen{}write semantics}
\label{\detokenize{packets:copy-on-write-semantics}}
The current implementation of the byte buffers and tag list is based on COW
(Copy On Write). An introduction to COW can be found in Scott Meyer’s “More
Effective C++”, items 17 and 29). This design feature and aspects of the public
interface borrows from the packet design of the Georgia Tech Network Simulator.
This implementation of COW uses a customized reference counting smart pointer
class.

What COW means is that copying packets without modifying them is very cheap (in
terms of CPU and memory usage) and modifying them can be also very cheap. What
is key for proper COW implementations is being able to detect when a given
modification of the state of a packet triggers a full copy of the data prior to
the modification: COW systems need to detect when an operation is “dirty” and
must therefore invoke a true copy.

Dirty operations:
\begin{itemize}
\item {} 
ns3::Packet::AddHeader

\item {} 
ns3::Packet::AddTrailer

\item {} 
both versions of ns3::Packet::AddAtEnd

\item {} 
ns3::Packet::RemovePacketTag

\end{itemize}

Non\sphinxhyphen{}dirty operations:
\begin{itemize}
\item {} 
ns3::Packet::AddPacketTag

\item {} 
ns3::Packet::PeekPacketTag

\item {} 
ns3::Packet::RemoveAllPacketTags

\item {} 
ns3::Packet::AddByteTag

\item {} 
ns3::Packet::FindFirstMatchingByteTag

\item {} 
ns3::Packet::RemoveAllByteTags

\item {} 
ns3::Packet::RemoveHeader

\item {} 
ns3::Packet::RemoveTrailer

\item {} 
ns3::Packet::CreateFragment

\item {} 
ns3::Packet::RemoveAtStart

\item {} 
ns3::Packet::RemoveAtEnd

\item {} 
ns3::Packet::CopyData

\end{itemize}

Dirty operations will always be slower than non\sphinxhyphen{}dirty operations, sometimes by
several orders of magnitude. However, even the dirty operations have been
optimized for common use\sphinxhyphen{}cases which means that most of the time, these
operations will not trigger data copies and will thus be still very fast.


\section{Error Model}
\label{\detokenize{error-model:error-model}}\label{\detokenize{error-model::doc}}
This section documents a few error model objects, typically associated with
NetDevice models, that are maintained as part of the \sphinxcode{\sphinxupquote{network}} module:
\begin{itemize}
\item {} 
RateErrorModel

\item {} 
ListErrorModel

\item {} 
ReceiveListErrorModel

\item {} 
BurstErrorModel

\end{itemize}

Error models are used to indicate that a packet should be considered to
be errored, according to the underlying (possibly stochastic or
empirical) error model.


\subsection{Model Description}
\label{\detokenize{error-model:model-description}}
The source code for error models live in the directory \sphinxcode{\sphinxupquote{src/packet/utils}}.

Two types of error models are generally provided.  The first are stochastic
models.  In this case, packets are errored according to underlying
random variable distributions.  An example of this is the \sphinxcode{\sphinxupquote{RateErrorModel}}.
The other type of model is a deterministic or empirical model, in which
packets are errored according to a particular prescribed pattern.
An example is the \sphinxcode{\sphinxupquote{ListErrorModel}} that allows users to specify
the list of packets to be errored, by listing the specific packet UIDs.

The \sphinxcode{\sphinxupquote{ns3::RateErrorModel}} errors packets according to an underlying
random variable distribution, which is by default a UniformRandomVariable
distributed between 0.0 and 1.0.  The error rate and error units (bit,
byte, or packet) are set by the user.  For instance, by setting ErrorRate
to 0.1 and ErrorUnit to “Packet”, in the long run, around 10\% of the
packets will be lost.


\subsubsection{Design}
\label{\detokenize{error-model:design}}
Error models are \sphinxstyleemphasis{ns\sphinxhyphen{}3} objects and can be created using the typical
pattern of \sphinxcode{\sphinxupquote{CreateObject\textless{}\textgreater{}()}}.  They have configuration attributes.

An ErrorModel can be applied anywhere, but are commonly deployed on
NetDevice models so that artificial losses (mimicking channel losses)
can be induced.


\subsubsection{Scope and Limitations}
\label{\detokenize{error-model:scope-and-limitations}}
No known limitations.  There are no existing models that try to modify
the packet contents (e.g. apply bit or byte errors to the byte buffers).
This type of operation will likely be performance\sphinxhyphen{}expensive, and existing
Packet APIs may not easily support it.

The \sphinxstyleemphasis{ns\sphinxhyphen{}3} spectrum model and devices that derive from it (e.g. LTE) have
their own error model base class, found in


\subsubsection{References}
\label{\detokenize{error-model:references}}
The initial \sphinxstyleemphasis{ns\sphinxhyphen{}3} error models were ported from ns\sphinxhyphen{}2 (queue/errmodel.\{cc,h\})


\subsection{Usage}
\label{\detokenize{error-model:usage}}
The base class API is as follows:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bool ErrorModel::IsCorrupt (Ptr\textless{}Packet\textgreater{} pkt)}}:  Evaluate the packet and
return true or false whether the packet should be considered errored or not.
Some models could potentially alter the contents of the packet bit buffer.

\item {} 
\sphinxcode{\sphinxupquote{void ErrorModel::Reset (void)}}:  Reset any state.

\item {} 
\sphinxcode{\sphinxupquote{void ErrorModel::Enable (void)}}:  Enable the model

\item {} 
\sphinxcode{\sphinxupquote{void ErrorModel::Disble (void)}}:  Disable the model; IsCorrupt() will
always return false.

\item {} 
\sphinxcode{\sphinxupquote{bool ErrorModel::IsEnabled (void) const}}:  Return the enabled state

\end{itemize}

Many \sphinxstyleemphasis{ns\sphinxhyphen{}3} NetDevices contain attributes holding pointers to error
models.  The error model is applied in the notional physical layer
processing chain of the device, and drops should show up on the \sphinxcode{\sphinxupquote{PhyRxDrop}}
trace source of the device.  The following are known to include an attribute
with a pointer available to hold this type of error model:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SimpleNetDevice}}

\item {} 
\sphinxcode{\sphinxupquote{PointToPointNetDevice}}

\item {} 
\sphinxcode{\sphinxupquote{CsmaNetDevice}}

\item {} 
\sphinxcode{\sphinxupquote{VirtualNetDevice}}

\end{itemize}

However, the ErrorModel could be used anywhere where packets are used


\subsubsection{Helpers}
\label{\detokenize{error-model:helpers}}
This model is typically not used with helpers.


\subsubsection{Attributes}
\label{\detokenize{error-model:attributes}}
The \sphinxcode{\sphinxupquote{RateErrorModel}} contains the following attributes:


\subsubsection{Output}
\label{\detokenize{error-model:output}}
What kind of data does the model generate?  What are the key trace
sources?   What kind of logging output can be enabled?


\subsubsection{Examples}
\label{\detokenize{error-model:examples}}
Error models are used in the tutorial \sphinxcode{\sphinxupquote{fifth}} and \sphinxcode{\sphinxupquote{sixth}} programs.

The directory \sphinxcode{\sphinxupquote{examples/error\sphinxhyphen{}model/}} contains an example
\sphinxcode{\sphinxupquote{simple\sphinxhyphen{}error\sphinxhyphen{}model.cc}} that exercises the Rate and List error models.

The TCP example \sphinxcode{\sphinxupquote{examples/tcp/tcp\sphinxhyphen{}nsc\sphinxhyphen{}lfn.cc}} uses the Rate error model.


\subsubsection{Troubleshooting}
\label{\detokenize{error-model:troubleshooting}}
No known issues.


\subsection{Validation}
\label{\detokenize{error-model:validation}}
The \sphinxcode{\sphinxupquote{error\sphinxhyphen{}model}} unit test suite provides a single test case of
of a particular combination of ErrorRate and ErrorUnit for the
\sphinxcode{\sphinxupquote{RateErrorModel}} applied to a \sphinxcode{\sphinxupquote{SimpleNetDevice}}.


\subsection{Acknowledgements}
\label{\detokenize{error-model:acknowledgements}}
The basic ErrorModel, RateErrorModel, and ListErrorModel classes were ported
from \sphinxstyleemphasis{ns\sphinxhyphen{}2} to \sphinxstyleemphasis{ns\sphinxhyphen{}3} in 2007.  The ReceiveListErrorModel was added at that
time.

The burst error model is due to Truc Anh N. Nguyen at the University of
Kansas (James P.G. Sterbenz \textless{}\sphinxhref{mailto:jpgs@ittc.ku.edu}{jpgs@ittc.ku.edu}\textgreater{}, director, ResiliNets
Research Group (\sphinxurl{http://wiki.ittc.ku.edu/resilinets}), Information and
Telecommunication Technology Center (ITTC) and Department of Electrical
Engineering and Computer Science, The University of Kansas Lawrence, KS USA).
Work supported in part by NSF FIND (Future Internet Design) Program
under grant CNS\sphinxhyphen{}0626918 (Postmodern Internet Architecture),
NSF grant CNS\sphinxhyphen{}1050226 (Multilayer Network Resilience Analysis and
Experimentation on GENI), US Department of Defense (DoD), and ITTC at
The University of Kansas.


\section{Node and NetDevices Overview}
\label{\detokenize{network-overview:node-and-netdevices-overview}}\label{\detokenize{network-overview::doc}}
This chapter describes how \sphinxstyleemphasis{ns\sphinxhyphen{}3} nodes are put together, and provides a
walk\sphinxhyphen{}through of how packets traverse an internet\sphinxhyphen{}based Node.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{node}.pdf}
\caption{High\sphinxhyphen{}level node architecture}\label{\detokenize{network-overview:id1}}\label{\detokenize{network-overview:node-architecture}}\end{figure}

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, nodes are instances of \sphinxcode{\sphinxupquote{ns3::Node}}. This class may be
subclassed, but instead, the conceptual model is that we \sphinxstyleemphasis{aggregate} or insert
objects to it rather than define subclasses.

One might think of a bare \sphinxstyleemphasis{ns\sphinxhyphen{}3} node as a shell of a computer, to which one may
add NetDevices (cards) and other innards including the protocols and
applications. {\hyperref[\detokenize{network-overview:node-architecture}]{\sphinxcrossref{\DUrole{std,std-ref}{High\sphinxhyphen{}level node architecture}}}} illustrates that \sphinxcode{\sphinxupquote{ns3::Node}}
objects contain a list of \sphinxcode{\sphinxupquote{ns3::Application}} instances (initially,
the list is empty), a list of \sphinxcode{\sphinxupquote{ns3::NetDevice}} instances (initially,
the list is empty), a list of \sphinxcode{\sphinxupquote{ns3::Node::ProtocolHandler}} instances,
a unique integer ID, and a system ID (for distributed simulation).

The design tries to avoid putting too many dependencies on the class
\sphinxcode{\sphinxupquote{ns3::Node}}, \sphinxcode{\sphinxupquote{ns3::Application}}, or
\sphinxcode{\sphinxupquote{ns3::NetDevice}} for the following:
\begin{itemize}
\item {} 
IP version, or whether IP is at all even used in the \sphinxcode{\sphinxupquote{ns3::Node}}.

\item {} 
implementation details of the IP stack.

\end{itemize}

From a software perspective, the lower interface of applications corresponds to
the C\sphinxhyphen{}based sockets API. The upper interface of \sphinxcode{\sphinxupquote{ns3::NetDevice}}
objects corresponds to the device independent sublayer of the Linux stack.
Everything in between can be aggregated and plumbed together as needed.

Let’s look more closely at the protocol demultiplexer. We want incoming frames
at layer\sphinxhyphen{}2 to be delivered to the right layer\sphinxhyphen{}3 protocol such as IPv4. The
function of this demultiplexer is to register callbacks for receiving packets.
The callbacks are indexed based on the \sphinxhref{http://en.wikipedia.org/wiki/EtherType}{EtherType} in the layer\sphinxhyphen{}2 frame.

Many different types of higher\sphinxhyphen{}layer protocols may be connected to the
NetDevice, such as IPv4, IPv6, ARP, MPLS, IEEE 802.1x, and packet sockets.
Therefore, the use of a callback\sphinxhyphen{}based demultiplexer avoids the need to use a
common base class for all of these protocols, which is problematic because of
the different types of objects (including packet sockets) expected to be
registered there.


\section{Sockets APIs}
\label{\detokenize{sockets-api:sockets-apis}}\label{\detokenize{sockets-api:id1}}\label{\detokenize{sockets-api::doc}}
The \sphinxhref{http://en.wikipedia.org/wiki/Berkeley\_sockets}{sockets API}
is a long\sphinxhyphen{}standing API used by user\sphinxhyphen{}space applications to access
network services in the kernel.  A \sphinxstyleemphasis{socket} is an abstraction, like
a Unix file handle, that allows applications to connect to other
Internet hosts and exchange reliable byte streams and unreliable
datagrams, among other services.

\sphinxstyleemphasis{ns\sphinxhyphen{}3} provides two types of sockets APIs, and it is important to
understand the differences between them.  The first is a \sphinxstyleemphasis{native}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} API, while the second uses the services of the native API to
provide a \sphinxhref{http://en.wikipedia.org/wiki/POSIX}{POSIX\sphinxhyphen{}like}
API as part of an overall application process.  Both APIs strive
to be close to the typical sockets API that application writers
on Unix systems are accustomed to, but the POSIX variant is much
closer to a real system’s sockets API.


\subsection{ns\sphinxhyphen{}3 sockets API}
\label{\detokenize{sockets-api:ns-3-sockets-api}}
The native sockets API for ns\sphinxhyphen{}3 provides an interface to various
types of transport protocols (TCP, UDP) as well as to packet sockets
and, in the future, Netlink\sphinxhyphen{}like sockets.  However, users are cautioned
to understand that the semantics are \sphinxstyleemphasis{not} the exact same as
one finds in a real system (for an API which is very much aligned
to real systems, see the next section).

\sphinxcode{\sphinxupquote{ns3::Socket}} is defined in \sphinxcode{\sphinxupquote{src/network/model/socket.h}}.
Readers will note that many public member functions are aligned
with real sockets function calls, and all other things being equal,
we have tried to align with a Posix sockets API.  However, note that:
\begin{itemize}
\item {} 
ns\sphinxhyphen{}3 applications handle a smart pointer to a Socket object, not
a file descriptor;

\item {} 
there is no notion of synchronous API or a \sphinxstyleemphasis{blocking} API;
in fact, the model for interaction between application and socket is
one of asynchronous I/O, which is not typically found in real systems
(more on this below);

\item {} 
the C\sphinxhyphen{}style socket address structures are not used;

\item {} 
the API is not a complete sockets API, such as supporting
all socket options or all function variants;

\item {} 
many calls use \sphinxcode{\sphinxupquote{ns3::Packet}} class to transfer data
between application and socket.  This may seem peculiar to
pass \sphinxstyleemphasis{Packets} across a stream socket API, but think
of these packets as just fancy byte buffers at this level (more
on this also below).

\end{itemize}


\subsubsection{Basic operation and calls}
\label{\detokenize{sockets-api:basic-operation-and-calls}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sockets-overview}.pdf}
\caption{Implementation overview of native sockets API}\label{\detokenize{sockets-api:id3}}\label{\detokenize{sockets-api:sockets-overview}}\end{figure}


\subsubsection{Creating sockets}
\label{\detokenize{sockets-api:creating-sockets}}
An application that wants to use sockets must first create one.
On real systems using a C\sphinxhyphen{}based API, this is accomplished by calling \sphinxcode{\sphinxupquote{socket()}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{int} \PYG{n+nf}{socket}\PYG{p}{(}\PYG{k+kt}{int} \PYG{n}{domain}\PYG{p}{,} \PYG{k+kt}{int} \PYG{n}{type}\PYG{p}{,} \PYG{k+kt}{int} \PYG{n}{protocol}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which creates a socket in the system and returns an integer descriptor.

In ns\sphinxhyphen{}3, we have no equivalent of a system call at the lower layers,
so we adopt the following model.  There are certain \sphinxstyleemphasis{factory}
objects that can create sockets.  Each factory is capable of creating
one type of socket, and if sockets of a particular type are able to
be created on a given node, then a factory that can create such sockets
must be aggregated to the Node:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{static} \PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{CreateSocket} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{node}\PYG{p}{,} \PYG{n}{TypeId} \PYG{n}{tid}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Examples of TypeIds to pass to this method are \sphinxcode{\sphinxupquote{ns3::TcpSocketFactory}},
\sphinxcode{\sphinxupquote{ns3::PacketSocketFactory}}, and \sphinxcode{\sphinxupquote{ns3::UdpSocketFactory}}.

This method returns a smart pointer to a Socket object.  Here is an
example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Node}\PYG{o}{\PYGZgt{}} \PYG{n}{n0}\PYG{p}{;}
\PYG{c+c1}{// Do some stuff to build up the Node\PYGZsq{}s internet stack}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Socket}\PYG{o}{\PYGZgt{}} \PYG{n}{localSocket} \PYG{o}{=}
   \PYG{n}{Socket}\PYG{o}{:}\PYG{o}{:}\PYG{n}{CreateSocket} \PYG{p}{(}\PYG{n}{n0}\PYG{p}{,} \PYG{n}{TcpSocketFactory}\PYG{o}{:}\PYG{o}{:}\PYG{n}{GetTypeId} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In some ns\sphinxhyphen{}3 code, sockets will not be explicitly created by user’s
main programs, if an ns\sphinxhyphen{}3 application does it.  For instance, for
\sphinxcode{\sphinxupquote{ns3::OnOffApplication}}, the function \sphinxcode{\sphinxupquote{ns3::OnOffApplication::StartApplication()}}
performs the socket creation, and the application holds the socket
pointer.


\subsubsection{Using sockets}
\label{\detokenize{sockets-api:using-sockets}}
Below is a typical sequence of socket calls for a TCP client in a
real implementation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sock} \PYG{o}{=} \PYG{n}{socket}\PYG{p}{(}\PYG{n}{PF\PYGZus{}INET}\PYG{p}{,} \PYG{n}{SOCK\PYGZus{}STREAM}\PYG{p}{,} \PYG{n}{IPPROTO\PYGZus{}TCP}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{bind}\PYG{p}{(}\PYG{n}{sock}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{connect}\PYG{p}{(}\PYG{n}{sock}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{send}\PYG{p}{(}\PYG{n}{sock}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{recv}\PYG{p}{(}\PYG{n}{sock}\PYG{p}{,} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{close}\PYG{p}{(}\PYG{n}{sock}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

There are analogs to all of these calls in ns\sphinxhyphen{}3, but we will focus on
two aspects here.  First, most usage of sockets in real systems
requires a way to manage I/O between the application and kernel.
These models include \sphinxstyleemphasis{blocking sockets}, \sphinxstyleemphasis{signal\sphinxhyphen{}based I/O},
and \sphinxstyleemphasis{non\sphinxhyphen{}blocking sockets} with polling.  In ns\sphinxhyphen{}3, we make use
of the callback mechanisms to support a fourth mode, which is
analogous to POSIX \sphinxstyleemphasis{asynchronous I/O}.

In this model, on the sending side, if the \sphinxcode{\sphinxupquote{send()}} call were to
fail because of insufficient buffers, the application suspends the
sending of more data until a function registered at the
\sphinxcode{\sphinxupquote{ns3::Socket::SetSendCallback()}} callback is invoked.
An application can also ask the socket how much space is available
by calling \sphinxcode{\sphinxupquote{ns3::Socket::GetTxAvailable()}}.  A typical sequence
of events for sending data (ignoring connection setup) might be:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{SetSendCallback} \PYG{p}{(}\PYG{n}{MakeCallback}\PYG{p}{(}\PYG{o}{\PYGZam{}}\PYG{n}{HandleSendCallback}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Send} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Send} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\PYG{c+c1}{// Send fails because buffer is full}
\PYG{c+c1}{// Wait until HandleSendCallback is called}
\PYG{c+c1}{// HandleSendCallback is called by socket, since space now available}
\PYG{n}{Send} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Start sending again}
\end{sphinxVerbatim}

Similarly, on the receive side, the socket user does not block on
a call to \sphinxcode{\sphinxupquote{recv()}}.  Instead, the application sets a callback
with \sphinxcode{\sphinxupquote{ns3::Socket::SetRecvCallback()}} in which the socket will notify the
application when (and how much) there is data to be read, and
the application then calls \sphinxcode{\sphinxupquote{ns3::Socket::Recv()}} to read the data until
no more can be read.


\subsection{Packet vs. buffer variants}
\label{\detokenize{sockets-api:packet-vs-buffer-variants}}
There are two basic variants of \sphinxcode{\sphinxupquote{Send()}} and \sphinxcode{\sphinxupquote{Recv()}} supported:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{virtual} \PYG{k+kt}{int} \PYG{n+nf}{Send} \PYG{p}{(}\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{p}\PYG{p}{)} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;}
\PYG{k+kt}{int} \PYG{n+nf}{Send} \PYG{p}{(}\PYG{k}{const} \PYG{k+kt}{uint8\PYGZus{}t}\PYG{o}{*} \PYG{n}{buf}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{size}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{Recv} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{int} \PYG{n+nf}{Recv} \PYG{p}{(}\PYG{k+kt}{uint8\PYGZus{}t}\PYG{o}{*} \PYG{n}{buf}\PYG{p}{,} \PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{size}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The non\sphinxhyphen{}Packet variants are provided for legacy API reasons.  When calling
the raw buffer variant of \sphinxcode{\sphinxupquote{ns3::Socket::Send()}}, the buffer is immediately
written into a Packet and the packet variant is invoked.

Users may find it semantically odd to pass a Packet to a stream socket
such as TCP.  However, do not let the name bother you; think of
\sphinxcode{\sphinxupquote{ns3::Packet}} to be a fancy byte buffer.  There are a few reasons why
the Packet variants are more likely to be preferred in ns\sphinxhyphen{}3:
\begin{itemize}
\item {} 
Users can use the Tags facility of packets to, for example, encode
a flow ID or other helper data at the application layer.

\item {} 
Users can exploit the copy\sphinxhyphen{}on\sphinxhyphen{}write implementation to avoid
memory copies (on the receive side, the conversion back to a
\sphinxcode{\sphinxupquote{uint8\_t* buf}} may sometimes incur an additional copy).

\item {} 
Use of Packet is more aligned with the rest of the ns\sphinxhyphen{}3 API

\end{itemize}


\subsection{Sending dummy data}
\label{\detokenize{sockets-api:sending-dummy-data}}
Sometimes, users want the simulator to just pretend that there is an
actual data payload in the packet (e.g. to calculate transmission delay)
but do not want to actually produce or consume the data.  This is
straightforward to support in ns\sphinxhyphen{}3; have applications call
\sphinxcode{\sphinxupquote{Create\textless{}Packet\textgreater{} (size);}} instead of \sphinxcode{\sphinxupquote{Create\textless{}Packet\textgreater{} (buffer, size);}}.
Similarly, passing in a zero to the pointer argument in the raw buffer
variants has the same effect.  Note that, if some subsequent code tries
to read the Packet data buffer, the fake buffer will be converted to
a real (zeroed) buffer on the spot, and the efficiency will be lost there.


\subsection{Socket options}
\label{\detokenize{sockets-api:socket-options}}\label{\detokenize{sockets-api:id2}}

\subsubsection{ToS (Type of Service)}
\label{\detokenize{sockets-api:tos-type-of-service}}\label{\detokenize{sockets-api:type-of-service}}
The native sockets API for ns\sphinxhyphen{}3 provides two public methods
(of the Socket base class):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{SetIpTos} \PYG{p}{(}\PYG{k+kt}{uint8\PYGZus{}t} \PYG{n}{ipTos}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{uint8\PYGZus{}t} \PYG{n+nf}{GetIpTos} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

to set and get, respectively, the type of service associated with the socket.
These methods are equivalent to using the IP\_TOS option of BSD sockets.
Clearly, setting the type of service only applies to sockets using the IPv4 protocol.
However, users typically do not set the type of service associated with a socket
through \sphinxcode{\sphinxupquote{ns3::Socket::SetIpTos()}} because sockets are normally created
by application helpers and users cannot get a pointer to the sockets.
Instead, users can create an address of type \sphinxcode{\sphinxupquote{ns3::InetSocketAddress}}
with the desired type of service value and pass it to the application helpers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{InetSocketAddress} \PYG{n+nf}{destAddress} \PYG{p}{(}\PYG{n}{ipv4Address}\PYG{p}{,} \PYG{n}{udpPort}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{destAddress}\PYG{p}{.}\PYG{n}{SetTos} \PYG{p}{(}\PYG{n}{tos}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{OnOffHelper} \PYG{n+nf}{onoff} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::UdpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{destAddress}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For this to work, the application must eventually call the
\sphinxcode{\sphinxupquote{ns3::Socket::Connect()}} method to connect to the provided
destAddress and the Connect method of the particular socket type must
support setting the type of service associated with a socket (by using
the \sphinxcode{\sphinxupquote{ns3::Socket::SetIpTos()}} method). Currently, the socket
types that support setting the type of service in such a way are
\sphinxcode{\sphinxupquote{ns3::UdpSocketImpl}} and \sphinxcode{\sphinxupquote{ns3::TcpSocketBase}}.

The type of service associated with a socket is then used to determine the value
of the Type of Service field (renamed as Differentiated Services field by RFC
2474) of the IPv4 header of the packets sent through that socket, as detailed
in the next sections.


\paragraph{Setting the ToS with UDP sockets}
\label{\detokenize{sockets-api:setting-the-tos-with-udp-sockets}}
For IPv4 packets, the ToS field is set according to the following rules:
\begin{itemize}
\item {} 
If the socket is connected, the ToS field is set to the ToS value associated
with the socket.

\item {} 
If the socket is not connected, the ToS field is set to the value specified
in the destination address (of type \sphinxcode{\sphinxupquote{ns3::InetSocketAddress}}) passed
to \sphinxcode{\sphinxupquote{ns3::Socket::SendTo()}}, and the ToS value associated with the
socket is ignored.

\end{itemize}


\paragraph{Setting the ToS with TCP sockets}
\label{\detokenize{sockets-api:setting-the-tos-with-tcp-sockets}}
For IPv4 packets, the ToS field is set to the ToS value associated with the
socket.


\subsubsection{Priority}
\label{\detokenize{sockets-api:priority}}
The native sockets API for ns\sphinxhyphen{}3 provides two public methods
(of the Socket base class):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{SetPriority} \PYG{p}{(}\PYG{k+kt}{uint8\PYGZus{}t} \PYG{n}{priority}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{uint8\PYGZus{}t} \PYG{n+nf}{GetPriority} \PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{k}{const}\PYG{p}{;}
\end{sphinxVerbatim}

to set and get, respectively, the priority associated with the socket.
These methods are equivalent to using the SO\_PRIORITY option of BSD sockets.
Only values in the range 0..6 can be set through the above method.

Note that setting the type of service associated with a socket (by calling
\sphinxcode{\sphinxupquote{ns3::Socket::SetIpTos()}}) also sets the priority for the socket
to the value that the \sphinxcode{\sphinxupquote{ns3::Socket::IpTos2Priority()}} function
returns when it is passed the type of service value. This function
is implemented after the Linux rt\_tos2priority function, which takes
an 8\sphinxhyphen{}bit value as input and returns a value which is a function of bits 3\sphinxhyphen{}6
(where bit 0 is the most significant bit) of the input value:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Bits 3\sphinxhyphen{}6
&\sphinxstyletheadfamily 
Priority
\\
\hline
0 to 3
&
0 (Best Effort)
\\
\hline
4 to 7
&
2 (Bulk)
\\
\hline
8 to 11
&
6 (Interactive)
\\
\hline
12 to 15
&
4 (Interactive Bulk)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The rationale is that bits 3\sphinxhyphen{}6 of the Type of Service field were interpreted
as the TOS subfield by (the obsolete) RFC 1349. Readers can refer to the
doxygen documentation of \sphinxcode{\sphinxupquote{ns3::Socket::IpTos2Priority()}}
for more information, including how DSCP values map onto priority values.

The priority set for a socket (as described above) is then used to determine
the priority of the packets sent through that socket, as detailed in the next
sections. Currently, the socket types that support setting the packet priority
are \sphinxcode{\sphinxupquote{ns3::UdpSocketImpl}}, \sphinxcode{\sphinxupquote{ns3::TcpSocketBase}} and
\sphinxcode{\sphinxupquote{ns3::PacketSocket}}. The packet priority is used, e.g., by queuing
disciplines such as the default PfifoFastQueueDisc to classify packets into
distinct queues.


\paragraph{Setting the priority with UDP sockets}
\label{\detokenize{sockets-api:setting-the-priority-with-udp-sockets}}
If the packet is an IPv4 packet and the value to be inserted in the ToS field
is not null, then the packet is assigned a priority based on such ToS value
(according to the \sphinxcode{\sphinxupquote{ns3::Socket::IpTos2Priority()}} function). Otherwise,
the priority associated with the socket is assigned to the packet.


\paragraph{Setting the priority with TCP sockets}
\label{\detokenize{sockets-api:setting-the-priority-with-tcp-sockets}}
Every packet is assigned a priority equal to the priority associated with the
socket.


\paragraph{Setting the priority with packet sockets}
\label{\detokenize{sockets-api:setting-the-priority-with-packet-sockets}}
Every packet is assigned a priority equal to the priority associated with the
socket.


\subsection{Socket errno}
\label{\detokenize{sockets-api:socket-errno}}
\sphinxstyleemphasis{to be completed}


\subsection{Example programs}
\label{\detokenize{sockets-api:example-programs}}
\sphinxstyleemphasis{to be completed}


\subsection{POSIX\sphinxhyphen{}like sockets API}
\label{\detokenize{sockets-api:posix-like-sockets-api}}

\section{Simple NetDevice}
\label{\detokenize{simple:simple-netdevice}}\label{\detokenize{simple::doc}}
\sphinxstyleemphasis{Placeholder chapter}


\section{Queues}
\label{\detokenize{queue:queues}}\label{\detokenize{queue::doc}}
This section documents the queue object, which is typically used by NetDevices
and QueueDiscs to store packets.

Packets stored in a queue can be managed according to different policies.
Currently, only the DropTail policy is available.


\subsection{Model Description}
\label{\detokenize{queue:model-description}}
The source code for the new module lives in the directory \sphinxcode{\sphinxupquote{src/network/utils}}.

ns3::Queue has been redesigned as a template class object to allow us to
instantiate queues storing different types of items. The unique template
type parameter specifies the type of items stored in the queue.
The only requirement on the item type is that it must provide a GetSize ()
method which returns the size of the packet included in the item.
Currently, queue items can be objects of the following classes:
\begin{itemize}
\item {} 
Packet

\item {} 
QueueItem and subclasses (e.g., QueueDiscItem)

\item {} 
WifiMacQueueItem

\end{itemize}

The internal queues of the queue discs are of type Queue\textless{}QueueDiscItem\textgreater{}
(an alias of which being InternalQueue). A number of network devices
(SimpleNetDevice, PointToPointNetDevice, CsmaNetDevice) use a Queue\textless{}Packet\textgreater{}
to store packets to be transmitted. WifiNetDevices use instead queues of
type WifiMacQueue, which is a subclass of Queue storing objects of
type WifiMacQueueItem. Other devices, such as WiMax and LTE, use specialized
queues.


\subsubsection{Design}
\label{\detokenize{queue:design}}
The Queue class derives from the QueueBase class, which is a non\sphinxhyphen{}template
class providing all the methods that are independent of the type of the items
stored in the queue. The Queue class provides instead all the operations that
depend on the item type, such as enqueue, dequeue, peek and remove. The Queue
class also provides the ability to trace certain queue operations such as
enqueuing, dequeuing, and dropping.

Queue is an abstract base class and is subclassed for specific scheduling and
drop policies. Subclasses need to define the following public methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bool Enqueue (Ptr\textless{}Item\textgreater{} item)}}:  Enqueue a packet

\item {} 
\sphinxcode{\sphinxupquote{Ptr\textless{}Item\textgreater{} Dequeue (void)}}:  Dequeue a packet

\item {} 
\sphinxcode{\sphinxupquote{Ptr\textless{}Item\textgreater{} Remove (void)}}:  Remove a packet

\item {} 
\sphinxcode{\sphinxupquote{Ptr\textless{}const Item\textgreater{} Peek (void)}}:  Peek a packet

\end{itemize}

The Enqueue method does not allow to store a packet if the queue capacity is exceeded.
Subclasses may also define specialized public methods. For instance, the
WifiMacQueue class provides a method to dequeue a packet based on its tid
and MAC address.

There are five trace sources that may be hooked:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Enqueue}}

\item {} 
\sphinxcode{\sphinxupquote{Dequeue}}

\item {} 
\sphinxcode{\sphinxupquote{Drop}}

\item {} 
\sphinxcode{\sphinxupquote{DropBeforeEnqueue}}

\item {} 
\sphinxcode{\sphinxupquote{DropAfterDequeue}}

\end{itemize}

Also, the QueueBase class defines two additional trace sources:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{PacketsInQueue}}

\item {} 
\sphinxcode{\sphinxupquote{BytesInQueue}}

\end{itemize}


\paragraph{DropTail}
\label{\detokenize{queue:droptail}}
This is a basic first\sphinxhyphen{}in\sphinxhyphen{}first\sphinxhyphen{}out (FIFO) queue that performs a tail drop
when the queue is full.

The DropTailQueue class defines one attribute:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize}}: the maximum queue size

\end{itemize}


\subsection{Usage}
\label{\detokenize{queue:usage}}

\subsubsection{Helpers}
\label{\detokenize{queue:helpers}}
A typical usage pattern is to create a device helper and to configure
the queue type and attributes from the helper, such as this example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{PointToPointHelper} \PYG{n}{p2p}\PYG{p}{;}

\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetQueue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::DropTailQueue}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataRate}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Delay}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2ms}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devn0n2} \PYG{o}{=} \PYG{n}{p2p}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n0n2}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetQueue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::DropTailQueue}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataRate}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Delay}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3ms}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devn1n2} \PYG{o}{=} \PYG{n}{p2p}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n1n2}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetQueue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::DropTailQueue}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{50p}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataRate}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{linkDataRate}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{p2p}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Delay}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{linkDelay}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devn2n3} \PYG{o}{=} \PYG{n}{p2p}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{n2n3}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Please note that the SetQueue method of the PointToPointHelper class allows
to specify “ns3::DropTailQueue” instead of “ns3::DropTailQueue\textless{}Packet\textgreater{}”. The
same holds for CsmaHelper, SimpleNetDeviceHelper and TrafficControlHelper.


\subsubsection{Output}
\label{\detokenize{queue:output}}
The ns\sphinxhyphen{}3 ascii trace helpers used by many of the NetDevices will hook
the Enqueue, Dequeue, and Drop traces of these queues and print out
trace statements, such as the following from \sphinxcode{\sphinxupquote{examples/udp/udp\sphinxhyphen{}echo.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+ 2 /NodeList/0/DeviceList/1/\PYGZdl{}ns3::CsmaNetDevice/TxQueue/Enqueue ns3::EthernetHeader
( length/type=0x806, source=00:00:00:00:00:01, destination=ff:ff:ff:ff:ff:ff)
ns3::ArpHeader (request source mac: 00\PYGZhy{}06\PYGZhy{}00:00:00:00:00:01 source ipv4: 10.1.1.1
dest ipv4: 10.1.1.2) Payload (size=18) ns3::EthernetTrailer (fcs=0)
\PYGZhy{} 2 /NodeList/0/DeviceList/1/\PYGZdl{}ns3::CsmaNetDevice/TxQueue/Dequeue ns3::EthernetHeader
( length/type=0x806, source=00:00:00:00:00:01, destination=ff:ff:ff:ff:ff:ff)
ns3::ArpHeader (request source mac: 00\PYGZhy{}06\PYGZhy{}00:00:00:00:00:01 source ipv4: 10.1.1.1
dest ipv4: 10.1.1.2) Payload (size=18) ns3::EthernetTrailer (fcs=0)
\end{sphinxVerbatim}

which shows an enqueue “+” and dequeue “\sphinxhyphen{}” event at time 2 seconds.

Users are, of course, free to define and hook their own trace sinks to
these trace sources.


\subsubsection{Examples}
\label{\detokenize{queue:examples}}
The drop\sphinxhyphen{}tail queue is used in several examples, such as
\sphinxcode{\sphinxupquote{examples/udp/udp\sphinxhyphen{}echo.cc}}.


\section{Queue limits}
\label{\detokenize{queue-limits:queue-limits}}\label{\detokenize{queue-limits::doc}}
This section documents the queue limits model, which is used by the traffic control
to limit the NetDevices queueing delay. It operates on the transmission path of
the network node.

The reduction of the NetDevices queueing delay is essential to improve the effectiveness of
Active Queue Management (AQM) algorithms.
Careful assessment of the queueing delay includes a byte\sphinxhyphen{}based measure of the NetDevices
queue length. In this design, traffic control can use different byte\sphinxhyphen{}based schemes to
limit the queueing delay. Currently the only available scheme is DynamicQueueLimits, which is
modelled after the dynamic queue limit library of Linux.


\subsection{Model Description}
\label{\detokenize{queue-limits:model-description}}
The source code for the model lives in the directory \sphinxcode{\sphinxupquote{src/network/utils}}.

The model allows a byte\sphinxhyphen{}based measure of the netdevice queue. The byte\sphinxhyphen{}based measure
more accurately approximates the time required to empty the queue than a packet\sphinxhyphen{}based measure.

To inform the upper layers about the transmission of packets, NetDevices can call a couple
of functions:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{void NotifyQueuedBytes (uint32\_t bytes)}}: Report the number of bytes queued to the device queue

\item {} 
\sphinxcode{\sphinxupquote{void NotifyTransmittedBytes (uint32\_t bytes)}}: Report the number of bytes transmitted by device

\end{itemize}

Based on this information, the QueueLimits object can stop the transmission queue.

In case of multiqueue NetDevices this mechanism is available for each queue.

The QueueLimits model can be used on any NetDevice modelled in ns\sphinxhyphen{}3.


\subsubsection{Design}
\label{\detokenize{queue-limits:design}}
An abstract base class, class QueueLimits, is subclassed for specific
byte\sphinxhyphen{}based limiting strategies.

Common operations provided by the base class QueueLimits include:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{void Reset ()}}:  Reset queue limits state

\item {} 
\sphinxcode{\sphinxupquote{void Completed (uint32\_t count)}}:  Record the number of completed bytes and recalculate the limit

\item {} 
\sphinxcode{\sphinxupquote{int32\_t Available () const}}:  Return how many bytes can be queued

\item {} 
\sphinxcode{\sphinxupquote{void Queued (uint32\_t count)}}:  Record number of bytes queued

\end{itemize}


\paragraph{DynamicQueueLimits}
\label{\detokenize{queue-limits:dynamicqueuelimits}}
Dynamic queue limits (DQL) is a basic library implemented in the Linux kernel to limit the Ethernet
queueing delay. DQL is a general purpose queue length controller. The goal of DQL is to calculate
the limit as the minimum number of bytes needed to prevent starvation.

Three attributes are defined in the DynamicQueueLimits class:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{HoldTime}}: The DQL algorithm hold time

\item {} 
\sphinxcode{\sphinxupquote{MaxLimit}}: Maximum limit

\item {} 
\sphinxcode{\sphinxupquote{MinLimit}}: Minimum limit

\end{itemize}

The DQL algorithm hold time is 1 s. Reducing the HoldTime increases the responsiveness of
DQL with consequent greater number of limit variation events. Conversely, increasing the HoldTime
decreases the responsiveness of DQL with a minor number of limit variation events.
The limit calculated by DQL is in the range from MinLimit to MaxLimit.
The default values are respectively 0 and DQL\_MAX\_LIMIT.
Increasing the MinLimit is recommended in case of higher NetDevice transmission rate (e.g. 1 Gbps)
while reducing the MaxLimit is recommended in case of lower NetDevice transmission rate (e.g. 500 Kbps).

There is one trace source in DynamicQueueLimits class that may be hooked:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Limit}}: Limit value calculated by DQL

\end{itemize}


\subsection{Usage}
\label{\detokenize{queue-limits:usage}}

\subsubsection{Helpers}
\label{\detokenize{queue-limits:helpers}}
A typical usage pattern is to create a traffic control helper and configure
the queue limits type and attributes from the helper, such as this example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TrafficControlHelper} \PYG{n}{tch}\PYG{p}{;}
\PYG{k+kt}{uint32\PYGZus{}t} \PYG{n}{handle} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetRootQueueDisc} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::PfifoFastQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Limit}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{1000}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetQueueLimits} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::DynamicQueueLimits}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{HoldTime}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4ms}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

then install the configuration on a NetDevices container

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{devices}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\chapter{Nix\sphinxhyphen{}Vector Routing Documentation}
\label{\detokenize{nix-vector-routing:nix-vector-routing-documentation}}\label{\detokenize{nix-vector-routing::doc}}
Nix\sphinxhyphen{}vector routing is a simulation specific routing protocol and is
intended for large network topologies.  The on\sphinxhyphen{}demand nature of this
protocol as well as the low\sphinxhyphen{}memory footprint of the nix\sphinxhyphen{}vector provides
improved performance in terms of memory usage and simulation run time
when dealing with a large number of nodes.


\section{Model Description}
\label{\detokenize{nix-vector-routing:model-description}}
The source code for the NixVectorRouting module lives in
the directory \sphinxcode{\sphinxupquote{src/nix\sphinxhyphen{}vector\sphinxhyphen{}routing}}.

\sphinxstyleemphasis{ns\sphinxhyphen{}3} nix\sphinxhyphen{}vector\sphinxhyphen{}routing performs on\sphinxhyphen{}demand route computation using
a breadth\sphinxhyphen{}first search and an efficient route\sphinxhyphen{}storage data structure
known as a nix\sphinxhyphen{}vector.

When a packet is generated at a node for transmission, the route is
calculated, and the nix\sphinxhyphen{}vector is built.
The nix\sphinxhyphen{}vector stores an index for each hop along the path, which
corresponds to the neighbor\sphinxhyphen{}index.  This index is used to determine
which net\sphinxhyphen{}device and gateway should be used.  To route a packet, the
nix\sphinxhyphen{}vector must be transmitted with the packet. At each hop, the
current node extracts the appropriate neighbor\sphinxhyphen{}index from the
nix\sphinxhyphen{}vector and transmits the packet through the corresponding
net\sphinxhyphen{}device.  This continues until the packet reaches the destination.


\subsection{Scope and Limitations}
\label{\detokenize{nix-vector-routing:scope-and-limitations}}
Currently, the ns\sphinxhyphen{}3 model of nix\sphinxhyphen{}vector routing supports IPv4 p2p links
as well as CSMA links.  It does not (yet) provide support for
efficient adaptation to link failures.  It simply flushes all nix\sphinxhyphen{}vector
routing caches. Finally, IPv6 is not supported.


\section{Usage}
\label{\detokenize{nix-vector-routing:usage}}
The usage pattern is the one of all the Internet routing protocols.
Since NixVectorRouting is not installed by default in the
Internet stack, it is necessary to set it in the Internet Stack
helper by using \sphinxcode{\sphinxupquote{InternetStackHelper::SetRoutingHelper}}


\subsection{Examples}
\label{\detokenize{nix-vector-routing:examples}}
The examples for the NixVectorRouting module lives in
the directory \sphinxcode{\sphinxupquote{src/nix\sphinxhyphen{}vector\sphinxhyphen{}routing/examples}}.


\chapter{Optimized Link State Routing (OLSR)}
\label{\detokenize{olsr:optimized-link-state-routing-olsr}}\label{\detokenize{olsr::doc}}
This model implements the base specification of the Optimized
Link State Routing (OLSR) protocol, which is a dynamic mobile ad hoc
unicast routing protocol.  It has been developed at the
University of Murcia (Spain) by Francisco J. Ros for NS\sphinxhyphen{}2, and was
ported to NS\sphinxhyphen{}3 by Gustavo Carneiro at INESC Porto (Portugal).

The implementation is based on OLSR Version 1 (\index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}} \sphinxcite{olsr:rfc3626}) and
it is \sphinxstyleemphasis{not} compliant with OLSR Version 2 (\index{RFC@\spxentry{RFC}!RFC 7181@\spxentry{RFC 7181}}\sphinxhref{https://tools.ietf.org/html/rfc7181.html}{\sphinxstylestrong{RFC 7181}} \sphinxcite{olsr:rfc7181}) or any
of the Version 2 extensions.


\section{Model Description}
\label{\detokenize{olsr:model-description}}
The source code for the OLSR model lives in the directory \sphinxtitleref{src/olsr}.
As stated before, the model is based on \index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}} (\sphinxcite{olsr:rfc3626}). Moreover, many
design choices are based on the previous ns2 model.


\subsection{Scope and Limitations}
\label{\detokenize{olsr:scope-and-limitations}}
The model is for IPv4 only.
\begin{itemize}
\item {} 
Mostly compliant with OLSR as documented in \index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}} (\sphinxcite{olsr:rfc3626}),

\item {} 
The use of multiple interfaces was not supported by the NS\sphinxhyphen{}2 version, but is supported in NS\sphinxhyphen{}3;

\item {} 
OLSR does not respond to the routing event notifications corresponding to dynamic interface up and down (\sphinxcode{\sphinxupquote{ns3::RoutingProtocol::NotifyInterfaceUp}} and \sphinxcode{\sphinxupquote{ns3::RoutingProtocol::NotifyInterfaceDown}}) or address insertion/removal \sphinxcode{\sphinxupquote{ns3::RoutingProtocol::NotifyAddAddress}} and \sphinxcode{\sphinxupquote{ns3::RoutingProtocol::NotifyRemoveAddress}}).

\item {} 
Unlike the NS\sphinxhyphen{}2 version, does not yet support MAC layer feedback as described in \index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}} (\sphinxcite{olsr:rfc3626});

\end{itemize}

Host Network Association (HNA) is supported in this implementation
of OLSR. Refer to \sphinxcode{\sphinxupquote{examples/olsr\sphinxhyphen{}hna.cc}} to see how the API
is used.


\subsection{References}
\label{\detokenize{olsr:references}}

\section{Usage}
\label{\detokenize{olsr:usage}}
The usage pattern is the one of all the Internet routing protocols.
Since OLSR is not installed by default in the Internet stack, it is necessary to
set it in the Internet Stack helper by using \sphinxcode{\sphinxupquote{InternetStackHelper::SetRoutingHelper}}

Typically, OLSR is enabled in a main program by use of an OlsrHelper class that
installs OLSR into an Ipv4ListRoutingProtocol object. The following sample
commands will enable OLSR in a simulation using this helper class along with
some other routing helper objects. The setting of priority value 10, ahead of
the staticRouting priority of 0, means that OLSR will be consulted for a route
before the node’s static routing table.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{c}\PYG{p}{:}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{/}\PYG{o}{/} \PYG{n}{Enable} \PYG{n}{OLSR}
\PYG{n}{NS\PYGZus{}LOG\PYGZus{}INFO} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Enabling OLSR Routing.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{OlsrHelper} \PYG{n}{olsr}\PYG{p}{;}

\PYG{n}{Ipv4StaticRoutingHelper} \PYG{n}{staticRouting}\PYG{p}{;}

\PYG{n}{Ipv4ListRoutingHelper} \PYG{n+nb}{list}\PYG{p}{;}
\PYG{n+nb}{list}\PYG{o}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{staticRouting}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n+nb}{list}\PYG{o}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{olsr}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{InternetStackHelper} \PYG{n}{internet}\PYG{p}{;}
\PYG{n}{internet}\PYG{o}{.}\PYG{n}{SetRoutingHelper} \PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{internet}\PYG{o}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{c}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once installed,the OLSR “main interface” can be set with the SetMainInterface()
command. If the user does not specify a main address, the protocol will select
the first primary IP address that it finds, starting first the loopback
interface and then the next non\sphinxhyphen{}loopback interface found, in order of Ipv4
interface index. The loopback address of 127.0.0.1 is not selected. In addition,
a number of protocol constants are defined in olsr\sphinxhyphen{}routing\sphinxhyphen{}protocol.cc.

Olsr is started at time zero of the simulation, based on a call to
Object::Start() that eventually calls OlsrRoutingProtocol::DoStart(). Note:  a
patch to allow the user to start and stop the protocol at other times would be
welcome.


\subsection{Examples}
\label{\detokenize{olsr:examples}}
The examples are in the \sphinxcode{\sphinxupquote{src/olsr/examples/}} directory. However, many other examples esists in the
general examples directory, e.g., \sphinxcode{\sphinxupquote{examples/routing/manet\sphinxhyphen{}routing\sphinxhyphen{}compare.cc}}.

For specific examples of the HNA feature, see the examples in \sphinxcode{\sphinxupquote{src/olsr/examples/}}.


\subsection{Helpers}
\label{\detokenize{olsr:helpers}}
A helper class for OLSR has been written.  After an IPv4 topology
has been created and unique IP addresses assigned to each node, the
simulation script writer can call one of three overloaded functions
with different scope to enable OLSR: \sphinxcode{\sphinxupquote{ns3::OlsrHelper::Install
(NodeContainer container)}}; \sphinxcode{\sphinxupquote{ns3::OlsrHelper::Install (Ptr\textless{}Node\textgreater{}
node)}}; or \sphinxcode{\sphinxupquote{ns3::OlsrHelper::InstallAll (void)}}


\subsection{Attributes}
\label{\detokenize{olsr:attributes}}
In addition, the behavior of OLSR can be modified by changing certain
attributes.  The method \sphinxcode{\sphinxupquote{ns3::OlsrHelper::Set ()}} can be used
to set OLSR attributes.  These include HelloInterval, TcInterval,
MidInterval, Willingness.  Other parameters are defined as macros
in \sphinxcode{\sphinxupquote{olsr\sphinxhyphen{}routing\sphinxhyphen{}protocol.cc}}.

The list of configurabel attributes is:
\begin{itemize}
\item {} 
HelloInterval (time, default 2s), HELLO messages emission interval.

\item {} 
TcInterval (time, default 5s), TC messages emission interval.

\item {} 
MidInterval (time, default 5s), MID messages emission interval.

\item {} 
HnaInterval (time, default 5s), HNA messages emission interval.

\item {} 
Willingness (enum, default OLSR\_WILL\_DEFAULT), Willingness of a node to carry and forward traffic for other nodes.

\end{itemize}


\subsection{Tracing}
\label{\detokenize{olsr:tracing}}
The available traces are:
\begin{itemize}
\item {} 
Rx: Receive OLSR packet.

\item {} 
Tx: Send OLSR packet.

\item {} 
RoutingTableChanged: The OLSR routing table has changed.

\end{itemize}


\subsection{Caveats}
\label{\detokenize{olsr:caveats}}
Presently, OLSR is limited to use with an Ipv4ListRouting object, and does not
respond to dynamic changes to a device’s IP address or link up/down
notifications; i.e. the topology changes are due to loss/gain of connectivity
over a wireless channel.

The code does not present any known issue.


\section{Validation}
\label{\detokenize{olsr:validation}}
The code validationhas been done through Wireshark message compliance and unit testings.


\chapter{OpenFlow switch support}
\label{\detokenize{openflow-switch:openflow-switch-support}}\label{\detokenize{openflow-switch::doc}}
ns\sphinxhyphen{}3 simulations can use OpenFlow switches (McKeown et al. %
\begin{footnote}[1]\sphinxAtStartFootnote
McKeown, N.; Anderson, T.; Balakrishan, H.; Parulkar, G.; Peterson, L.; Rexford, J.; Shenker, S.; Turner, J.; OpenFlow: enabling innovation in campus networks, ACM SIGCOMM Computer Communication Review, Vol. 38, Issue 2, April 2008.
%
\end{footnote}),
widely used in research.  OpenFlow switches are configurable via the
OpenFlow API, and also have an MPLS extension for quality\sphinxhyphen{}of\sphinxhyphen{}service and
service\sphinxhyphen{}level\sphinxhyphen{}agreement support. By extending these capabilities to ns\sphinxhyphen{}3
for a simulated OpenFlow switch that is both configurable and can use
the MPLS extension, ns\sphinxhyphen{}3 simulations can accurately simulate many different
switches.

The OpenFlow software implementation distribution is hereby referred to as
the OFSID. This is a demonstration of running OpenFlow in software that
the OpenFlow research group has made available. There is also an OFSID
that Ericsson researchers created to add MPLS capabilities; this is the
OFSID currently used with ns\sphinxhyphen{}3. The design will allow the users to,
with minimal effort, switch in a different OFSID that may include more
efficient code than a previous OFSID.


\section{Model Description}
\label{\detokenize{openflow-switch:model-description}}
The model relies on building an external OpenFlow switch library (OFSID),
and then building some ns\sphinxhyphen{}3 wrappers that call out to the library.
The source code for the ns\sphinxhyphen{}3 wrappers lives in the directory
\sphinxcode{\sphinxupquote{src/openflow/model}}.


\subsection{Design}
\label{\detokenize{openflow-switch:design}}
The OpenFlow module presents a OpenFlowSwitchNetDevice and a OpenFlowSwitchHelper for
installing it on nodes. Like the Bridge module, it takes a collection of
NetDevices to set up as ports, and it acts as the intermediary between
them, receiving a packet on one port and forwarding it on another, or all
but the received port when flooding. Like an OpenFlow switch, it maintains
a configurable flow table that can match packets by their headers and do
different actions with the packet based on how it matches. The module’s
understanding of OpenFlow configuration messages are kept the same format
as a real OpenFlow\sphinxhyphen{}compatible switch, so users testing Controllers via
ns\sphinxhyphen{}3 won’t have to rewrite their Controller to work on real
OpenFlow\sphinxhyphen{}compatible switches.

The ns\sphinxhyphen{}3 OpenFlow switch device models an OpenFlow\sphinxhyphen{}enabled switch. It is designed to
express basic use of the OpenFlow protocol, with the maintaining of a virtual
Flow Table and TCAM to provide OpenFlow\sphinxhyphen{}like results.

The functionality comes down to the Controllers, which send messages to the
switch that configure its flows, producing different effects. Controllers can
be added by the user, under the ofi namespace extending ofi::Controller. To
demonstrate this, a DropController, which creates flows for ignoring every single
packet, and LearningController, which effectively makes the switch a more complicated
BridgeNetDevice. A user versed in a standard OFSID, and/or OF protocol, can write
virtual controllers to create switches of all kinds of types.


\subsubsection{OpenFlow switch Model}
\label{\detokenize{openflow-switch:openflow-switch-model}}
The OpenFlow switch device behaves somewhat according to the diagram setup as a classical OFSID
switch, with a few modifications made for a proper simulation environment.

Normal OF\sphinxhyphen{}enabled Switch:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
| Secure Channel                  | \PYGZlt{}\PYGZhy{}\PYGZhy{}OF Protocol\PYGZhy{}\PYGZhy{}\PYGZgt{} | Controller is external |
| Hardware or Software Flow Table |
\end{sphinxVerbatim}

ns\sphinxhyphen{}3 OF\sphinxhyphen{}enabled Switch (module):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
| m\PYGZus{}controller\PYGZhy{}\PYGZgt{}ReceiveFromSwitch() | \PYGZlt{}\PYGZhy{}\PYGZhy{}OF Protocol\PYGZhy{}\PYGZhy{}\PYGZgt{} | Controller is internal |
| Software Flow Table, virtual TCAM |
\end{sphinxVerbatim}

In essence, there are two differences:

1) No SSL, Embedded Controller: Instead of a secure channel and connecting to an
outside location for the Controller program/machine, we currently only allow a
Controller extended from ofi::Controller, an extension of an ns3::Object. This
means ns\sphinxhyphen{}3 programmers cannot model the SSL part of the interface or possibility
of network failure. The connection to the OpenFlowSwitch is local and there aren’t any
reasons for the channel/connection to break down. \textless{}\textless{}This difference may be an
option in the future. Using EmuNetDevices, it should be possible to engage an
external Controller program/machine, and thus work with controllers designed
outside of the ns\sphinxhyphen{}3 environment, that simply use the proper OF protocol when
communicating messages to the switch through a tap device.\textgreater{}\textgreater{}

2) Virtual Flow Table, TCAM: Typical OF\sphinxhyphen{}enabled switches are implemented on a hardware
TCAM. The OFSID we turn into a library includes a modelled software TCAM, that produces
the same results as a hardware TCAM. We include an attribute FlowTableLookupDelay, which
allows a simple delay of using the TCAM to be modelled. We don’t endeavor to make this
delay more complicated, based on the tasks we are running on the TCAM, that is a possible
future improvement.

The OpenFlowSwitch network device is aimed to model an OpenFlow switch, with a TCAM and a connection
to a controller program. With some tweaking, it can model every switch type, per OpenFlow’s
extensibility. It outsources the complexity of the switch ports to NetDevices of the user’s choosing.
It should be noted that these NetDevices must behave like practical switch ports, i.e. a Mac Address
is assigned, and nothing more. It also must support a SendFrom function so that
the OpenFlowSwitch can forward across that port.


\subsection{Scope and Limitations}
\label{\detokenize{openflow-switch:scope-and-limitations}}
All MPLS capabilities are implemented on the OFSID side in the OpenFlowSwitchNetDevice,
but ns\sphinxhyphen{}3\sphinxhyphen{}mpls hasn’t been integrated, so ns\sphinxhyphen{}3 has no way to pass in
proper MPLS packets to the OpenFlowSwitch. If it did, one would only need to make
BufferFromPacket pick up the MplsLabelStack or whatever the MPLS header
is called on the Packet, and build the MPLS header into the ofpbuf.


\subsection{Future Work}
\label{\detokenize{openflow-switch:future-work}}

\subsection{References}
\label{\detokenize{openflow-switch:references}}

\section{Usage}
\label{\detokenize{openflow-switch:usage}}
The OFSID requires libxml2 (for MPLS FIB xml file parsing), libdl (for address fault checking),
and boost (for assert) libraries to be installed.


\subsection{Building OFSID}
\label{\detokenize{openflow-switch:building-ofsid}}
In order to use the OpenFlowSwitch module, you must create and link the
OFSID (OpenFlow Software Implementation Distribution) to ns\sphinxhyphen{}3.
To do this:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Obtain the OFSID code.
An ns\sphinxhyphen{}3 specific OFSID branch is provided to ensure
operation with ns\sphinxhyphen{}3. Use mercurial to download this branch and waf to build
the library:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} hg clone http://code.nsnam.org/openflow
\PYGZdl{} \PYG{n+nb}{cd} openflow
\end{sphinxVerbatim}

From the “openflow” directory, run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure
\PYGZdl{} ./waf build
\end{sphinxVerbatim}

\item {} 
Your OFSID is now built into a libopenflow.a library!
To link to an ns\sphinxhyphen{}3 build with this OpenFlow switch module, run from the ns\sphinxhyphen{}3\sphinxhyphen{}dev
(or whatever you have named your distribution):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests \PYGZhy{}\PYGZhy{}with\PYGZhy{}openflow\PYG{o}{=}path/to/openflow
\end{sphinxVerbatim}

\item {} 
Under \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}\sphinxhyphen{}\sphinxhyphen{} Summary of optional NS\sphinxhyphen{}3 features:}} you should see:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}NS\PYGZhy{}3 OpenFlow Integration     : enabled\PYGZdq{}
\end{sphinxVerbatim}

indicating the library has been linked to ns\sphinxhyphen{}3. Run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf build
\end{sphinxVerbatim}

\end{enumerate}

to build ns\sphinxhyphen{}3 and activate the OpenFlowSwitch module in ns\sphinxhyphen{}3.


\subsection{Examples}
\label{\detokenize{openflow-switch:examples}}
For an example demonstrating its use in a simple learning controller/switch,
run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run openflow\PYGZhy{}switch
\end{sphinxVerbatim}

To see it in detailed logging, run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}openflow\PYGZhy{}switch \PYGZhy{}v\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Helpers}
\label{\detokenize{openflow-switch:helpers}}

\subsection{Attributes}
\label{\detokenize{openflow-switch:attributes}}
The SwitchNetDevice provides following Attributes:
\begin{itemize}
\item {} 
FlowTableLookUpDelay:      This time gets run off the clock when making a lookup in our Flow Table.

\item {} \begin{description}
\item[{Flags:                     OpenFlow specific configuration flags. They are defined in the ofp\_config\_flags enum. Choices include:}] \leavevmode
OFPC\_SEND\_FLOW\_EXP (Switch notifies controller when a flow has expired),
OFPC\_FRAG\_NORMAL (Match fragment against Flow table),
OFPC\_FRAG\_DROP (Drop fragments),
OFPC\_FRAG\_REASM (Reassemble only if OFPC\_IP\_REASM set, which is currently impossible,
because switch implementation does not support IP reassembly)
OFPC\_FRAG\_MASK (Mask Fragments)

\end{description}

\item {} \begin{description}
\item[{FlowTableMissSendLength:   When the packet doesn’t match in our Flow Table, and we forward to the controller,}] \leavevmode
this sets \# of bytes forwarded (packet is not forwarded in its entirety, unless specified).

\end{description}

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Tracing}
\label{\detokenize{openflow-switch:tracing}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Logging}
\label{\detokenize{openflow-switch:logging}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Caveats}
\label{\detokenize{openflow-switch:caveats}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\section{Validation}
\label{\detokenize{openflow-switch:validation}}
This model has one test suite which can be run as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./test.py \PYGZhy{}\PYGZhy{}suite\PYG{o}{=}openflow
\end{sphinxVerbatim}


\chapter{PointToPoint NetDevice}
\label{\detokenize{point-to-point:pointtopoint-netdevice}}\label{\detokenize{point-to-point::doc}}
This is the introduction to PointToPoint NetDevice chapter, to complement the
PointToPoint model doxygen.


\section{Overview of the PointToPoint model}
\label{\detokenize{point-to-point:overview-of-the-pointtopoint-model}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} point\sphinxhyphen{}to\sphinxhyphen{}point model is of a very simple point to point data link
connecting exactly two PointToPointNetDevice devices over an
PointToPointChannel. This can be viewed as equivalent to a full duplex RS\sphinxhyphen{}232 or
RS\sphinxhyphen{}422 link with null modem and no handshaking.

Data is encapsulated in the Point\sphinxhyphen{}to\sphinxhyphen{}Point Protocol (PPP \textendash{} RFC 1661), however
the Link Control Protocol (LCP) and associated state machine is not implemented.
The PPP link is assumed to be established and authenticated at all times.

Data is not framed, therefore Address and Control fields will not be found.
Since the data is not framed, there is no need to provide Flag Sequence and
Control Escape octets, nor is a Frame Check Sequence appended. All that is
required to implement non\sphinxhyphen{}framed PPP is to prepend the PPP protocol number for
IP Version 4 which is the sixteen\sphinxhyphen{}bit number 0x21 (see
\sphinxurl{http://www.iana.org/assignments/ppp-numbers}).

The PointToPointNetDevice provides following Attributes:
\begin{itemize}
\item {} 
Address:  The ns3::Mac48Address of the device (if desired);

\item {} 
DataRate:  The data rate (ns3::DataRate) of the device;

\item {} 
TxQueue:  The transmit queue (ns3::Queue) used by the device;

\item {} 
InterframeGap:  The optional ns3::Time to wait between “frames”;

\item {} 
Rx:  A trace source for received packets;

\item {} 
Drop:  A trace source for dropped packets.

\end{itemize}

The PointToPointNetDevice models a transmitter section that puts bits on a
corresponding channel “wire.” The DataRate attribute specifies the number of
bits per second that the device will simulate sending over the channel. In
reality no bits are sent, but an event is scheduled for an elapsed time
consistent with the number of bits in each packet and the specified DataRate.
The implication here is that the receiving device models a receiver section that
can receive any any data rate. Therefore there is no need, nor way to set a
receive data rate in this model. By setting the DataRate on the transmitter of
both devices connected to a given PointToPointChannel one can model a symmetric
channel; or by setting different DataRates one can model an asymmetric channel
(e.g., ADSL).

The PointToPointNetDevice supports the assignment of a “receive error model.”
This is an ErrorModel object that is used to simulate data corruption on the
link.


\section{Point\sphinxhyphen{}to\sphinxhyphen{}Point Channel Model}
\label{\detokenize{point-to-point:point-to-point-channel-model}}
The point to point net devices are connected via an PointToPointChannel. This
channel models two wires transmitting bits at the data rate specified by the
source net device. There is no overhead beyond the eight bits per byte of the
packet sent. That is, we do not model Flag Sequences, Frame Check Sequences nor
do we “escape” any data.

The PointToPointChannel provides following Attributes:
\begin{itemize}
\item {} 
Delay:  An ns3::Time specifying the propagation delay for the channel.

\end{itemize}


\section{Using the PointToPointNetDevice}
\label{\detokenize{point-to-point:using-the-pointtopointnetdevice}}
The PointToPoint net devices and channels are typically created and configured
using the associated \sphinxcode{\sphinxupquote{PointToPointHelper}} object. The various ns3 device
helpers generally work in a similar way, and their use is seen in many of our
example programs and is also covered in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} tutorial.

The conceptual model of interest is that of a bare computer “husk” into which
you plug net devices. The bare computers are created using a \sphinxcode{\sphinxupquote{NodeContainer}}
helper. You just ask this helper to create as many computers (we call them
\sphinxcode{\sphinxupquote{Nodes}}) as you need on your network:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{nodes}\PYG{p}{;}
\PYG{n}{nodes}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once you have your nodes, you need to instantiate a \sphinxcode{\sphinxupquote{PointToPointHelper}} and
set any attributes you may want to change. Note that since this is a
point\sphinxhyphen{}to\sphinxhyphen{}point (as compared to a point\sphinxhyphen{}to\sphinxhyphen{}multipoint) there may only be two
nodes with associated net devices connected by a PointToPointChannel.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{PointToPointHelper} \PYG{n}{pointToPoint}\PYG{p}{;}
\PYG{n}{pointToPoint}\PYG{p}{.}\PYG{n}{SetDeviceAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataRate}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{pointToPoint}\PYG{p}{.}\PYG{n}{SetChannelAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Delay}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2ms}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once the attributes are set, all that remains is to create the devices and
install them on the required nodes, and to connect the devices together using a
PointToPoint channel. When we create the net devices, we add them to a container
to allow you to use them in the future. This all takes just one line of code.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NetDeviceContainer} \PYG{n}{devices} \PYG{o}{=} \PYG{n}{pointToPoint}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{nodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\section{PointToPoint Tracing}
\label{\detokenize{point-to-point:pointtopoint-tracing}}
Like all \sphinxstyleemphasis{ns\sphinxhyphen{}3} devices, the Point\sphinxhyphen{}to\sphinxhyphen{}Point Model provides a number of trace
sources. These trace sources can be hooked using your own custom trace code, or
you can use our helper functions to arrange for tracing to be enabled on devices
you specify.


\subsection{Upper\sphinxhyphen{}Level (MAC) Hooks}
\label{\detokenize{point-to-point:upper-level-mac-hooks}}
From the point of view of tracing in the net device, there are several
interesting points to insert trace hooks. A convention inherited from other
simulators is that packets destined for transmission onto attached networks pass
through a single “transmit queue” in the net device. We provide trace hooks at
this point in packet flow, which corresponds (abstractly) only to a transition
from the network to data link layer, and call them collectively
the device MAC hooks.

When a packet is sent to the Point\sphinxhyphen{}to\sphinxhyphen{}Point net device for transmission it
always passes through the transmit queue. The transmit queue in the
PointToPointNetDevice inherits from Queue, and therefore inherits three trace
sources:
\begin{itemize}
\item {} 
An Enqueue operation source (see ns3::Queue::m\_traceEnqueue);

\item {} 
A Dequeue operation source (see ns3::Queue::m\_traceDequeue);

\item {} 
A Drop operation source (see ns3::Queue::m\_traceDrop).

\end{itemize}

The upper\sphinxhyphen{}level (MAC) trace hooks for the PointToPointNetDevice are, in fact,
exactly these three trace sources on the single transmit queue of the device.

The m\_traceEnqueue event is triggered when a packet is placed on the transmit
queue. This happens at the time that ns3::PointtoPointNetDevice::Send or
ns3::PointToPointNetDevice::SendFrom is called by a higher layer to queue a
packet for transmission. An Enqueue trace event firing should be interpreted
as only indicating that a higher level protocol has sent a packet to the device.

The m\_traceDequeue event is triggered when a packet is removed from the transmit
queue. Dequeues from the transmit queue can happen in two situations:  1) If the
underlying channel is idle when PointToPointNetDevice::Send is called, a packet
is dequeued from the transmit queue and immediately transmitted;  2) a packet
may be dequeued and immediately transmitted in an internal TransmitCompleteEvent
that functions much  like a transmit complete interrupt service routine. An
Dequeue trace event firing may be viewed as indicating that the
PointToPointNetDevice has begun transmitting a packet.


\subsection{Lower\sphinxhyphen{}Level (PHY) Hooks}
\label{\detokenize{point-to-point:lower-level-phy-hooks}}
Similar to the upper level trace hooks, there are trace hooks available at the
lower levels of the net device. We call these the PHY hooks. These events fire
from the device methods that talk directly to the
PointToPointChannel.

The trace source m\_dropTrace is called to indicate a packet that is dropped by
the device. This happens when a packet is discarded as corrupt due to a receive
error model indication (see ns3::ErrorModel and the associated attribute
“ReceiveErrorModel”).

The other low\sphinxhyphen{}level trace source fires on reception of a packet (see
ns3::PointToPointNetDevice::m\_rxTrace) from the PointToPointChannel.


\chapter{Propagation}
\label{\detokenize{propagation:propagation}}\label{\detokenize{propagation:id1}}\label{\detokenize{propagation::doc}}
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} propagation module defines two generic interfaces, namely \sphinxcode{\sphinxupquote{PropagationLossModel}}
and \sphinxcode{\sphinxupquote{PropagationDelayModel}}, for the modeling of respectively propagation loss and propagation delay.


\section{PropagationLossModel}
\label{\detokenize{propagation:propagationlossmodel}}
Propagation loss models calculate the Rx signal power considering the Tx signal power and the
mutual Rx and Tx antennas positions.

A propagation loss model can be “chained” to another one, making a list. The final Rx power
takes into account all the chained models. In this way one can use a slow fading and a fast
fading model (for example), or model separately different fading effects.

The following propagation loss models are implemented:
\begin{itemize}
\item {} 
Cost231PropagationLossModel

\item {} 
FixedRssLossModel

\item {} 
FriisPropagationLossModel

\item {} 
ItuR1411LosPropagationLossModel

\item {} 
ItuR1411NlosOverRooftopPropagationLossModel

\item {} 
JakesPropagationLossModel

\item {} 
Kun2600MhzPropagationLossModel

\item {} 
LogDistancePropagationLossModel

\item {} 
MatrixPropagationLossModel

\item {} 
NakagamiPropagationLossModel

\item {} 
OkumuraHataPropagationLossModel

\item {} 
RandomPropagationLossModel

\item {} 
RangePropagationLossModel

\item {} 
ThreeLogDistancePropagationLossModel

\item {} 
TwoRayGroundPropagationLossModel

\item {} 
ThreeGppPropagationLossModel
\begin{itemize}
\item {} 
ThreeGppRMaPropagationLossModel

\item {} 
ThreeGppUMaPropagationLossModel

\item {} 
ThreeGppUmiStreetCanyonPropagationLossModel

\item {} 
ThreeGppIndoorOfficePropagationLossModel

\end{itemize}

\end{itemize}

Other models could be available thanks to other modules, e.g., the \sphinxcode{\sphinxupquote{building}} module.

Each of the available propagation loss models of ns\sphinxhyphen{}3 is explained in
one of the following subsections.


\subsection{FriisPropagationLossModel}
\label{\detokenize{propagation:friispropagationlossmodel}}
This model implements the Friis propagation loss model. This model was first described in \sphinxcite{propagation:friis}.
The original equation was described as:
\begin{equation*}
\begin{split}\frac{P_r}{P_t} = \frac{A_r A_t}{d^2\lambda^2}\end{split}
\end{equation*}
with the following equation for the case of an isotropic antenna with no heat loss:
\begin{equation*}
\begin{split}A_{isotr.} = \frac{\lambda^2}{4\pi}\end{split}
\end{equation*}
The final equation becomes:
\begin{equation*}
\begin{split}\frac{P_r}{P_t} = \frac{\lambda^2}{(4 \pi d)^2}\end{split}
\end{equation*}
Modern extensions to this original equation are:
\begin{equation*}
\begin{split}P_r = \frac{P_t G_t G_r \lambda^2}{(4 \pi d)^2 L}\end{split}
\end{equation*}
With:
\begin{quote}

\(P_t\) : transmission power (W)

\(P_r\) : reception power (W)

\(G_t\) : transmission gain (unit\sphinxhyphen{}less)

\(G_r\) : reception gain (unit\sphinxhyphen{}less)

\(\lambda\) : wavelength (m)

\(d\) : distance (m)

\(L\) : system loss (unit\sphinxhyphen{}less)
\end{quote}

In the implementation, \(\lambda\) is calculated as
\(\frac{C}{f}\), where \(C = 299792458\) m/s is the speed of light in
vacuum, and \(f\) is the frequency in Hz which can be configured by
the user via the Frequency attribute.

The Friis model is valid only for propagation in free space within
the so\sphinxhyphen{}called far field region, which can be considered
approximately as the region for \(d > 3 \lambda\).
The model will still return a value for \(d < 3 \lambda\), as
doing so (rather than triggering a fatal error) is practical for
many simulation scenarios. However, we stress that the values
obtained in such conditions shall not be considered realistic.

Related with this issue, we note that the Friis formula is
undefined for \(d = 0\), and results in
\(P_r > P_t\) for \(d < \lambda / 2 \sqrt{\pi}\).

Both these conditions occur outside of the far field region, so in
principle the Friis model shall not be used in these conditions.
In practice, however, Friis is often used in scenarios where accurate
propagation modeling is not deemed important, and values of
\(d = 0\) can occur.

To allow practical use of the model in such
scenarios, we have to 1) return some value for \(d = 0\), and
2) avoid large discontinuities in propagation loss values (which
could lead to artifacts such as bogus capture effects which are
much worse than inaccurate propagation loss values). The two issues
are conflicting, as, according to the Friis formula,
\(\lim_{d \to 0}  P_r = +\infty\);
so if, for \(d = 0\), we use a fixed loss value, we end up with an infinitely large
discontinuity, which as we discussed can cause undesirable
simulation artifacts.

To avoid these artifact, this implementation of the Friis model
provides an attribute called MinLoss which allows to specify the
minimum total loss (in dB) returned by the model. This is used in
such a way that
\(P_r\) continuously increases for \(d \to 0\), until
MinLoss is reached, and then stay constant; this allow to
return a value for \(d = 0\) and at the same time avoid
discontinuities. The model won’t be much realistic, but at least
the simulation artifacts discussed before are avoided. The default value of
MinLoss is 0 dB, which means that by default the model will return
\(P_r = P_t\) for \(d <= \lambda / 2 \sqrt{\pi}\).
We note that this value of \(d\) is outside of the far field
region, hence the validity of the model in the far field region is
not affected.


\subsection{TwoRayGroundPropagationLossModel}
\label{\detokenize{propagation:tworaygroundpropagationlossmodel}}
This model implements a Two\sphinxhyphen{}Ray Ground propagation loss model ported from NS2

The Two\sphinxhyphen{}ray ground reflection model uses the formula
\begin{equation*}
\begin{split}P_r = \frac{P_t * G_t * G_r * (H_t^2 * H_r^2)}{d^4 * L}\end{split}
\end{equation*}
The original equation in Rappaport’s book assumes \(L = 1\).
To be consistent with the free space equation, \(L\) is added here.

\(H_t\) and \(H_r\) are set at the respective nodes \(z\) coordinate plus a model parameter
set via SetHeightAboveZ.

The two\sphinxhyphen{}ray model does not give a good result for short distances, due to the
oscillation caused by constructive and destructive combination of the two
rays. Instead the Friis free\sphinxhyphen{}space model is used for small distances.

The crossover distance, below which Friis is used, is calculated as follows:
\begin{equation*}
\begin{split}dCross = \frac{(4 * \pi * H_t * H_r)}{\lambda}\end{split}
\end{equation*}
In the implementation,  \(\lambda\) is calculated as
\(\frac{C}{f}\), where \(C = 299792458\) m/s is the speed of light in
vacuum, and \(f\) is the frequency in Hz which can be configured by
the user via the Frequency attribute.


\subsection{LogDistancePropagationLossModel}
\label{\detokenize{propagation:logdistancepropagationlossmodel}}
This model implements a log distance propagation model.

The reception power is calculated with a so\sphinxhyphen{}called
log\sphinxhyphen{}distance propagation model:
\begin{equation*}
\begin{split}L = L_0 + 10 n \log(\frac{d}{d_0})\end{split}
\end{equation*}
where:
\begin{quote}

\(n\) : the path loss distance exponent

\(d_0\) : reference distance (m)

\(L_0\) : path loss at reference distance (dB)

\(d\) :  \sphinxhyphen{} distance (m)

\(L\) : path loss (dB)
\end{quote}

When the path loss is requested at a distance smaller than
the reference distance, the tx power is returned.


\subsection{ThreeLogDistancePropagationLossModel}
\label{\detokenize{propagation:threelogdistancepropagationlossmodel}}
This model implements a log distance path loss propagation model with three distance
fields. This model is the same as ns3::LogDistancePropagationLossModel
except that it has three distance fields: near, middle and far with
different exponents.

Within each field the reception power is calculated using the log\sphinxhyphen{}distance
propagation equation:
\begin{equation*}
\begin{split}L = L_0 + 10 \cdot n_0 \log_{10}(\frac{d}{d_0})\end{split}
\end{equation*}
Each field begins where the previous ends and all together form a continuous function.

There are three valid distance fields: near, middle, far. Actually four: the
first from 0 to the reference distance is invalid and returns txPowerDbm.
\begin{equation*}
\begin{split}\underbrace{0 \cdots\cdots}_{=0} \underbrace{d_0 \cdots\cdots}_{n_0} \underbrace{d_1 \cdots\cdots}_{n_1} \underbrace{d_2 \cdots\cdots}_{n_2} \infty\end{split}
\end{equation*}
Complete formula for the path loss in dB:
\begin{equation*}
\begin{split}\displaystyle L =
\begin{cases}
0 & d < d_0 \\
L_0 + 10 \cdot n_0 \log_{10}(\frac{d}{d_0}) & d_0 \leq d < d_1 \\
L_0 + 10 \cdot n_0 \log_{10}(\frac{d_1}{d_0}) + 10 \cdot n_1 \log_{10}(\frac{d}{d_1}) & d_1 \leq d < d_2 \\
L_0 + 10 \cdot n_0 \log_{10}(\frac{d_1}{d_0}) + 10 \cdot n_1 \log_{10}(\frac{d_2}{d_1}) + 10 \cdot n_2 \log_{10}(\frac{d}{d_2})& d_2 \leq d
\end{cases}\end{split}
\end{equation*}
where:
\begin{quote}

\(d_0, d_1, d_2\) : three distance fields (m)

\(n_0, n_1, n_2\) : path loss distance exponent for each field (unitless)

\(L_0\) : path loss at reference distance (dB)

\(d\) :  \sphinxhyphen{} distance (m)

\(L\) : path loss (dB)
\end{quote}

When the path loss is requested at a distance smaller than the reference
distance \(d_0\), the tx power (with no path loss) is returned. The
reference distance defaults to 1m and reference loss defaults to
\sphinxcode{\sphinxupquote{FriisPropagationLossModel}} with 5.15 GHz and is thus \(L_0\) = 46.67 dB.


\subsection{JakesPropagationLossModel}
\label{\detokenize{propagation:jakespropagationlossmodel}}

\subsubsection{ToDo}
\label{\detokenize{propagation:todo}}

\subsection{RandomPropagationLossModel}
\label{\detokenize{propagation:randompropagationlossmodel}}
The propagation loss is totally random, and it changes each time the model is called.
As a consequence, all the packets (even those between two fixed nodes) experience a random
propagation loss.


\subsection{NakagamiPropagationLossModel}
\label{\detokenize{propagation:nakagamipropagationlossmodel}}
This propagation loss model implements the Nakagami\sphinxhyphen{}m fast fading
model, which accounts for the variations in signal strength due to multipath
fading. The model does not account for the path loss due to the
distance traveled by the signal, hence for typical simulation usage it
is recommended to consider using it in combination with other models
that take into account this aspect.

The Nakagami\sphinxhyphen{}m distribution is applied to the power level. The probability density function is defined as
\begin{equation*}
\begin{split}p(x; m, \omega) = \frac{2 m^m}{\Gamma(m) \omega^m} x^{2m - 1} e^{-\frac{m}{\omega} x^2} )\end{split}
\end{equation*}
with \(m\) the fading depth parameter and \(\omega\) the average received power.

It is implemented by either a \sphinxcode{\sphinxupquote{GammaRandomVariable}} or a \sphinxcode{\sphinxupquote{ErlangRandomVariable}}
random variable.

The implementation of the model allows to specify different values of
the \(m\) parameter (and hence different fast fading profiles)
for three different distance ranges:
\begin{equation*}
\begin{split}\underbrace{0 \cdots\cdots}_{m_0} \underbrace{d_1 \cdots\cdots}_{m_1} \underbrace{d_2 \cdots\cdots}_{m_2} \infty\end{split}
\end{equation*}
For \(m = 1\) the Nakagami\sphinxhyphen{}m distribution equals the Rayleigh distribution. Thus
this model also implements Rayleigh distribution based fast fading.


\subsection{FixedRssLossModel}
\label{\detokenize{propagation:fixedrsslossmodel}}
This model sets a constant received power level independent of the transmit power.

The received power is constant independent of the transmit power; the user
must set received power level.  Note that if this loss model is chained to other loss
models, it should be the first loss model in the chain.
Else it will disregard the losses computed by loss models that precede it in the chain.


\subsection{MatrixPropagationLossModel}
\label{\detokenize{propagation:matrixpropagationlossmodel}}
The propagation loss is fixed for each pair of nodes and doesn’t depend on their actual positions.
This model should be useful for synthetic tests. Note that by default the propagation loss is
assumed to be symmetric.


\subsection{RangePropagationLossModel}
\label{\detokenize{propagation:rangepropagationlossmodel}}
This propagation loss depends only on the distance (range) between transmitter and receiver.

The single MaxRange attribute (units of meters) determines path loss.
Receivers at or within MaxRange meters receive the transmission at the
transmit power level. Receivers beyond MaxRange receive at power
\sphinxhyphen{}1000 dBm (effectively zero).


\subsection{OkumuraHataPropagationLossModel}
\label{\detokenize{propagation:okumurahatapropagationlossmodel}}
This model is used to model open area pathloss for long distance (i.e., \textgreater{} 1 Km).
In order to include all the possible frequencies usable by LTE we need to consider
several variants of the well known Okumura Hata model. In fact, the original Okumura
Hata model \sphinxcite{propagation:hata} is designed for frequencies ranging from 150 MHz to 1500 MHz,
the COST231 \sphinxcite{propagation:cost231} extends it for the frequency range from 1500 MHz to 2000 MHz.
Another important aspect is the scenarios considered by the models, in fact the all
models are originally designed for urban scenario and then only the standard one and
the COST231 are extended to suburban, while only the standard one has been extended
to open areas. Therefore, the model cannot cover all scenarios at all frequencies.
In the following we detail the models adopted.

The pathloss expression of the COST231 OH is:
\begin{equation*}
\begin{split}L = 46.3 + 33.9\log{f} - 13.82 \log{h_\mathrm{b}} + (44.9 - 6.55\log{h_\mathrm{b}})\log{d} - F(h_\mathrm{M}) + C\end{split}
\end{equation*}
where
\begin{equation*}
\begin{split}F(h_\mathrm{M}) = \left\{\begin{array}{ll} (1.1\log(f))-0.7 \times h_\mathrm{M} - (1.56\times \log(f)-0.8) & \mbox{for medium and small size cities} \\ 3.2\times (\log{(11.75\times h_\mathrm{M}}))^2 & \mbox{for large cities}\end{array} \right.\end{split}
\end{equation*}\begin{equation*}
\begin{split}C = \left\{\begin{array}{ll} 0dB & \mbox{for medium-size cities and suburban areas} \\ 3dB & \mbox{for large cities}\end{array} \right.\end{split}
\end{equation*}
and
\begin{quote}

\(f\) : frequency {[}MHz{]}

\(h_\mathrm{b}\) : eNB height above the ground {[}m{]}

\(h_\mathrm{M}\) : UE height above the ground {[}m{]}

\(d\) : distance {[}km{]}

\(log\) : is a logarithm in base 10 (this for the whole document)
\end{quote}

This model is only for urban scenarios.

The pathloss expression of the standard OH in urban area is:
\begin{equation*}
\begin{split}L = 69.55 + 26.16\log{f} - 13.82 \log{h_\mathrm{b}} + (44.9 - 6.55\log{h_\mathrm{b}})\log{d} - C_\mathrm{H}\end{split}
\end{equation*}
where for small or medium sized city
\begin{equation*}
\begin{split}C_\mathrm{H} = 0.8 + (1.1\log{f} - 0.7)h_\mathrm{M} -1.56\log{f}\end{split}
\end{equation*}
and for large cities
\begin{equation*}
\begin{split}C_\mathrm{H} = \left\{\begin{array}{ll} 8.29 (\log{(1.54h_M)})^2 -1.1 & \mbox{if } 150\leq f\leq 200 \\ 3.2(\log{(11.75h_M)})^2 -4.97 & \mbox{if } 200<f\leq 1500\end{array} \right.\end{split}
\end{equation*}
There extension for the standard OH in suburban is
\begin{equation*}
\begin{split}L_\mathrm{SU} = L_\mathrm{U} - 2 \left(\log{\frac{f}{28}}\right)^2 - 5.4\end{split}
\end{equation*}
where
\begin{quote}

\(L_\mathrm{U}\) : pathloss in urban areas
\end{quote}

The extension for the standard OH in open area is
\begin{equation*}
\begin{split}L_\mathrm{O} = L_\mathrm{U} - 4.70 (\log{f})^2 + 18.33\log{f} - 40.94\end{split}
\end{equation*}
The literature lacks of extensions of the COST231 to open area (for suburban it seems that
we can just impose C = 0); therefore we consider it a special case fo the suburban one.


\subsection{Cost231PropagationLossModel}
\label{\detokenize{propagation:cost231propagationlossmodel}}

\subsubsection{ToDo}
\label{\detokenize{propagation:id5}}

\subsection{ItuR1411LosPropagationLossModel}
\label{\detokenize{propagation:itur1411lospropagationlossmodel}}
This model is designed for Line\sphinxhyphen{}of\sphinxhyphen{}Sight (LoS) short range outdoor communication in the
frequency range 300 MHz to 100 GHz.  This model provides an upper and lower bound
respectively according to the following formulas
\begin{equation*}
\begin{split}L_\mathrm{LoS,l} = L_\mathrm{bp} + \left\{\begin{array}{ll} 20\log{\frac{d}{R_\mathrm{bp}}} & \mbox{for $d \le R_\mathrm{bp}$} \\ 40\log{\frac{d}{R_\mathrm{bp}}} & \mbox{for $d > R_\mathrm{bp}$}\end{array} \right.\end{split}
\end{equation*}\begin{equation*}
\begin{split}L_\mathrm{LoS,u} = L_\mathrm{bp} + 20 + \left\{\begin{array}{ll} 25\log{\frac{d}{R_\mathrm{bp}}} & \mbox{for $d \le R_\mathrm{bp}$} \\ 40\log{\frac{d}{R_\mathrm{bp}}} & \mbox{for $d > R_\mathrm{bp}$}\end{array} \right.\end{split}
\end{equation*}
where the breakpoint distance is given by
\begin{equation*}
\begin{split}R_\mathrm{bp} \approx \frac{4h_\mathrm{b}h_\mathrm{m}}{\lambda}\end{split}
\end{equation*}
and the above parameters are
\begin{quote}

\(\lambda\) : wavelength {[}m{]}

\(h_\mathrm{b}\) : eNB height above the ground {[}m{]}

\(h_\mathrm{m}\) : UE height above the ground {[}m{]}

\(d\) : distance {[}m{]}
\end{quote}

and \(L_{bp}\) is the value for the basic transmission loss at the break point, defined as:
\begin{equation*}
\begin{split}L_{bp} = \left|20\log \left(\frac{\lambda^2}{8\pi h_\mathrm{b}h\mathrm{m}}\right)\right|\end{split}
\end{equation*}
The value used by the simulator is the average one for modeling the median pathloss.


\subsection{ItuR1411NlosOverRooftopPropagationLossModel}
\label{\detokenize{propagation:itur1411nlosoverrooftoppropagationlossmodel}}
This model is designed for Non\sphinxhyphen{}Line\sphinxhyphen{}of\sphinxhyphen{}Sight (LoS) short range outdoor communication over
rooftops in the frequency range 300 MHz to 100 GHz. This model includes several scenario\sphinxhyphen{}dependent
parameters, such as average street width, orientation, etc. It is advised to set the values of
these parameters manually (using the ns\sphinxhyphen{}3 attribute system) according to the desired scenario.

In detail, the model is based on \sphinxcite{propagation:walfisch} and \sphinxcite{propagation:ikegami}, where the loss is expressed
as the sum of free\sphinxhyphen{}space loss (\(L_{bf}\)), the diffraction loss from rooftop to
street (\(L_{rts}\)) and the reduction due to multiple screen diffraction past
rows of building (\(L_{msd}\)). The formula is:
\begin{equation*}
\begin{split}L_{NLOS1} = \left\{ \begin{array}{ll} L_{bf} + L_{rts} + L_{msd} & \mbox{for } L_{rts} + L_{msd} > 0 \\ L_{bf} & \mbox{for } L_{rts} + L_{msd} \le 0\end{array}\right.\end{split}
\end{equation*}
The free\sphinxhyphen{}space loss is given by:
\begin{equation*}
\begin{split}L_{bf} = 32.4 + 20 \log {(d/1000)} + 20\log{(f)}\end{split}
\end{equation*}
where:
\begin{quote}

\(f\) : frequency {[}MHz{]}

\(d\) : distance (where \(d > 1\)) {[}m{]}
\end{quote}

The term \(L_{rts}\) takes into account the width of the street and its orientation, according to the formulas
\begin{align*}\!\begin{aligned}
L_{rts} = -8.2 - 10\log {(w)} + 10\log{(f)} + 20\log{(\Delta h_m)} + L_{ori}\\
L_{ori} = \left\{ \begin{array}{lll} -10 + 0.354\varphi & \mbox{for } 0^{\circ} \le \varphi < 35^{\circ} \\ 2.5 + 0.075(\varphi-35) & \mbox{for } 35^{\circ} \le \varphi < 55^{\circ} \\ 4.0 -0.114(\varphi-55) & \mbox{for } 55^{\circ} \varphi \le 90^{\circ}\end{array}\right.\\
\Delta h_m = h_r - h_m\\
\end{aligned}\end{align*}
where:
\begin{quote}

\(h_r\) : is the height of the rooftop {[}m{]}

\(h_m\) : is the height of the mobile {[}m{]}

\(\varphi\) : is the street orientation with respect to the direct path (degrees)
\end{quote}

The multiple screen diffraction loss depends on the BS antenna height relative to the building
height and on the incidence angle. The former is selected as the higher antenna in the communication
link. Regarding the latter, the “settled field distance” is used for select the proper model;
its value is given by
\begin{equation*}
\begin{split}d_{s} = \frac{\lambda d^2}{\Delta h_{b}^2}\end{split}
\end{equation*}
with
\begin{quote}

\(\Delta h_b = h_b - h_m\)
\end{quote}

Therefore, in case of \(l > d_s\) (where \sphinxtitleref{l} is the distance over which the building extend),
it can be evaluated according to
\begin{align*}\!\begin{aligned}
L_{msd} = L_{bsh} + k_{a} + k_{d}\log{(d/1000)} + k_{f}\log{(f)} - 9\log{(b)}\\
L_{bsh} = \left\{ \begin{array}{ll} -18\log{(1+\Delta h_{b})} & \mbox{for } h_{b} > h_{r} \\ 0 & \mbox{for } h_{b} \le h_{hr} \end{array}\right.\\
k_a = \left\{ \begin{array}{lll}
    71.4 & \mbox{for } h_{b} > h_{r} \mbox{ and } f>2000 \mbox{ MHz} \\
    54 & \mbox{for } h_{b} > h_{r} \mbox{ and } f\le2000 \mbox{ MHz} \\
    54-0.8\Delta h_b & \mbox{for } h_{b} \le h_{r} \mbox{ and } d \ge 500 \mbox{ m} \\
    54-1.6\Delta h_b & \mbox{for } h_{b} \le h_{r} \mbox{ and } d < 500 \mbox{ m} \\
    \end{array} \right.\\
k_d = \left\{ \begin{array}{ll}
      18 & \mbox{for } h_{b} > h_{r} \\
      18 -15\frac{\Delta h_b}{h_r} & \mbox{for } h_{b} \le h_{r}
      \end{array} \right.\\
k_f = \left\{ \begin{array}{ll}
      -8 & \mbox{for } f>2000 \mbox{ MHz} \\
      -4 + 0.7(f/925 -1) & \mbox{for medium city and suburban centres and} f\le2000 \mbox{ MHz} \\
      -4 + 1.5(f/925 -1) & \mbox{for metropolitan centres and } f\le2000 \mbox{ MHz}
      \end{array}\right.\\
\end{aligned}\end{align*}
Alternatively, in case of \(l < d_s\), the formula is:
\begin{equation*}
\begin{split}L_{msd} = -10\log{\left(Q_M^2\right)}\end{split}
\end{equation*}
where
\begin{equation*}
\begin{split}Q_M = \left\{ \begin{array}{lll}
      2.35\left(\frac{\Delta h_b}{d}\sqrt{\frac{b}{\lambda}}\right)^{0.9} & \mbox{for } h_{b} > h_{r} \\
      \frac{b}{d} &  \mbox{for } h_{b} \approx h_{r} \\
      \frac{b}{2\pi d}\sqrt{\frac{\lambda}{\rho}}\left(\frac{1}{\theta}-\frac{1}{2\pi + \theta}\right) & \mbox{for }  h_{b} < h_{r}
      \end{array}\right.\end{split}
\end{equation*}
where:
\begin{align*}\!\begin{aligned}
\theta = arc tan \left(\frac{\Delta h_b}{b}\right)\\
\rho = \sqrt{\Delta h_b^2 + b^2}\\
\end{aligned}\end{align*}

\subsection{Kun2600MhzPropagationLossModel}
\label{\detokenize{propagation:kun2600mhzpropagationlossmodel}}
This is the empirical model for the pathloss at 2600 MHz for urban areas which is described in \sphinxcite{propagation:kun2600mhz}.
The model is as follows. Let \(d\) be the distance between the transmitter and the receiver
in meters; the pathloss \(L\) in dB is calculated as:
\begin{equation*}
\begin{split}L = 36 + 26\log{d}\end{split}
\end{equation*}

\subsection{ThreeGppPropagationLossModel}
\label{\detokenize{propagation:threegpppropagationlossmodel}}
The base class \sphinxcode{\sphinxupquote{ThreeGppPropagationLossModel}} and its derived classes implement
the path loss and shadow fading models described in 3GPP TR 38.901 %
\begin{footnote}[38901]\sphinxAtStartFootnote
3GPP. 2018. TR 38.901, Study on channel model for frequencies from 0.5 to 100 GHz, V15.0.0. (2018\sphinxhyphen{}06).
%
\end{footnote}.
3GPP TR 38.901 includes multiple scenarios modeling different propagation
environments, i.e., indoor, outdoor urban and rural, for frequencies between
0.5 and 100 GHz.

\sphinxstyleemphasis{Implemented features:}
\begin{itemize}
\item {} 
Path loss and shadowing models (3GPP TR 38.901, Sec. 7.4.1)

\item {} 
Autocorrelation of shadow fading (3GPP TR 38.901, Sec. 7.4.4)

\item {} 
\sphinxhref{propagation.html\#threegppchannelconditionmodel}{Channel condition models} (3GPP TR 38.901, Sec. 7.4.2)

\end{itemize}

\sphinxstyleemphasis{To be implemented:}
\begin{itemize}
\item {} 
O2I penetration loss (3GPP TR 38.901, Sec. 7.4.3)

\item {} 
Spatial consistent update of the channel states (3GPP TR 38.901 Sec. 7.6.3.3)

\end{itemize}

\sphinxstylestrong{Configuration}

The \sphinxcode{\sphinxupquote{ThreeGppPropagationLossModel}} instance is paired with a \sphinxcode{\sphinxupquote{ChannelConditionModel}}
instance used to retrieve the LOS/NLOS channel condition. By default, a 3GPP
channel condition model related to the same scenario is set (e.g., by default,
\sphinxcode{\sphinxupquote{ThreeGppRmaPropagationLossModel}} is paired with
\sphinxcode{\sphinxupquote{ThreeGppRmaChannelConditionModel}}), but it can be configured using
the method SetChannelConditionModel. The channel condition models are stored inside the
propagation module, for a limitation of the current spectrum API and to avoid
a circular dependency between the spectrum and the propagation modules. Please
note that it is necessary to install at least one \sphinxcode{\sphinxupquote{ChannelConditionModel}} when
using any \sphinxcode{\sphinxupquote{ThreeGppPropagationLossModel}} subclass. Please look below for more
information about the Channel Condition models.

The operating frequency has to be set using the attribute “Frequency”,
otherwise an assert is raised. The addition of the shadow fading component can
be enabled/disabled through the attribute “ShadowingEnabled”.
Other scenario\sphinxhyphen{}related parameters can be configured through attributes of the
derived classes.

\sphinxstylestrong{Implementation details}

The method DoCalcRxPower computes the propagation loss considering the path loss
and the shadow fading (if enabled). The path loss is computed by the method
GetLossLos or GetLossNlos depending on the LOS/NLOS channel condition, and their
implementation is left to the derived classes. The shadow fading is computed by
the method GetShadowing, which generates an additional random loss component
characterized by Gaussian distribution with zero mean and scenario\sphinxhyphen{}specific
standard deviation. Subsequent shadowing components of each BS\sphinxhyphen{}UT link are
correlated as described in 3GPP TR 38.901, Sec. 7.4.4 \sphinxfootnotemark[38901].

\sphinxstyleemphasis{Note 1}: The TR defines height ranges for UTs and BSs, depending on the chosen
propagation model (for the exact values, please see below in the specific model
documentation). If the user does not set correct values, the model will emit
a warning but perform the calculation anyway.

\sphinxstyleemphasis{Note 2}: The 3GPP model is originally intended to be used to represent BS\sphinxhyphen{}UT
links. However, in ns\sphinxhyphen{}3, we may need to compute the pathloss between two BSs
or UTs to evaluate the interference. We have decided to support this case by
considering the tallest node as a BS and the smallest as a UT. As a consequence,
the height values may be outside the validity range of the chosen class:
therefore, an inaccuracy warning may be printed, but it can be ignored.

There are four derived class, each one implementing the propagation model for a different scenario:


\subsubsection{ThreeGppRMaPropagationLossModel}
\label{\detokenize{propagation:threegpprmapropagationlossmodel}}
This class implements the LOS/NLOS path loss and shadow fading models described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.1\sphinxhyphen{}1 for the RMa scenario.
It supports frequencies between 0.5 and 30 GHz.
It is possible to configure some scenario\sphinxhyphen{}related parameters through the attributes AvgBuildingHeight and AvgStreetWidth.

As specified in the TR, the 2D distance between the transmitter and the receiver
should be between 10 m and 10 km for the LOS case, or between 10 m and 5 km for
the NLOS case, otherwise the model may not be accurate (a warning message is
printed if the user has enabled logging on the model). Also, the height of the
base station (hBS) should be between 10 m and 150 m, while the height of the
user terminal (hUT) should be between 1 m and 10 m.


\subsubsection{ThreeGppUMaPropagationLossModel}
\label{\detokenize{propagation:threegppumapropagationlossmodel}}
This implements the LOS/NLOS path loss and shadow fading models described in 3GPP
TR 38.901 \sphinxfootnotemark[38901], Table 7.4.1\sphinxhyphen{}1 for the UMa scenario. It supports frequencies
between 0.5 and 100 GHz.

As specified in the TR, the 2D distance between the transmitter and the receiver
should be between 10 m and 5 km both for the LOS and NLOS cases, otherwise the model may not be
accurate (a warning message is printed if the user has enabled logging on the model).
Also, the height of the base station (hBS) should be 25 m and the height of the
user terminal (hUT) should be between 1.5 m and 22.5 m.


\subsubsection{ThreeGppUmiStreetCanyonPropagationLossModel}
\label{\detokenize{propagation:threegppumistreetcanyonpropagationlossmodel}}
This implements the LOS/NLOS path loss and shadow fading models described in 3GPP
TR 38.901 \sphinxfootnotemark[38901], Table 7.4.1\sphinxhyphen{}1 for the UMi\sphinxhyphen{}Street Canyon scenario. It
supports frequencies between 0.5 and 100 GHz.

As specified in the TR, the 2D distance between the transmitter and the receiver
should be between 10 m and 5 km both for the LOS and NLOS cases, otherwise the model may not be
accurate (a warning message is printed if the user has enabled logging on
the model). Also, the height of the base station (hBS) should be 10 m and the
height of the user terminal (hUT) should be between 1.5 m and 10 m (the validity
range is reduced because we assume that the height of the UT nodes is always
lower that the height of the BS nodes).


\subsubsection{ThreeGppIndoorOfficePropagationLossModel}
\label{\detokenize{propagation:threegppindoorofficepropagationlossmodel}}
This implements the LOS/NLOS path loss and shadow fading models described in 3GPP
TR 38.901 \sphinxfootnotemark[38901], Table 7.4.1\sphinxhyphen{}1 for the Indoor\sphinxhyphen{}Office scenario. It supports
frequencies between 0.5 and 100 GHz.

As specified in the TR, the 3D distance between the transmitter and the receiver
should be between 1 m and 150 m both for the LOS and NLOS cases, otherwise the
model may not be accurate (a warning log message is printed if the user has
enabled logging on the model).


\subsubsection{Testing}
\label{\detokenize{propagation:testing}}
The test suite \sphinxcode{\sphinxupquote{ThreeGppPropagationLossModelsTestSuite}} provides test cases for the classes
implementing the 3GPP propagation loss models.
The test cases \sphinxcode{\sphinxupquote{ThreeGppRmaPropagationLossModelTestCase}},
\sphinxcode{\sphinxupquote{ThreeGppUmaPropagationLossModelTestCase}},
\sphinxcode{\sphinxupquote{ThreeGppUmiPropagationLossModelTestCase}} and
\sphinxcode{\sphinxupquote{ThreeGppIndoorOfficePropagationLossModelTestCas\textasciigrave{}e compute the path loss between two nodes and compares it with the value obtained using the formulas in 3GPP TR 38.901 {[}38901{]}\_, Table 7.4.1\sphinxhyphen{}1.
The test case :cpp:class:\textasciigrave{}ThreeGppShadowingTestCase}} checks if the shadowing is correctly computed by testing the deviation of the overall propagation loss from the path loss. The test is carried out for all the scenarios, both in LOS and NLOS condition.


\section{ChannelConditionModel}
\label{\detokenize{propagation:channelconditionmodel}}
The loss models require to know if two nodes are in Line\sphinxhyphen{}of\sphinxhyphen{}Sight (LoS) or if
they are not. The interface for that is represented by this class. The main
method is GetChannelCondition (a, b), which returns a \sphinxcode{\sphinxupquote{ChannelCondition}} object
containing the information about the channel state.

We modeled the LoS condition in two ways: (i) by using a probabilistic model
specified by the 3GPP (), and (ii) by using an ns\sphinxhyphen{}3 specific
building\sphinxhyphen{}aware model, which checks the space position of the BSs and the UTs.
For what regards the first option, the probability is independent of the node
location: in other words, following the 3GPP model, two UT spatially separated
by an epsilon may have different LoS conditions. To take into account mobility,
we have inserted a parameter called “UpdatePeriod,” which indicates how often a
3GPP\sphinxhyphen{}based channel condition has to be updated. By default, this attribute is
set to 0, meaning that after the channel condition is generated, it is never
updated. With this default value, we encourage the users to run multiple
simulations with different seeds to get statistical significance from the data.
For the users interested in using mobile nodes, we suggest changing this
parameter to a value that takes into account the node speed and the desired
accuracy. For example, lower\sphinxhyphen{}speed node conditions may be updated in terms of
seconds, while high\sphinxhyphen{}speed UT or BS may be updated more often.

The two approach are coded, respectively, in the classes:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ThreeGppChannelConditionModel}}

\item {} 
\sphinxcode{\sphinxupquote{BuildingsChannelConditionModel}} (see the \sphinxcode{\sphinxupquote{building}} module documentation for further details)

\end{itemize}


\subsection{ThreeGppChannelConditionModel}
\label{\detokenize{propagation:threegppchannelconditionmodel}}
This is the base class for the 3GPP channel condition models.
It provides the possibility to updated the condition of each channel periodically,
after a given time period which can be configured through the attribute “UpdatePeriod”.
If “UpdatePeriod” is set to 0, the channel condition is never updated.
It has five derived classes implementing the channel condition models described in 3GPP TR 38.901 \sphinxfootnotemark[38901] for different propagation scenarios.


\subsubsection{ThreeGppRmaChannelConditionModel}
\label{\detokenize{propagation:threegpprmachannelconditionmodel}}
This implements the statistical channel condition model described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1, for the RMa scenario.


\subsubsection{ThreeGppUmaChannelConditionModel}
\label{\detokenize{propagation:threegppumachannelconditionmodel}}
This implements the statistical channel condition model described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1, for the UMa scenario.


\subsubsection{ThreeGppUmiStreetCanyonChannelConditionModel}
\label{\detokenize{propagation:threegppumistreetcanyonchannelconditionmodel}}
This implements the statistical channel condition model described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1, for the UMi\sphinxhyphen{}Street Canyon scenario.


\subsubsection{ThreeGppIndoorMixedOfficeChannelConditionModel}
\label{\detokenize{propagation:threegppindoormixedofficechannelconditionmodel}}
This implements the statistical channel condition model described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1, for the Indoor\sphinxhyphen{}Mixed office scenario.


\subsubsection{ThreeGppIndoorOpenOfficeChannelConditionModel}
\label{\detokenize{propagation:threegppindooropenofficechannelconditionmodel}}
This implements the statistical channel condition model described in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1, for the Indoor\sphinxhyphen{}Open office scenario.


\subsection{Testing}
\label{\detokenize{propagation:id21}}
The test suite \sphinxcode{\sphinxupquote{ChannelConditionModelsTestSuite}} contains a single test case:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ThreeGppChannelConditionModelTestCase}}, which tests all the 3GPP channel condition models. It determines the channel condition between two nodes multiple times, estimates the LOS probability, and compares it with the value given by the formulas in 3GPP TR 38.901 \sphinxfootnotemark[38901], Table 7.4.2\sphinxhyphen{}1

\end{itemize}


\section{PropagationDelayModel}
\label{\detokenize{propagation:propagationdelaymodel}}
The following propagation delay models are implemented:
\begin{itemize}
\item {} 
ConstantSpeedPropagationDelayModel

\item {} 
RandomPropagationDelayModel

\end{itemize}


\subsection{ConstantSpeedPropagationDelayModel}
\label{\detokenize{propagation:constantspeedpropagationdelaymodel}}
In this model, the signal travels with constant speed.
The delay is calculated according with the transmitter and receiver positions.
The Euclidean distance between the Tx and Rx antennas is used.
Beware that, according to this model, the Earth is flat.


\subsection{RandomPropagationDelayModel}
\label{\detokenize{propagation:randompropagationdelaymodel}}
The propagation delay is totally random, and it changes each time the model is called.
All the packets (even those between two fixed nodes) experience a random delay.
As a consequence, the packets order is not preserved.


\section{References}
\label{\detokenize{propagation:references}}

\chapter{Spectrum Module}
\label{\detokenize{spectrum:spectrum-module}}\label{\detokenize{spectrum:sec-spectrum-module}}\label{\detokenize{spectrum::doc}}
The Spectrum module aims at providing support for modeling the frequency\sphinxhyphen{}dependent
aspects of communications in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.
The model was first introduced in
\sphinxcite{spectrum:baldo2009spectrum}, and has been enhanced and refined over the years.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{spectrum-analyzer-example}.pdf}
\caption{Spectrogram produced by a spectrum analyzer in a scenario
involving wifi signals interfered by a microwave oven, as simulated
by the example \sphinxcode{\sphinxupquote{adhoc\sphinxhyphen{}aloha\sphinxhyphen{}ideal\sphinxhyphen{}phy\sphinxhyphen{}with\sphinxhyphen{}microwave\sphinxhyphen{}oven}}.}\label{\detokenize{spectrum:id21}}\label{\detokenize{spectrum:fig-spectrum-analyzer-example}}\end{figure}


\section{Model Description}
\label{\detokenize{spectrum:model-description}}
The module provides:
\begin{itemize}
\item {} 
a set of classes for modeling signals and

\item {} 
a Channel/PHY interface based on a power spectral density
signal representation that is technology\sphinxhyphen{}independent

\item {} 
two technology\sphinxhyphen{}independent Channel implementations based on the Channel/PHY interface

\item {} 
a set of basic PHY model implementations based on the Channel/PHY interface

\end{itemize}

The source code for the spectrum module is located at \sphinxcode{\sphinxupquote{src/spectrum}}.


\subsection{Design}
\label{\detokenize{spectrum:design}}

\subsubsection{Signal model}
\label{\detokenize{spectrum:signal-model}}
The signal model is implemented by the
\sphinxcode{\sphinxupquote{SpectrumSignalParameters}} class. This class provides the following
information for a signal being transmitted/received by PHY devices:
\begin{itemize}
\item {} 
a reference to the transmitting PHY device

\item {} 
a reference to the antenna model used by the transmitting PHY device
to transmit this signal

\item {} 
the duration of the signal

\item {} 
its Power Spectral Density (PSD) of the signal, which is assumed to be constant for
the duration of the signal.

\end{itemize}

The PSD is represented as a set of discrete scalar values each
corresponding to a certain subband in frequency. The set of frequency subbands
to which the PSD refers to is defined by an instance of the
\sphinxcode{\sphinxupquote{SpectrumModel}} class. The PSD itself is implemented as an instance
of the \sphinxcode{\sphinxupquote{SpectrumValue}} class which contains a reference to the
associated \sphinxcode{\sphinxupquote{SpectrumModel}} class instance. The \sphinxcode{\sphinxupquote{SpectrumValue}}
class provides several arithmetic operators to allow to perform calculations
with PSD instances. Additionally, the \sphinxcode{\sphinxupquote{SpectrumConverter}} class
provides means for the conversion of \sphinxcode{\sphinxupquote{SpectrumValue}} instances from
one \sphinxcode{\sphinxupquote{SpectrumModel}} to another.

For a more formal mathematical description of the signal model just
described, the reader is referred to \sphinxcite{spectrum:baldo2009spectrum}.

The \sphinxcode{\sphinxupquote{SpectrumSignalParameters}} class is meant to include only
information that is valid for all signals; as such, it is not meant to
be modified to add technology\sphinxhyphen{}specific information (such as type of
modulation and coding schemes used, info on preambles and reference
signals, etc). Instead, such information shall be put in a new class
that inherits from \sphinxcode{\sphinxupquote{SpectrumSignalParameters}} and extends it with
any technology\sphinxhyphen{}specific information that is needed. This design
is intended to model the fact that in the real world we have signals
of different technologies being simultaneously transmitted and
received over the air.


\subsubsection{Channel/PHY interface}
\label{\detokenize{spectrum:channel-phy-interface}}
The spectrum Channel/PHY interface is defined by the base classes \sphinxcode{\sphinxupquote{SpectrumChannel}}
and \sphinxcode{\sphinxupquote{SpectrumPhy}}. Their interaction simulates the transmission and
reception of signals over the medium. The way this interaction works is depicted in {\hyperref[\detokenize{spectrum:fig-spectrum-channel-phy-interface}]{\sphinxcrossref{\DUrole{std,std-ref}{Sequence diagram showing the interaction between SpectrumPhy and SpectrumChannel}}}}:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{spectrum-channel-phy-interface}.pdf}
\caption{Sequence diagram showing the interaction between SpectrumPhy and SpectrumChannel}\label{\detokenize{spectrum:id22}}\label{\detokenize{spectrum:fig-spectrum-channel-phy-interface}}\end{figure}


\subsubsection{Spectrum Channel implementations}
\label{\detokenize{spectrum:spectrum-channel-implementations}}
The module provides two \sphinxcode{\sphinxupquote{SpectrumChannel}} implementations:
\sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}}. They
both provide this functionality:
\begin{itemize}
\item {} 
Propagation loss modeling, in two forms:
\begin{itemize}
\item {} 
you can plug models based on \sphinxcode{\sphinxupquote{PropagationLossModel}} on these
channels. Only linear models (where the loss value does not
depend on the transmission power) can be used.
These models are single\sphinxhyphen{}frequency in the sense that the loss value is
applied equally to all components of the power spectral density.

\item {} 
you can plug models based on \sphinxcode{\sphinxupquote{SpectrumPropagationLossModel}} on these
channels. These models can have frequency\sphinxhyphen{}dependent loss, i.e.,
a separate loss value is calculated and applied to each component
of the power spectral density.

\end{itemize}

\item {} 
Propagation delay modeling, by plugging a model based on
\sphinxcode{\sphinxupquote{PropagationDelayModel}}. The delay is independent of frequency and
applied to the signal as a whole. Delay modeling is implemented by
scheduling the \sphinxcode{\sphinxupquote{StartRx}} event with a delay respect to the
\sphinxcode{\sphinxupquote{StartTx}} event.

\end{itemize}

\sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} are
quite similar, the main difference is that
\sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} allows to use different
\sphinxcode{\sphinxupquote{SpectrumModel}} instances with the same channel instance, by
automatically taking care of the conversion of PSDs among the
different models.


\subsubsection{Example model implementations}
\label{\detokenize{spectrum:example-model-implementations}}\label{\detokenize{spectrum:sec-example-model-implementations}}
The spectrum module provides some basic implementation of several components that
are mainly intended as a proof\sphinxhyphen{}of\sphinxhyphen{}concept and as an example for
building custom models with the spectrum module. Here is a brief list
of the available implementations:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SpectrumModel300Khz300GhzLog}} and
\sphinxcode{\sphinxupquote{SpectrumModelIsm2400MhzRes1Mhz}} are two example \sphinxcode{\sphinxupquote{SpectrumModel}} implementations

\item {} 
\sphinxcode{\sphinxupquote{HalfDuplexIdealPhy}}: a basic PHY model using a gaussian
interference model (implemented in \sphinxcode{\sphinxupquote{SpectrumInterference}})
together with an error model based on Shannon capacity (described
in \sphinxcite{spectrum:baldo2009spectrum} and implemented in \sphinxcode{\sphinxupquote{SpectrumErrorModel}}. This PHY
uses the \sphinxcode{\sphinxupquote{GenericPhy}} interface. Its addditional custom signal
parameters are defined in \sphinxcode{\sphinxupquote{HalfDuplexIdealPhySignalParameters}}.

\item {} 
\sphinxcode{\sphinxupquote{WifiSpectrumValueHelper}} is an helper object that makes it easy
to create \sphinxcode{\sphinxupquote{SpectrumValues}} representing PSDs and RF filters for
the wifi technology.

\item {} 
\sphinxcode{\sphinxupquote{AlohaNoackNetDevice}}: a minimal NetDevice that allows to send
packets over \sphinxcode{\sphinxupquote{HalfDuplexIdealPhy}} (or other PHY model based on
the  \sphinxcode{\sphinxupquote{GenericPhy}} interface).

\item {} 
\sphinxcode{\sphinxupquote{SpectrumAnalyzer}}, \sphinxcode{\sphinxupquote{WaveformGenerator}} and \sphinxcode{\sphinxupquote{MicrowaveOven}} are examples of PHY
models other than communication devices \sphinxhyphen{} the names should be
self\sphinxhyphen{}explaining.

\end{itemize}


\subsection{References}
\label{\detokenize{spectrum:references}}

\section{Usage}
\label{\detokenize{spectrum:usage}}
The main use case of the spectrum model is for developers who want to
develop a new model for the PHY layer of some wireless technology to
be used within ns\sphinxhyphen{}3.
Here are some notes on how the spectrum module is expected to be used.
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SpectrumPhy}} and \sphinxcode{\sphinxupquote{SpectrumChannel}} are abstract base classes. Real
code will use classes that inherit from these classes.

\item {} 
If you are implementing a new model for some wireless
technology of your interest, and want to use the spectrum module,
you’ll typically create your own module and make it depend on the
spectrum module. Then you typically have to implement:
\begin{itemize}
\item {} 
a child class of \sphinxcode{\sphinxupquote{SpectrumModel}} which defines the (sets of) frequency
subbands used by the considered wireless technology. \sphinxstylestrong{Note}:
instances of \sphinxcode{\sphinxupquote{SpectrumModel}} are typically statically allocated,
in order to allow several \sphinxcode{\sphinxupquote{SpectrumValue}} instances to reference
the same \sphinxcode{\sphinxupquote{SpectrumModel}} instance.

\item {} 
a child class of \sphinxcode{\sphinxupquote{SpectrumPhy}} which will handle transmission and
reception of signals (including, if appropriate, interference
and error modeling).

\item {} 
a child class of \sphinxcode{\sphinxupquote{SpectrumSignalParameters}} which will contain
all the information needed to model the signals for the wireless
technology being considered that is not already provided by the
base \sphinxcode{\sphinxupquote{SpectrumSignalParameters}} class. Examples of such
information are the type of modulation and coding schemes used,
the PHY preamble format, info on the pilot/reference signals, etc.

\end{itemize}

\item {} 
The available \sphinxcode{\sphinxupquote{SpectrumChannel}} implementations
(\sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and \sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}},
are quite generic. Chances are you can use them as\sphinxhyphen{}is. Whether you
prefer one or the other it is just a matter of whether you will
have a single SpectrumModel or multiple ones in your
simulations.

\item {} 
Typically, there will be a single SpectrumChannel instance to which
several SpectrumPhy instances are plugged. The rule of thumb is
that all PHYs that are interfering with each other shall be plugged
on the same channel. Multiple SpectrumChannel instances are
expected to be used mainly when simulating completely orthogonal
channels; for example, when simulating the uplink and downlink
of a Frequency Division Duplex system, it is a good choice to use
two SpectrumChannel instances in order to reduce computational
complexity.

\item {} 
Different types of SpectrumPhy (i.e., instances of different child
classes) can be plugged on the same SpectrumChannel instance. This
is one of the main features of the
spectrum module, to support inter\sphinxhyphen{}technology interference. For
example, if you implement a WifiSpectrumPhy and a
BluetoohSpectrumPhy, and plug both on a SpectrumChannel, then you’ll
be able to simulate interference between wifi and bluetooth and
vice versa.

\item {} 
Different child classes of \sphinxcode{\sphinxupquote{SpectrumSignalParameters}} can coexist
in the same simulation, and be transmitted over the same channel
object.  Again, this is part of the support for inter\sphinxhyphen{}technology
interference. A PHY device model is expected to use the
\sphinxcode{\sphinxupquote{DynamicCast\textless{}\textgreater{}}} operator to determine if a signal is of a certain
type it can attempt to receive. If not, the signal is normally
expected to be considered as interference.

\end{itemize}


\subsection{Helpers}
\label{\detokenize{spectrum:helpers}}
The helpers provided in \sphinxcode{\sphinxupquote{src/spectrum/helpers}} are mainly intended
for the example implementations described in {\hyperref[\detokenize{spectrum:sec-example-model-implementations}]{\sphinxcrossref{\DUrole{std,std-ref}{Example model implementations}}}}.
If you are developing your custom model based on the
spectrum framework, you will probably prefer to define your own
helpers.


\subsection{Attributes}
\label{\detokenize{spectrum:attributes}}\begin{itemize}
\item {} 
Both \sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and
\sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} have an attribute \sphinxcode{\sphinxupquote{MaxLossDb}} which
can use to avoid propagating signals affected by very high
propagation loss. You can use this to reduce the complexity of
interference calculations. Just be careful to choose a value that
does not make the interference calculations inaccurate.

\item {} 
The example implementations described in {\hyperref[\detokenize{spectrum:sec-example-model-implementations}]{\sphinxcrossref{\DUrole{std,std-ref}{Example model implementations}}}} also have several attributes.

\end{itemize}


\subsection{Output}
\label{\detokenize{spectrum:output}}\begin{itemize}
\item {} 
Both \sphinxcode{\sphinxupquote{SingleModelSpectrumChannel}} and
\sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} provide a trace source called
\sphinxcode{\sphinxupquote{PathLoss}} which is fired whenever a new path loss value is
calclulated. \sphinxstylestrong{Note}: only single\sphinxhyphen{}frequency path loss is accounted
for, see the attribute description.

\item {} 
The example implementations described in {\hyperref[\detokenize{spectrum:sec-example-model-implementations}]{\sphinxcrossref{\DUrole{std,std-ref}{Example model implementations}}}} also provide some trace sources.

\item {} 
The helper class \sphinxcode{\sphinxupquote{SpectrumAnalyzerHelper}} can be conveniently
used to generate an output text file containing the spectrogram
produced by a SpectrumAnalyzer instance. The format is designed to
be easily plotted with \sphinxcode{\sphinxupquote{gnuplot}}. For example, if your run the
example \sphinxcode{\sphinxupquote{adhoc\sphinxhyphen{}aloha\sphinxhyphen{}ideal\sphinxhyphen{}phy\sphinxhyphen{}with\sphinxhyphen{}microwave\sphinxhyphen{}oven}} you will get
an output file called \sphinxcode{\sphinxupquote{spectrum\sphinxhyphen{}analyzer\sphinxhyphen{}output\sphinxhyphen{}3\sphinxhyphen{}0.tr}}. From
this output file, you can generate a figure similar to
{\hyperref[\detokenize{spectrum:fig-spectrum-analyzer-example}]{\sphinxcrossref{\DUrole{std,std-ref}{Spectrogram produced by a spectrum analyzer in a scenario
involving wifi signals interfered by a microwave oven, as simulated
by the example adhoc\sphinxhyphen{}aloha\sphinxhyphen{}ideal\sphinxhyphen{}phy\sphinxhyphen{}with\sphinxhyphen{}microwave\sphinxhyphen{}oven.}}}} by executing the following
gnuplot commands:

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
unset surface
set pm3d at s
set palette
set key off
set view 50,50
set xlabel \PYGZdq{}time (ms)\PYGZdq{}
set ylabel \PYGZdq{}freq (MHz)\PYGZdq{}
set zlabel \PYGZdq{}PSD (dBW/Hz)\PYGZdq{} offset 15,0,0
splot \PYGZdq{}./spectrum\PYGZhy{}analyzer\PYGZhy{}output\PYGZhy{}3\PYGZhy{}0.tr\PYGZdq{} using (\PYGZdl{}1*1000.0):(\PYGZdl{}2/1e6):(10*log10(\PYGZdl{}3))
\end{sphinxVerbatim}


\subsection{Examples}
\label{\detokenize{spectrum:examples}}
The example programs in \sphinxcode{\sphinxupquote{src/spectrum/examples/}} allow to see the
example implementations described in {\hyperref[\detokenize{spectrum:sec-example-model-implementations}]{\sphinxcrossref{\DUrole{std,std-ref}{Example model implementations}}}} in action.


\subsection{Troubleshooting}
\label{\detokenize{spectrum:troubleshooting}}\begin{itemize}
\item {} 
\sphinxstylestrong{Disclaimer on inter\sphinxhyphen{}technology interference}: the spectrum model
makes it very easy to implement an inter\sphinxhyphen{}technology interference
model, but this does not guarantee
that the resulting model is accurate. For example, the gaussian
interference model implemented in the \sphinxcode{\sphinxupquote{SpectrumInterference}} class can be used
to calculate inter\sphinxhyphen{}technology interference, however the results might not be valid in some
scenarios, depending on the actual waveforms involved, the number
of interferers, etc. Moreover, it is very important to use error
models that are consistent with the interference model. The
responsibility of ensuring that the models being used are correct
is left to the user.

\end{itemize}


\section{Testing}
\label{\detokenize{spectrum:testing}}
In this section we describe the test suites that are provided within
the spectrum module.


\subsection{SpectrumValue test}
\label{\detokenize{spectrum:spectrumvalue-test}}
The test suite \sphinxcode{\sphinxupquote{spectrum\sphinxhyphen{}value}} verifies the correct functionality of the arithmetic
operators implemented by the \sphinxcode{\sphinxupquote{SpectrumValue}} class. Each test case
corresponds to a different operator. The test passes if the result
provided by the operator implementation is equal to the reference
values which were calculated offline by hand. Equality is verified
within a tolerance of \(10^{-6}\) which is to account for
numerical errors.


\subsection{SpectrumConverter test}
\label{\detokenize{spectrum:spectrumconverter-test}}
The test suite \sphinxcode{\sphinxupquote{spectrum\sphinxhyphen{}converter}} verifies the correct
functionality of the \sphinxcode{\sphinxupquote{SpectrumConverter}} class. Different test cases
correspond to the conversion of different \sphinxcode{\sphinxupquote{SpectrumValue}} instances
to different \sphinxcode{\sphinxupquote{SpectrumModel}} instances. Each test passes if the
\sphinxcode{\sphinxupquote{SpectrumValue}} instance resulting from the conversion is equal to the reference
values which were calculated offline by hand. Equality is verified
within a tolerance of \(10^{-6}\) which is to account for
numerical errors.

Describe how the model has been tested/validated.  What tests run in the
test suite?  How much API and code is covered by the tests?  Again,
references to outside published work may help here.


\subsection{Interference test}
\label{\detokenize{spectrum:interference-test}}
The test suite \sphinxcode{\sphinxupquote{spectrum\sphinxhyphen{}interference}} verifies the correct
functionality of the \sphinxcode{\sphinxupquote{SpectrumInterference}} and
\sphinxcode{\sphinxupquote{ShannonSpectrumErrorModel}} in a scenario involving four
signals (an intended signal plus three interferers). Different test
cases are created corresponding to different PSDs of the intended
signal and different amount of transmitted bytes. The test passes if
the output of the error model (successful or failed) coincides with
the expected one which was determine offline by manually calculating
the achievable rate using Shannon’s formula.


\subsection{IdealPhy test}
\label{\detokenize{spectrum:idealphy-test}}
The test verifies that \sphinxcode{\sphinxupquote{AlohaNoackNetDevice}} and
\sphinxcode{\sphinxupquote{HalfDuplexIdealPhy}} work properly when installed in a node. The
test recreates a scenario with two nodes (a TX and a RX) affected by a path loss such
that a certain SNR is obtained. The TX node transmits with a
pre\sphinxhyphen{}determined PHY rate and with an application layer rate which is
larger than the PHY rate, so as to saturate the
channel. \sphinxcode{\sphinxupquote{PacketSocket}} is used in order to avoid protocol
overhead. Different
test cases correspond to different PHY rate and SNR values. For each
test case, we calculated offline (using Shannon’s formula) whether
the PHY rate is achievable or not. Each test case passes if the
following conditions are satisfied:
\begin{itemize}
\item {} 
if the PHY rate is achievable, the application throughput shall be within
\(1\%\) of the PHY rate;

\item {} 
if the PHY rate is not achievable, the application throughput shall
be zero.

\end{itemize}


\section{Additional Models}
\label{\detokenize{spectrum:additional-models}}

\subsection{TV Transmitter Model}
\label{\detokenize{spectrum:tv-transmitter-model}}
A TV Transmitter model is implemented by the \sphinxcode{\sphinxupquote{TvSpectrumTransmitter}} class.
This model enables transmission of realistic TV signals to be simulated and can
be used for interference modeling. It provides a customizable power spectral
density (PSD) model, with configurable attributes including the type of
modulation (with models for analog, 8\sphinxhyphen{}VSB, and COFDM), signal bandwidth,
power spectral density level, frequency, and transmission duration. A helper
class, \sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}}, is also provided to assist users in
setting up simulations.


\subsubsection{Main Model Class}
\label{\detokenize{spectrum:main-model-class}}
The main TV Transmitter model class, \sphinxcode{\sphinxupquote{TvSpectrumTransmitter}}, provides a
user\sphinxhyphen{}configurable PSD model that can be transmitted on the \sphinxcode{\sphinxupquote{SpectrumChannel}}.
It inherits from \sphinxcode{\sphinxupquote{SpectrumPhy}} and is comprised of attributes and methods to
create and transmit the signal on the channel.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{spectrum-tv-cofdm}.png}
\caption{8K COFDM signal spectrum generated from \sphinxcode{\sphinxupquote{TvSpectrumTransmitter}} (Left) and
theoretical COFDM signal spectrum \sphinxcite{spectrum:koppcofdm} (Right)}\label{\detokenize{spectrum:id23}}\label{\detokenize{spectrum:spectrum-tv-cofdm}}\end{figure}

One of the user\sphinxhyphen{}configurable attributes is the type of modulation for the TV
transmitter to use. The options are 8\sphinxhyphen{}VSB (Eight\sphinxhyphen{}Level Vestigial Sideband
Modulation) which is notably used in the North America ATSC digital television
standard, COFDM (Coded Orthogonal Frequency Division Multiplexing) which is
notably used in the DVB\sphinxhyphen{}T and ISDB\sphinxhyphen{}T digital television standards adopted by
various countries around the world, and analog modulation which is a legacy
technology but is still being used by some countries today. To accomplish
realistic PSD models for these modulation types, the signals’ PSDs were
approximated from real standards and developed into models that are scalable by
frequency and power. The COFDM PSD is approximated from Figure 12 (8k mode) of
\sphinxcite{spectrum:koppcofdm}, the 8\sphinxhyphen{}VSB PSD is approximated from Figure 3 of \sphinxcite{spectrum:baron8vsb}, and the
analog PSD is approximated from Figure 4 of \sphinxcite{spectrum:qualcommanalog}. Note that the
analog model is approximated from the NTSC standard, but other analog modulation
standards such as PAL have similar signals. The approximated COFDM PSD model is
in 8K mode. The other configurable attributes are the start frequency,
signal/channel bandwidth, base PSD, antenna type, starting time,
and transmit duration.

\sphinxcode{\sphinxupquote{TvSpectrumTransmitter}} uses \sphinxcode{\sphinxupquote{IsotropicAntennaModel}} as its antenna model by
default, but any model that inherits from \sphinxcode{\sphinxupquote{AntennaModel}} is selectable, so
directional antenna models can also be used. The propagation loss models used
in simulation are configured in the \sphinxcode{\sphinxupquote{SpectrumChannel}} that the user chooses to
use. Terrain and spherical Earth/horizon effects may be supported in future ns\sphinxhyphen{}3
propagation loss models.

After the attributes are set, along with the \sphinxcode{\sphinxupquote{SpectrumChannel}},
\sphinxcode{\sphinxupquote{MobilityModel}}, and node locations, the PSD of the TV transmitter signal can
be created and transmitted on the channel.


\subsubsection{Helper Class}
\label{\detokenize{spectrum:helper-class}}\label{\detokenize{spectrum:sec-tv-helper-class}}
The helper class, \sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}}, consists of features to
assist users in setting up TV transmitters for their simulations. Functionality
is also provided to easily simulate real\sphinxhyphen{}world scenarios.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{spectrum-tv-8vsb}.png}
\caption{North America ATSC channel 19 \& 20 signals generated using
\sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}} (Left) and theoretical 8\sphinxhyphen{}VSB signal
\sphinxcite{spectrum:baron8vsb} (Right). Note that the theoretical signal is not shown in dB
while the ns\sphinxhyphen{}3 generated signals are.}\label{\detokenize{spectrum:id24}}\label{\detokenize{spectrum:spectrum-tv-8vsb}}\end{figure}

Using this helper class, users can easily set up TV transmitters right after
configuring attributes. Multiple transmitters can be created at a time. Also
included are real characteristics of specific geographic regions that can be
used to run realistic simulations. The regions currently included are
North America, Europe, and Japan. The frequencies and bandwidth of each TV
channel for each these regions are provided.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{spectrum-tv-rand-geo-points}.pdf}
\caption{Plot from MATLAB implementation of CreateRegionalTvTransmitters method in
\sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}}. Shows 100 random points on Earth’s surface
(with altitude 0) corresponding to TV transmitter locations within a 2000 km
radius of 35° latitude and \sphinxhyphen{}100° longitude.}\label{\detokenize{spectrum:id25}}\label{\detokenize{spectrum:spectrum-tv-rand-geo-points}}\end{figure}

A method (CreateRegionalTvTransmitters) is provided that enables users to
randomly generate multiple TV transmitters from a specified region with a given
density within a chosen radius around a point on Earth’s surface. The region,
which determines the channel frequencies of the generated TV transmitters, can
be specified to be one of the three provided, while the density determines the
amount of transmitters generated. The TV transmitters’ antenna heights
(altitude) above Earth’s surface can also be randomly generated to be within a
given maximum altitude. This method models Earth as a perfect sphere, and
generated location points are referenced accordingly in Earth\sphinxhyphen{}Centered
Earth\sphinxhyphen{}Fixed Cartesian coordinates. Note that bodies of water on Earth are not
considered in location point generation\textendash{}TV transmitters can be generated
anywhere on Earth around the origin point within the chosen maximum radius.


\subsubsection{Examples}
\label{\detokenize{spectrum:id9}}
Two example simulations are provided that demonstrate the functionality of the
TV transmitter model. \sphinxcode{\sphinxupquote{tv\sphinxhyphen{}trans\sphinxhyphen{}example}} simulates two 8\sphinxhyphen{}VSB TV transmitters
with adjacent channel frequencies. \sphinxcode{\sphinxupquote{tv\sphinxhyphen{}trans\sphinxhyphen{}regional\sphinxhyphen{}example}} simulates
randomly generated COFDM TV transmitters (modeling the DVB\sphinxhyphen{}T standard)
located around the Paris, France area with channel frequencies and bandwidths
corresponding to the European television channel allocations.


\subsubsection{Testing}
\label{\detokenize{spectrum:id10}}
The \sphinxcode{\sphinxupquote{tv\sphinxhyphen{}spectrum\sphinxhyphen{}transmitter}} test suite verifies the accuracy of the
spectrum/PSD model in \sphinxcode{\sphinxupquote{TvSpectrumTransmitter}} by testing if the maximum power
spectral density, start frequency, and end frequency comply with expected values
for various test cases.

The \sphinxcode{\sphinxupquote{tv\sphinxhyphen{}helper\sphinxhyphen{}distribution}} test suite verifies the functionality of the
method in \sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}} that generates a random number of TV
transmitters based on the given density (low, medium, or high) and maximum
number of TV channels. It verifies that the number of TV transmitters generated
does not exceed the expected bounds.

The CreateRegionalTvTransmitters method in \sphinxcode{\sphinxupquote{TvSpectrumTransmitterHelper}}
described in {\hyperref[\detokenize{spectrum:sec-tv-helper-class}]{\sphinxcrossref{\DUrole{std,std-ref}{Helper Class}}}} uses two methods from the
\sphinxcode{\sphinxupquote{GeographicPositions}} class in the Mobility module to generate the random
Cartesian points on or above earth’s surface around an origin point which
correspond to TV transmitter positions. The first method converts Earth
geographic coordinates to Earth\sphinxhyphen{}Centered Earth\sphinxhyphen{}Fixed (ECEF) Cartesian
coordinates, and is tested in the \sphinxcode{\sphinxupquote{geo\sphinxhyphen{}to\sphinxhyphen{}cartesian}} test suite by comparing
(with 10 meter tolerance) its output with the output of the geographic to ECEF
conversion function \sphinxcite{spectrum:matlabgeo} of the MATLAB Mapping Toolbox for numerous
test cases. The other used method generates random ECEF Cartesian points around
the given geographic origin point, and is tested in the \sphinxcode{\sphinxupquote{rand\sphinxhyphen{}cart\sphinxhyphen{}around\sphinxhyphen{}geo}}
test suite by verifying that the generated points do not exceed the given
maximum distance radius from the origin point.


\subsection{3GPP TR 38.901 fast fading model}
\label{\detokenize{spectrum:gpp-tr-38-901-fast-fading-model}}
The framework described by TR 38.901 \sphinxcite{spectrum:tr38901} is a 3D statistical Spatial
Channel Model supporting different propagation environments (e.g., urban,
rural, indoor), multi\sphinxhyphen{}antenna operations and the modeling of wireless channels
between 0.5 and 100 GHz.
The overall channel is represented by the matrix H(t,τ), in which each
entry H $_{\text{u,s}}$ (t,τ) corresponds to the impulse response of the channel between the
s\sphinxhyphen{}th element of the transmitting antenna and the u\sphinxhyphen{}th element of the receiving
antenna. H $_{\text{u,s}}$ (t,τ) is generated by the superposition of N different multi\sphinxhyphen{}path
components, called clusters, each of which composed of M different rays.
The channel matrix generation procedure accounts for large and small scale
propagation phenomena. The classes ThreeGppSpectrumPropagationLossModel and
ThreeGppChannelModel included in the spectrum module takes care of the generation
of the channel coefficients and the computation of the frequency\sphinxhyphen{}dependent
propagation loss.


\subsubsection{Implementation}
\label{\detokenize{spectrum:implementation}}
Our implementation is described in \sphinxcite{spectrum:zugno}. It is based on the model described
in \sphinxcite{spectrum:zhang}, but the code has been refactored, extended, and aligned to TR 38.901
\sphinxcite{spectrum:tr38901}.
The fundamental assumption behind this model is the channel reciprocity, i.e.,
the impulse response of the channel between node a and node b is the same as
between node b and node a.
To deal with the equivalence of the channel between a and b, no matter who is
the transmitter and who is the receiver, the model considers the pair of nodes
to be composed by one “s” and one “u” node. The channel matrix, as well as other
parameters, are saved and used under the assumption that, within a pair, the
definition of the “s” and “u” node will always be the same. For more details,
please have a look at the documentation of the classes
ThreeGppChannelModel and ThreeGppSpectrumPropagationLossModel.

\sphinxstylestrong{Note:}
\begin{itemize}
\item {} 
Currently, no error model is provided; a link\sphinxhyphen{}to\sphinxhyphen{}system campaign may be
needed to incorporate it in existing modules.

\item {} 
The model does not include any spatial consistency update procedure
(see \sphinxcite{spectrum:tr38901}, Sec. 7.6.1). The implementation of this feature is left
as future work.

\item {} 
Issue regarding the blockage model: according to 3GPP TR 38.901 v15.0.0
(2018\sphinxhyphen{}06) section 7.6.4.1, the blocking region for self\sphinxhyphen{}blocking is provided
in LCS.

However, here, clusterAOA and clusterZOA are in GCS and blocking check is
performed for self\sphinxhyphen{}blocking similar to non\sphinxhyphen{}self blocking, that is in GCS.
One would expect the angles to be transposed to LCS before checking
self\sphinxhyphen{}blockage.

\end{itemize}


\subsubsection{ThreeGppSpectrumPropagationLossModel}
\label{\detokenize{spectrum:threegppspectrumpropagationlossmodel}}
The class ThreeGppSpectrumPropagationLossModel extends the SpectrumPropagationLossModel
interface and enables the modeling of frequency
dependent propagation phenomena. The main method is DoCalcRxPowerSpectralDensity,
which takes as input the power spectral density (PSD) of the transmitted signal,
the mobility models of the transmitting node and receiving node, and
returns the PSD of the received signal.

Procedure used to compute the PSD of to compute the PSD of the received signal:

1. Retrieve the beamforming vectors
To account for the beamforming, ThreeGppSpectrumPropagationLossModel has to
retrieve the beamforming vectors of the transmitting and receiving antennas.
The method DoCalcRxPowerSpectralDensity uses m\_deviceAntennaMap to obtain the
antenna objects associated to the transmitting and receiving devices, and calls
the method GetCurrentBeamformingVector to retrieve the beamforming vectors.
For each device using the channel, the m\_deviceAntennaMap contains the associated
antenna object of type ThreeGppAntennaArrayModel. Since the mapping is one\sphinxhyphen{}to\sphinxhyphen{}one,
the model supports a single antenna object for each device.
The m\_deviceAntennaMap has to be initialized by inserting the device\sphinxhyphen{}antenna
pairs using the method AddDevice.

2. Retrieve the channel matrix
The ThreeGppSpectrumPropagationLossModel relies on the ThreeGppChannelModel class
to obtain the channel matrix. In particular, it makes use of the method GetChannel,
which returns a ThreeGppChannelMatrix object containing the channel
matrix and other channel parameters.
The ThreeGppChannelModel instance is automatically
created in the the ThreeGppSpectrumPropagationLossModel constructor and it can
be configured using the method SetChannelModelAttribute ().

4. Compute the long term component
The method GetLongTerm returns the long term component obtained by multiplying
the channel matrix and the beamforming vectors. To reduce the computational
load, the long term components associated to the different channels are
stored in the m\_longTermMap and recomputed only if the associated channel
matrix is updated or if the transmitting and/or receiving beamforming vectors
have changed. Given the channel reciprocity assumption, for each node pair a
single long term component is saved in the map.

5. Apply the small scale fading and compute the channel gain
The method CalcBeamformingGain computes the channel gain in each sub\sphinxhyphen{}band and
applies it to the PSD of the transmitted signal to obtain the received PSD.
To compute the sub\sphinxhyphen{}band gain, it accounts for the Doppler phenomenon and the
time dispersion effect on each cluster.
In order to reduce the computational load, the Doppler component of each
cluster is computed considering only the central ray.


\subsubsection{ThreeGppChannelModel}
\label{\detokenize{spectrum:threegppchannelmodel}}
The class ThreeGppChannelModel implements the channel matrix generation procedure
described in Sec. of \sphinxcite{spectrum:tr38901}.
The main method is GetChannel, which takes as input the mobility models of
the transmitter and receiver nodes, the associated antenna objects,
and returns a ThreeGppChannelMatrix object containing:
\begin{itemize}
\item {} 
the channel matrix of size UxSxN, where U is the number of receiving antenna elements, S is the number of transmitting antenna elements and N is the number of clusters

\item {} 
the clusters delays, as an array of size N

\item {} 
the clusters arrival and departure angles, as a 2D array in which each row corresponds to a direction (AOA, ZOA, AOD, ZOD) and each column corresponds to a different cluster

\item {} 
a time stamp indicating the time at which the channel matrix was generated

\item {} 
the node IDs

\item {} 
other channel parameters

\end{itemize}

The ThreeGppChannelMatrix objects are saved
in the map m\_channelMap and updated when the coherence time
expires, or in case the LOS/NLOS channel condition changes.
The coherence time can be configured through
the attribute “UpdatePeriod”, and should be chosen by taking into account all the
factors that affects the channel variability, such as mobility, frequency,
propagation scenario, etc. By default, it is set to 0, which means that the
channel is recomputed only when the LOS/NLOS condition changes.
It is possible to configure the propagation scenario and the operating frequency
of interest through the attributes “Scenario” and “Frequency”, respectively.

\sphinxstylestrong{Blockage model:} 3GPP TR 38.901 also provides an optional
feature that can be used to model the blockage effect due to the
presence of obstacles, such as trees, cars or humans, at the level
of a single cluster. This differs from a complete blockage, which
would result in an LOS to NLOS transition. Therefore, when this
feature is enabled, an additional attenuation is added to certain
clusters, depending on their angle of arrival. There are two possi\sphinxhyphen{}
ble methods for the computation of the additional attenuation, i.e.,
stochastic (Model A) and geometric (Model B). In this work, we
used the implementation provided by \sphinxcite{spectrum:zhang}, which
uses the stochastic method. In particular, the model is implemented by the
method CalcAttenuationOfBlockage, which computes the additional attenuation.
The blockage feature can be disable through the attribute “Blockage”. Also, the
attributes “NumNonselfBlocking”, “PortraitMode” and “BlockerSpeed” can be used
to configure the model.


\subsubsection{Testing}
\label{\detokenize{spectrum:id19}}
The test suite ThreeGppChannelTestSuite includes three test cases:
\begin{itemize}
\item {} 
ThreeGppChannelMatrixComputationTest checks if the channel matrix has the
correct dimensions and if it correctly normalized

\item {} 
ThreeGppChannelMatrixUpdateTest, which checks if the channel matrix
is correctly updated when the coherence time exceeds

\item {} 
ThreeGppSpectrumPropagationLossModelTest, which tests the functionalities
of the class ThreeGppSpectrumPropagationLossModel. It builds a simple
network composed of two nodes, computes the power spectral density
received by the receiving node, and
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Checks if the long term components for the direct and
the reverse link are the same,

\item {} 
Checks if the long term component is updated when changing
the beamforming vectors,

\item {} 
Checks if the long term is updated when changing the channel matrix

\end{enumerate}

\end{itemize}

\sphinxstylestrong{Note:} TR 38.901 includes a calibration procedure that can be used to validate
the model, but it requires some additional features which are not currently
implemented, thus is left as future work.


\subsubsection{References}
\label{\detokenize{spectrum:id20}}

\chapter{6LoWPAN: Transmission of IPv6 Packets over IEEE 802.15.4 Networks}
\label{\detokenize{sixlowpan:lowpan-transmission-of-ipv6-packets-over-ieee-802-15-4-networks}}\label{\detokenize{sixlowpan::doc}}
This chapter describes the implementation of \sphinxstyleemphasis{ns\sphinxhyphen{}3} model for the
compression of IPv6 packets over IEEE 802.15.4\sphinxhyphen{}Based Networks
as specified by \index{RFC@\spxentry{RFC}!RFC 4944@\spxentry{RFC 4944}}\sphinxhref{https://tools.ietf.org/html/rfc4944.html}{\sphinxstylestrong{RFC 4944}} (\sphinxcite{sixlowpan:rfc4944}) and \index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}} (\sphinxcite{sixlowpan:rfc6282}).


\section{Model Description}
\label{\detokenize{sixlowpan:model-description}}
The source code for the sixlowpan module lives in the directory \sphinxcode{\sphinxupquote{src/sixlowpan}}.


\subsection{Design}
\label{\detokenize{sixlowpan:design}}
The model design does not follow strictly the standard from an architectural
standpoint, as it does extend it beyond the original scope by supporting also
other kinds of networks.

Other than that, the module strictly follows \index{RFC@\spxentry{RFC}!RFC 4944@\spxentry{RFC 4944}}\sphinxhref{https://tools.ietf.org/html/rfc4944.html}{\sphinxstylestrong{RFC 4944}} and \index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}}, with the
following exceptions:
\begin{itemize}
\item {} 
HC2 encoding is not supported

\item {} 
IPHC’s SAC and DAC are not supported

\end{itemize}

The HC2 encoding is not supported, as it has been superseded by IPHC and NHC
compression type (\index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}}).

IPHC SAC and DAC are not yet supported, as they do require \index{RFC@\spxentry{RFC}!RFC 6775@\spxentry{RFC 6775}}\sphinxhref{https://tools.ietf.org/html/rfc6775.html}{\sphinxstylestrong{RFC 6775}} (\sphinxcite{sixlowpan:rfc6775}) for full
compliance. It is planned to support them in the future.


\subsubsection{NetDevice}
\label{\detokenize{sixlowpan:netdevice}}
The whole module is developed as a transparent NetDevice, which can act as a
proxy between IPv6 and any NetDevice (the module has been successfully tested
with PointToPointNedevice, CsmaNetDevice and LrWpanNetDevice).

For this reason, the module implements a virtual NetDevice, and all the calls are passed
without modifications to the underlying NetDevice. The only important difference is in
GetMtu behaviour. It will always return \sphinxstyleemphasis{at least} 1280 bytes, as is the minimum IPv6 MTU.

The module does provide some attributes and some tracesources.
The attributes are:
\begin{itemize}
\item {} 
\index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}} (boolean, default true), used to activate HC1 (\index{RFC@\spxentry{RFC}!RFC 4944@\spxentry{RFC 4944}}\sphinxhref{https://tools.ietf.org/html/rfc4944.html}{\sphinxstylestrong{RFC 4944}}) or IPHC (\index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}}) compression.

\item {} 
OmitUdpChecksum (boolean, default true), used to activate UDP checksum compression in IPHC.

\item {} 
FragmentReassemblyListSize (integer, default 0), indicating the number of packets that can be reassembled at the same time. If the limit is reached, the oldest packet is discarded. Zero means infinite.

\item {} 
FragmentExpirationTimeout (Time, default 60 seconds), being the timeout to wait for further fragments before discarding a partial packet.

\item {} 
CompressionThreshold (unsigned 32 bits integer, default 0), minimum compressed payload size.

\item {} 
ForceEtherType (boolean, default false).

\item {} 
EtherType (unsigned 16 bits integer, default 0xFFFF), to force a particular L2 EtherType.

\item {} 
UseMeshUnder (boolean, default false), it enables mesh\sphinxhyphen{}under flood routing.

\item {} 
MeshUnderRadius (unsigned 8 bits integer, default 10), the maximum number of hops that a packet will be forwarded.

\item {} 
MeshCacheLength (unsigned 16 bits integer, default 10), the length of the cache for each source.

\item {} 
MeshUnderJitter (ns3::UniformRandomVariable{[}Min=0.0|Max=10.0{]}), the jitter in ms a node uses to forward mesh\sphinxhyphen{}under packets \sphinxhyphen{} used to prevent collisions.

\end{itemize}

The CompressionThreshold attribute is similar to Contiki’s SICSLOWPAN\_CONF\_MIN\_MAC\_PAYLOAD
option. If a compressed packet size is less than the threshold, the uncompressed version is
used (plus one byte for the correct dispatch header).
This option is useful when a MAC requires a minimum frame size (e.g., ContikiMAC) and the
compression would violate the requirement.

The last two attributes are needed to use the module with a NetDevice other than 802.15.4, as
neither IANA or IEEE did reserve an EtherType for 6LoWPAN. As a consequence there might be a
conflict with the L2 multiplexer/demultiplexer which is based on EtherType. The default
value is 0xFFFF, which is reserved by IEEE (see \sphinxcite{sixlowpan:iana802} and \sphinxcite{sixlowpan:ethertype}).
The default module behaviour is to not change the EtherType, however this would not work with
any NetDevice actually understanding and using the EtherType.

Note that the \sphinxtitleref{ForceEtherType} parameter have also a direct effect on the MAC address kind the
module is expecting to handle:
* ForceEtherType true: Mac48Address (Ethernet, WiFi, etc.).
* ForceEtherType false: Mac16Address or Mac64Address (IEEE 802.15.4).

Note that using 6LoWPAN over any NetDevice other than 802.15.4 will produce valid .pcap files,
but they will not be correctly dissected by Wireshark.
The reason lies on the fact that 6LoWPAN was really meant to be used only over 802.15.4, so
Wireshark dissectors will not even try to decode 6LoWPAN headers on top of protocols other than
802.15.4.

The Trace sources are:
\begin{itemize}
\item {} 
Tx \sphinxhyphen{} exposing packet (including 6LoWPAN header), SixLoWPanNetDevice Ptr, interface index.

\item {} 
Rx \sphinxhyphen{} exposing packet (including 6LoWPAN header), SixLoWPanNetDevice Ptr, interface index.

\item {} 
Drop \sphinxhyphen{} exposing DropReason, packet (including 6LoWPAN header), SixLoWPanNetDevice Ptr, interface index.

\end{itemize}

The Tx and Rx traces are called as soon as a packet is received or sent. The Drop trace is
invoked when a packet (or a fragment) is discarded.


\subsubsection{Mesh\sphinxhyphen{}Under routing}
\label{\detokenize{sixlowpan:mesh-under-routing}}
The module provides a very simple mesh\sphinxhyphen{}under routing \sphinxcite{sixlowpan:shelby}, implemented as a flooding
(a mesh\sphinxhyphen{}under routing protocol is a routing system implemented below IP).

This functionality can be activated through the UseMeshUnder attribute and fine\sphinxhyphen{}tuned using
the MeshUnderRadius and MeshUnderJitter attributes.

Note that flooding in a PAN generates a lot of overhead, which is often not wanted.
Moreover, when using the mesh\sphinxhyphen{}under facility, ALL the packets are sent without acknowledgment
because, at lower level, they are sent to a broadcast address.

At node level, each packet is re\sphinxhyphen{}broadcasted if its BC0 Sequence Number is not in the cache of the
recently seen packets. The cache length (by default 10) can be changed through the MeshCacheLength
attribute.


\subsection{Scope and Limitations}
\label{\detokenize{sixlowpan:scope-and-limitations}}
Future versions of this module will support \index{RFC@\spxentry{RFC}!RFC 6775@\spxentry{RFC 6775}}\sphinxhref{https://tools.ietf.org/html/rfc6775.html}{\sphinxstylestrong{RFC 6775}}, however no timeframe is guaranteed.

It would be a good idea to improve the mesh\sphinxhyphen{}under flooding by providing the following:
\begin{itemize}
\item {} 
Adaptive hop\sphinxhyphen{}limit calculation,

\item {} 
Adaptive forwarding jitter,

\item {} 
Use of direct (non mesh) transmission for packets directed to 1\sphinxhyphen{}hop neighbors.

\end{itemize}


\subsubsection{Using 6LoWPAN with IPv4 (or other L3 protocols)}
\label{\detokenize{sixlowpan:using-6lowpan-with-ipv4-or-other-l3-protocols}}
As the name implies, 6LoWPAN can handle only IPv6 packets. Any other protocol will be discarded.
Moreover, 6LoWPAN assumes that the network is uniform, as is all the devices connected by the
same same channel are using 6LoWPAN. Mixed environments are not supported by the standard.
The reason is simple: 802.15.4 frame doesn’t have a “protocol” field. As a consequence,
there is no demultiplexing at MAC layer and the protocol carried by L2 frames must be known
in advance.

In the \sphinxstyleemphasis{ns\sphinxhyphen{}3} implementation it is possible, but not advisable, to violate this requirement
if the underlying NetDevice is capable of discriminating different protocols. As an example,
CsmaNetDevice can carry IPv4 and 6LoWPAN at the same time. However, this configuration has
not been tested.


\subsection{References}
\label{\detokenize{sixlowpan:references}}

\section{Usage}
\label{\detokenize{sixlowpan:usage}}

\subsection{Enabling sixlowpan}
\label{\detokenize{sixlowpan:enabling-sixlowpan}}
Add \sphinxcode{\sphinxupquote{sixlowpan}} to the list of modules built with \sphinxstyleemphasis{ns\sphinxhyphen{}3}.


\subsection{Helper}
\label{\detokenize{sixlowpan:helper}}
The helper is patterned after other device helpers.


\subsection{Examples}
\label{\detokenize{sixlowpan:examples}}
The following example can be found in \sphinxcode{\sphinxupquote{src/sixlowpan/examples/}}:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{example\sphinxhyphen{}sixlowpan.cc}}:  A simple example showing end\sphinxhyphen{}to\sphinxhyphen{}end data transfer.

\end{itemize}

In particular, the example enables a very simplified end\sphinxhyphen{}to\sphinxhyphen{}end data
transfer scenario, with a CSMA network forced to carry 6LoWPAN compressed packets.


\subsection{Tests}
\label{\detokenize{sixlowpan:tests}}
The test provided checks the connection between two UDP clients and the correctness of the received packets.


\section{Validation}
\label{\detokenize{sixlowpan:validation}}
The model has been validated against WireShark, checking whatever the packets are correctly
interpreted and validated.


\chapter{Tap NetDevice}
\label{\detokenize{tap:tap-netdevice}}\label{\detokenize{tap::doc}}
The Tap NetDevice can be used to allow a host system or virtual machines to
interact with a simulation.


\section{TapBridge Model Overview}
\label{\detokenize{tap:tapbridge-model-overview}}
The Tap Bridge is designed to integrate “real” internet hosts (or more
precisely, hosts that support Tun/Tap devices) into ns\sphinxhyphen{}3 simulations.  The
goal is to make it appear to a “real” host node in that it has an ns\sphinxhyphen{}3 net
device as a local device.  The concept of a “real host” is a bit slippery
since the “real host” may actually be virtualized using readily available
technologies such as VMware, VirtualBox or OpenVZ.

Since we are, in essence, connecting the inputs and outputs of an ns\sphinxhyphen{}3 net
device to the inputs and outputs of a Linux Tap net device, we call this
arrangement a Tap Bridge.

There are three basic operating modes of this device available to users.
Basic functionality is essentially identical, but the modes are different
in details regarding how the arrangement is created and configured;
and what devices can live on which side of the bridge.

We call these three modes the ConfigureLocal, UseLocal and UseBridge modes.
The first “word” in the camel case mode identifier indicates who has the
responsibility for creating and configuring the taps.  For example,
the “Configure” in ConfigureLocal mode indicates that it is the TapBridge
that has responsibility for configuring the tap.  In UseLocal mode and
UseBridge modes, the “Use” prefix indicates that the TapBridge is asked to
“Use” an existing configuration.

In other words, in ConfigureLocal mode, the TapBridge has the responsibility
for creating and configuring the TAP devices.  In UseBridge or UseLocal
modes, the user provides a configuration and the TapBridge adapts to that
configuration.


\subsection{TapBridge ConfigureLocal Mode}
\label{\detokenize{tap:tapbridge-configurelocal-mode}}
In the ConfigureLocal mode, the configuration of the tap device is ns\sphinxhyphen{}3
configuration\sphinxhyphen{}centric.  Configuration information is taken from a device
in the ns\sphinxhyphen{}3 simulation and a tap device matching the ns\sphinxhyphen{}3 attributes is
automatically created.  In this case, a Linux computer is made to appear as
if it was directly connected to a simulated ns\sphinxhyphen{}3 network.

This is illustrated below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|  Linux |
|  host  |                    +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   ghost  |
|  apps  |                    |   node   |
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
|  stack |                    |    IP    |     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   stack  |     |   node   |
|  TAP   |                    |==========|     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
| device | \PYGZlt{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} IPC \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} |   tap    |     |    IP    |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                    |  bridge  |     |   stack  |
                              | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
                              |   ns\PYGZhy{}3   |     |   ns\PYGZhy{}3   |
                              |   net    |     |   net    |
                              |  device  |     |  device  |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                   ||               ||
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                              |        ns\PYGZhy{}3 channel       |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
\end{sphinxVerbatim}

In this case, the “ns\sphinxhyphen{}3 net device” in the “ghost node” appears as if it
were actually replacing the TAP device in the Linux host.  The ns\sphinxhyphen{}3
simulation creates the TAP device on the underlying Linux OS and configures
the IP and MAC addresses of the TAP device to match the values assigned to
the simulated ns\sphinxhyphen{}3 net device.  The “IPC” link shown above is the network
tap mechanism in the underlying OS.  The whole arrangement acts as a
conventional bridge; but a bridge between devices that happen to have the
same shared MAC and IP addresses.

Here, the user is not required to provide any configuration information
specific to the tap.  A tap device will be created and configured by ns\sphinxhyphen{}3
according to its defaults, and the tap device will have its name assigned
by the underlying operating system according to its defaults.

If the user has a requirement to access the created tap device, he or she
may optionally provide a “DeviceName” attribute.  In this case, the created
OS tap device will be named accordingly.

The ConfigureLocal mode is the default operating mode of the Tap Bridge.


\subsection{TapBridge UseLocal Mode}
\label{\detokenize{tap:tapbridge-uselocal-mode}}
The UseLocal mode is quite similar to the ConfigureLocal mode.  The
significant difference is, as the mode name implies, the TapBridge is
going to “Use” an existing tap device previously created and configured
by the user.  This mode is particularly useful when a virtualization
scheme automatically creates tap devices and ns\sphinxhyphen{}3 is used to provide
simulated networks for those devices.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|  Linux |
|  host  |                    +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   ghost  |
|  apps  |                    |   node   |
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
|  stack |                    |    IP    |     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                    |   stack  |     |   node   |
|  TAP   |                    |==========|     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
| device | \PYGZlt{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} IPC \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} |   tap    |     |    IP    |
| MAC X  |                    |  bridge  |     |   stack  |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                    | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
                              |   ns\PYGZhy{}3   |     |   ns\PYGZhy{}3   |
                              |   net    |     |   net    |
                              |  device  |     |  device  |
                              |  MAC Y   |     |  MAC Z   |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                   ||               ||
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                              |        ns\PYGZhy{}3 channel       |
                              +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
\end{sphinxVerbatim}

In this case, the pre\sphinxhyphen{}configured MAC address of the “Tap device” (MAC X)
will not be the same as that of the bridged “ns\sphinxhyphen{}3 net device” (MAC Y) shown
in the illustration above.  In order to bridge to ns\sphinxhyphen{}3 net devices which do
not support SendFrom() (especially wireless STA nodes) we impose a requirement
that only one Linux device (with one unique MAC address \textendash{} here X) generates
traffic that flows across the IPC link.  This is because the MAC addresses of
traffic across the IPC link will be “spoofed” or changed to make it appear to
Linux and ns\sphinxhyphen{}3 that they have the same address.  That is, traffic moving from
the Linux host to the ns\sphinxhyphen{}3 ghost node will have its MAC address changed from
X to Y and traffic from the ghost node to the Linux host will have its MAC
address changed from Y to X.  Since there is a one\sphinxhyphen{}to\sphinxhyphen{}one correspondence
between devices, there may only be one MAC source flowing from the Linux side.
This means that Linux bridges with more than one net device added are
incompatible with UseLocal mode.

In UseLocal mode, the user is expected to create and configure a tap device
completely outside the scope of the ns\sphinxhyphen{}3 simulation using something like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo tunctl \PYGZhy{}t tap0
\PYGZdl{} sudo ifconfig tap0 hw ether \PYG{l+m}{08}:00:2e:00:00:01
\PYGZdl{} sudo ifconfig tap0 \PYG{l+m}{10}.1.1.1 netmask \PYG{l+m}{255}.255.255.0 up
\end{sphinxVerbatim}

To tell the TapBridge what is going on, the user will set either directly
into the TapBridge or via the TapBridgeHelper, the “DeviceName” attribute.
In the case of the configuration above, the “DeviceName” attribute would be
set to “tap0” and the “Mode” attribute would be set to “UseLocal”.

One particular use case for this mode is in the OpenVZ environment.  There it
is possible to create a Tap device on the “Hardware Node” and move it into a
Virtual Private Server.  If the TapBridge is able to use an existing tap device
it is then possible to avoid the overhead of an OS bridge in that environment.


\subsection{TapBridge UseBridge Mode}
\label{\detokenize{tap:tapbridge-usebridge-mode}}
The simplest mode for those familiar with Linux networking is the UseBridge
mode.  Again, the “Use” prefix indicates that the TapBridge is going to Use
an existing configuration.  In this case, the TapBridge is going to logically
extend a Linux bridge into ns\sphinxhyphen{}3.

This is illustrated below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
|  Linux  |                             +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                             |   ghost  |
|  apps   |                             |   node   |
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |                             | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
|  stack  |                             |    IP    |     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
| \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} | +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                  |   stack  |     |   node   |
| Virtual | |  TAP   |                  |==========|     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
| Device  | | Device | \PYGZlt{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} IPC \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} |   tap    |     |    IP    |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+ +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                  |  bridge  |     |   stack  |
    ||          ||                      | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |     | \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                  |   ns\PYGZhy{}3   |     |   ns\PYGZhy{}3   |
| OS (brctl) Bridge  |                  |   net    |     |   net    |
+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+                  |  device  |     |  device  |
                                        +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+     +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                             ||               ||
                                        +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
                                        |        ns\PYGZhy{}3 channel       |
                                        +\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+
\end{sphinxVerbatim}

In this case, a computer running Linux applications, protocols, etc., is
connected to a ns\sphinxhyphen{}3 simulated network in such a way as to make it appear
to the Linux host that the TAP device is a real network device participating
in the Linux bridge.

In the ns\sphinxhyphen{}3 simulation, a TapBridge is created to match each TAP Device.
The name of the TAP Device is assigned to the Tap Bridge using the
“DeviceName” attribute.  The TapBridge then logically extends the OS bridge
to encompass the ns\sphinxhyphen{}3 net device.

Since this mode logically extends an OS bridge, there may be many Linux net
devices on the non\sphinxhyphen{}ns\sphinxhyphen{}3 side of the bridge.  Therefore, like a net device on
any bridge, the ns\sphinxhyphen{}3 net device must deal with the possibly of many source
addresses.  Thus, ns\sphinxhyphen{}3 devices must support SendFrom()
(NetDevice::SupportsSendFrom() must return true) in order to be configured
for use in UseBridge mode.

It is expected that the user will do something like the following to
configure the bridge and tap completely outside ns\sphinxhyphen{}3:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sudo brctl addbr mybridge
\PYGZdl{} sudo tunctl \PYGZhy{}t mytap
\PYGZdl{} sudo ifconfig mytap hw ether \PYG{l+m}{00}:00:00:00:00:01
\PYGZdl{} sudo ifconfig mytap \PYG{l+m}{0}.0.0.0 up
\PYGZdl{} sudo brctl addif mybridge mytap
\PYGZdl{} sudo brctl addif mybridge ...
\PYGZdl{} sudo ifconfig mybridge \PYG{l+m}{10}.1.1.1 netmask \PYG{l+m}{255}.255.255.0 up
\end{sphinxVerbatim}

To tell the TapBridge what is going on, the user will set either directly
into the TapBridge or via the TapBridgeHelper, the “DeviceName” attribute.
In the case of the configuration above, the “DeviceName” attribute would be
set to “mytap” and the “Mode” attribute would be set to “UseBridge”.

This mode is especially  useful in the case of virtualization where the
configuration of the virtual hosts may be dictated by another system and
not be changeable to suit ns\sphinxhyphen{}3.  For example, a particular VM scheme may create
virtual “vethx” or “vmnetx” devices that appear local to virtual hosts.  In
order to connect to such systems, one would need to manually create TAP devices
on the host system and brigde these TAP devices to the existing (VM) virtual
devices.  The job of the Tap Bridge in this case is to extend the bridge to
join a ns\sphinxhyphen{}3 net device.


\subsection{TapBridge ConfigureLocal Operation}
\label{\detokenize{tap:tapbridge-configurelocal-operation}}
In ConfigureLocal mode, the TapBridge and therefore its associated ns\sphinxhyphen{}3 net
device appears to the Linux host computer as a network device just like any
arbitrary “eth0” or “ath0” might appear.  The creation and configuration
of the TAP device is done by the ns\sphinxhyphen{}3 simulation and no manual configuration
is required by the user.  The IP addresses, MAC addresses, gateways, etc.,
for created TAP devices are extracted from the simulation itself by querying
the configuration of the ns\sphinxhyphen{}3 device and the TapBridge Attributes.

Since the MAC addresses are identical on the Linux side and the ns\sphinxhyphen{}3 side,
we can use Send() on the ns\sphinxhyphen{}3 device which is available on all ns\sphinxhyphen{}3 net devices.
Since the MAC addresses are identical there is no requirement to hook the
promiscuous callback on the receive side.  Therefore there are no restrictions
on the kinds of net device that are usable in ConfigureLocal mode.

The TapBridge appears to an ns\sphinxhyphen{}3 simulation as a channel\sphinxhyphen{}less net device.
This device must not have an IP address associated with it, but the bridged
(ns\sphinxhyphen{}3) net device must have an IP address.  Be aware that this is the inverse
of an ns\sphinxhyphen{}3 BridgeNetDevice (or a conventional bridge in general) which
demands that its bridge ports not have IP addresses, but allows the bridge
device itself to have an IP address.

The host computer will appear in a simulation as a “ghost” node that contains
one TapBridge for each NetDevice that is being bridged.  From the perspective
of a simulation, the only difference between a ghost node and any other node
will be the presence of the TapBridge devices.  Note however, that the
presence of the TapBridge does affect the connectivity of the net device to
the IP stack of the ghost node.

Configuration of address information and the ns\sphinxhyphen{}3 devices is not changed in
any way if a TapBridge is present.  A TapBridge will pick up the addressing
information from the ns\sphinxhyphen{}3 net device to which it is connected (its “bridged”
net device) and use that information to create and configure the TAP device
on the real host.

The end result of this is a situation where one can, for example, use the
standard ping utility on a real host to ping a simulated ns\sphinxhyphen{}3 node.  If
correct routes are added to the internet host (this is expected to be done
automatically in future ns\sphinxhyphen{}3 releases), the routing systems in ns\sphinxhyphen{}3 will
enable correct routing of the packets across simulated ns\sphinxhyphen{}3 networks.
For an example of this, see the example program, tap\sphinxhyphen{}wifi\sphinxhyphen{}dumbbell.cc in
the ns\sphinxhyphen{}3 distribution.

The Tap Bridge lives in a kind of a gray world somewhere between a Linux host
and an ns\sphinxhyphen{}3 bridge device.  From the Linux perspective, this code appears as
the user mode handler for a TAP net device.  In ConfigureLocal mode, this Tap
device is automatically created by the ns\sphinxhyphen{}3 simulation.  When the Linux host
writes to one of these automatically created /dev/tap devices, the write is
redirected into the TapBridge that lives in the ns\sphinxhyphen{}3 world; and from this
perspective, the packet write on Linux becomes a packet read in the Tap Bridge.
In other words, a Linux process writes a packet to a tap device and this packet
is redirected by the network tap mechanism toan ns\sphinxhyphen{}3 process where it is
received by the TapBridge as a result of a read operation there.  The TapBridge
then writes the packet to the ns\sphinxhyphen{}3 net device to which it is bridged; and
therefore it appears as if the Linux host sent a packet directly through an
ns\sphinxhyphen{}3 net device onto an ns\sphinxhyphen{}3 network.

In the other direction, a packet received by the ns\sphinxhyphen{}3 net device connected to
the Tap Bridge is sent via a receive callback to the TapBridge.  The
TapBridge then takes that packet and writes it back to the host using the
network tap mechanism.  This write to the device will appear to the Linux
host as if a packet has arrived on a net device; and therefore as if a packet
received by the ns\sphinxhyphen{}3 net device during a simulation has appeared on a real
Linux net device.

The upshot is that the Tap Bridge appears to bridge a tap device on a
Linux host in the “real world” to an ns\sphinxhyphen{}3 net device in the simulation.
Because the TAP device and the bridged ns\sphinxhyphen{}3 net device have the same MAC
address and the network tap IPC link is not externalized, this particular
kind of bridge makes it appear that a ns\sphinxhyphen{}3 net device is actually installed
in the Linux host.

In order to implement this on the ns\sphinxhyphen{}3 side, we need a “ghost node” in the
simulation to hold the bridged ns\sphinxhyphen{}3 net device and the TapBridge.  This node
should not actually do anything else in the simulation since its job is
simply to make the net device appear in Linux.  This is not just arbitrary
policy, it is because:
\begin{itemize}
\item {} 
Bits sent to the TapBridge from higher layers in the ghost node (using
the TapBridge Send method) are completely ignored.  The TapBridge is
not, itself, connected to any network, neither in Linux nor in ns\sphinxhyphen{}3.  You
can never send nor receive data over a TapBridge from the ghost node.

\item {} 
The bridged ns\sphinxhyphen{}3 net device has its receive callback disconnected
from the ns\sphinxhyphen{}3 node and reconnected to the Tap Bridge.  All data received
by a bridged device will then be sent to the Linux host and will not be
received by the node.  From the perspective of the ghost node, you can
send over this device but you cannot ever receive.

\end{itemize}

Of course, if you understand all of the issues you can take control of
your own destiny and do whatever you want \textendash{} we do not actively
prevent you from using the ghost node for anything you decide.  You
will be able to perform typical ns\sphinxhyphen{}3 operations on the ghost node if
you so desire.  The internet stack, for example, must be there and
functional on that node in order to participate in IP address
assignment and global routing.  However, as mentioned above,
interfaces talking to any TapBridge or associated bridged net devices
will not work completely.  If you understand exactly what you are
doing, you can set up other interfaces and devices on the ghost node
and use them; or take advantage of the operational send side of the
bridged devices to create traffic generators.  We generally recommend
that you treat this node as a ghost of the Linux host and leave it to
itself, though.


\subsection{TapBridge UseLocal Mode Operation}
\label{\detokenize{tap:tapbridge-uselocal-mode-operation}}
As described in above, the TapBridge acts like a bridge from the “real” world
into the simulated ns\sphinxhyphen{}3 world.  In the case of the ConfigureLocal mode,
life is easy since the IP address of the Tap device matches the IP address of
the ns\sphinxhyphen{}3 device and the MAC address of the Tap device matches the MAC address
of the ns\sphinxhyphen{}3 device; and there is a one\sphinxhyphen{}to\sphinxhyphen{}one relationship between the
devices.

Things are slightly complicated when a Tap device is externally configured
with a  different MAC address than the ns\sphinxhyphen{}3 net device.  The conventional way
to deal with this kind of difference is to use promiscuous mode in the
bridged device to receive packets destined for the different MAC address and
forward them off to Linux.  In order to move packets the other way, the
conventional solution is SendFrom() which allows a caller to “spoof” or change
the source MAC address to match the different Linux MAC address.

We do have a specific requirement to be able to bridge Linux Virtual Machines
onto wireless STA nodes.  Unfortunately, the 802.11 spec doesn’t provide a
good way to implement SendFrom(), so we have to work around that problem.

To this end, we provided the UseLocal mode of the Tap Bridge.  This mode allows
you approach the problem as if you were creating a bridge with a single net
device.  A single allowed address on the Linux side is remembered in the
TapBridge, and all packets coming from the Linux side are repeated out the
ns\sphinxhyphen{}3 side using the ns\sphinxhyphen{}3 device MAC source address.  All packets coming in
from the ns\sphinxhyphen{}3 side are repeated out the Linux side using the remembered MAC
address.  This allows us to use Send() on the ns\sphinxhyphen{}3 device side which is
available on all ns\sphinxhyphen{}3 net devices.

UseLocal mode is identical to the ConfigureLocal mode except for the creation
and configuration of the tap device and the MAC address spoofing.


\subsection{TapBridge UseBridge Operation}
\label{\detokenize{tap:tapbridge-usebridge-operation}}
As described in the ConfigureLocal mode section, when the Linux host writes to
one of the /dev/tap devices, the write is redirected into the TapBridge
that lives in the ns\sphinxhyphen{}3 world.  In the case of the UseBridge mode, these
packets will need to be sent out on the ns\sphinxhyphen{}3 network as if they were sent on
a device participating in the Linux bridge.  This means calling the
SendFrom() method on the bridged device and providing the source MAC address
found in the packet.

In the other direction, a packet received by an ns\sphinxhyphen{}3 net device is hooked
via callback to the TapBridge.  This must be done in promiscuous mode since
the goal is to bridge the ns\sphinxhyphen{}3 net device onto the OS (brctl) bridge of
which the TAP device is a part.

For these reasons, only ns\sphinxhyphen{}3 net devices that support SendFrom() and have a
hookable promiscuous receive callback are allowed to participate in UseBridge
mode TapBridge configurations.


\section{Tap Bridge Channel Model}
\label{\detokenize{tap:tap-bridge-channel-model}}
There is no channel model associated with the Tap Bridge.  In fact, the
intention is make it appear that the real internet host is connected to
the channel of the bridged net device.


\section{Tap Bridge Tracing Model}
\label{\detokenize{tap:tap-bridge-tracing-model}}
Unlike most ns\sphinxhyphen{}3 devices, the TapBridge does not provide any standard trace
sources.  This is because the bridge is an intermediary that is essentially
one function call away from the bridged device.  We expect that the trace
hooks in the bridged device will be sufficient for most users,


\section{Using the TapBridge}
\label{\detokenize{tap:using-the-tapbridge}}
We expect that most users will interact with the TapBridge device through
the TapBridgeHelper.  Users of other helper classes, such as CSMA or Wifi,
should be comfortable with the idioms used there.


\chapter{Topology Input Readers}
\label{\detokenize{topology:topology-input-readers}}\label{\detokenize{topology::doc}}
The topology modules aim at reading a topology file generated by an automatic topology generator.

The process is divided in two steps:
\begin{itemize}
\item {} 
running a topology generator to build a topology file

\item {} 
reading the topology file and build a ns\sphinxhyphen{}3 simulation

\end{itemize}

Hence, model is focused on being able to read correctly the various topology formats.

Currently there are three models:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ns3::OrbisTopologyReader}} for \sphinxhref{http://sysnet.ucsd.edu/~pmahadevan/topo\_research/topo.html}{Orbis} 0.7 traces

\item {} 
\sphinxcode{\sphinxupquote{ns3::InetTopologyReader}} for \sphinxhref{http://topology.eecs.umich.edu/inet/}{Inet} 3.0 traces

\item {} 
\sphinxcode{\sphinxupquote{ns3::RocketfuelTopologyReader}} for \sphinxhref{http://www.cs.washington.edu/research/networking/rocketfuel/}{Rocketfuel} traces

\end{itemize}

An helper \sphinxcode{\sphinxupquote{ns3::TopologyReaderHelper}} is provided to assist on trivial tasks.

A good source for topology data is also \sphinxhref{http://www.caida.org/projects/ark/}{Archipelago}.

The current Archipelago \sphinxhref{http://data.caida.org/datasets/topology/ipv4.allpref24-aslinks/}{Measurements}, monthly updated, are stored in the CAIDA website using
a complete notation and triple data source, one for each working group.

A different and more compact notation reporting only the AS\sphinxhyphen{}relationships (a sort of more
Orbis\sphinxhyphen{}like format) is here: \sphinxhref{http://www.caida.org/data/active/as-relationships/index.xml}{as\sphinxhyphen{}relationships}.

The compact notation can be easily stripped down to a pure Orbis format, just removing
the double relationships (the compact format use one\sphinxhyphen{}way links, while Orbis use two\sphinxhyphen{}way
links) and pruning the 3rd parameter. Note that with the compact data Orbis can then be
used create a rescaled version of the topology, thus being the most effective way
(to my best knowledge) to make an internet\sphinxhyphen{}like topology.

Examples can be found in the directory \sphinxcode{\sphinxupquote{src/topology\sphinxhyphen{}read/examples/}}


\chapter{Traffic Control Layer}
\label{\detokenize{traffic-control:traffic-control-layer}}\label{\detokenize{traffic-control::doc}}

\section{Traffic Control Layer}
\label{\detokenize{traffic-control-layer:traffic-control-layer}}\label{\detokenize{traffic-control-layer::doc}}
The Traffic Control layer aims at introducing an equivalent of the Linux Traffic
Control infrastructure into ns\sphinxhyphen{}3. The Traffic Control layer sits in between
the NetDevices (L2) and any network protocol (e.g. IP). It is in charge of processing
packets and performing actions on them: scheduling, dropping, marking, policing, etc.


\subsection{Introducing the Traffic Control Layer}
\label{\detokenize{traffic-control-layer:introducing-the-traffic-control-layer}}
The Traffic Control layer intercepts both outgoing packets flowing downwards from
the network layer to the network device and incoming packets flowing in the opposite
direction. Currently, only outgoing packets are processed by the Traffic Control layer.
In particular, outgoing packets are enqueued in a queuing discipline, which can perform
multiple actions on them.

In the following, more details are given about how the Traffic Control layer intercepts
outgoing and incoming packets and, more in general, about how the packets traverse the
network stack.


\subsubsection{Transmitting packets}
\label{\detokenize{traffic-control-layer:transmitting-packets}}
The IPv\{4,6\} interfaces uses the aggregated object TrafficControlLayer to send
down packets, instead of calling NetDevice::Send() directly. After the analysis
and the process of the packet, when the backpressure mechanism allows it,
TrafficControlLayer will call the Send() method on the right NetDevice.


\subsubsection{Receiving packets}
\label{\detokenize{traffic-control-layer:receiving-packets}}
The callback chain that (in the past) involved IPv\{4,6\}L3Protocol and NetDevices,
through ReceiveCallback, is extended to involve TrafficControlLayer. When an
IPv\{4,6\}Interface is added in the IPv\{4,6\}L3Protocol, the callback chain is
configured to have the following packet exchange:

NetDevice \textendash{}\textgreater{} Node \textendash{}\textgreater{} TrafficControlLayer \textendash{}\textgreater{} IPv\{4,6\}L3Protocol


\subsection{Brief description of old node/device/protocol interactions}
\label{\detokenize{traffic-control-layer:brief-description-of-old-node-device-protocol-interactions}}
The main question that we would like to answer in the following paragraphs is:
how a ns\sphinxhyphen{}3 node can send/receive packets?

If we analyze any example out there, the ability of the node to receive/transmit
packets derives from the interaction of two helper:
\begin{itemize}
\item {} 
L2 Helper (something derived from NetDevice)

\item {} 
L3 Helper (usually from Internet module)

\end{itemize}


\subsubsection{L2 Helper main operations}
\label{\detokenize{traffic-control-layer:l2-helper-main-operations}}
Any good L2 Helper will do the following operations:
\begin{itemize}
\item {} 
Create n netdevices (n\textgreater{}1)

\item {} 
Attach a channel between these devices

\item {} 
Call Node::AddDevice ()

\end{itemize}

Obviously the last point is the most important.

Node::AddDevice (network/model/node.cc:128) assigns an interface index to the
device, calls NetDevice::SetNode, sets the receive callback of the device to
Node::NonPromiscReceiveFromDevice. Then, it schedules NetDevice::Initialize() method at
Seconds(0.0), then notify the registered DeviceAdditionListener handlers (not used BY ANYONE).

Node::NonPromiscReceiveFromDevice calls Node::ReceiveFromDevice.

Node::ReceiveFromDevice iterates through ProtocolHandlers, which are callbacks
which accept as signature:

ProtocolHandler (Ptr\textless{}NetDevice\textgreater{}, Ptr\textless{}const Packet\textgreater{}, protocol, from\_addr, to\_addr, packetType).

If device, protocol number and promiscuous flag corresponds, the handler is
invoked.

Who is responsible to set ProtocolHandler ? We will analyze that in the next
section.


\subsubsection{L3 Helper}
\label{\detokenize{traffic-control-layer:l3-helper}}
We have only internet which provides network protocol (IP). That module splits
the operations between two helpers: InternetStackHelper and Ipv\{4,6\}AddressHelper.

InternetStackHelper::Install (internet/helper/internet\sphinxhyphen{}stack\sphinxhyphen{}helper.cc:423)
creates and aggregates protocols \{ArpL3,Ipv4L3,Icmpv4\}Protocol. It creates the
routing protocol, and if Ipv6 is enabled it adds \{Ipv6L3,Icmpv6L4\}Protocol. In
any case, it instantiates and aggregates an UdpL4Protocol object, along with a
PacketSocketFactory.
Ultimately, it creates the required objects and aggregates them to the node.

Let’s assume an Ipv4 environment (things are the same for Ipv6).

Ipv4AddressHelper::Assign (src/internet/helper/ipv4\sphinxhyphen{}address\sphinxhyphen{}helper.cc:131)
registers the handlers. The process is a bit long. The method is called with
a list of NetDevice. For each of them, the node and Ipv4L3Protocol pointers are
retrieved; if an Ipv4Interface is already registered for the device, on that the
address is set. Otherwise, the method Ipv4L3Protocol::AddInterface is called,
before adding the address.


\subsubsection{IP interfaces}
\label{\detokenize{traffic-control-layer:ip-interfaces}}
In Ipv4L3Protocol::AddInterface (src/internet/model/ipv4\sphinxhyphen{}l3\sphinxhyphen{}protocol.cc:300)
two protocol handlers are installed: one that react to ipv4 protocol number,
and one that react to arp protocol number (Ipv4L3Protocol::Receive and
ArpL3Protocol::Receive, respectively). The interface is then created,
initialized, and returned.

Ipv4L3Protocol::Receive (src/internet/model/ipv4\sphinxhyphen{}l3\sphinxhyphen{}protocol.cc:472) iterates
through the interface. Once it finds the Ipv4Interface which has the same device
as the one passed as argument, invokes the rxTrace callback. If the interface is
down, the packet is dropped. Then, it removes the header and trim any residual
frame padding. If checksum is not OK, it drops the packet. Otherwise, forward
the packet to the raw sockets (not used). Then, it ask the routing protocol what
is the destiny of that packet. The choices are: Ipv4L3Protocol::\{IpForward,
IpMulticastForward,LocalDeliver,RouteInputError\}.


\section{Queue disciplines}
\label{\detokenize{queue-discs:queue-disciplines}}\label{\detokenize{queue-discs::doc}}

\subsection{Model Description}
\label{\detokenize{queue-discs:model-description}}
Packets received by the Traffic Control layer for transmission to a netdevice
can be passed to a queueing discipline (queue disc) to perform scheduling and
policing.  The \sphinxstyleemphasis{ns\sphinxhyphen{}3} term “queue disc” corresponds to what Linux calls a “qdisc”.
A netdevice can have a single (root) queue disc installed on it.
Installing a queue disc on a netdevice is not mandatory. If a netdevice does
not have a queue disc installed on it, the traffic control layer sends the packets
directly to the netdevice. This is the case, for instance, of the loopback netdevice.

As in Linux, queue discs may be simple queues or may be complicated hierarchical
structures.  A queue disc may contain distinct elements:
\begin{itemize}
\item {} 
queues, which actually store the packets waiting for transmission

\item {} 
classes, which permit the definition of different treatments for different subdivisions of traffic

\item {} 
filters, which determine the queue or class which a packet is destined to

\end{itemize}

Linux uses the terminology “classful qdiscs” or “classless qdiscs” to describe
how packets are handled.  This use of the term “class” should be distinguished
from the C++ language “class”.  In general, the below discussion uses “class”
in the Linux, not C++, sense, but there are some uses of the C++ term, so
please keep in mind the dual use of this term in the below text.

Notice that a child queue disc must be attached to every class and a packet
filter is only able to classify packets of a single protocol. Also, while in Linux
some queue discs (e.g., fq\sphinxhyphen{}codel) use an internal classifier and do not make use of
packet filters, in ns\sphinxhyphen{}3 every queue disc including multiple queues or multiple classes
needs an external filter to classify packets (this is to avoid having the traffic\sphinxhyphen{}control
module depend on other modules such as internet).

Queue disc configuration vary from queue disc to queue disc. A typical taxonomy divides
queue discs in classful (i.e., support classes) and classless (i.e., do not support
classes). More recently, after the appearance of multi\sphinxhyphen{}queue devices (such as Wi\sphinxhyphen{}Fi),
some multi\sphinxhyphen{}queue aware queue discs have been introduced. Multi\sphinxhyphen{}queue aware queue discs
handle as many queues (or queue discs \textendash{} without using classes) as the number of
transmission queues used by the device on which the queue disc is installed.
An attempt is made, also, to classify each packet similarly in the queue disc and within
the device (i.e., to keep the packet classification consistent across layers).

The traffic control layer interacts with a queue disc in a simple manner: after requesting
to enqueue a packet, the traffic control layer requests the qdisc to “run”, i.e., to
dequeue a set of packets, until a predefined number (“quota”) of packets is dequeued
or the netdevice stops the queue disc.  A netdevice shall
stop the queue disc when its transmission queue does not have room for another
packet. Also, a netdevice shall wake the queue disc when it detects that there
is room for another packet in its transmission queue, but the transmission queue
is stopped. Waking a queue disc is equivalent to make it run.

Every queue disc collects statistics about the total number of packets/bytes
received from the upper layers (in case of root queue disc) or from the parent
queue disc (in case of child queue disc), enqueued, dequeued, requeued, dropped,
dropped before enqueue, dropped after dequeue, marked, and stored in the queue disc and
sent to the netdevice or to the parent queue disc. Note that packets that are
dequeued may be requeued, i.e., retained by the traffic control infrastructure,
if the netdevice is not ready to receive them. Requeued packets are not part
of the queue disc. The following identities hold:
\begin{itemize}
\item {} 
dropped = dropped before enqueue + dropped after dequeue

\item {} 
received = dropped before enqueue + enqueued

\item {} 
queued = enqueued \sphinxhyphen{} dequeued

\item {} 
sent = dequeued \sphinxhyphen{} dropped after dequeue (\sphinxhyphen{} 1 if there is a requeued packet)

\end{itemize}

Separate counters are also kept for each possible reason to drop a packet.
When a packet is dropped by an internal queue, e.g., because the queue is full,
the reason is “Dropped by internal queue”. When a packet is dropped by a child
queue disc, the reason is “(Dropped by child queue disc) ” followed by the
reason why the child queue disc dropped the packet.

The QueueDisc base class provides the SojournTime trace source, which provides
the sojourn time of every packet dequeued from a queue disc, including packets
that are dropped or requeued after being dequeued. The sojourn time is taken
when the packet is dequeued from the queue disc, hence it does not account for
the additional time the packet is retained within the queue disc in case it is
requeued.


\subsubsection{Design}
\label{\detokenize{queue-discs:design}}
A C++ abstract base class, class QueueDisc, is subclassed to implement a specific
queue disc. A subclass is required to implement the following methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bool DoEnqueue (Ptr\textless{}QueueDiscItem\textgreater{} item)}}:  Enqueue a packet

\item {} 
\sphinxcode{\sphinxupquote{Ptr\textless{}QueueDiscItem\textgreater{} DoDequeue (void)}}:  Dequeue a packet

\item {} 
\sphinxcode{\sphinxupquote{bool CheckConfig (void) const}}: Check if the configuration is correct

\item {} 
\sphinxcode{\sphinxupquote{void InitializeParams (void)}}: Initialize queue disc parameters

\end{itemize}

and may optionally override the default implementation of the following method:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Ptr\textless{}const QueueDiscItem\textgreater{} DoPeek (void) const}}: Peek the next packet to extract

\end{itemize}

The default implementation of the \sphinxcode{\sphinxupquote{DoPeek}} method is based on the qdisc\_peek\_dequeued
function of the Linux kernel, which dequeues a packet and retains it in the
queue disc as a requeued packet. This approach is recommended
especially for queue discs for which it is not obvious what is the next
packet that will be dequeued (e.g., queue discs having multiple internal
queues or child queue discs or queue discs that drop packets after dequeue).
Therefore, unless the subclass redefines the \sphinxcode{\sphinxupquote{DoPeek}} method, calling \sphinxcode{\sphinxupquote{Peek}} causes
the next packet to be dequeued from the queue disc, though the packet is still
considered to be part of the queue disc and the dequeue trace is fired when
Dequeue is called and the packet is actually extracted from the queue disc.

The C++ base class QueueDisc implements:
\begin{itemize}
\item {} 
methods to add/get a single queue, class or filter and methods to get the number of installed queues, classes or filters

\item {} 
a \sphinxcode{\sphinxupquote{Classify}} method which classifies a packet by processing the list of filters until a filter able to classify the packet is found

\item {} 
methods to extract multiple packets from the queue disc, while handling transmission (to the device) failures by requeuing packets

\end{itemize}

The base class QueueDisc provides many trace sources:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Enqueue}}

\item {} 
\sphinxcode{\sphinxupquote{Dequeue}}

\item {} 
\sphinxcode{\sphinxupquote{Requeue}}

\item {} 
\sphinxcode{\sphinxupquote{Drop}}

\item {} 
\sphinxcode{\sphinxupquote{Mark}}

\item {} 
\sphinxcode{\sphinxupquote{PacketsInQueue}}

\item {} 
\sphinxcode{\sphinxupquote{BytesInQueue}}

\end{itemize}

The C++ base class QueueDisc holds the list of attached queues, classes and filter
by means of three vectors accessible through attributes (InternalQueueList,
QueueDiscClassList and PacketFilterList).

Internal queues are implemented as (subclasses of) Queue objects. A Queue stores
QueueItem objects, which consist of just a Ptr\textless{}Packet\textgreater{}. Since a queue disc has to
store at least the destination address and the protocol number for each enqueued
packet, a new C++ class, QueueDiscItem, is derived from QueueItem to store such
additional information for each packet. Thus, internal queues are implemented as
Queue objects storing QueueDiscItem objects. Also, there could be the need to store
further information depending on the network layer protocol of the packet. For
instance, for IPv4 and IPv6 packets it is needed to separately store the header
and the payload, so that header fields can be manipulated, e.g., to support
Explicit Congestion Notification as defined in RFC 3168.  To this end,
subclasses \sphinxcode{\sphinxupquote{Ipv4QueueDiscItem}} and \sphinxcode{\sphinxupquote{Ipv6QueueDiscItem}} are derived from
\sphinxcode{\sphinxupquote{QueueDiscItem}} to additionally store the IP header and provide protocol
specific operations such as ECN marking.

Classes (in the Linux sense of the term) are implemented via the QueueDiscClass class, which consists of a pointer
to the attached queue disc. Such a pointer is accessible through the QueueDisc attribute.
Classful queue discs needing to set parameters for their classes can subclass
QueueDiscClass and add the required parameters as attributes.

An abstract base class, PacketFilter, is subclassed to implement specific filters.
Subclasses are required to implement two virtual private pure methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bool CheckProtocol (Ptr\textless{}QueueDiscItem\textgreater{} item) const}}: check whether the filter is able to classify packets of the same protocol as the given packet

\item {} 
\sphinxcode{\sphinxupquote{int32\_t DoClassify (Ptr\textless{}QueueDiscItem\textgreater{} item) const}}: actually classify the packet

\end{itemize}

PacketFilter provides a public method, \sphinxcode{\sphinxupquote{Classify}}, which first calls \sphinxcode{\sphinxupquote{CheckProtocol}}
to check that the protocol of the packet matches the protocol of the filter and then
calls \sphinxcode{\sphinxupquote{DoClassify}}. Specific filters subclassed from PacketFilter should not be
placed in the traffic\sphinxhyphen{}control module but in the module corresponding to the protocol
of the classified packets.


\subsection{Usage}
\label{\detokenize{queue-discs:usage}}
The traffic control layer is automatically created and inserted on an \sphinxcode{\sphinxupquote{ns3::Node}} object
when typical device and internet module helpers are used.  By default, the
\sphinxcode{\sphinxupquote{InternetStackHelper::Install()}} method aggregates a TrafficControlLayer object to every
node. When invoked to assign an IPv\{4,6\} address to a device, the Ipv\{4,6\}AddressHelper,
besides creating an Ipv\{4,6\}Interface, also installs the default qdisc
on the device, unless a queue disc has been already installed.
For single\sphinxhyphen{}queue NetDevices (such as PointToPoint, Csma and Simple), the default root
qdisc is FqCoDel. For multi\sphinxhyphen{}queue NetDevices (such as Wifi), the default root qdisc is
Mq with as many FqCoDel child qdiscs as the number of device queues.

To install a queue disc other than the default one, it is necessary to install such queue
disc before an IP address is assigned to the device. Alternatively, the default queue disc
can be removed from the device after assigning an IP address, by using the
Uninstall method of the TrafficControlHelper C++ class, and then installing a different
queue disc on the device.  By uninstalling without adding a new queue disc, it is also possible
to have no queue disc installed on a device.


\subsubsection{Helpers}
\label{\detokenize{queue-discs:helpers}}
A typical usage pattern is to create a traffic control helper and to configure type
and attributes of queue discs, queues, classes and filters from the helper, For example,
the pfifo\_fast can be configured as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TrafficControlHelper} \PYG{n}{tch}\PYG{p}{;}
\PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{handle} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetRootQueueDisc} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::PfifoFastQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddInternalQueues} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::DropTailQueue}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1000p}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{QueueDiscContainer} \PYG{n}{qdiscs} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{devices}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The above code adds three internal queues to the root queue disc of type PfifoFast.
With the above configuration, the config path of the root queue disc installed on the j\sphinxhyphen{}th
device of the i\sphinxhyphen{}th node (the index of a device is the same as in DeviceList) is:

/NodeList/{[}i{]}/\$ns3::TrafficControlLayer/RootQueueDiscList/{[}j{]}

and the config path of the second internal queue is:

/NodeList/{[}i{]}/\$ns3::TrafficControlLayer/RootQueueDiscList/{[}j{]}/InternalQueueList/1

For this helper’s configuration to take effect, it should be added to the ns\sphinxhyphen{}3 program after
\sphinxcode{\sphinxupquote{InternetStackHelper::Install()}} is called, but before IP addresses are configured using
\sphinxcode{\sphinxupquote{Ipv\{4,6\}AddressHelper}}.


\subsection{Implementation details}
\label{\detokenize{queue-discs:implementation-details}}
In Linux, the struct netdev\_queue is used to store information about a single
transmission queue of a device: status (i.e., whether it has been stopped or not),
data used by techniques such as Byte Queue Limits and a qdisc pointer field that
is mainly used to solve the following problems:
\begin{itemize}
\item {} 
if a device transmission queue is (almost) empty, identify the queue disc to wake

\item {} 
if a packet will be enqueued in a given device transmission queue, identify the queue disc which the packet must be enqueued into

\end{itemize}

The latter problem arises because Linux attempts to determine the device transmission
queue which a packet will be enqueued into before passing the packet to a queue disc.
This is done by calling a specific function of the device driver, if implemented, or
by employing fallback mechanisms (such as hashing of the addresses) otherwise. The
identifier of the selected device transmission queue is stored in the queue\_mapping field of the struct sk\_buff, so that both the queue disc and the device driver can
get the same information. In ns\sphinxhyphen{}3, such identifier is stored in a member of the
QueueDiscItem class.

The NetDeviceQueue class in ns\sphinxhyphen{}3 is the equivalent of the Linux struct netdev\_queue.
The qdisc field of the Linux struct netdev\_queue, however, cannot be
similarly stored in a NetDeviceQueue object, because it would make the network module
depend on the traffic\sphinxhyphen{}control module. Instead, this information is stored in the
TrafficControlLayer object aggregated to each node. In particular, a TrafficControlLayer
object holds a struct NetDeviceInfo which stores, for each NetDevice, a pointer to the
root queue disc installed on the device, a pointer to the netdevice queue interface
(see below) aggregated to the device, and a vector of pointers (one for each device
transmission queue) to the queue discs to activate when the above
problems occur. The traffic control layer takes care of configuring such a vector
at initialization time, based on the “wake mode” of the root queue disc. If the
wake mode of the root queue disc is WAKE\_ROOT, then all the elements of the vector
are pointers to the root queue disc. If the wake mode of the root queue disc is
WAKE\_CHILD, then each element of the vector is a pointer to a distinct child queue
disc. This requires that the number of child queue discs matches the number of
netdevice queues. It follows that the wake mode of a classless queue disc must
necessarily be WAKE\_ROOT. These two configurations are illustrated by the figures below.

{\hyperref[\detokenize{queue-discs:fig-classful-queue-disc}]{\sphinxcrossref{\DUrole{std,std-ref}{Setup of a queue disc (wake mode: WAKE\_ROOT)}}}} below shows how the TrafficControlLayer map looks like in
case of a classful root queue disc whose wake mode is WAKE\_ROOT.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{classful-queue-disc}.pdf}
\caption{Setup of a queue disc (wake mode: WAKE\_ROOT)}\label{\detokenize{queue-discs:id1}}\label{\detokenize{queue-discs:fig-classful-queue-disc}}\end{figure}

{\hyperref[\detokenize{queue-discs:fig-multi-queue-aware-queue-disc}]{\sphinxcrossref{\DUrole{std,std-ref}{Setup of a multi\sphinxhyphen{}queue aware queue disc}}}} below shows instead how the TrafficControlLayer
map looks like in case of a classful root queue disc whose wake mode is WAKE\_CHILD.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{multi-queue-aware-queue-disc}.pdf}
\caption{Setup of a multi\sphinxhyphen{}queue aware queue disc}\label{\detokenize{queue-discs:id2}}\label{\detokenize{queue-discs:fig-multi-queue-aware-queue-disc}}\end{figure}

A NetDeviceQueueInterface object is used by the traffic control layer to access the
information stored in the NetDeviceQueue objects, retrieve the number of transmission
queues of the device and get the transmission queue selected for the transmission of a
given packet. A NetDeviceQueueInterface object must be therefore aggregated to all the
devices having an interface supporting the traffic control layer (i.e., an IPv4 or IPv6
interface). In particular:
\begin{itemize}
\item {} 
a NetDeviceQueueInterface object is aggregated to all the devices by the NetDevice
helper classes, at \sphinxcode{\sphinxupquote{Install}} time.  See, for example, the implementation in the
method \sphinxcode{\sphinxupquote{CsmaHelper::InstallPriv()}}.

\item {} 
when notified that a netdevice queue interface has been aggregated, traffic control aware devices can cache the pointer to the netdevice queue interface created by the traffic control layer into a member variable. Also, multi\sphinxhyphen{}queue devices can set the number of device transmission queues and set the select queue callback through the netdevice queue interface

\item {} 
at initialization time, the traffic control (after calling device\sphinxhyphen{}\textgreater{}Initialize () to ensure that the netdevice has set the number of device transmission queues, if it has to do so) completes the installation of the queue discs by setting the wake callbacks on the device transmission queues (through the netdevice queue interface). Also, the traffic control calls the Initialize method of the root queue discs.  This initialization of queue discs triggers calls to the \sphinxcode{\sphinxupquote{CheckConfig}} and \sphinxcode{\sphinxupquote{InitializeParams}} methods of the queue disc.

\end{itemize}


\subsubsection{Requeue}
\label{\detokenize{queue-discs:requeue}}
In Linux, a packet dequeued from a queue disc can be requeued (i.e., stored somewhere
and sent to the device at a later time) in some circumstances. Firstly, the function
used to dequeue a packet (dequeue\_skb) actually dequeues a packet only if the device
is multi\sphinxhyphen{}queue or the (unique) device queue is not stopped. If a packet has been
dequeued from the queue disc, it is passed to the sch\_direct\_xmit function for
transmission to the device. This function checks whether the device queue the packet is destined
to is stopped, in which case the packet is requeued. Otherwise, the packet is sent to the device.
If the device returns NETDEV\_TX\_BUSY, the packet is requeued. However, it is advised that
the function called to send a packet to the device (ndo\_start\_xmit) should always
return NETDEV\_TX\_OK, which means that the packet is consumed by the device driver
and thus needs not to be requeued. However, the ndo\_start\_xmit function of the device
driver is allowed to return NETDEV\_TX\_BUSY (and hence the packet is requeued) when
there is no room for the received packet in the device queue, despite the queue is
not stopped. This case is considered as a corner case or an hard error, and should be avoided.

ns\sphinxhyphen{}3 implements the requeue mechanism in a similar manner, the only difference being
that packets are not requeued when such corner cases occur. Basically, the method used
to dequeue a packet (QueueDisc::DequeuePacket) actually dequeues a packet only if the
device is multi\sphinxhyphen{}queue or the (unique) device queue is not stopped. If a packet has been
dequeued from the queue disc, it is passed to the QueueDisc::Transmit method for
transmission to the device. This method checks whether the device queue the packet is destined
to is stopped, in which case the packet is requeued. Otherwise, the packet is sent to the device.
We request netdevices to stop a device queue when it is not able to store another packet,
so as to avoid the situation in which a packet is received that cannot be enqueued while
the device queue is not stopped. Should such a corner case occur, the netdevice drops
the packet but, unlike Linux, the value returned by NetDevice::Send is ignored and the
packet is not requeued.

The way the requeue mechanism is implemented in ns\sphinxhyphen{}3 has the following implications:
\begin{itemize}
\item {} 
if the underlying device has a single queue, no packet will ever be requeued. Indeed, if the device queue is not stopped when QueueDisc::DequeuePacket is called, it will not be stopped also when QueueDisc::Transmit is called, hence the packet is not requeued (recall that a packet is not requeued after being sent to the device, as the value returned by NetDevice::Send is ignored).

\item {} 
if the underlying device does not implement flow control, i.e., it does not stop its queue(s), no packet will ever be requeued (recall that a packet is only requeued by QueueDisc::Transmit when the device queue the packet is destined to is stopped)

\end{itemize}

It turns out that packets may only be requeued when the underlying device is multi\sphinxhyphen{}queue
and supports flow control.


\section{Fifo queue disc}
\label{\detokenize{fifo:fifo-queue-disc}}\label{\detokenize{fifo::doc}}

\subsection{Model Description}
\label{\detokenize{fifo:model-description}}
FifoQueueDisc implements the FIFO (First\sphinxhyphen{}In First\sphinxhyphen{}Out) policy.
Packets are enqueued in the unique internal queue, which is implemented
as a DropTail queue. The queue disc capacity can be specified in terms of
either packets or bytes, depending on the value of the Mode attribute.

User is allowed to provide an internal queue before the queue disc is initialized.
If no internal queue is provided, one DropTail queue having the same capacity
of the queue disc is created by default. No packet filter can be added to a
FifoQueueDisc.


\subsubsection{Attributes}
\label{\detokenize{fifo:attributes}}
The FifoQueueDisc class holds the following attribute:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The maximum number of packets/bytes the queue disc can hold. The default value is 1000 packets.

\end{itemize}


\subsection{Validation}
\label{\detokenize{fifo:validation}}
The fifo model is tested using \sphinxcode{\sphinxupquote{FifoQueueDiscTestSuite}} class defined
in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/test/fifo\sphinxhyphen{}queue\sphinxhyphen{}disc\sphinxhyphen{}test\sphinxhyphen{}suite.cc}}. The test aims to
check that the capacity of the queue disc is not exceeded and packets are dequeued
in the correct order.


\section{pfifo\_fast queue disc}
\label{\detokenize{pfifo-fast:pfifo-fast-queue-disc}}\label{\detokenize{pfifo-fast::doc}}

\subsection{Model Description}
\label{\detokenize{pfifo-fast:model-description}}
PfifoFastQueueDisc behaves like pfifo\_fast, which is the default queue disc
enabled on Linux systems (init systems such as systemd may override such default
setting). Packets are enqueued in three priority bands (implemented
as FIFO droptail queues) based on their priority (users can read
{\hyperref[\detokenize{sockets-api:socket-options}]{\sphinxcrossref{\DUrole{std,std-ref}{Socket options}}}} for details on how to set packet priority).
The four least significant bits of the priority are used to determine
the selected band according to the following table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Priority \& 0xf
&\sphinxstyletheadfamily 
Band
\\
\hline
0
&
1
\\
\hline
1
&
2
\\
\hline
2
&
2
\\
\hline
3
&
2
\\
\hline
4
&
1
\\
\hline
5
&
2
\\
\hline
6
&
0
\\
\hline
7
&
0
\\
\hline
8
&
1
\\
\hline
9
&
1
\\
\hline
10
&
1
\\
\hline
11
&
1
\\
\hline
12
&
1
\\
\hline
13
&
1
\\
\hline
14
&
1
\\
\hline
15
&
1
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The system behaves similar to three ns3::DropTail queues operating
together, in which packets from higher priority bands are always
dequeued before a packet from a lower priority band is dequeued.

The queue disc capacity, i.e., the maximum number of packets that can
be enqueued in the queue disc, is set through the MaxSize attribute, which
plays the same role as txqueuelen in Linux. If no internal queue is
provided, three DropTail queues having each a capacity equal to MaxSize are
created by default. User is allowed to provide queues, but they must be
three, operate in packet mode and each have a capacity not less
than MaxSize. No packet filter can be added to a PfifoFastQueueDisc.


\subsubsection{Attributes}
\label{\detokenize{pfifo-fast:attributes}}
The PfifoFastQueueDisc class holds a single attribute:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The maximum number of packets accepted by the queue disc. The default value is 1000.

\end{itemize}


\subsubsection{Examples}
\label{\detokenize{pfifo-fast:examples}}
Various examples located in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples}} (e.g., codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric.cc)
shows how to configure and install a PfifoFastQueueDisc on internet nodes.


\subsection{Validation}
\label{\detokenize{pfifo-fast:validation}}
The pfifo\_fast model is tested using \sphinxcode{\sphinxupquote{PfifoFastQueueDiscTestSuite}} class defined
in \sphinxcode{\sphinxupquote{src/test/ns3tc/pfifo\sphinxhyphen{}fast\sphinxhyphen{}queue\sphinxhyphen{}disc\sphinxhyphen{}test\sphinxhyphen{}suite.cc}}. The suite includes 4 test cases:
\begin{itemize}
\item {} 
Test 1: The first test checks whether IPv4 packets are enqueued in the correct band based on the TOS byte

\item {} 
Test 2: The second test checks whether IPv4 packets are enqueued in the correct band based on the TOS byte

\item {} 
Test 3: The third test checks that the queue disc cannot enqueue more packets than its limit

\item {} 
Test 4: The fourth test checks that packets that the filters have not been able to classify are enqueued into the default band of 1

\end{itemize}


\section{Prio queue disc}
\label{\detokenize{prio:prio-queue-disc}}\label{\detokenize{prio::doc}}

\subsection{Model Description}
\label{\detokenize{prio:model-description}}
PrioQueueDisc implements a strict priority policy, where packets are dequeued from
a band only if higher priority bands are all empty. PrioQueueDisc is a classful
queue disc and can have an arbitrary number of bands, each of which is handled by a
queue disc of any kind. The capacity of PrioQueueDisc is not limited; packets can
only be dropped by child queue discs (which may have a limited capacity).
If no packet filter is installed or able to classify a packet, then the
packet is enqueued into a priority band based on its priority (modulo 16), which
is used as an index into an array called priomap. Users can read {\hyperref[\detokenize{sockets-api:socket-options}]{\sphinxcrossref{\DUrole{std,std-ref}{Socket options}}}}
for details on how to set the packet priority. If a packet is classified
by an installed packet filter and the returned value \sphinxcode{\sphinxupquote{i}} is non\sphinxhyphen{}negative and less than the
number of priority bands, then the packet is enqueued into the \sphinxcode{\sphinxupquote{i}}\sphinxhyphen{}th priority band.
Otherwise, the packet is enqueued into the priority band specified by the first element
of the priomap array.

If no queue disc class is added by the user before the queue disc is initialized,
three child queue discs of type FifoQueueDisc are automatically added. It has to
be noted that PrioQueueDisc needs at least two child queue discs.


\subsubsection{Attributes}
\label{\detokenize{prio:attributes}}
The PrioQueueDisc class holds the following attribute:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Priomap:}} The priority to band mapping. The default value is the same mapping as the (fixed) one used by PfifoFastQueueDisc.

\end{itemize}


\subsubsection{Examples}
\label{\detokenize{prio:examples}}
An example of how to configure PrioQueueDisc with custom child queue discs and priomap
is provided by \sphinxtitleref{queue\sphinxhyphen{}discs\sphinxhyphen{}benchmark.cc} located in \sphinxcode{\sphinxupquote{examples/traffic\sphinxhyphen{}control}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TrafficControlHelper} \PYG{n}{tch}\PYG{p}{;}
\PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{handle} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetRootQueueDisc} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::PrioQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Priomap}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{TrafficControlHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ClassIdList} \PYG{n}{cid} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddQueueDiscClasses} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::QueueDiscClass}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddChildQueueDisc} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{n}{cid}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::FifoQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddChildQueueDisc} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{n}{cid}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The code above adds two classes (bands) to a PrioQueueDisc. The highest priority one
is a FifoQueueDisc, the other one is a RedQueueDisc. The attribute Priomap is set to
an array containing only 0 and 1 (since PrioQueueDisc only has two bands).


\subsection{Validation}
\label{\detokenize{prio:validation}}
PrioQueueDisc is tested using \sphinxcode{\sphinxupquote{PrioQueueDiscTestSuite}} class defined
in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/test/prio\sphinxhyphen{}queue\sphinxhyphen{}disc\sphinxhyphen{}test\sphinxhyphen{}suite.cc}}. The test aims to
check that: i) packets are enqueued in the correct band based on their priority and
the priomap or according to the value returned by the installed packet filter;
ii) packets are dequeued in the correct order.

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests
\PYGZdl{} ./waf build
\PYGZdl{} ./test.py \PYGZhy{}s prio\PYGZhy{}queue\PYGZhy{}disc
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nv}{NS\PYGZus{}LOG}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}PrioQueueDisc\PYGZdq{}} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}test\PYGZhy{}runner \PYGZhy{}\PYGZhy{}suite=prio\PYGZhy{}queue\PYGZhy{}disc\PYGZdq{}}
\end{sphinxVerbatim}


\section{TBF queue disc}
\label{\detokenize{tbf:tbf-queue-disc}}\label{\detokenize{tbf::doc}}
This chapter describes the TBF (\sphinxcite{tbf:ref1}) queue disc implementation
in \sphinxstyleemphasis{ns\sphinxhyphen{}3}. The TBF model in ns\sphinxhyphen{}3 is ported based on Linux kernel code implemented by
A. Kuznetsov and D. Torokhov.

TBF is a qdisc that allows controlling the bandwidth of the output according
to a set rate with the possibility of managing burst conditions also. The TBF implementation
consists of a bucket (buffer) having a limited capacity into which tokens (normally representing a
unit of bytes or a single packet of predetermined size) are added at a fixed rate ‘r’ called the
token rate. Whenever a packet arrives into the tx queue (fifo by default), the bucket is checked
to see if there are appropriate number of tokens that is equivalent to the length of the packet in
bytes. If yes, then the tokens are removed and the packet is passed for transmission. If no, then
packets will have to wait until there are sufficient tokens in the bucket. This data conformance
can be thus put into three possible scenarios \sphinxcite{tbf:ref3}:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Data rate = Token rate : Packets pass without delay.

\item {} 
Data rate \textless{} Token rate : The tokens might accumulate and the bucket might become
full. Then, the next packets to enter TBF will be transmitted right away without
having any limit applied to them, until the bucket is empty. This is called a burst
condition and in TBF the burst parameter defines the size of the bucket. In order
to overcome this problem and provide better control over the bursts, TBF
implements a second bucket which is smaller and generally the same size as the
MTU. This second bucket cannot store large amount of tokens, but its
replenishing rate will be a lot faster than the one of the big bucket. This second
rate is called ‘peakRate’ and it will determine the maximum rate of a burst.

\item {} 
Data rate \textgreater{} Token rate : This causes the TBF algorithm to throttle itself for a while as
soon as the bucket gets empty. This is called an ‘overlimit situation’ \sphinxcite{tbf:ref2}. In this situation,
some of the packets will be blocked until enough tokens are available at which time a schedule for
the waking of the queue will be done. If packets keep coming in, at a larger rate, then the
packets will start to get dropped when the total number of bytes exceeds the QueueLimit.

\end{enumerate}


\subsection{Model Description}
\label{\detokenize{tbf:model-description}}
The TBF queue disc does not require packet filters, does not admit internal queues
and uses a single child queue disc. If the user does not provide a child queue disc,
a Fifo queue disc operating in the same mode (packet or byte) as the TBF queue disc
and having a size equal to the TBF QueueLimit attribute is created. Otherwise, the
capacity of the TBF queue disc is determined by the capacity of the child queue disc.

There are two token buckets: first bucket and second bucket. The size of the
first bucket called ‘Burst’ should always be greater than the size of the second
bucket called the Mtu (which is usually the size of a single packet). But the
‘PeakRate’ which is the second bucket’s token rate should be always greater than
the ‘Rate’ which is the first bucket’s token rate.

If the PeakRate is zero, then the second bucket does not exist. In order to activate
the second bucket, both the Mtu and PeakRate values have to be greater than zero. If
the Mtu value is zero at initialization time, then if a NetDevice exits, the Mtu’s
value will be equal to the Mtu of the NetDevice. But if no NetDevice exists, then
the QueueDisc will complain thus prompting the user to set the Mtu value.

The source code for the TBF model is located in the directory \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/model}}
and consists of 2 files \sphinxtitleref{tbf\sphinxhyphen{}queue\sphinxhyphen{}disc.h} and \sphinxtitleref{tbf\sphinxhyphen{}queue\sphinxhyphen{}disc.cc} defining a TbfQueueDisc
class.
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{TbfQueueDisc}}: This class implements the main TBF algorithm:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{TbfQueueDisc::DoEnqueue ()}}: This routine enqueue’s the incoming packet if the queue is not full and drops the packet otherwise.

\item {} 
\sphinxcode{\sphinxupquote{TbfQueueDisc::DoPeek ()}}: This routine peeks for the top item in the queue and if the queue is not empty, it returns the topmost item.

\item {} 
\sphinxcode{\sphinxupquote{TbfQueueDisc::DoDequeue ()}}: This routine performs the dequeuing of packets according to the following logic:
\begin{itemize}
\item {} 
It calls \sphinxcode{\sphinxupquote{TbfQueueDisc::Peek ()}} and calculates the size of the packet to be dequeued in bytes.

\item {} 
Then it calculates the time difference ‘delta’, which is the time elapsed since the last update of tokens in the buckets.

\item {} 
If the second bucket exists, the number of tokens are updated according to the ‘PeakRate’ and ‘delta’.

\item {} 
From this second bucket a number of tokens equal to the size of the packet to be dequeued is subtracted.

\item {} 
Now the number of tokens in the first bucket are updated according to ‘Rate’ and ‘delta’.

\item {} 
From this first bucket a number of tokens equal to the size of the packet to be dequeued is subtracted.

\item {} 
If after this, both the first and second buckets have tokens greater than zero, then the packet is dequeued.

\item {} 
Else, an event to \sphinxcode{\sphinxupquote{QueueDisc::Run ()}} is scheduled after a time period when enough tokens will be present for the dequeue operation.

\end{itemize}

\end{itemize}

\end{itemize}


\subsubsection{References}
\label{\detokenize{tbf:references}}

\subsubsection{Attributes}
\label{\detokenize{tbf:attributes}}
The key attributes that the TbfQueueDisc class holds include the following:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The maximum number of packets/bytes the queue disc can hold. The default value is 1000 packets.

\item {} 
\sphinxcode{\sphinxupquote{Burst:}} Size of the first bucket, in bytes. The default value is 125000 bytes.

\item {} 
\sphinxcode{\sphinxupquote{Mtu:}} Size of second bucket defaults to the MTU of the attached NetDevice, if any, or 0 otherwise.

\item {} 
\sphinxcode{\sphinxupquote{Rate:}} Rate at which tokens enter the first bucket. The default value is 125KB/s.

\item {} 
\sphinxcode{\sphinxupquote{PeakRate:}} Rate at which tokens enter the second bucket. The default value is 0KB/s, which means that there is no second bucket.

\end{itemize}


\subsubsection{TraceSources}
\label{\detokenize{tbf:tracesources}}
The TbfQueueDisc class provides the following trace sources:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{TokensInFirstBucket:}} Number of First Bucket Tokens in bytes

\item {} 
\sphinxcode{\sphinxupquote{TokensInSecondBucket:}} Number of Second Bucket Tokens in bytes

\end{itemize}


\subsubsection{Examples}
\label{\detokenize{tbf:examples}}
The example for TBF is \sphinxtitleref{tbf\sphinxhyphen{}example.cc} located in \sphinxcode{\sphinxupquote{examples/traffic\sphinxhyphen{}control/}}.  The command to run the file (the invocation below shows the available command\sphinxhyphen{}line options) is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{.}\PYG{p}{.} \PYG{n}{sourcecode}\PYG{o}{:}\PYG{o}{:} \PYG{n}{bash}
\end{sphinxVerbatim}
\begin{quote}

\$ ./waf \textendash{}run “tbf\sphinxhyphen{}example \textendash{}PrintHelp”
\$ ./waf \textendash{}run “tbf\sphinxhyphen{}example \textendash{}burst=125000 \textendash{}rate=1Mbps \textendash{}peakRate=1.5Mbps”
\end{quote}

The expected output from the previous commands are traced value changes in the number of tokens in the first and second buckets.


\subsection{Validation}
\label{\detokenize{tbf:validation}}
The TBF model is tested using \sphinxcode{\sphinxupquote{TbfQueueDiscTestSuite}} class defined in \sphinxtitleref{src/traffic\sphinxhyphen{}control/test/tbf\sphinxhyphen{}queue\sphinxhyphen{}disc\sphinxhyphen{}test\sphinxhyphen{}suite.cc}. The suite includes 4 test cases:
\begin{itemize}
\item {} 
Test 1: Simple Enqueue/Dequeue with verification of attribute setting and subtraction of tokens from the buckets.

\item {} 
Test 2: When DataRate == FirstBucketTokenRate; packets should pass smoothly.

\item {} 
Test 3: When DataRate \textgreater{}\textgreater{}\textgreater{} FirstBucketTokenRate; some packets should get blocked and waking of queue should get scheduled.

\item {} 
Test 4: When DataRate \textless{} FirstBucketTokenRate; burst condition, peakRate is set so that bursts are controlled.

\end{itemize}

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{.}\PYG{p}{.} \PYG{n}{sourcecode}\PYG{o}{:}\PYG{o}{:} \PYG{n}{bash}
\end{sphinxVerbatim}
\begin{quote}

\$ ./waf configure \textendash{}enable\sphinxhyphen{}examples \textendash{}enable\sphinxhyphen{}tests
\$ ./waf build
\$ ./test.py \sphinxhyphen{}s tbf\sphinxhyphen{}queue\sphinxhyphen{}disc
\end{quote}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{.}\PYG{p}{.} \PYG{n}{sourcecode}\PYG{o}{:}\PYG{o}{:} \PYG{n}{bash}
\end{sphinxVerbatim}
\begin{quote}

\$ NS\_LOG=”TbfQueueDisc” ./waf \textendash{}run “test\sphinxhyphen{}runner \textendash{}suite=tbf\sphinxhyphen{}queue\sphinxhyphen{}disc”
\end{quote}


\section{RED queue disc}
\label{\detokenize{red:red-queue-disc}}\label{\detokenize{red::doc}}

\subsection{Model Description}
\label{\detokenize{red:model-description}}
Random Early Detection (RED) is a queue discipline that aims to provide
early signals to transport protocol congestion control (e.g. TCP) that
congestion is imminent, so that they back off their rate gracefully
rather than with a bunch of tail\sphinxhyphen{}drop losses (possibly incurring
TCP timeout).  The model in ns\sphinxhyphen{}3 is a port of Sally Floyd’s ns\sphinxhyphen{}2
RED model.

Note that, starting from ns\sphinxhyphen{}3.25, RED is no longer a queue variant and
cannot be installed as a NetDevice queue. Instead, RED is a queue disc
and must be installed in the context of the traffic control (see the
examples mentioned below).

The RED queue disc does not require packet filters, does not admit
child queue discs and uses a single internal queue. If not provided by
the user, a DropTail queue operating in the same mode (packet or byte)
as the queue disc and having a size equal to the RED MaxSize attribute
is created. Otherwise, the capacity of the queue disc is determined by
the capacity of the internal queue provided by the user.


\subsubsection{Adaptive Random Early Detection (ARED)}
\label{\detokenize{red:adaptive-random-early-detection-ared}}
ARED is a variant of RED with two main features: (i) automatically sets Queue
weight, MinTh and MaxTh and (ii) adapts maximum drop probability. The model
in ns\sphinxhyphen{}3 contains implementation of both the features, and is a port of Sally
Floyd’s ns\sphinxhyphen{}2 ARED model. Note that the user is allowed to choose and explicitly
configure the simulation by selecting feature (i) or feature (ii), or both.


\subsubsection{Feng’s Adaptive RED}
\label{\detokenize{red:feng-s-adaptive-red}}
Feng’s Adaptive RED is a variant of RED that adapts the maximum drop
probability. The model in ns\sphinxhyphen{}3 contains implementation of this feature, and is a
port of ns\sphinxhyphen{}2 Feng’s Adaptive RED model.


\subsubsection{Nonlinear Random Early Detection (NLRED)}
\label{\detokenize{red:nonlinear-random-early-detection-nlred}}
NLRED is a variant of RED in which the linear packet dropping function of
RED is replaced by a nonlinear quadratic function. This approach makes packet
dropping gentler for light traffic load and aggressive for heavy traffic load.


\subsubsection{Explicit Congestion Notification (ECN)}
\label{\detokenize{red:explicit-congestion-notification-ecn}}
This RED model supports an ECN mode of operation to notify endpoints of
congestion that may be developing in a bottleneck queue, without resorting
to packet drops. Such a mode is enabled by setting the UseEcn attribute to
true (it is false by default) and only affects incoming packets with the
ECT bit set in their header. When the average queue length is between the
minimum and maximum thresholds, an incoming packet is marked instead of being
dropped. When the average queue length is above the maximum threshold, an
incoming packet is marked (instead of being dropped) only if the UseHardDrop
attribute is set to false (it is true by default).

The implementation of support for ECN marking is done in such a way as
to not impose an internet module dependency on the traffic control module.
The RED model does not directly set ECN bits on the header, but delegates
that job to the QueueDiscItem class.  As a result, it is possible to
use RED queues for other non\sphinxhyphen{}IP QueueDiscItems that may or may not support
the \sphinxcode{\sphinxupquote{Mark ()}} method.


\subsubsection{References}
\label{\detokenize{red:references}}
The RED queue disc aims to be close to the results cited in:
S.Floyd, K.Fall \sphinxurl{http://icir.org/floyd/papers/redsims.ps}

ARED queue implementation is based on the algorithm provided in:
S. Floyd et al, \sphinxurl{http://www.icir.org/floyd/papers/adaptiveRed.pdf}

Feng’s Adaptive RED queue implementation is based on the algorithm
provided in:
W. C. Feng et al, \sphinxurl{http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=752150}

NLRED queue implementation is based on the algorithm provided in:
Kaiyu Zhou et al, \sphinxurl{http://www.sciencedirect.com/science/article/pii/S1389128606000879}

The addition of explicit congestion notification (ECN) to IP:
K. K. Ramakrishnan et al, \sphinxurl{https://tools.ietf.org/html/rfc3168}


\subsubsection{Attributes}
\label{\detokenize{red:attributes}}
The RED queue contains a number of attributes that control the RED
policies:
\begin{itemize}
\item {} 
MaxSize

\item {} 
MeanPktSize

\item {} 
IdlePktSize

\item {} 
Wait (time)

\item {} 
Gentle mode

\item {} 
MinTh, MaxTh

\item {} 
Queue weight

\item {} 
LInterm

\item {} 
LinkBandwidth

\item {} 
LinkDelay

\item {} 
UseEcn

\item {} 
UseHardDrop

\end{itemize}

In addition to RED attributes, ARED queue requires following attributes:
\begin{itemize}
\item {} 
ARED (Boolean attribute. Default: false)

\item {} 
AdaptMaxP (Boolean attribute to adapt m\_curMaxP. Default: false)

\item {} 
Target Delay (time)

\item {} 
Interval (time)

\item {} 
LastSet (time)

\item {} 
Top (upper limit of m\_curMaxP)

\item {} 
Bottom (lower limit of m\_curMaxP)

\item {} 
Alpha (increment parameter for m\_curMaxP)

\item {} 
Beta (decrement parameter for m\_curMaxP)

\item {} 
RTT

\end{itemize}

In addition to RED attributes, Feng’s Adaptive RED queue requires following
attributes:
\begin{itemize}
\item {} 
FengAdaptive  (Boolean attribute, Default: false)

\item {} 
Status        (status of current queue length, Default: Above)

\item {} 
FengAlpha     (increment parameter for m\_curMaxP, Default: 3)

\item {} 
FengBeta      (decrement parameter for m\_curMaxP, Default: 2)

\end{itemize}

The following attribute should be turned on to simulate NLRED queue disc:
\begin{itemize}
\item {} 
NLRED (Boolean attribute. Default: false)

\end{itemize}

Consult the ns\sphinxhyphen{}3 documentation for explanation of these attributes.


\subsubsection{Simulating ARED}
\label{\detokenize{red:simulating-ared}}
To switch on ARED algorithm, the attribute ARED must be set to true,
as done in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/adaptive\sphinxhyphen{}red\sphinxhyphen{}tests.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::ARED}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Setting ARED to true implicitly configures both: (i) automatic setting
of Queue weight, MinTh and MaxTh and (ii) adapting m\_curMaxP.

NOTE: To explicitly configure (i) or (ii), set ARED attribute to false
and follow the procedure described next:

To configure (i); Queue weight, MinTh and MaxTh, all must be set to 0,
as done in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/adaptive\sphinxhyphen{}red\sphinxhyphen{}tests.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::QW}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::MinTh}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::MaxTh}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

To configure (ii); AdaptMaxP must be set to true, as done in
\sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/adaptive\sphinxhyphen{}red\sphinxhyphen{}tests.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::AdaptMaxP}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Simulating Feng’s Adaptive RED}
\label{\detokenize{red:simulating-feng-s-adaptive-red}}
To switch on Feng’s Adaptive RED algorithm, the attribute FengAdaptive must be
set to true, as done in \sphinxcode{\sphinxupquote{examples/traffic\sphinxhyphen{}control/red\sphinxhyphen{}vs\sphinxhyphen{}fengadaptive.cc}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::FengAdaptive}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Simulating NLRED}
\label{\detokenize{red:simulating-nlred}}
To switch on NLRED algorithm, the attribute NLRED must be set to true,
as shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::RedQueueDisc::NLRED}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Examples}
\label{\detokenize{red:examples}}
The RED queue example is found at \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/red\sphinxhyphen{}tests.cc}}.

ARED queue examples can be found at:
\sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/adaptive\sphinxhyphen{}red\sphinxhyphen{}tests.cc}} and
\sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples/red\sphinxhyphen{}vs\sphinxhyphen{}ared.cc}}

Feng’s Adaptive RED example can be found at:
\sphinxcode{\sphinxupquote{examples/traffic\sphinxhyphen{}control/red\sphinxhyphen{}vs\sphinxhyphen{}fengadaptive.cc}}

NLRED queue example can be found at:
\sphinxcode{\sphinxupquote{examples/traffic\sphinxhyphen{}control/red\sphinxhyphen{}vs\sphinxhyphen{}nlred.cc}}


\subsection{Validation}
\label{\detokenize{red:validation}}
The RED model has been validated and the report is currently stored
at: \sphinxurl{https://github.com/downloads/talau/ns-3-tcp-red/report-red-ns3.pdf}


\section{CoDel queue disc}
\label{\detokenize{codel:codel-queue-disc}}\label{\detokenize{codel::doc}}
This chapter describes the CoDel (\sphinxcite{codel:nic12}, \sphinxcite{codel:nic14}) queue disc implementation
in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

Developed by Kathleen Nichols and Van Jacobson as a solution to the
bufferbloat \sphinxcite{codel:buf14} problem, CoDel (Controlled Delay Management) is a queuing
discipline that uses a packet’s sojourn time (time in queue) to make
decisions on packet drops.

Note that, starting from ns\sphinxhyphen{}3.25, CoDel is no longer a queue variant and
cannot be installed as a NetDevice queue. Instead, CoDel is a queue disc
and must be installed in the context of the traffic control (see the
examples mentioned below).


\subsection{Model Description}
\label{\detokenize{codel:model-description}}
The source code for the CoDel model is located in the directory \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/model}}
and consists of 2 files \sphinxtitleref{codel\sphinxhyphen{}queue\sphinxhyphen{}disc.h} and \sphinxtitleref{codel\sphinxhyphen{}queue\sphinxhyphen{}disc.cc} defining a CoDelQueueDisc
class and a helper CoDelTimestampTag class. The code was ported to \sphinxstyleemphasis{ns\sphinxhyphen{}3} by
Andrew McGregor based on Linux kernel code implemented by Dave Täht and Eric Dumazet.
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{CoDelQueueDisc}}: This class implements the main CoDel algorithm:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{CoDelQueueDisc::DoEnqueue ()}}: This routine tags a packet with the current time before pushing it into the queue.  The timestamp tag is used by \sphinxcode{\sphinxupquote{CoDelQueue::DoDequeue()}} to compute the packet’s sojourn time.  If the queue is full upon the packet arrival, this routine will drop the packet and record the number of drops due to queue overflow, which is stored in \sphinxtitleref{m\_dropOverLimit}.

\item {} 
\sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}}: This routine is \sphinxcode{\sphinxupquote{CoDelQueueDisc::DoDequeue()}}’s helper routine that determines whether a packet should be dropped or not based on its sojourn time.  If the sojourn time goes above \sphinxtitleref{m\_target} and remains above continuously for at least \sphinxtitleref{m\_interval}, the routine returns \sphinxcode{\sphinxupquote{true}} indicating that it is OK to drop the packet. Otherwise, it returns \sphinxcode{\sphinxupquote{false}}.

\item {} 
\sphinxcode{\sphinxupquote{CoDelQueueDisc::DoDequeue ()}}: This routine performs the actual packet drop based on \sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}}’s return value and schedules the next drop.

\end{itemize}

\item {} 
class \sphinxcode{\sphinxupquote{CoDelTimestampTag}}: This class implements the timestamp tagging for a packet.  This tag is used to compute the packet’s sojourn time (the difference between the time the packet is dequeued and the time it is pushed into the queue).

\end{itemize}

There are 2 branches to \sphinxcode{\sphinxupquote{CoDelQueueDisc::DoDequeue ()}}:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
If the queue is currently in the dropping state, which means the sojourn time has remained above \sphinxtitleref{m\_target} for more than \sphinxtitleref{m\_interval}, the routine determines if it’s OK to leave the dropping state or it’s time for the next drop. When \sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}} returns \sphinxcode{\sphinxupquote{false}}, the queue can move out of the dropping state (set \sphinxtitleref{m\_dropping} to \sphinxcode{\sphinxupquote{false}}).  Otherwise, the queue continuously drops packets and updates the time for next drop (\sphinxtitleref{m\_dropNext}) until one of the following conditions is met:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumii}{enumiii}{}{.}%
\item {} 
The queue is empty, upon which the queue leaves the dropping state and exits \sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}} routine;

\item {} 
\sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}} returns \sphinxcode{\sphinxupquote{false}} (meaning the sojourn time goes below \sphinxtitleref{m\_target}) upon which the queue leaves the dropping state;

\item {} 
It is not yet time for next drop (\sphinxtitleref{m\_dropNext} is less than current time) upon which the queue waits for the next packet dequeue to check the condition again.

\end{enumerate}

\item {} 
If the queue is not in the dropping state, the routine enters the dropping state and drop the first packet if \sphinxcode{\sphinxupquote{CoDelQueueDisc::ShouldDrop ()}} returns \sphinxcode{\sphinxupquote{true}} (meaning the sojourn time has gone above \sphinxtitleref{m\_target} for at least \sphinxtitleref{m\_interval} for the first time or it has gone above again after the queue leaves the dropping state).

\end{enumerate}

The CoDel queue disc does not require packet filters, does not admit
child queue discs and uses a single internal queue. If not provided by
the user, a DropTail queue operating in the same mode (packet or byte)
as the queue disc and having a size equal to the CoDel MaxSize attribute
is created. Otherwise, the capacity of the queue disc is determined by
the capacity of the internal queue provided by the user.


\subsubsection{References}
\label{\detokenize{codel:references}}

\subsubsection{Attributes}
\label{\detokenize{codel:attributes}}
The key attributes that the CoDelQueue class holds include the following:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The maximum number of packets/bytes the queue can hold. The default value is 1500 * DEFAULT\_CODEL\_LIMIT, which is 1500 * 1000 bytes.

\item {} 
\sphinxcode{\sphinxupquote{MinBytes:}} The CoDel algorithm minbytes parameter. The default value is 1500 bytes.

\item {} 
\sphinxcode{\sphinxupquote{Interval:}} The sliding\sphinxhyphen{}minimum window. The default value is 100 ms.

\item {} 
\sphinxcode{\sphinxupquote{Target:}} The CoDel algorithm target queue delay. The default value is 5 ms.

\end{itemize}


\subsubsection{Examples}
\label{\detokenize{codel:examples}}
The first example is \sphinxtitleref{codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}basic\sphinxhyphen{}test.cc} located in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples}}.  To run the file (the first invocation below shows the available
command\sphinxhyphen{}line options):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}codel\PYGZhy{}vs\PYGZhy{}pfifo\PYGZhy{}basic\PYGZhy{}test \PYGZhy{}\PYGZhy{}PrintHelp\PYGZdq{}}
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}codel\PYGZhy{}vs\PYGZhy{}pfifo\PYGZhy{}basic\PYGZhy{}test \PYGZhy{}\PYGZhy{}queueType=CoDel \PYGZhy{}\PYGZhy{}pcapFileName=codel.pcap \PYGZhy{}\PYGZhy{}cwndTrFileName=cwndCodel.tr\PYGZdq{}}
\end{sphinxVerbatim}

The expected output from the previous commands are two files: \sphinxtitleref{codel.pcap} file and \sphinxtitleref{cwndCoDel.tr} (ASCII trace) file The .pcap file can be analyzed using
wireshark or tcptrace:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} tcptrace \PYGZhy{}l \PYGZhy{}r \PYGZhy{}n \PYGZhy{}W codel.pcap
\end{sphinxVerbatim}

The second example is \sphinxtitleref{codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric.cc} located in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples}}.  This example is intended to model a typical cable modem
deployment scenario.  To run the file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}codel\PYGZhy{}vs\PYGZhy{}pfifo\PYGZhy{}asymmetric \PYGZhy{}\PYGZhy{}PrintHelp\PYGZdq{}}
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run codel\PYGZhy{}vs\PYGZhy{}pfifo\PYGZhy{}asymmetric
\end{sphinxVerbatim}

The expected output from the previous commands is six pcap files:
\begin{itemize}
\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}server\sphinxhyphen{}lan.pcap

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}router\sphinxhyphen{}wan.pcap

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}router\sphinxhyphen{}lan.pcap

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}cmts\sphinxhyphen{}wan.pcap

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}cmts\sphinxhyphen{}lan.pcap

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}host\sphinxhyphen{}lan.pcap

\end{itemize}

One attribute file:
\begin{itemize}
\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel.attr

\end{itemize}

Five ASCII trace files:
\begin{itemize}
\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}drop.tr

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}drop\sphinxhyphen{}state.tr

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}sojourn.tr

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}length.tr

\item {} 
codel\sphinxhyphen{}vs\sphinxhyphen{}pfifo\sphinxhyphen{}asymmetric\sphinxhyphen{}CoDel\sphinxhyphen{}cwnd.tr

\end{itemize}


\subsection{Validation}
\label{\detokenize{codel:validation}}
The CoDel model is tested using \sphinxcode{\sphinxupquote{CoDelQueueDiscTestSuite}} class defined in \sphinxtitleref{src/traffic\sphinxhyphen{}control/test/codel\sphinxhyphen{}queue\sphinxhyphen{}test\sphinxhyphen{}suite.cc}.  The suite includes 5 test cases:
\begin{itemize}
\item {} 
Test 1: The first test checks the enqueue/dequeue with no drops and makes sure that CoDel attributes can be set correctly.

\item {} 
Test 2: The second test checks the enqueue with drops due to queue overflow.

\item {} 
Test 3: The third test checks the NewtonStep() arithmetic against explicit port of Linux implementation

\item {} 
Test 4: The fourth test checks the ControlLaw() against explicit port of Linux implementation

\item {} 
Test 5: The fifth test checks the enqueue/dequeue with drops according to CoDel algorithm

\end{itemize}

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests
\PYGZdl{} ./waf build
\PYGZdl{} ./test.py \PYGZhy{}s codel\PYGZhy{}queue\PYGZhy{}disc
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nv}{NS\PYGZus{}LOG}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}CoDelQueueDisc\PYGZdq{}} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}test\PYGZhy{}runner \PYGZhy{}\PYGZhy{}suite=codel\PYGZhy{}queue\PYGZhy{}disc\PYGZdq{}}
\end{sphinxVerbatim}


\section{FqCoDel queue disc}
\label{\detokenize{fq-codel:fqcodel-queue-disc}}\label{\detokenize{fq-codel::doc}}
This chapter describes the FqCoDel (\sphinxcite{fq-codel:hoe16}) queue disc implementation in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

The FlowQueue\sphinxhyphen{}CoDel (FQ\sphinxhyphen{}CoDel) algorithm is a combined packet scheduler and
Active Queue Management (AQM) algorithm developed as part of the
bufferbloat\sphinxhyphen{}fighting community effort (\sphinxcite{fq-codel:buf16}).
FqCoDel classifies incoming packets into different queues (by default, 1024
queues are created), which are served according to a modified Deficit Round
Robin (DRR) queue scheduler. Each queue is managed by the CoDel AQM algorithm.
FqCoDel distinguishes between “new” queues (which don’t build up a standing
queue) and “old” queues, that have queued enough data to be around for more
than one iteration of the round\sphinxhyphen{}robin scheduler.

FqCoDel is installed by default on single\sphinxhyphen{}queue NetDevices (such as PointToPoint,
Csma and Simple). Also, on multi\sphinxhyphen{}queue devices (such as Wifi), the default root
qdisc is Mq with as many FqCoDel child queue discs as the number of device queues.


\subsection{Model Description}
\label{\detokenize{fq-codel:model-description}}
The source code for the FqCoDel queue disc is located in the directory
\sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/model}} and consists of 2 files \sphinxtitleref{fq\sphinxhyphen{}codel\sphinxhyphen{}queue\sphinxhyphen{}disc.h}
and \sphinxtitleref{fq\sphinxhyphen{}codel\sphinxhyphen{}queue\sphinxhyphen{}disc.cc} defining a FqCoDelQueueDisc class and a helper
FqCoDelFlow class. The code was ported to \sphinxstyleemphasis{ns\sphinxhyphen{}3} based on Linux kernel code
implemented by Eric Dumazet.
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{FqCoDelQueueDisc}}: This class implements the main FqCoDel algorithm:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{FqCoDelQueueDisc::DoEnqueue ()}}: If no packet filter has been configured, this routine calls the QueueDiscItem::Hash() method to classify the given packet into an appropriate queue. Otherwise, the configured filters are used to classify the packet. If the filters are unable to classify the packet, the packet is dropped. Otherwise, it is handed over to the CoDel algorithm for timestamping. Then, if the queue is not currently active (i.e., if it is not in either the list of new or the list of old queues), it is added to the end of the list of new queues, and its deficit is initiated to the configured quantum. Otherwise,  the queue is left in its current queue list. Finally, the total number of enqueued packets is compared with the configured limit, and if it is above this value (which can happen since a packet was just enqueued), packets are dropped from the head of the queue with the largest current byte count until the number of dropped packets reaches the configured drop batch size or the backlog of the queue has been halved. Note that this in most cases means that the packet that was just enqueued is not among the packets that get dropped, which may even be from a different queue.

\item {} 
\sphinxcode{\sphinxupquote{FqCoDelQueueDisc::DoDequeue ()}}: The first task performed by this routine is selecting a queue from which to dequeue a packet. To this end, the scheduler first looks at the list of new queues; for the queue at the head of that list, if that queue has a negative deficit (i.e., it has already dequeued at least a quantum of bytes), it is given an additional amount of deficit, the queue is put onto the end of the list of old queues, and the routine selects the next queue and starts again. Otherwise, that queue is selected for dequeue. If the list of new queues is empty, the scheduler proceeds down the list of old queues in the same fashion (checking the deficit, and either selecting the queue for dequeuing, or increasing deficit and putting the queue back at the end of the list). After having selected a queue from which to dequeue a packet, the CoDel algorithm is invoked on that queue. As a result of this, one or more packets may be discarded from the head of the selected queue, before the packet that should be dequeued is returned (or nothing is returned if the queue is or becomes empty while being handled by the CoDel algorithm). Finally, if the CoDel algorithm does not return a packet, then the queue must be empty, and the scheduler does one of two things: if the queue selected for dequeue came from the list of new queues, it is moved to the end of the list of old queues.  If instead it came from the list of old queues, that queue is removed from the list, to be added back (as a new queue) the next time a packet for that queue arrives. Then (since no packet was available for dequeue), the whole dequeue process is restarted from the beginning. If, instead, the scheduler did get a packet back from the CoDel algorithm, it subtracts the size of the packet from the byte deficit for the selected queue and returns the packet as the result of the dequeue operation.

\item {} 
\sphinxcode{\sphinxupquote{FqCoDelQueueDisc::FqCoDelDrop ()}}: This routine is invoked by \sphinxcode{\sphinxupquote{FqCoDelQueueDisc::DoEnqueue()}} to drop packets from the head of the queue with the largest current byte count. This routine keeps dropping packets until the number of dropped packets reaches the configured drop batch size or the backlog of the queue has been halved.

\end{itemize}

\item {} 
class \sphinxcode{\sphinxupquote{FqCoDelFlow}}: This class implements a flow queue, by keeping its current status (whether it is in the list of new queues, in the list of old queues or inactive) and its current deficit.

\end{itemize}

In Linux, by default, packet classification is done by hashing (using a Jenkins
hash function) on the 5\sphinxhyphen{}tuple of IP protocol, and source and destination IP
addresses and port numbers (if they exist), and taking the hash value modulo
the number of queues. The hash is salted by modulo addition of a random value
selected at initialisation time, to prevent possible DoS attacks if the hash
is predictable ahead of time. Alternatively, any other packet filter can be
configured.
In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, packet classification is performed in the same way as in Linux.
Neither internal queues nor classes can be configured for an FqCoDel
queue disc.


\subsubsection{References}
\label{\detokenize{fq-codel:references}}

\subsubsection{Attributes}
\label{\detokenize{fq-codel:attributes}}
The key attributes that the FqCoDelQueue class holds include the following:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Interval:}} The interval parameter to be used on the CoDel queues. The default value is 100 ms.

\item {} 
\sphinxcode{\sphinxupquote{Target:}} The target parameter to be used on the CoDel queues. The default value is 5 ms.

\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The limit on the maximum number of packets stored by FqCoDel.

\item {} 
\sphinxcode{\sphinxupquote{Flows:}} The number of flow queues managed by FqCoDel.

\item {} 
\sphinxcode{\sphinxupquote{DropBatchSize:}} The maximum number of packets dropped from the fat flow.

\item {} 
\sphinxcode{\sphinxupquote{Perturbation:}} The salt used as an additional input to the hash function used to classify packets.

\end{itemize}

Perturbation is an optional configuration attribute and can be used to generate
different hash outcomes for different inputs.  For instance, the tuples
used as input to the hash may cause hash collisions (mapping to the same
bucket) for a given set of inputs, but by changing the perturbation value,
the same hash inputs now map to distinct buckets.

Note that the quantum, i.e., the number of bytes each queue gets to dequeue on
each round of the scheduling algorithm, is set by default to the MTU size of the
device (at initialisation time). The \sphinxcode{\sphinxupquote{FqCoDelQueueDisc::SetQuantum ()}} method
can be used (at any time) to configure a different value.


\subsubsection{Examples}
\label{\detokenize{fq-codel:examples}}
A typical usage pattern is to create a traffic control helper and to configure type
and attributes of queue disc and filters from the helper. For example, FqCodel
can be configured as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TrafficControlHelper} \PYG{n}{tch}\PYG{p}{;}
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetRootQueueDisc} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::FqCoDelQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DropBatchSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
                                               \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Perturbation}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{QueueDiscContainer} \PYG{n}{qdiscs} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{devices}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Validation}
\label{\detokenize{fq-codel:validation}}
The FqCoDel model is tested using \sphinxcode{\sphinxupquote{FqCoDelQueueDiscTestSuite}} class defined in \sphinxtitleref{src/test/ns3tc/codel\sphinxhyphen{}queue\sphinxhyphen{}test\sphinxhyphen{}suite.cc}.  The suite includes 5 test cases:
\begin{itemize}
\item {} 
Test 1: The first test checks that packets that cannot be classified by any available filter are dropped.

\item {} 
Test 2: The second test checks that IPv4 packets having distinct destination addresses are enqueued into different flow queues. Also, it checks that packets are dropped from the fat flow in case the queue disc capacity is exceeded.

\item {} 
Test 3: The third test checks the dequeue operation and the deficit round robin\sphinxhyphen{}based scheduler.

\item {} 
Test 4: The fourth test checks that TCP packets with distinct port numbers are enqueued into different flow queues.

\item {} 
Test 5: The fifth test checks that UDP packets with distinct port numbers are enqueued into different flow queues.

\end{itemize}

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests
\PYGZdl{} ./waf build
\PYGZdl{} ./test.py \PYGZhy{}s fq\PYGZhy{}codel\PYGZhy{}queue\PYGZhy{}disc
\end{sphinxVerbatim}

or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nv}{NS\PYGZus{}LOG}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}FqCoDelQueueDisc\PYGZdq{}} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}test\PYGZhy{}runner \PYGZhy{}\PYGZhy{}suite=fq\PYGZhy{}codel\PYGZhy{}queue\PYGZhy{}disc\PYGZdq{}}
\end{sphinxVerbatim}


\section{PIE queue disc}
\label{\detokenize{pie:pie-queue-disc}}\label{\detokenize{pie::doc}}
This chapter describes the PIE (\sphinxcite{pie:pan13}, \sphinxcite{pie:pan16}) queue disc implementation
in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

Proportional Integral controller Enhanced (PIE) is a queuing discipline that aims to
solve the bufferbloat \sphinxcite{codel:buf14} problem. The model in ns\sphinxhyphen{}3 is a port of Preethi
Natarajan’s ns\sphinxhyphen{}2 PIE model.


\subsection{Model Description}
\label{\detokenize{pie:model-description}}
The source code for the PIE model is located in the directory \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/model}}
and consists of 2 files \sphinxtitleref{pie\sphinxhyphen{}queue\sphinxhyphen{}disc.h} and \sphinxtitleref{pie\sphinxhyphen{}queue\sphinxhyphen{}disc.cc} defining a PieQueueDisc
class. The code was ported to \sphinxstyleemphasis{ns\sphinxhyphen{}3} by Mohit P. Tahiliani, Shravya K. S. and Smriti Murali
based on ns\sphinxhyphen{}2 code implemented by Preethi Natarajan, Rong Pan, Chiara Piglione, Greg White
and Takashi Hayakawa.
\begin{itemize}
\item {} 
class \sphinxcode{\sphinxupquote{PieQueueDisc}}: This class implements the main PIE algorithm:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{PieQueueDisc::DoEnqueue ()}}: This routine checks whether the queue is full, and if so, drops the packets and records the number of drops due to queue overflow. If queue is not full, this routine calls \sphinxcode{\sphinxupquote{PieQueueDisc::DropEarly()}}, and depending on the value returned, the incoming packet is either enqueued or dropped.

\item {} 
\sphinxcode{\sphinxupquote{PieQueueDisc::DropEarly ()}}: The decision to enqueue or drop the packet is taken by invoking this routine, which returns a boolean value; false indicates enqueue and true indicates drop.

\item {} 
\sphinxcode{\sphinxupquote{PieQueueDisc::CalculateP ()}}: This routine is called at a regular interval of \sphinxtitleref{m\_tUpdate} and updates the drop probability, which is required by \sphinxcode{\sphinxupquote{PieQueueDisc::DropEarly()}}

\item {} 
\sphinxcode{\sphinxupquote{PieQueueDisc::DoDequeue ()}}: This routine calculates the average departure rate which is required for updating the drop probability in \sphinxcode{\sphinxupquote{PieQueueDisc::CalculateP ()}}

\end{itemize}

\end{itemize}


\subsubsection{References}
\label{\detokenize{pie:references}}

\subsubsection{Attributes}
\label{\detokenize{pie:attributes}}
The key attributes that the PieQueue class holds include the following:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{MaxSize:}} The maximum number of bytes or packets the queue can hold.

\item {} 
\sphinxcode{\sphinxupquote{MeanPktSize:}} Mean packet size in bytes. The default value is 1000 bytes.

\item {} 
\sphinxcode{\sphinxupquote{Tupdate:}} Time period to calculate drop probability. The default value is 30 ms.

\item {} 
\sphinxcode{\sphinxupquote{Supdate:}} Start time of the update timer. The default value is 0 ms.

\item {} 
\sphinxcode{\sphinxupquote{DequeueThreshold:}} Minimum queue size in bytes before dequeue rate is measured. The default value is 10000 bytes.

\item {} 
\sphinxcode{\sphinxupquote{QueueDelayReference:}} Desired queue delay. The default value is 20 ms.

\item {} 
\sphinxcode{\sphinxupquote{MaxBurstAllowance:}} Current max burst allowance in seconds before random drop. The default value is 0.1 seconds.

\item {} 
\sphinxcode{\sphinxupquote{A:}} Value of alpha. The default value is 0.125.

\item {} 
\sphinxcode{\sphinxupquote{B:}} Value of beta. The default value is 1.25.

\end{itemize}


\subsubsection{Examples}
\label{\detokenize{pie:examples}}
The example for PIE is \sphinxtitleref{pie\sphinxhyphen{}example.cc} located in \sphinxcode{\sphinxupquote{src/traffic\sphinxhyphen{}control/examples}}.  To run the file (the first invocation below shows the available
command\sphinxhyphen{}line options):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}pie\PYGZhy{}example \PYGZhy{}\PYGZhy{}PrintHelp\PYGZdq{}}
\PYGZdl{} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}pie\PYGZhy{}example \PYGZhy{}\PYGZhy{}writePcap=1\PYGZdq{}}
\end{sphinxVerbatim}

The expected output from the previous commands are 10 .pcap files.


\subsection{Validation}
\label{\detokenize{pie:validation}}
The PIE model is tested using \sphinxcode{\sphinxupquote{PieQueueDiscTestSuite}} class defined in \sphinxtitleref{src/traffic\sphinxhyphen{}control/test/pie\sphinxhyphen{}queue\sphinxhyphen{}test\sphinxhyphen{}suite.cc}. The suite includes 5 test cases:
\begin{itemize}
\item {} 
Test 1: simple enqueue/dequeue with defaults, no drops

\item {} 
Test 2: more data with defaults, unforced drops but no forced drops

\item {} 
Test 3: same as test 2, but with higher QueueDelayReference

\item {} 
Test 4: same as test 2, but with reduced dequeue rate

\item {} 
Test 5: same dequeue rate as test 4, but with higher Tupdate

\end{itemize}

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests
\PYGZdl{} ./waf build
\PYGZdl{} ./test.py \PYGZhy{}s pie\PYGZhy{}queue\PYGZhy{}disc
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nv}{NS\PYGZus{}LOG}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}PieQueueDisc\PYGZdq{}} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}test\PYGZhy{}runner \PYGZhy{}\PYGZhy{}suite=pie\PYGZhy{}queue\PYGZhy{}disc\PYGZdq{}}
\end{sphinxVerbatim}


\section{Mq queue disc}
\label{\detokenize{mq:mq-queue-disc}}\label{\detokenize{mq::doc}}
This chapter describes the mq queue disc implementation in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.

mq is a classful multiqueue dummy scheduler developed to best fit the multiqueue
traffic control API in Linux. The mq scheduler presents device transmission queues as
classes, allowing to attach different queue discs to them, which are grafted to the
device transmission queues.

Mq is installed by default on multi\sphinxhyphen{}queue devices (such as Wifi) with as many FqCodel
child queue discs as the number of device queues.


\subsection{Model Description}
\label{\detokenize{mq:model-description}}
mq is a multi\sphinxhyphen{}queue aware queue disc, meaning that it has as many child queue discs as
the number of device transmission queues. Each child queue disc maps to a distinct
device transmission queue. Every packet is enqueued into the child queue disc which
maps to the device transmission queue in which the device will enqueue
the packet.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, \sphinxcode{\sphinxupquote{MqQueueDisc}} has a wake mode of WAKE\_CHILD, which means that the
traffic control layer enqueues packets directly into one of the child queue discs
(multi\sphinxhyphen{}queue devices can provide a callback to inform the traffic control layer of
the device transmission queue that will be selected for a given packet). Therefore,
\sphinxcode{\sphinxupquote{MqQueueDisc::DoEnqueue ()}} shall never be called (in fact, it raises a fatal error).
Given that dequeuing packets is triggered by enqueuing a packet in the queue disc or
by the device invoking the wake callback, it turns out that \sphinxcode{\sphinxupquote{MqQueueDisc::DoDequeue ()}}
is never called as well (in fact, it raises a fatal error, too).

The mq queue disc does not require packet filters, does not admit internal queues
and must have as many child queue discs as the number of device transmission queues.


\subsubsection{Examples}
\label{\detokenize{mq:examples}}
A typical usage pattern is to create a traffic control helper used to add the required number of
queue disc classes, attach child queue discs to the classes and (if needed) add packet filters to the
child queue discs. The following code shows how to install an mq queue disc having FqCodel child queue
discs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TrafficControlHelper} \PYG{n}{tch}\PYG{p}{;}
\PYG{k+kt}{uint16\PYGZus{}t} \PYG{n}{handle} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{SetRootQueueDisc} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::MqQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{TrafficControlHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ClassIdList} \PYG{n}{cls} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddQueueDiscClasses} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{n}{numTxQueues}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::QueueDiscClass}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{tch}\PYG{p}{.}\PYG{n}{AddChildQueueDiscs} \PYG{p}{(}\PYG{n}{handle}\PYG{p}{,} \PYG{n}{cls}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::FqCoDelQueueDisc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{QueueDiscContainer} \PYG{n}{qdiscs} \PYG{o}{=} \PYG{n}{tch}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{devices}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Note that the child queue discs attached to the classes do not necessarily have to be of the same type.


\subsection{Validation}
\label{\detokenize{mq:validation}}
The mq model is tested using \sphinxcode{\sphinxupquote{WifiAcMappingTestSuite}} class defined in
\sphinxtitleref{src/test/wifi\sphinxhyphen{}ac\sphinxhyphen{}mapping\sphinxhyphen{}test\sphinxhyphen{}suite.cc}. The suite considers a node with a QoS\sphinxhyphen{}enabled
wifi device (which has 4 transmission queues) and includes 4 test cases:
\begin{itemize}
\item {} 
Test 1: EF\sphinxhyphen{}marked packets are enqueued in the queue disc which maps to the AC\_VI queue

\item {} 
Test 2: AF11\sphinxhyphen{}marked packets are enqueued in the queue disc which maps to the AC\_BK queue

\item {} 
Test 3: AF32\sphinxhyphen{}marked packets are enqueued in the queue disc which maps to the AC\_BE queue

\item {} 
Test 4: CS7\sphinxhyphen{}marked packets are enqueued in the queue disc which maps to the AC\_VO queue

\end{itemize}

The test suite can be run using the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} ./waf configure \PYGZhy{}\PYGZhy{}enable\PYGZhy{}examples \PYGZhy{}\PYGZhy{}enable\PYGZhy{}tests
\PYGZdl{} ./waf build
\PYGZdl{} ./test.py \PYGZhy{}s ns3\PYGZhy{}wifi\PYGZhy{}ac\PYGZhy{}mapping
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} \PYG{n+nv}{NS\PYGZus{}LOG}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}WifiAcMappingTest\PYGZdq{}} ./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}test\PYGZhy{}runner \PYGZhy{}\PYGZhy{}suite=ns3\PYGZhy{}wifi\PYGZhy{}ac\PYGZhy{}mapping\PYGZdq{}}
\end{sphinxVerbatim}


\chapter{UAN Framework}
\label{\detokenize{uan:uan-framework}}\label{\detokenize{uan::doc}}
The main goal of the UAN Framework is to enable researchers to
model a variety of underwater network scenarios.  The UAN model
is broken into four main parts:  The channel, PHY, MAC and
Autonomous Underwater Vehicle (AUV) models.

The need for underwater wireless communications exists in applications such as remote control in offshore oil industry %
\begin{footnote}[1]\sphinxAtStartFootnote
BINGHAM, D.; DRAKE, T.; HILL, A.; LOTT, R.; The Application of Autonomous Underwater Vehicle (AUV) Technology in the Oil Industry \textendash{} Vision and Experiences, URL: \sphinxurl{http://www.fig.net/pub/fig\_2002/Ts4-4/TS4\_4\_bingham\_etal.pdf}
%
\end{footnote}, pollution monitoring in environmental systems, speech transmission between divers, mapping of the ocean floor, mine counter measures %
\begin{footnote}[2]\sphinxAtStartFootnote
AUVfest2008: Underwater mines; URL: \sphinxurl{http://oceanexplorer.noaa.gov/explorations/08auvfest/background/mines/mines.html}
%
\end{footnote} %
\begin{footnote}[4]\sphinxAtStartFootnote
WHOI, Autonomous Underwater Vehicle, REMUS; URL: \sphinxurl{http://www.whoi.edu/page.do?pid=29856}
%
\end{footnote}, seismic monitoring of ocean faults as well as climate changes monitoring. Unfortunately, making on\sphinxhyphen{}field measurements is very expensive and there are no commonly accepted standard to base on. Hence, the priority to make research work going on, it is to realize a complete simulation framework that researchers can use to experiment, make tests and make performance evaluation and comparison.

The NS\sphinxhyphen{}3 UAN module is a first step in this direction, trying to offer a reliable and realistic tool. In fact, the UAN module offers accurate modelling of the underwater acoustic channel, a model of the WHOI acoustic modem (one of the widely used acoustic modems) %
\begin{footnote}[6]\sphinxAtStartFootnote
L. Freitag, M. Grund, I. Singh, J. Partan, P. Koski, K. Ball, and W. Hole, The whoi
micro\sphinxhyphen{}modem: an acoustic communications and navigation system for multiple platforms,
In Proc. IEEE OCEANS05 Conf, 2005. URL: \sphinxurl{http://ieeexplore.ieee.org/iel5/10918/34367/01639901.pdf}
%
\end{footnote} and its communications performance, and some MAC protocols.


\section{Model Description}
\label{\detokenize{uan:model-description}}
The source code for the UAN Framework lives in the directory
\sphinxcode{\sphinxupquote{src/uan}} and in \sphinxcode{\sphinxupquote{src/energy}} for the contribution on
the li\sphinxhyphen{}ion battery model.

The UAN Framework is composed of two main parts:
\begin{itemize}
\item {} 
the AUV mobility models, including Electric motor propelled AUV (REMUS class %
\begin{footnote}[3]\sphinxAtStartFootnote
Hydroinc Products; URL: \sphinxurl{http://www.hydroidinc.com/products.html}
%
\end{footnote} \sphinxfootnotemark[4] ) and Seaglider %
\begin{footnote}[5]\sphinxAtStartFootnote
Eriksen, C.C., T.J. Osse, R.D. Light, T. Wen, T.W. Lehman, P.L. Sabin, J.W. Ballard, and A.M.
Chiodi. Seaglider: A Long\sphinxhyphen{}Range Autonomous Underwater Vehicle for Oceanographic Research,
IEEE Journal of Oceanic Engineering, 26, 4, October 2001.
URL: \sphinxurl{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=972073\&userType=inst}
%
\end{footnote} models

\item {} 
the energy models, including AUV energy models, AUV energy sources (batteries) and an acoustic modem energy model

\end{itemize}

As enabling component for the energy models, a Li\sphinxhyphen{}Ion batteries energy source has been implemented basing on %
\begin{footnote}[7]\sphinxAtStartFootnote
C. M. Shepherd, “Design of Primary and Secondary Cells \sphinxhyphen{} Part 3.
Battery discharge equation,” U.S. Naval Research Laboratory, 1963
%
\end{footnote} %
\begin{footnote}[8]\sphinxAtStartFootnote
Tremblay, O.; Dessaint, L.\sphinxhyphen{}A.; Dekkiche, A.\sphinxhyphen{}I., “A Generic Battery Model for the
Dynamic Simulation of Hybrid Electric Vehicles,” Ecole de Technologie Superieure,
Universite du Quebec, 2007 URL: \sphinxurl{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=4544139}
%
\end{footnote}.


\subsection{Design}
\label{\detokenize{uan:design}}

\subsubsection{UAN Propagation Models}
\label{\detokenize{uan:uan-propagation-models}}
Modelling of the underwater acoustic channel has been an active
area of research for quite some time.  Given the complications involved,
surface and bottom interactions, varying speed of sound, etc…, the detailed
models in use for ocean acoustics research are much too complex
(in terms of runtime) for use in network level simulations.  We have
attempted to provide the often used models as well as make an attempt to bridge, in part, the gap between
complicated ocean acoustic models and network level simulation.  The three propagation
models included are the ideal channel model, the Thorp propagation model and
the Bellhop propagation model (Available as an addition).

All of the Propagation Models follow the same simple interface in \sphinxcode{\sphinxupquote{ns3::UanPropModel}}.
The propagation models provide a power delay profile (PDP) and pathloss
information.  The PDP is retrieved using the GetPdp method which returns type UanPdp.
\sphinxcode{\sphinxupquote{ns3::UanPdp}} utilises a tapped delay line model for the acoustic channel.
The UanPdp class is a container class for Taps, each tap has a delay and amplitude
member corresponding to the time of arrival (relative to the first tap arrival time)
and amplitude.   The propagation model also provides pathloss between the source
and receiver in dB re 1uPa.  The PDP and pathloss can then be used to find the
received signal power over a duration of time (i.e. received signal power in
a symbol duration and ISI which interferes with neighbouring signals).  Both
UanPropModelIdeal and UanPropModelThorp return a single impulse for a PDP.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{)}%
\item {} 
Ideal Channel Model \sphinxcode{\sphinxupquote{ns3::UanPropModelIdeal}}

\end{enumerate}

The ideal channel model assumes 0 pathloss inside a cylindrical area with bounds
set by attribute.  The ideal channel model also assumes an impulse PDP.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{)}%
\setcounter{enumi}{1}
\item {} 
Thorp Propagation Model \sphinxcode{\sphinxupquote{ns3::UanPropModelThorp}}

\end{enumerate}

The Thorp Propagation Model calculates pathloss using the well\sphinxhyphen{}known Thorp approximation.
This model is similar to the underwater channel model implemented in ns2 as described here:

Harris, A. F. and Zorzi, M. 2007. Modeling the underwater acoustic channel in ns2. In Proceedings
of the 2nd international Conference on Performance Evaluation Methodologies and Tools
(Nantes, France, October 22 \sphinxhyphen{} 27, 2007). ValueTools, vol. 321. ICST (Institute for Computer
Sciences Social\sphinxhyphen{}Informatics and Telecommunications Engineering), ICST, Brussels, Belgium, 1\sphinxhyphen{}8.

The frequency used in calculation however, is the center frequency of the modulation as found from
ns3::UanTxMode.  The Thorp Propagation Model also assumes an impulse channel response.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{)}%
\setcounter{enumi}{2}
\item {} 
Bellhop Propagation Model \sphinxcode{\sphinxupquote{ns3::UanPropModelBh}} (Available as an addition)

\end{enumerate}

The Bellhop propagation model reads propagation information from a database.  A configuration
file describing the location, and resolution of the archived information must be supplied via
attributes.  We have included a utility, create\sphinxhyphen{}dat, which can create these data files using the Bellhop
Acoustic Ray Tracing software (\sphinxurl{http://oalib.hlsresearch.com/}).

The create\sphinxhyphen{}dat utility requires a Bellhop installation to run.  Bellhop takes
environment information about the channel, such as sound speed profile, surface height
bottom type, water depth, and uses a Gaussian ray tracing algorithm to determine
propagation information.  Arrivals from Bellhop are grouped together into equal length
taps (the arrivals in a tap duration are coherently summed).  The maximum taps are then
aligned to take the same position in the PDP.  The create\sphinxhyphen{}dat utility averages together
several runs and then normalizes the average such that the sum of all taps is 1.  The same
configuration file used to create the data files using create\sphinxhyphen{}dat should be passed via
attribute to the Bellhop Propagation Model.

The Bellhop propagation model is available as a patch.  The link address will be
made available here when it is posted online.  Otherwise email \sphinxhref{mailto:lentracy@gmail.com}{lentracy@gmail.com}
for more information.


\subsubsection{UAN PHY Model Overview}
\label{\detokenize{uan:uan-phy-model-overview}}
The PHY has been designed to allow for relatively easy extension
to new networking scenarios.  We feel this is important as, to date,
there has been no commonly accepted network level simulation model
for underwater networks.  The lack of commonly accepted network simulation
tools has resulted in a wide array of simulators and models used to report
results in literature.  The lack of standardization makes comparing results
nearly impossible.

The main component of the PHY Model is the generic
PHY class, \sphinxcode{\sphinxupquote{ns3::UanPhyGen}}.  The PHY class’s general responsibility
is to handle packet acquisition, error determination, and forwarding of successful
packets up to the MAC layer.  The Generic PHY uses two models for determination
of signal to noise ratio (SINR) and packet error rate (PER).  The
combination of the PER and SINR models determine successful reception
of packets.  The PHY model connects to the channel via a Transducer class.
The Transducer class is responsible for tracking all arriving packets and
departing packets over the duration of the events. How the PHY class and the PER and SINR models
respond to packets is based on the “Mode” of the transmission as described by the \sphinxcode{\sphinxupquote{ns3::UanTxMode}}
class.

When a MAC layer sends down a packet to the PHY for transmission it specifies a “mode number” to
be used for the transmission.  The PHY class accepts, as an attribute, a list of supported modes.  The
mode number corresponds to an index in the supported modes.  The UanTxMode contains simple modulation
information and a unique string id.  The generic PHY class will only acquire arriving packets which
use a mode which is in the supported modes list of the PHY.  The mode along with received signal power,
and other pertinent attributes (e.g. possibly interfering packets and their modes) are passed to the SINR
and PER models for calculation of SINR and probability of error.

Several simple example PER and SINR models have been created.
a) The PER models
\sphinxhyphen{} Default (simple) PER model (\sphinxcode{\sphinxupquote{ns3::UanPhyPerGenDefault}}):  The Default PER model tests the packet against a threshold and
assumes error (with prob. 1) if the SINR is below the threshold or success if the SINR is above
the threshold
\sphinxhyphen{} Micromodem FH\sphinxhyphen{}FSK PER (\sphinxcode{\sphinxupquote{ns3::UanPhyPerUmodem}}).  The FH\sphinxhyphen{}FSK PER model calculates probability of error assuming a
rate 1/2 convolutional code with constraint length 9 and a CRC check capable of correcting
up to 1 bit error.  This is similar to what is used in the receiver of the WHOI Micromodem.

b) SINR models
\sphinxhyphen{} Default Model (\sphinxcode{\sphinxupquote{ns3::UanPhyCalcSinrDefault}}), The default SINR model assumes that all transmitted energy is captured at the receiver
and that there is no ISI.  Any received signal power from interferes acts as additional ambient noise.
\sphinxhyphen{} FH\sphinxhyphen{}FSK SINR Model (\sphinxcode{\sphinxupquote{ns3::UanPhyCalcSinrFhFsk}}), The WHOI Micromodem operating in FH\sphinxhyphen{}FSK mode uses a predetermined hopping
pattern that is shared by all nodes in the network.  We model this by only including signal
energy receiving within one symbol time (as given by \sphinxcode{\sphinxupquote{ns3::UanTxMode}}) in calculating the
received signal power.  A channel clearing time is given to the FH\sphinxhyphen{}FSK SINR model via attribute.
Any signal energy arriving in adjacent signals (after a symbol time and the clearing time) is
considered ISI and is treated as additional ambient noise.   Interfering signal arrivals inside
a symbol time (any symbol time) is also counted as additional ambient noise
\sphinxhyphen{} Frequency filtered SINR (\sphinxcode{\sphinxupquote{ns3::UanPhyCalcSinrDual}}).  This SINR model calculates SINR in the same manner
as the default model.  This model however only considers interference if there is an overlap in frequency
of the arriving packets as determined by UanTxMode.

In addition to the generic PHY a dual phy layer is also included (\sphinxcode{\sphinxupquote{ns3::UanPhyDual}}).  This wraps two
generic phy layers together to model a net device which includes two receivers.  This was primarily
developed for UanMacRc, described in the next section.


\subsubsection{UAN MAC Model Overview}
\label{\detokenize{uan:uan-mac-model-overview}}
Over the last several years there have been a myriad of underwater MAC proposals
in the literature.  We have included three MAC protocols with this distribution:
a) CW\sphinxhyphen{}MAC, a MAC protocol which uses a slotted contention window similar in nature to
the IEEE 802.11 DCF.  Nodes have a constant contention window measured in slot times (configured
via attribute).  If the channel is sensed busy, then nodes backoff by randomly (uniform distribution) choose
a slot to transmit in.  The slot time durations are also configured via attribute.  This MAC was described in

Parrish N.; Tracy L.; Roy S. Arabshahi P.; and Fox, W.,  System Design Considerations for Undersea Networks:
Link and Multiple Access Protocols , IEEE Journal on Selected Areas in Communications (JSAC), Special
Issue on Underwater Wireless Communications and Networks, Dec. 2008.

b) RC\sphinxhyphen{}MAC (\sphinxcode{\sphinxupquote{ns3::UanMacRc}} \sphinxcode{\sphinxupquote{ns3::UanMacRcGw}}) a reservation channel protocol which dynamically divides
the available bandwidth into a data channel and a control channel.  This MAC protocol
assumes there is a gateway node which all network traffic is destined for.  The current
implementation assumes a single gateway and a single network neighborhood (a single hop network).
RTS/CTS handshaking is used and time is divided into cycles.  Non\sphinxhyphen{}gateway nodes transmit RTS packets
on the control channel in parallel to data packet transmissions which were scheduled in the previous cycle
at the start of a new cycle, the gateway responds on the data channel with a CTS packet which includes
packet transmission times of data packets for received RTS packets in the previous cycle as well as bandwidth
allocation information.  At the end of a cycle ACK packets are transmitted for received data packets.

When a publication is available it will be cited here.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{)}%
\setcounter{enumi}{2}
\item {} 
Simple ALOHA (\sphinxcode{\sphinxupquote{ns3::UanMacAloha}})  Nodes transmit at will.

\end{enumerate}


\subsubsection{AUV mobility models}
\label{\detokenize{uan:auv-mobility-models}}
The AUV mobility models have been designed as in the follows.


\paragraph{Use cases}
\label{\detokenize{uan:use-cases}}
The user will be able to:
\begin{itemize}
\item {} 
program the AUV to navigate over a path of waypoints

\item {} 
control the velocity of the AUV

\item {} 
control the depth of the AUV

\item {} 
control the direction of the AUV

\item {} 
control the pitch of the AUV

\item {} 
tell the AUV to emerge or submerge to a specified depth

\end{itemize}


\paragraph{AUV mobility models design}
\label{\detokenize{uan:auv-mobility-models-design}}
Implement a model of the navigation of AUV. This involves implementing two classes modelling the two major categories of AUVs: electric motor propelled (like REMUS class \sphinxfootnotemark[3] \sphinxfootnotemark[4]) and “sea gliders” \sphinxfootnotemark[5].
The classic AUVs are submarine\sphinxhyphen{}like devices, propelled by an electric motor linked with a propeller. Instead, the “sea glider” class exploits small changes in its buoyancy that, in conjunction with wings, can convert vertical motion to horizontal. So, a glider will reach a point into the water by describing a “saw\sphinxhyphen{}tooth” movement.
Modelling the AUV navigation, involves in considering a real\sphinxhyphen{}world AUV class thus, taking into account maximum speed, directional capabilities, emerging and submerging times.
Regarding the sea gliders, it is modelled the characteristic saw\sphinxhyphen{}tooth movement, with AUV’s speed driven by buoyancy and glide angle.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{auvmobility-classes}.pdf}
\caption{AUV’s mobility model classes overview}\label{\detokenize{uan:id27}}\label{\detokenize{uan:auvmobilitymodel}}\end{figure}

An \sphinxcode{\sphinxupquote{ns3::AuvMobilityModel}} interface has been designed to give users a generic interface to access AUV’s navigation functions.
The AuvMobilityModel interface is implemented by the RemusMobilityModel and the GliderMobilityModel classes. The AUV’s mobility models organization it is shown in {\hyperref[\detokenize{uan:auvmobilitymodel}]{\sphinxcrossref{\DUrole{std,std-ref}{AUV’s mobility model classes overview}}}}.
Both models use a constant velocity movement, thus the AuvMobilityModel interface derives from the ConstantVelocityMobilityModel. The two classes hold the navigation parameters for the two different AUVs, like maximum pitch angles, maximum operating depth, maximum and minimum speed values. The Glider model holds also some extra parameters like maximum buoyancy values, and maximum and minimum glide slopes.
Both classes, RemusMobilityModel and GliderMobilityModel, handle also the AUV power consumption, utilizing the relative power models.
Has been modified the WaypointMobilityModel to let it use a generic underlying ConstantVelocityModel to validate the waypoints and, to keep trace of the node’s position. The default model is the classic ConstantVelocityModel but, for example in case of REMUS mobility model, the user can install the AUV mobility model into the waypoint model and then validating the waypoints against REMUS navigation constraints.


\subsubsection{Energy models}
\label{\detokenize{uan:energy-models}}
The energy models have been designed as in the follows.


\paragraph{Use cases}
\label{\detokenize{uan:id13}}
The user will be able to:
\begin{itemize}
\item {} 
use a specific power profile for the acoustic modem

\item {} 
use a specific energy model for the AUV

\item {} 
trace the power consumption of AUV navigation, through AUV’s energy model

\item {} 
trace the power consumption underwater acoustic communications, through acoustic modem power profile

\end{itemize}

We have integrated the Energy Model with the UAN module, to implement energy handling. We have implemented a specific energy model for the two AUV classes and, an energy source for Lithium batteries. This will be really useful for researchers to keep trace of the AUV operational life.
We have implemented also an acoustic modem power profile, to keep trace of its power consumption. This can be used to compare protocols specific power performance. In order to use such power profile, the acoustic transducer physical layer has been modified to use the modem power profile. We have decoupled the physical layer from the transducer specific energy model, to let the users change the different energy models without changing the physical layer.


\paragraph{AUV energy models}
\label{\detokenize{uan:auv-energy-models}}
Basing on the Device Energy Model interface, it has been implemented a specific energy model for the two AUV classes (REMUS and Seaglider). This models reproduce the AUV’s specific power consumption to give users accurate information. This model can be naturally used to evaluates the AUV operating life, as well as mission\sphinxhyphen{}related power consumption, etc. Have been developed two AUV energy models:
\begin{itemize}
\item {} 
GliderEnergyModel, computes the power consumption of the vehicle based on the current buoyancy value and vertical speed \sphinxfootnotemark[5]

\item {} 
RemusEnergyModel, computes the power consumption of the vehicle based on the current speed, as it is propelled by a brush\sphinxhyphen{}less electric motor

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
TODO extend a little bit
\end{sphinxadmonition}


\paragraph{AUV energy sources}
\label{\detokenize{uan:auv-energy-sources}}
\begin{sphinxadmonition}{note}{Note:}
{[}TODO{]}
\end{sphinxadmonition}


\paragraph{Acoustic modem energy model}
\label{\detokenize{uan:acoustic-modem-energy-model}}
Basing on the Device Energy Model interface, has been implemented a generic energy model for acoustic modem. The model allows to trace four modem’s power\sphinxhyphen{}states: Sleep, Idle, Receiving, Transmitting. The default parameters for the energy model are set to fit those of the WHOI μmodem. The class follows pretty closely the RadioEnergyModel class as the transducer behaviour is pretty close to that of a Wi\sphinxhyphen{}Fi radio.

The default power consumption values implemented into the model are as follows \sphinxfootnotemark[6]:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Modem State
&
Power Consumption
\\
\hline
TX
&
50 W
\\
\hline
RX
&
158 mW
\\
\hline
Idle
&
158 mW
\\
\hline
Sleep
&
5.8 mW
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\paragraph{UAN module energy modifications}
\label{\detokenize{uan:uan-module-energy-modifications}}
The UAN module has been modified in order to utilize the implemented energy classes. Specifically, it has been modified the physical layer of the UAN module. It Has been implemented an UpdatePowerConsumption method that takes the modem’s state as parameter. It checks if an energy source is installed into the node and, in case, it then use the AcousticModemEnergyModel to update the power consumption with the current modem’s state. The modem power consumption’s update takes place whenever the modem changes its state.

A user should take into account that, if the power consumption handling is enabled (if the node has an energy source installed), all the communications processes will terminate whether the node depletes all the energy source.


\paragraph{Li\sphinxhyphen{}Ion batteries model}
\label{\detokenize{uan:li-ion-batteries-model}}
A generic Li\sphinxhyphen{}Ion battery model has been implemented based on {[}7{]}{[}8{]}. The model can be fitted to any type of Li\sphinxhyphen{}Ion battery simply changing the model’s parameters The default values are fitted for the Panasonic CGR18650DA Li\sphinxhyphen{}Ion Battery {[}9{]}.
{[}TODO insert figure{]}
As shown in figure the model approximates very well the Li\sphinxhyphen{}Ion cells.
Regarding Seagliders, the batteries used into the AUV are Electrochem 3B36 Lithium / Sulfuryl Chloride cells %
\begin{footnote}[10]\sphinxAtStartFootnote
Electrochem 3B36 Datasheet, URL: \sphinxurl{http://www.electrochem.com.cn/products/Primary/HighRate/CSC/3B36.pdf}
%
\end{footnote}. Also with this cell type, the model seems to approximates the different discharge curves pretty well, as shown in the figure.

\begin{sphinxadmonition}{note}{Note:}
should I insert the li\sphinxhyphen{}ion model deatils here? I think it is better to put them into an Energy\sphinxhyphen{}related chapter..
\end{sphinxadmonition}


\subsection{Scope and Limitations}
\label{\detokenize{uan:scope-and-limitations}}
The framework is designed to simulate AUV’s behaviour. We have modeled the navigation and power consumption behaviour of REMUS class and Seaglider AUVs.
The communications stack, associated with the AUV, can be modified depending on simulation needs. Usually, the default underwater stack is being used, composed of an half duplex acoustic modem, an Aloha MAC protocol and a generic physical layer.

Regarding the AUV energy consumption, the user should be aware that the level of accuracy differs for the two classes:
\begin{itemize}
\item {} 
Seaglider, high level of accuracy, thanks to the availability of detailed information on AUV’s components and behaviour {[}5{]} {[}10{]}. Have been modeled both the navigation power consumption and the Li battery packs (according to {[}5{]}).

\item {} 
REMUS, medium level of accuracy, due to the lack of publicly available information on AUV’s components. We have approximated the power consumption of the AUV’s motor with a linear behaviour and, the energy source uses an ideal model (BasicEnergySource) with a power capacity equal to that specified in {[}4{]}.

\end{itemize}


\subsection{Future Work}
\label{\detokenize{uan:future-work}}
Some ideas could be :
\begin{itemize}
\item {} 
insert a data logging capability

\item {} 
modify the framework to use sockets (enabling the possibility to use applications)

\item {} 
introduce some more MAC protocols

\item {} 
modify the physical layer to let it consider the Doppler spread (problematic in underwater environments)

\item {} 
introduce OFDM modulations

\end{itemize}


\subsection{References}
\label{\detokenize{uan:references}}

\section{Usage}
\label{\detokenize{uan:usage}}
The main way that users who write simulation scripts will typically
interact with the UAN Framework is through the helper API and through
the publicly visible attributes of the model.

The helper API is defined in \sphinxcode{\sphinxupquote{src/uan/helper/acoustic\sphinxhyphen{}modem\sphinxhyphen{}energy\sphinxhyphen{}model\sphinxhyphen{}helper.\{cc,h\}}} and in \sphinxcode{\sphinxupquote{/src/uan/helper/...\{cc,h\}}}.

The example folder \sphinxcode{\sphinxupquote{src/uan/examples/}} contain some basic code that shows how to set up and use the models.
further examples can be found into the Unit tests in \sphinxcode{\sphinxupquote{src/uan/test/...cc}}


\subsection{Examples}
\label{\detokenize{uan:examples}}
Examples of the Framework’s usage can be found into the examples folder. There are mobility related examples and UAN related ones.


\subsubsection{Mobility Model Examples}
\label{\detokenize{uan:mobility-model-examples}}\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{auv\sphinxhyphen{}energy\sphinxhyphen{}model}}:}] \leavevmode
In this example we show the basic usage of an AUV energy model.
Specifically, we show how to create a generic node, adding to it a basic energy source
and consuming energy from the energy source. In this example we show the basic usage of
an AUV energy model.

The Seaglider AUV power consumption depends on buoyancy and vertical speed values, so we simulate a 20 seconds movement at 0.3 m/s of vertical speed and 138g of buoyancy. Then a 20 seconds movement at 0.2 m/s of vertical speed and 138g of buoyancy and then a stop of 5 seconds.

The required energy will be drained by the model basing on the given buoyancy/speed values, from the energy source installed onto the node. We finally register a callback to the TotalEnergyConsumption traced value.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{auv\sphinxhyphen{}mobility}}:}] \leavevmode
In this example we show how to use the AuvMobilityHelper to install an AUV mobility model into a (set of) node. Then we make the AUV to submerge to a depth of 1000 meters. We then set a callback function called on reaching of the target depth.
The callback then makes the AUV to emerge to water surface (0 meters). We set also a callback function called on reaching of the target depth.
The emerge callback then, stops the AUV.

During the whole navigation process, the AUV’s position is tracked by the TracePos function and plotted into a Gnuplot graph.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{waypoint\sphinxhyphen{}mobility}}:}] \leavevmode
We show how to use the WaypointMobilityModel with a non\sphinxhyphen{}standard ConstantVelocityMobilityModel.
We first create a waypoint model with an underlying RemusMobilityModel setting the mobility trace with two waypoints.
We then create a waypoint model with an underlying GliderMobilityModel setting the waypoints separately with the AddWaypoint method.
The AUV’s position is printed out every seconds.

\end{description}

\end{itemize}


\subsubsection{UAN Examples}
\label{\detokenize{uan:uan-examples}}\begin{itemize}
\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{li\sphinxhyphen{}ion\sphinxhyphen{}energy\sphinxhyphen{}source}}}] \leavevmode
In this simple example, we show how to create and drain energy from a LiIonEnergySource.
We make a series of discharge calls to the energy source class, with different current drain and durations, until all the energy is depleted from the cell (i.e. the voltage of the cell goes below the threshold level).
Every 20 seconds we print out the actual cell voltage to verify that it follows the discharge curve {[}9{]}.
At the end of the example it is verified that after the energy depletion call, the cell voltage is below the threshold voltage.

\end{description}

\item {} \begin{description}
\item[{\sphinxcode{\sphinxupquote{uan\sphinxhyphen{}energy\sphinxhyphen{}auv}}}] \leavevmode
This is a comprehensive example where all the project’s components are used.
We setup two nodes, one fixed surface gateway equipped with an acoustic modem and a moving Seaglider AUV with an acoustic modem too.
Using the waypoint mobility model with an underlying GliderMobilityModel, we make the glider descend to \sphinxhyphen{}1000 meters and then emerge to the water surface.
The AUV sends a generic 17\sphinxhyphen{}bytes packet every 10 seconds during the navigation process. The gateway receives the packets and stores the total bytes amount.
At the end of the simulation are shown the energy consumptions of the two nodes and the networking stats.

\end{description}

\end{itemize}


\subsection{Helpers}
\label{\detokenize{uan:helpers}}
In this section we give an overview of the available helpers and their behaviour.


\subsubsection{AcousticModemEnergyModelHelper}
\label{\detokenize{uan:acousticmodemenergymodelhelper}}
This helper installs AcousticModemEnergyModel into UanNetDevice objects only. It requires an UanNetDevice and an EnergySource as input objects.

The helper creates an AcousticModemEnergyModel with default parameters and associate it with the given energy source. It configures an EnergyModelCallback and an EnergyDepletionCallback. The depletion callback can be configured as a parameter.


\subsubsection{AuvGliderHelper}
\label{\detokenize{uan:auvgliderhelper}}
Installs into a node (or set of nodes) the Seaglider’s features:
\begin{itemize}
\item {} 
waypoint model with underlying glider mobility model

\item {} 
glider energy model

\item {} 
glider energy source

\item {} 
micro modem energy model

\end{itemize}

The glider mobility model is the GliderMobilityModel with default parameters.
The glider energy model is the GliderEnergyModel with default parameters.

Regarding the energy source, the Seaglider features two battery packs, one for motor power and one for digital\sphinxhyphen{}analog power.
Each pack is composed of 12 (10V) and 42 (24V) lithium chloride DD\sphinxhyphen{}cell batteries, respectively {[}5{]}. The total power capacity is around 17.5 MJ (3.9 MJ + 13.6 MJ).
In the original version of the Seaglider there was 18 + 63 D\sphinxhyphen{}cell with a total power capacity of 10MJ.

The packs design is as follows:
\begin{itemize}
\item {} 
10V \sphinxhyphen{} 3 in\sphinxhyphen{}series string x 4 strings = 12 cells \sphinxhyphen{} typical capacity \textasciitilde{}100 Ah

\item {} 
24V \sphinxhyphen{} 7 in\sphinxhyphen{}series\sphinxhyphen{}strings x 6 strings = 42 cells \sphinxhyphen{} typical capacity \textasciitilde{}150 Ah

\end{itemize}

Battery cells are Electrochem 3B36, with 3.6 V nominal voltage and 30.0 Ah nominal capacity.
The 10V battery pack is associated with the electronic devices, while the 24V one is associated with the pump motor.

The micro modem energy model is the MicroModemEnergyModel with default parameters.


\subsubsection{AuvRemusHelper}
\label{\detokenize{uan:auvremushelper}}
Install into a node (or set of nodes) the REMUS features:
\begin{itemize}
\item {} 
waypoint model with REMUS mobility model validation

\item {} 
REMUS energy model

\item {} 
REMUS energy source

\item {} 
micro modem energy model

\end{itemize}

The REMUS mobility model is the RemusMobilityModel with default parameters.
The REMUS energy model is the RemusEnergyModel with default parameters.

Regarding the energy source, the REMUS features a rechargeable lithium ion battery pack rated 1.1 kWh @ 27 V (40 Ah) in operating conditions (specifications from {[}3{]} and Hydroinc European salesman).
Since more detailed information about battery pack were not publicly available, the energy source used is a BasicEnergySource.

The micro modem energy model is the MicroModemEnergyModel with default parameters.


\subsection{Attributes}
\label{\detokenize{uan:attributes}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Tracing}
\label{\detokenize{uan:tracing}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Logging}
\label{\detokenize{uan:logging}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\subsection{Caveats}
\label{\detokenize{uan:caveats}}
\begin{sphinxadmonition}{note}{Note:}
TODO
\end{sphinxadmonition}


\section{Validation}
\label{\detokenize{uan:validation}}
This model has been tested with three UNIT test:
\begin{itemize}
\item {} 
auv\sphinxhyphen{}energy\sphinxhyphen{}model

\item {} 
auv\sphinxhyphen{}mobility

\item {} 
li\sphinxhyphen{}ion\sphinxhyphen{}energy\sphinxhyphen{}source

\end{itemize}


\subsection{Auv Energy Model}
\label{\detokenize{uan:auv-energy-model}}
Includes test cases for single packet energy consumption, energy depletion, Glider and REMUS energy consumption.
The unit test can be found in \sphinxcode{\sphinxupquote{src/uan/test/auv\sphinxhyphen{}energy\sphinxhyphen{}model\sphinxhyphen{}test.cc}}.

The single packet energy consumption test do the following:
\begin{itemize}
\item {} 
creates a two node network, one surface gateway and one fixed node at \sphinxhyphen{}500 m of depth

\item {} 
install the acoustic communication stack with energy consumption support into the nodes

\item {} 
a packet is sent from the underwater node to the gateway

\item {} 
it is verified that both, the gateway and the fixed node, have consumed the expected amount of energy from their sources

\end{itemize}

The energy depletion test do the following steps:
\begin{itemize}
\item {} 
create a node with an empty energy source

\item {} 
try to send a packet

\item {} 
verify that the energy depletion callback has been invoked

\end{itemize}

The Glider energy consumption test do the following:
\begin{itemize}
\item {} 
create a node with glider capabilities

\item {} 
make the vehicle to move to a predetermined waypoint

\item {} 
verify that the energy consumed for the navigation is correct, according to the glider specifications

\end{itemize}

The REMUS energy consumption test do the following:
\begin{itemize}
\item {} 
create a node with REMUS capabilities

\item {} 
make the vehicle to move to a predetermined waypoint

\item {} 
verify that the energy consumed for the navigation is correct, according to the REMUS specifications

\end{itemize}


\subsection{Auv Mobility}
\label{\detokenize{uan:auv-mobility}}
Includes test cases for glider and REMUS mobility models.
The unit test can be found in \sphinxcode{\sphinxupquote{src/uan/test/auv\sphinxhyphen{}mobility\sphinxhyphen{}test.cc}}.
\begin{itemize}
\item {} 
create a node with glider capabilities

\item {} 
set a specified velocity vector and verify if the resulting buoyancy is the one that is supposed to be

\item {} 
make the vehicle to submerge to a specified depth and verify if, at the end of the process the position is the one that is supposed to be

\item {} 
make the vehicle to emerge to a specified depth and verify if, at the end of the process the position is the one that is supposed to be

\item {} 
make the vehicle to navigate to a specified point, using direction, pitch and speed settings and, verify if at the end of the process the position is the one that is supposed to be

\item {} 
make the vehicle to navigate to a specified point, using a velocity vector and, verify if at the end of the process the position is the one that is supposed to be

\end{itemize}

The REMUS mobility model test do the following:
* create a node with glider capabilities
* make the vehicle to submerge to a specified depth and verify if, at the end of the process the position is the one that is supposed to be
* make the vehicle to emerge to a specified depth and verify if, at the end of the process the position is the one that is supposed to be
* make the vehicle to navigate to a specified point, using direction, pitch and speed settings and, verify if at the end of the process the position is the one that is supposed to be
* make the vehicle to navigate to a specified point, using a velocity vector and, verify if at the end of the process the position is the one that is supposed to be


\subsection{Li\sphinxhyphen{}Ion Energy Source}
\label{\detokenize{uan:li-ion-energy-source}}
Includes test case for Li\sphinxhyphen{}Ion energy source.
The unit test can be found in \sphinxcode{\sphinxupquote{src/energy/test/li\sphinxhyphen{}ion\sphinxhyphen{}energy\sphinxhyphen{}source\sphinxhyphen{}test.cc}}.

The test case verify that after a well\sphinxhyphen{}known discharge time with constant current drain, the cell voltage has followed the datasheet discharge curve {[}9{]}.


\chapter{WAVE models}
\label{\detokenize{wave:wave-models}}\label{\detokenize{wave::doc}}
WAVE is a system architecture for wireless\sphinxhyphen{}based vehicular communications,
specified by the IEEE.  This chapter documents available models for WAVE
within \sphinxstyleemphasis{ns\sphinxhyphen{}3}.  The focus is on the MAC layer and MAC extension layer
defined by \sphinxcite{wave:ieee80211p} and \sphinxcite{wave:ieee1609dot4}.


\section{Model Description}
\label{\detokenize{wave:model-description}}
WAVE is an overall system architecture for vehicular communications.
The standards for specifying WAVE include a set of extensions to the IEEE
802.11 standard, found in IEEE Std 802.11p\sphinxhyphen{}2010 \sphinxcite{wave:ieee80211p}, and
the IEEE 1609 standard set, consisting of four documents:
resource manager:  IEEE 1609.1 \sphinxcite{wave:ieee1609dot1},
security services:  IEEE 1609.2 \sphinxcite{wave:ieee1609dot2},
network and transport layer services:  IEEE 1609.3 \sphinxcite{wave:ieee1609dot3},
and multi\sphinxhyphen{}channel coordination:  IEEE 1609.4 \sphinxcite{wave:ieee1609dot4}.
Additionally, SAE standard J2735 \sphinxcite{wave:saej2735} describes a Dedicated
Short Range Communications (DSRC) application message set that allows
applications to transmit information using WAVE.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the focus of the \sphinxcode{\sphinxupquote{wave}} module is on both the MAC layer and the
multi\sphinxhyphen{}channel coordination layer.
The key design aspect of 802.11p\sphinxhyphen{}compilant MAC layer is that they allow
communications outside the context of a basic service set (BSS).
The literature uses the acronym OCB to denote “outside the context
of a BSS”, and the class \sphinxcode{\sphinxupquote{ns3::OcbWifiMac}} models this in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.
This MAC does not require any association between devices (similar to an
adhoc WiFi MAC). Many management frames will not be used, but when used, the BSSID field
needs to be set to a wildcard BSSID value. Management information is
transmitted by what is called a vendor specific action (VSA) frame. With these
changes, the packet transmissions (for a moving vehicle) can be fast with
small delay in the MAC layer. Users can create IEEE802.11p\sphinxhyphen{}compliant device
(the object of the class \sphinxcode{\sphinxupquote{ns3::WifiNetDevice}} associating with
\sphinxcode{\sphinxupquote{ns3::OcbWifiMac}}) .

The key design aspect of the WAVE\sphinxhyphen{}compilant MAC layer (including 802.11p MAC
layer and 1609.4 MAC extension layer) is that, based on OCB features, they
provide devices with the capability of switching between control and service channels, using a single radio or using multiple radios.
Therefore devices can communicate with others in single or multiple
channels, which can
support both safety related and non\sphinxhyphen{}safety related service for vehicular environments.

At the physical layer, the biggest difference is the use of the 5.9 GHz band
with a channel bandwidth of 10 MHz.  These physical
layer changes can make the wireless signal relatively more stable,
without degrading throughput too much (ranging from 3 Mbps to 27 Mbps).

The source code for the WAVE MAC models lives in the directory
\sphinxcode{\sphinxupquote{src/wave}}.

For better modeling WAVE and VANET, the WAVE models for high layers
(mainly \sphinxcite{wave:ieee1609dot3} ) are planned for a later patch.


\subsection{Design}
\label{\detokenize{wave:design}}
In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, support for 802.11p involves the MAC and PHY layers.
To use an 802.11p NetDevice, \sphinxcode{\sphinxupquote{ns3::Wifi80211pHelper}} is suggested.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, support for WAVE involves the MAC, its MAC extension and PHY layers.
To use a WAVE NetDevice, \sphinxcode{\sphinxupquote{ns3::WaveHelper}} is suggested.


\subsubsection{MAC layer}
\label{\detokenize{wave:mac-layer}}
The classes used to model the MAC layer are \sphinxcode{\sphinxupquote{ns3::OrganizationIdentifier}},
\sphinxcode{\sphinxupquote{ns3::VendorSpecificActionHeader}} and \sphinxcode{\sphinxupquote{ns3::OcbWifiMac}}.

The OrganizationIdentifier and VendorSpecificActionHeader are used to support
the sending of a Vendor Specific Action frame.

OcbWifiMac is very similar to AdhocWifiMac, with some modifications.
The \sphinxstyleemphasis{ns\sphinxhyphen{}3} AdhocWifiMac class is implemented very close to the 802.11p OCB
mode rather than a real 802.11 ad\sphinxhyphen{}hoc mode. The AdhocWifiMac has no BSS
context that is defined in 802.11 standard, so it will not take time to
send beacons and to authenticate, making its behavior similar to that
of an OcbWifiMac.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
SetBssid, GetBssid, SetSsid, GetSsid

\end{enumerate}
\begin{quote}

These methods are related to 802.11 BSS context, and are unused in the OCB context.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
SetLinkUpCallback, SetLinkDownCallback

WAVE device can send packets directly, so the WiFi link is never down.

\item {} 
SendVsc, AddReceiveVscCallback

WAVE management information shall be sent by vendor specific action frames,
sent by the upper layer 1609.4 standard as WSA
(WAVE Service Advertisement) packets or other vendor specific information.

\item {} 
SendTimingAdvertisement (not implemented)

Although Timing Advertisement is very important and specifically defined in
802.11p standard, it is not useful in a simulation environment.
Every node in \sphinxstyleemphasis{ns\sphinxhyphen{}3} vehicular simulation is assumed to be already time
synchronized (perhaps by GPS).

\item {} 
ConfigureEdca

This method will allow the user to set EDCA parameters of WAVE channels
including CCH ans SCHs. And the OcbWifiMac itself also uses this method
to configure default 802.11p EDCA parameters.

\item {} 
Wildcard BSSID

The Wildcard BSSID is set to “ff:ff:ff:ff:ff:ff”.
As defined in IEEE 802.11\sphinxhyphen{}2007, a wildcard BSSID shall not be used in the
BSSID field except for management frames of subtype probe request. But Adhoc
mode of \sphinxstyleemphasis{ns\sphinxhyphen{}3} simplifies this mechanism:  when stations receive packets,
they will be forwarded up to the higher layer, regardless of BSSID.
This process is very close
to OCB mode as defined in 802.11p\sphinxhyphen{}2010, in which stations use the wildcard
BSSID to allow the higher layer of other stations to hear directly.

\item {} 
Enqueue, Receive

The most important methods are send and receive methods. According to the
standard, we should filter the frames that are not permitted. Thus here we
just identify the frames we care about; the other frames will be discarded.

\end{enumerate}


\subsubsection{MAC extension layer}
\label{\detokenize{wave:mac-extension-layer}}
Although 1609.4 is still in the MAC layer, the implementation
approach for \sphinxstyleemphasis{ns\sphinxhyphen{}3} does not do much modification in the
source code of the wifi module. Instead, if some feature is related
to wifi MAC classes, then a relevant subclass is defined; if some
feature has no relation to wifi MAC classes, then a new class
will be defined. This approach was selected to be non\sphinxhyphen{}intrusive to the
\sphinxstyleemphasis{ns\sphinxhyphen{}3} wifi module. All of these classes will be hosted in a ‘container’
class called \sphinxcode{\sphinxupquote{ns3:: WaveNetDevice}}. This class is a subclass inherting
from \sphinxcode{\sphinxupquote{ns3::NetDeivce}}, composed of the objects of
\sphinxcode{\sphinxupquote{ns3::ChannelScheduler}}, \sphinxcode{\sphinxupquote{ns3::ChannelManager}},
\sphinxcode{\sphinxupquote{ns3::ChannelCoordinator}} and \sphinxcode{\sphinxupquote{ns3::VsaManager}}
classes to provide the features described in 1609.4 while still
containing the objects of \sphinxcode{\sphinxupquote{ns3::OcbWifiMac}} and \sphinxcode{\sphinxupquote{ns3::WifiPhy}}
classes.  Moreover, \sphinxcode{\sphinxupquote{ns3::OcbWifiMac}} class is further extended with
support for IEEE 1609.4 associating with \sphinxcode{\sphinxupquote{ns3::HigherLayerTxVectorTag}}
and \sphinxcode{\sphinxupquote{ns3::WaveMacLow}}. The main work of the WaveNetDevice is to create
objects, configure, check arguments and provide new APIs for multiple
channel operation as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
AddMac, GetMac and GetMacs

\end{enumerate}
\begin{quote}

Different from \sphinxcode{\sphinxupquote{ns3::WifiNetDevice}}, the WAVE device will have
multiple internal MAC entities rather than a single one. Each MAC
entity is used to support each WAVE channel. Thus, when
devices switch from the current channel to the next channel in different
channel intervals, the packets in the internal queue will not be
flushed and the current MAC entity will perform a suspend operation
until woken up in next appropriate channel interval.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
AddPhy, GetPhy and GetPhys

\end{enumerate}
\begin{quote}

Also in contrast to \sphinxcode{\sphinxupquote{ns3::WifiNetDevice}},  the WAVE device here
can allow more than one PHY entity, which permits the use cases of
of single\sphinxhyphen{}PHY devices or multiple\sphinxhyphen{}PHY devices.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
SetChannelScheduler and GetChannelScheduler

\end{enumerate}
\begin{quote}

How to deal with multiple MAC entities and PHY entities to assign
channel access for different requests from higher layer? IEEE
1609.4 \sphinxcite{wave:ieee1609dot4} does not seem to give a very clear and detailed
mechanism, deferring to the implementor. In this model, the class
\sphinxcode{\sphinxupquote{ns3::ChannelScheduler}} provides the API and delegates to the subclasses
to implement the virtual methods. In the current implementation, the default
assignment mechanism for channel access,
called \sphinxcode{\sphinxupquote{ns3::DefaultChannelScheduler}}, gives a simple answer that only
deals with multiple channel operation in the context of a single\sphinxhyphen{}PHY device.
If users define their own different assignment mechanisms such as in the
context of two PHY entities, they can easily reuse models using AddPhy and
SetChannelScheduler methods to import a new assignment mechanism.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
SetChannelManager and GetChannelManager

\end{enumerate}
\begin{quote}

class \sphinxcode{\sphinxupquote{ns3::ChannelManager}} is a WAVE channel set which contains
valid WAVE channel numbers. Moreover, the tx information in this channel
set such as data rate and tx power level is used for transmitting management frames.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
SetVsaManager and GetVsaManager

\end{enumerate}
\begin{quote}

class \sphinxcode{\sphinxupquote{ns3::VsaManager}} is used to deal with sending and receiving
VSA frames. According to different request parameters from the higher layer,
this class may transmit VSA frames repeatedly in the appropriate channel
number and channel interval.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{5}
\item {} 
SetChannelCoordinator and GetChannelCoordinator

\end{enumerate}
\begin{quote}

class \sphinxcode{\sphinxupquote{ns3::ChannelCoordinator}} is used to deal with channel coordination.
The WAVE device can be aware of the channel interval at the current time or
in the future.  It can also notify listeners about incoming channel coordination
events. Generally this class is used in the case of assigning alternating CCH and SCH access.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{6}
\item {} 
StartSch and StopSch

\end{enumerate}
\begin{quote}

In contrast to the basic 802.11p device that allow transmission packets
immediately after
the device is created, the WAVE device should assign channel access
for sending packets.  This method will call class \sphinxcode{\sphinxupquote{ns3::ChannelScheduler}}
to assign radio resources for the relevant channel.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{7}
\item {} 
ChangeAddress

\end{enumerate}
\begin{quote}

The WAVE device can support a change of address after devices are already
initialized, which will cause all of MAC entities reset their status.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
CancelTx

\end{enumerate}
\begin{quote}

The WAVE device can support a request to cancel all transmissions associated
with the particular category and channel number, which will reset the
particular interval queue and drop all of the queued packets in this queue.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{9}
\item {} 
RegisterTxProfile and DeleteTxProfile

\end{enumerate}
\begin{quote}

After channel access is assigned, we still cannot send IP\sphinxhyphen{}based
(or other protocol) packets by the Send () method. A tx profile should
be registered to specify tx parameters before transmission.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{10}
\item {} 
StartVsa, StopVsa and SetWaveVsaCallback

\end{enumerate}
\begin{quote}

These methods will call an object from class \sphinxcode{\sphinxupquote{ns3::VsaManager}} to send
and receive VSA frames.  Generally these methods are used by IEEE 1609.3
for WSA management information.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{11}
\item {} 
SendX

\end{enumerate}
\begin{quote}

After channel access is assigned, we can send WSMP (or other protocol)
packets via the SendX () method. We should specify the tx parameters for
each packet, e.g. the channel number for transmit.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{12}
\item {} 
Send and SetReceiveCallback

\end{enumerate}
\begin{quote}

This method is the abstract method defined in the parent class
\sphinxcode{\sphinxupquote{ns3::NetDevice}}, defined to allow the sending of IP\sphinxhyphen{}based packets.
The channel access should be already assigned and tx profile should
be registered, otherwise incoming packets from the higher layer will be
discarded. No matter whether packets are sent by Send method or SendX
method, the received packets will be only be delivered to the higher layer
by the registered ReceiveCallback.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{13}
\item {} 
other methods from its parent class \sphinxcode{\sphinxupquote{ns3::NetDevice}}

\end{enumerate}
\begin{quote}

These methods are implemented very similar to the code in \sphinxcode{\sphinxupquote{ns3::WifiNetDevice}}.
\end{quote}

In the above numbered list, we can categorize the methods into three types:
the first type, from 1 to 6 and also 14, is the configuration for modeling and
creating a WAVE device; the second type, from 7 to 11, is
the management plane of the standard; and the third type, 12 and 13,
is the data plane of the standard.

Channel coordination

The class \sphinxcode{\sphinxupquote{ns3::ChannelCoordinator}} defines the CCH Interval, SCH Interval and GuardInteval. Users can be aware of which interval the current time or
future time will be in. If channel access mode is assigned to
alternating CCH and SCH access,
channel interval events will be notified repeatedly for class
\sphinxcode{\sphinxupquote{ns3::ChannelCoordinator}} to switch channels.  Current default values are
for CCHI with 50ms interval, SCHI with 50ms interval, and GuardI with 4ms interval. Users can change these values by configuring the class attributes.

Channel routing

Channel routing service means different transmission approaches for WSMP data,
IP datagram and management information.
For WSMP data, the SendX () method implements the service primitive
MA\sphinxhyphen{}UNITDATAX, and users can
set transmission parameters for each individual packet. The parameters include
channel number, priority,
data rate and tx power level (expiration time is not supported now).
For IP datagrams, the Send () method is a virtual method from \sphinxcode{\sphinxupquote{ns3::NetDevice}} that implements the service primitive MA\sphinxhyphen{}UNITDATA.
Users should insert QoS tags into packets themselves if they want to use QoS.
Moreover, a tx profile should be registered
before the Send method is called for transmit; the profile contains SCH number, data rate, power level and adaptable mode.
For management information, StartVsa method implements the service primitive
MLMEX\sphinxhyphen{}VSA. The tx information is already configured
in \sphinxcode{\sphinxupquote{ns3::ChannelManager}}, including data rate, power level and adaptable mode.

Channel access assignment

The channel access assignment is done by class \sphinxcode{\sphinxupquote{ns3::ChannelScheduler}} to assign ContinuousAccess, ExtendedAccess
and AlternatingAccess. Besides that, immediate access is achieved by enabling
the “immediate” parameter, in which case
the request channel will be switched to immediately.  However this class is a
virtual parent class.  The current module provides a
subclass \sphinxcode{\sphinxupquote{ns3::DefaultChannelScheduler}} to assign channel access in the context of a single\sphinxhyphen{}PHY device. In this subclass, if the channel
access is already assigned for another request, the next coming request will
fail until the previous channel access is released.
Users can implement different assignment mechanisms to deal with multiple MAC entities and multiple PHY entities by
inheriting from parent class \sphinxcode{\sphinxupquote{ns3::ChannelScheduler}}.
An important point is that channel access should be assigned before sending
routing packets, otherwise the packets will be discard.

Vendor Specific Action frames

When users want to send VSA repeatedly by calling WaveNetDevice::StartVsa, VSA will be sent repeatedly by
\sphinxcode{\sphinxupquote{ns3::VsaManager}}. It is worth noting that if the peer MAC address is a unicast address, the VSA can only
be transmitted once even there is a repeat request. The tx parameters for VSA management frames can be obtained from the \sphinxcode{\sphinxupquote{ns3::ChannelManager}}.

User priority and Multi\sphinxhyphen{}channel synchronization

Since wifi module has already implemented a QoS mechanism, the wave module
reuses the mechanism; VSA frames will be assigned the default value with the
highest AC according to the standard.
Multiple\sphinxhyphen{}channel synchronization is very important in practice for devices
without a local timing source.
However, in simulation, every node is supposed to have the same system clock, which could be provided by GPS devices in a real environment, so this feature is not modelled in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.
During the guard interval, the device can only be in receive state, except
for the switch state when the device does channel switching operation.


\subsubsection{PHY layer}
\label{\detokenize{wave:phy-layer}}
No modification or extension is made to the \sphinxstyleemphasis{ns\sphinxhyphen{}3} PHY layer
corresponding to this model.
In the 802.11p standard, the PHY layer wireless technology is still 80211a OFDM with a 10MHz channel width,
so Wifi80211pHelper will only allow the user to set the standard
to WIFI\_PHY\_STANDARD\_80211\_10MHZ or WIFI\_PHY\_STANDARD\_80211\_20MHZ,
while WaveHelper will only support WIFI\_PHY\_STANDARD\_80211\_10MHZ.
The maximum station transmit power and maximum permitted EIRP defined in
802.11p is larger
than that of WiFi, so transmit range can normally become longer than the
usual WiFi.  However, this feature will
not be implemented. Users who want to obtain longer range should configure
attributes “TxPowerStart”,
“TxPowerEnd” and “TxPowerLevels” of the YansWifiPhy class by themselves.


\subsection{Scope and Limitations}
\label{\detokenize{wave:scope-and-limitations}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Does the model involve vehicular mobility of some sort?

\end{enumerate}

Vehicular networks involve not only communication protocols, but
also a communication environment including vehicular mobility and
propagation loss models. Because of specific features of the latter,
the protocols need to change. The MAC layer model in this project just
adapts MAC changes to vehicular environment. However this model
does not involve any vehicular mobility with time limit. While users
should understand that vehicular mobility is out of scope for the
current WAVE module, they can use any mobility model in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.  For
example, users may use a \sphinxcode{\sphinxupquote{ns3::RandomWaypointMobilityModel}} (RWP)
for node mobilty or may generate ns\sphinxhyphen{}2\sphinxhyphen{}style playback files using
other third\sphinxhyphen{}party tools and then playback those mobility traces
using \sphinxcode{\sphinxupquote{ns3::Ns2MobilityHelper}}.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
Does this model use different propagation models?

\end{enumerate}

Referring to the first issue, some more realistic propagation loss
models for vehicualr environment are suggested and welcome.  Some
existing propagation los models in \sphinxstyleemphasis{ns\sphinxhyphen{}3} are also suitable.
Normally, users can use Friis, Two\sphinxhyphen{}Ray Ground, and Nakagami models.
The \sphinxcode{\sphinxupquote{ns3::VanetRoutingExample}} example defaults to Two\sphinxhyphen{}Ray
Ground propagation loss with no additional fading, although adding
stochastic Nakagami\sphinxhyphen{}m fading is parametrically supported.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
Are there any vehicular application models to drive the code?

\end{enumerate}

About vehicular application models, SAE J2375 depends on WAVE
architecture and is an application message set in US.  Cooperative Awareness
Messages (CAM) and Decentralized Environment Notification Messages (DENM) can
be sent Europe between network and application layer, and is
very close to being an application model. The BSM in J2375 {[}saej2735{]} and CAM
send alert messages that every vehicle node will sent periodically about
its status information to cooperate with others. The
\sphinxcode{\sphinxupquote{ns3::VanetRoutingExample}} example sets up a network of (vehicular)
nodes that each broadcast BSMs at regular intervals and may additionally
attempt to route non\sphinxhyphen{}BSM data through the network using select IP\sphinxhyphen{}based
routing protocols.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
Why are there two kinds of NetDevice helpers?

\end{enumerate}

The current module provides two helpers to create two kinds of NetDevice.
The first is an object of WifiNetDevice (802.11p device) which mainly
contains class \sphinxcode{\sphinxupquote{ns3::OcbWifiMac}} to enable OCB mode. The second
is an object of WaveNetDevice (WAVE device) which contains additional
classes \sphinxcode{\sphinxupquote{ns3::ChannelScheduler}}, \sphinxcode{\sphinxupquote{ns3::ChannelManager}},
\sphinxcode{\sphinxupquote{ns3::ChannelCoordinator}} and \sphinxcode{\sphinxupquote{ns3::VsaManager}} to support
multi\sphinxhyphen{}channel operation mode.  The reason to provide a special 802.11p
device helper is that, considering the fact that many researchers are
interested in routing protocols or other aspects of vehicular environment in
a single channel context, they need neither multi\sphinxhyphen{}channel operation nor
WAVE architectures.
Besides that, the European standard may also reuse an 802.11p device in an
modified ITS\sphinxhyphen{}G5 implementation (maybe called ItsG5NetDevice).  Hence,
the model supports configuration of both types of devices.


\subsection{References}
\label{\detokenize{wave:references}}

\section{Usage}
\label{\detokenize{wave:usage}}

\subsection{Helpers}
\label{\detokenize{wave:helpers}}
The helpers include a) lower\sphinxhyphen{}level MAC and PHY channel helpers and
b) higher\sphinxhyphen{}level application helpers that handle the sending and receiving
of the Basic Safety Message (BSM).

The lower\sphinxhyphen{}level helpers include \sphinxcode{\sphinxupquote{ns3::YansWavePhyHelper}}, \sphinxcode{\sphinxupquote{ns3::NqosWaveMacHelper}}, \sphinxcode{\sphinxupquote{ns3::QosWaveMacHelper}},
\sphinxcode{\sphinxupquote{ns3::Wifi80211pHelper}} and \sphinxcode{\sphinxupquote{ns3::WaveHelper}}.

Wifi80211pHelper is used to create
802.11p devices that follow the 802.11p\sphinxhyphen{}2010 standard. WaveHelper is
used to create WAVE devices that follow both 802.11p\sphinxhyphen{}2010 and 1609.4\sphinxhyphen{}2010
standards which are the MAC and PHY layers of the WAVE architecture.

The relation of \sphinxcode{\sphinxupquote{ns3::NqosWaveMacHelper}}, \sphinxcode{\sphinxupquote{ns3::QosWaveMacHelper}} and
\sphinxcode{\sphinxupquote{ns3::Wifi80211pHelper}} is described as below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{use}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}   \PYG{n}{WifiMacHelper}
    \PYG{o}{\PYGZca{}}                                        \PYG{o}{\PYGZca{}}         \PYG{o}{\PYGZca{}}
    \PYG{o}{|}                                        \PYG{o}{|}         \PYG{o}{|}
    \PYG{o}{|}                                        \PYG{o}{|}         \PYG{o}{|}
  \PYG{n}{inherit}                                \PYG{n}{inherit}      \PYG{n}{inherit}
    \PYG{o}{|}                                        \PYG{o}{|}         \PYG{o}{|}
\PYG{n}{Wifi80211pHelper} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{use}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}  \PYG{n}{QosWaveMacHelper} \PYG{o+ow}{or} \PYG{n}{NqosWaveHelper}
\end{sphinxVerbatim}

From the above diagram, there are two Mac helper classes that both
inherit from the WifiMacHelper; when the WAVE module was originally
written, there were specialized versions (QoS and Nqos) of WifiMacHelper
that have since been removed from the Wifi codebase, but the distinction
remains in the WAVE helpers.  The functions of WiFi 802.11p device can be achieved by
WaveNetDevice’s ContinuousAccess assignment, Wifi80211pHelper is recommended
if there is no need for multiple channel operation.
Usage is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{nodes}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices}\PYG{p}{;}
\PYG{n}{nodes}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{YansWifiPhyHelper} \PYG{n}{wifiPhy} \PYG{o}{=} \PYG{n}{YansWifiPhyHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{YansWifiChannelHelper} \PYG{n}{wifiChannel} \PYG{o}{=} \PYG{n}{YansWifiChannelHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{o}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{wifiChannel}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NqosWave80211pMacHelper} \PYG{n}{wifi80211pMac} \PYG{o}{=} \PYG{n}{NqosWaveMacHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Wifi80211pHelper} \PYG{l+m+mi}{80211}\PYG{n}{pHelper} \PYG{o}{=} \PYG{n}{Wifi80211pHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{devices} \PYG{o}{=} \PYG{l+m+mi}{80211}\PYG{n}{pHelper}\PYG{o}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiPhy}\PYG{p}{,} \PYG{n}{wifi80211pMac}\PYG{p}{,} \PYG{n}{nodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The relation of  \sphinxcode{\sphinxupquote{ns3::YansWavePhyHelper}}, \sphinxcode{\sphinxupquote{ns3::QosWaveMacHelper}} and \sphinxcode{\sphinxupquote{ns3::WaveHelper}}
is described as below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
                                        \PYG{n}{WifiMacHelper}
                                              \PYG{o}{\PYGZca{}}
                                              \PYG{o}{|}
                                            \PYG{n}{inherit}
                                              \PYG{o}{|}
\PYG{n}{WaveHelper} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{only} \PYG{n}{use} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{QosWaveMacHelper}
\end{sphinxVerbatim}

From the above diagram, WaveHelper is not the subclass of WifiHelper and should only
use QosWaveMacHelper because WAVE MAC layer is based on QoS mechanism. But
the WaveHelper is recommended if there is a need for multiple channel operation.
Usage is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{nodes}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices}\PYG{p}{;}
\PYG{n}{nodes}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{YansWifiChannelHelper} \PYG{n}{wifiChannel} \PYG{o}{=} \PYG{n}{YansWifiChannelHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{YansWavePhyHelper} \PYG{n}{wavePhy} \PYG{o}{=}  \PYG{n}{YansWavePhyHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wavePhy}\PYG{o}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{wifiChannel}\PYG{o}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{QosWaveMacHelper} \PYG{n}{waveMac} \PYG{o}{=} \PYG{n}{QosWaveMacHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{WaveHelper} \PYG{n}{waveHelper} \PYG{o}{=} \PYG{n}{WaveHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{devices} \PYG{o}{=} \PYG{n}{waveHelper}\PYG{o}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wavePhy}\PYG{p}{,} \PYG{n}{waveMac}\PYG{p}{,} \PYG{n}{nodes}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The higher\sphinxhyphen{}level helpers include \sphinxcode{\sphinxupquote{ns3::WaveBsmStats}} and \sphinxcode{\sphinxupquote{ns3::WaveBsmHelper}}.

WaveBsmStats is used to collect and manage statistics, such as packet and byte
counts and Packet Delivery Ratio (PDR), regarding the sending
and receiving of WAVE BSM packets.  WaveBsmHelper is used by applications that
wish to send and receive BSMs.

The relation of \sphinxcode{\sphinxupquote{ns3::WaveBsmHelper}} and \sphinxcode{\sphinxupquote{WaveBsmStats}} is described
below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZlt{}}\PYG{n}{Your} \PYG{n}{Vanet} \PYG{n}{Routing} \PYG{n}{Application}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{use}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{WaveBsmHelper} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{use}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{WaveBsmStats}
\end{sphinxVerbatim}

From \textless{}Your Vanet Routing Application\textgreater{}, usage is as follows:
\begin{quote}

// declare WAVE BSM helper instance
WaveBsmHelper m\_waveBsmHelper;

// the following are passed to the WaveBsmHelpe::Install()
// method, and they are thus assumed to be created and
// initialized themselves, based on the user’s
// simulation setup criteria.
// container of network node
NodeContainer m\_adhocTxNodes;
// (transmitting) devices (1 per node)
NetDeviceContainer m\_adhocTxDevices;
// IPv4 interfaces (1 per device)
Ipv4InterfaceContainer m\_adhocTxInterfaces;
// total simulation time (in seconds)
double m\_TotalSimTime;
// WAVE BSM broadcast interval.  E.g., 100ms = 0.1 seconds
double m\_waveInterval; // seconds
// time\sphinxhyphen{}synchronization accuracy of GPS devices.  E.g., +/\sphinxhyphen{} 40ns
double m\_gpsAccuracyNs;
// array of distances (m) at which safety PDR shall be determined,
// e.g. 50m, 100m, 200m, 300m, 400m, 500m, 600m, 800m, 1000m, and 1500m
std::vector \textless{}double\textgreater{} m\_txSafetyRanges;
// used to get consistent random numbers across scenarios
int64\_t m\_streamIndex;
\begin{description}
\item[{m\_waveBsmHelper.Install (m\_adhocTxNodes,}] \leavevmode
m\_adhocTxDevices,
m\_adhocTxInterfaces,
Seconds(m\_TotalSimTime),
m\_wavePacketSize,
Seconds(m\_waveInterval),
// convert GPS accuracy, in ns, to Time
Seconds(m\_gpsAccuracyNs / 1000000.0),
m\_txSafetyRanges);

\end{description}

// fix random number streams
m\_streamIndex += m\_waveBsmHelper.AssignStreams (m\_streamIndex);
\end{quote}

Example usages of BSM statistics are as follows:
\begin{quote}

// Get the cumulative PDR of the first safety Tx range (i.e, 50m in the
// m\_txSafetyRanges example above).
double bsm\_pdr1 = m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}GetBsmPdr (1);

// total WAVE BSM bytes sent
uint32\_t cumulativeWaveBsmBytes = m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}GetTxByteCount ();

// get number of WAVE BSM packets sent
int wavePktsSent = m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}GetTxPktCount ();

// get number of WAVE BSM packets received
int wavePktsReceived = m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}GetRxPktCount ();

// reset count of WAVE BSM packets received
m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}SetRxPktCount (0);

// reset count of WAVE BSM packets sent
m\_waveBsmHelper.GetWaveBsmStats ()\sphinxhyphen{}\textgreater{}SetTxPktCount (0);

// indicate that a node (nodeId) is moving.  (set to 0 to “stop” node)
WaveBsmHelper::GetNodesMoving(){[}nodeId{]} = 1;
\end{quote}


\subsection{APIs}
\label{\detokenize{wave:apis}}

\subsubsection{MAC layer}
\label{\detokenize{wave:id11}}
The 802.11p device can allow the upper layer to send different information
over Vendor Specific Action management frames by using different
OrganizationIdentifier fields to identify differences.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
create some Node objects and WifiNetDevice objects, e.g. one sender and one receiver.

\item {} 
receiver defines an OrganizationIdentifier

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{uint8\PYGZus{}t} \PYG{n}{oi\PYGZus{}bytes}\PYG{p}{[}\PYG{l+m+mi}{5}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+m+mh}{0x00}\PYG{p}{,} \PYG{l+m+mh}{0x50}\PYG{p}{,} \PYG{l+m+mh}{0xC2}\PYG{p}{,} \PYG{l+m+mh}{0x4A}\PYG{p}{,} \PYG{l+m+mh}{0x40}\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\PYG{n}{OrganizationIdentifier} \PYG{n}{oi}\PYG{p}{(}\PYG{n}{oi\PYGZus{}bytes}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
receiver defines a Callback for the defined OrganizationIdentifier

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{VscCallback} \PYG{n}{vsccall} \PYG{o}{=} \PYG{n}{MakeCallback} \PYG{p}{(}\PYG{o}{\PYGZam{}}\PYG{n}{VsaExample}\PYG{p}{:}\PYG{p}{:}\PYG{n}{GetWsaAndOi}\PYG{p}{,} \PYG{n}{this}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
receiver registers this identifier and function

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{device1} \PYG{o}{=} \PYG{n}{DynamicCast}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}}\PYG{p}{(}\PYG{n}{nodes}\PYG{o}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetDevice} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{OcbWifiMac}\PYG{o}{\PYGZgt{}} \PYG{n}{ocb1} \PYG{o}{=} \PYG{n}{DynamicCast}\PYG{o}{\PYGZlt{}}\PYG{n}{OcbWifiMac}\PYG{o}{\PYGZgt{}}\PYG{p}{(}\PYG{n}{device}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetMac} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ocb1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddReceiveVscCallback} \PYG{p}{(}\PYG{n}{oi}\PYG{p}{,} \PYG{n}{vsccall}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
sender transmits management information over VSA frames

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{vsc} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ocb2}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SendVsc} \PYG{p}{(}\PYG{n}{vsc}\PYG{p}{,} \PYG{n}{Mac48Address}\PYG{p}{:}\PYG{p}{:}\PYG{n}{GetBroadcast} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{m\PYGZus{}16093oi}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{5}
\item {} 
then registered callbacks in the receiver will be called.

\end{enumerate}


\subsubsection{MAC extension layer}
\label{\detokenize{wave:id12}}
The WAVE devices allow the upper layer to route packets in different control
approaches.  However dedicated APIs and invocation sequences should be
followed; otherwise, the packets may be discarded by devices.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
create some Node objects and WaveNetDevice objects by helpers, e.g. one sender and one receiver.

\item {} 
receiver registers the receive callback if WSMP and IP\sphinxhyphen{}based packets are supposed to be received.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
// the class ``ns3::WaveNetDeviceExample``here will has a receive method \PYGZdq{}Receive\PYGZdq{} to be registered.
receiver\PYGZhy{}\PYGZgt{}SetReceiveCallback (MakeCallback (\PYGZam{}WaveNetDeviceExample::Receive, this));
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
receiver registers the receive callback if WSA frames are supposed to be received.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
// the class ``ns3::WaveNetDeviceExample``here will has a receive method \PYGZdq{}ReceiveVsa\PYGZdq{} to be registered.
receiver\PYGZhy{}\PYGZgt{}SetWaveVsaCallback (MakeCallback  (\PYGZam{}WaveNetDeviceExample::ReceiveVsa, this));
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
sender and receiver assign channel access by StartSch method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{in} \PYG{n}{this} \PYG{n}{case} \PYG{n}{that} \PYG{n}{alternating} \PYG{n}{access} \PYG{k}{with} \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{immediate} \PYG{n}{mode} \PYG{o+ow}{is} \PYG{n}{assigned} \PYG{k}{for} \PYG{n}{sender} \PYG{o+ow}{and} \PYG{n}{receiver} \PYG{n}{devices}\PYG{o}{.}
\PYG{n}{const} \PYG{n}{SchInfo} \PYG{n}{schInfo} \PYG{o}{=} \PYG{n}{SchInfo} \PYG{p}{(}\PYG{n}{SCH1}\PYG{p}{,} \PYG{n}{false}\PYG{p}{,} \PYG{n}{EXTENDED\PYGZus{}ALTERNATING}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{receiver}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{in} \PYG{n}{this} \PYG{n}{case} \PYG{n}{that} \PYG{n}{continuous} \PYG{n}{access} \PYG{k}{with} \PYG{n}{immediate} \PYG{n}{mode} \PYG{o+ow}{is} \PYG{n}{assigned} \PYG{k}{for} \PYG{n}{sender} \PYG{o+ow}{and} \PYG{n}{receiver} \PYG{n}{devices}\PYG{o}{.}
\PYG{n}{const} \PYG{n}{SchInfo} \PYG{n}{schInfo} \PYG{o}{=} \PYG{n}{SchInfo} \PYG{p}{(}\PYG{n}{SCH1}\PYG{p}{,} \PYG{n}{true}\PYG{p}{,} \PYG{n}{EXTENDED\PYGZus{}CONTINUOUS}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{receiver}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{in} \PYG{n}{this} \PYG{n}{case} \PYG{n}{that} \PYG{n}{extended} \PYG{n}{access} \PYG{k}{with} \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{immediate} \PYG{n}{mode} \PYG{o+ow}{is} \PYG{n}{assigned} \PYG{k}{for} \PYG{n}{sender} \PYG{o+ow}{and} \PYG{n}{receiver} \PYG{n}{devices}\PYG{o}{.}
\PYG{n}{const} \PYG{n}{SchInfo} \PYG{n}{schInfo} \PYG{o}{=} \PYG{n}{SchInfo} \PYG{p}{(}\PYG{n}{SCH1}\PYG{p}{,} \PYG{n}{false}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartSch}\PYG{p}{,} \PYG{n}{receiver}\PYG{p}{,} \PYG{n}{schInfo}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
sender registers a tx profile if IP\sphinxhyphen{}based packets are planned to be transmitted

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{n}{the} \PYG{n}{IP}\PYG{o}{\PYGZhy{}}\PYG{n}{based} \PYG{n}{packets} \PYG{n}{will} \PYG{n}{be} \PYG{n}{transmitted} \PYG{o+ow}{in} \PYG{n}{SCH1} \PYG{k}{with} \PYG{l+m+mi}{6}\PYG{n}{Mbps} \PYG{o+ow}{and} \PYG{l+m+mi}{4} \PYG{n}{txPowerLevel} \PYG{k}{with} \PYG{n}{adaptable} \PYG{n}{mode}\PYG{o}{.}
\PYG{n}{const} \PYG{n}{TxProfile} \PYG{n}{txProfile} \PYG{o}{=} \PYG{n}{TxProfile} \PYG{p}{(}\PYG{n}{SCH1}\PYG{p}{,} \PYG{n}{true}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{n}{WifiMode}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OfdmRate6MbpsBW10MHz}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{RegisterTxProfile}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{txProfile}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{5}
\item {} 
sender transmits  WSMP packets by SendX method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{n}{the} \PYG{n}{data} \PYG{n}{rate} \PYG{o+ow}{and} \PYG{n}{txPowerLevel} \PYG{o+ow}{is} \PYG{n}{controlled} \PYG{n}{by} \PYG{n}{the} \PYG{n}{high} \PYG{n}{layer} \PYG{n}{which} \PYG{n}{are} \PYG{l+m+mi}{6}\PYG{n}{Mbps} \PYG{o+ow}{and} \PYG{l+m+mi}{0} \PYG{n}{level} \PYG{n}{here}\PYG{o}{.}
\PYG{n}{const} \PYG{n}{TxInfo} \PYG{n}{txInfo} \PYG{o}{=} \PYG{n}{TxInfo} \PYG{p}{(}\PYG{n}{CCH}\PYG{p}{,} \PYG{l+m+mi}{7}\PYG{p}{,} \PYG{n}{WifiMode}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OfdmRate6MbpsBW10MHz}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}  \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{o}{/}\PYG{o}{/} \PYG{n}{this} \PYG{n}{packet} \PYG{n}{will} \PYG{n}{contain} \PYG{n}{WSMP} \PYG{n}{header} \PYG{n}{when} \PYG{n}{IEEE} \PYG{l+m+mf}{1609.3} \PYG{n}{model} \PYG{o+ow}{is} \PYG{n}{implemented}
\PYG{n}{const} \PYG{n}{static} \PYG{n}{uint16\PYGZus{}t} \PYG{n}{WSMP\PYGZus{}PROT\PYGZus{}NUMBER} \PYG{o}{=} \PYG{l+m+mh}{0x88DC}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{wsaPacket}  \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{const} \PYG{n}{Address} \PYG{n}{dest} \PYG{o}{=} \PYG{n}{receiver}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetAddress} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{,}  \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{SendX}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{wsaPacket}\PYG{p}{,} \PYG{n}{dest}\PYG{p}{,} \PYG{n}{WSMP\PYGZus{}PROT\PYGZus{}NUMBER}\PYG{p}{,} \PYG{n}{txInfo}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{n}{the} \PYG{n}{data} \PYG{n}{rate} \PYG{o+ow}{and} \PYG{n}{txPowerLevel} \PYG{o+ow}{is} \PYG{n}{controlled} \PYG{n}{by} \PYG{n}{the} \PYG{n}{MAC} \PYG{n}{layer} \PYG{n}{which} \PYG{n}{are} \PYG{n}{decided} \PYG{n}{by} \PYG{n}{WifiRemoteStationManager}
\PYG{n}{const} \PYG{n}{TxInfo} \PYG{n}{txInfo} \PYG{o}{=} \PYG{n}{TxInfo} \PYG{p}{(}\PYG{n}{CCH}\PYG{p}{,} \PYG{l+m+mi}{7}\PYG{p}{,} \PYG{n}{WifiMode}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}  \PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{;}
\PYG{o}{/}\PYG{o}{/} \PYG{n}{this} \PYG{n}{packet} \PYG{n}{will} \PYG{n}{contain} \PYG{n}{WSMP} \PYG{n}{header} \PYG{n}{when} \PYG{n}{IEEE} \PYG{l+m+mf}{1609.3} \PYG{n}{model} \PYG{o+ow}{is} \PYG{n}{implemented}
\PYG{n}{const} \PYG{n}{static} \PYG{n}{uint16\PYGZus{}t} \PYG{n}{WSMP\PYGZus{}PROT\PYGZus{}NUMBER} \PYG{o}{=} \PYG{l+m+mh}{0x88DC}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{wsaPacket}  \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{const} \PYG{n}{Address} \PYG{n}{dest} \PYG{o}{=} \PYG{n}{receiver}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetAddress} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{,}  \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{SendX}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{wsaPacket}\PYG{p}{,} \PYG{n}{dest}\PYG{p}{,} \PYG{n}{WSMP\PYGZus{}PROT\PYGZus{}NUMBER}\PYG{p}{,} \PYG{n}{txInfo}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{6}
\item {} 
sender transmits IP\sphinxhyphen{}based packets by Send method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{const} \PYG{n}{static} \PYG{n}{uint16\PYGZus{}t} \PYG{n}{IPv6\PYGZus{}PROT\PYGZus{}NUMBER} \PYG{o}{=} \PYG{l+m+mh}{0x86DD}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{packet}  \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{const} \PYG{n}{Address} \PYG{n}{dest} \PYG{o}{=} \PYG{n}{receiver}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetAddress} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{,}  \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Send}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{packet}\PYG{p}{,} \PYG{n}{dest}\PYG{p}{,} \PYG{n}{IPv6\PYGZus{}PROT\PYGZus{}NUMBER}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{7}
\item {} 
send transmits WSA frames repeatedly by StartVsa method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{o}{/}\PYG{o}{/} \PYG{n}{this} \PYG{n}{packet} \PYG{n}{will} \PYG{n}{contain} \PYG{n}{WSA} \PYG{n}{management} \PYG{n}{information} \PYG{n}{when} \PYG{n}{IEEE} \PYG{l+m+mf}{1609.3} \PYG{n}{model} \PYG{o+ow}{is} \PYG{n}{implemented}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{n}{wsaPacket} \PYG{o}{=} \PYG{n}{Create}\PYG{o}{\PYGZlt{}}\PYG{n}{Packet}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Mac48Address} \PYG{n}{dest} \PYG{o}{=} \PYG{n}{Mac48Address}\PYG{p}{:}\PYG{p}{:}\PYG{n}{GetBroadcast} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{const} \PYG{n}{VsaInfo} \PYG{n}{vsaInfo} \PYG{o}{=} \PYG{n}{VsaInfo} \PYG{p}{(}\PYG{n}{dest}\PYG{p}{,} \PYG{n}{OrganizationIdentifier} \PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{wsaPacket}\PYG{p}{,} \PYG{n}{SCH1}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{VSA\PYGZus{}TRANSMIT\PYGZus{}IN\PYGZus{}BOTHI}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StartVsa}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{vsaInfo}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
sender stops WSA frames repeatedly transmit by StopVsa method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{3.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StopVsa}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{SCH1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{9}
\item {} 
sender and receiver release assigned channel access by StopSch method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{4.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StopSch}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{SCH1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{4.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{StopSch}\PYG{p}{,} \PYG{n}{receiver}\PYG{p}{,} \PYG{n}{SCH1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{10}
\item {} 
sender or receiver changes current MAC address by ChangeAddress method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Address} \PYG{n}{newAddress} \PYG{o}{=} \PYG{n}{Mac48Address}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Allocate} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{4.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{ChangeAddress}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{newAddress}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{11}
\item {} 
sender cancels all transmissions with the particular category and channel number by CancelTx method.

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Simulator}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Schedule} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{4.0}\PYG{p}{)}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{WaveNetDevice}\PYG{p}{:}\PYG{p}{:}\PYG{n}{CancelTx}\PYG{p}{,} \PYG{n}{sender}\PYG{p}{,} \PYG{n}{CCH}\PYG{p}{,}  \PYG{n}{AC\PYGZus{}BE}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\end{quote}

For transmitting and receiving these packets successfully,
the normal and appropriate invocation procedures should be performed.

(a) For WSMP, channel access should be assigned for transmit and receive.
The channel access release operation may be optional if there is no need for
transmission in another channel.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{StartSch} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{SendX} \PYG{o}{/} \PYG{n}{ReceiveCallback} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}  \PYG{n}{StopSch}
\end{sphinxVerbatim}

(b) For IP, a tx profile should be registered before transmit and receive
operations. The delete operation of tx profile may be
optional if there is no need for transmission with other tx parameters.
The channel access assignment and release optional usage is the same with
WSMP here.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{StartSch} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{RegisterTxProfile} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Send} \PYG{o}{/} \PYG{n}{ReceiveCallback} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}  \PYG{n}{DeleteTxProfile} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{StopSch}
\end{sphinxVerbatim}

(c) For WSA, StartVsa is called to transmit while StopVsa is an optional
operation for canceling repeat transmit. The channel
access assignment and release optional usage is also the same with WSMP here.
To receive VSA, WaveVsaCallback should
be registered; otherwise, the received VSA frames will be discard by
the MAC extension layer and not delivered to the higher layer.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{StartSch} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{StartVsa} \PYG{o}{/} \PYG{n}{WaveVsaCallback} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}  \PYG{n}{StopVsa} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{StopSch}
\end{sphinxVerbatim}

(d) Here an important point is that if the higher layer wants to transmit
these packets in a control channel (the channel 178),
there will be no need to request for CCH by the StartSch method, which means
that StartSch can be optional or should be avoided
here. The reason is that the default continuous CCH access has been assigned automatically after WAVE devices are created and initialized.
Therefore, if calling StartSch and StopSch method with CCH as a parameter,
the request will be discarded by devices and the method will return false to
indicate failure.


\subsection{Attributes}
\label{\detokenize{wave:attributes}}
The channel interval duration’s default value is defined in the standard.
However, the current implementation allows users to configure these
attributes with other values. These attributes are included in the class
\sphinxcode{\sphinxupquote{ns3::ChannelCoodinator}} with config paths shown in the below. The method
IsValidConfig is suggested to test whether new configuration follows the
standard.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelCoordinator/\PYGZdl{}ns3::ChannelCoordinator/CchInterval
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelCoordinator/\PYGZdl{}ns3::ChannelCoordinator/SchInterval
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelCoordinator/\PYGZdl{}ns3::ChannelCoordinator/GuardInterval
\end{sphinxVerbatim}

The \sphinxcode{\sphinxupquote{ns3::WaveNetDevice}} is a wrapper class that contains those classes to support for multiple channel
operation. To set or get the pointers of those objects, users can also
use them by config paths shown in the below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/Mtu
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/Channel
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/PhyEntities
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/MacEntities
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelScheduler
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelManager
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/ChannelCoordinator
/NodeList/[i]/DeviceList/[i]/\PYGZdl{}ns3::WaveNetDevice/VsaManager
\end{sphinxVerbatim}


\subsection{Output}
\label{\detokenize{wave:output}}
For the 802.11p device, current classes provide output of the same type as WiFi devices;
namely, ASCII and pcap traces, and logging output.  The 802.11p logging
components can be enabled globally via the call to

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Wifi80211pHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{EnableLogComponents} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For the WAVE device, current classes provide output of the same type as WiFi
devices; namely, ASCII and pcap traces, and logging output. The WAVE logging
components can be enabled globally via the call to

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WaveHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{EnableLogComponents} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Advanced Usage}
\label{\detokenize{wave:advanced-usage}}

\subsubsection{Advanced WaveHelper configuration}
\label{\detokenize{wave:advanced-wavehelper-configuration}}
If users can make sure in which channel this WAVE device will work,
they can set specific channel numbers to save resources of unused channels .
Usage is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{in} \PYG{n}{this} \PYG{n}{case}\PYG{p}{,} \PYG{n}{the} \PYG{n}{MAC} \PYG{n}{entities} \PYG{k}{for} \PYG{n}{SCH2} \PYG{n}{to} \PYG{n}{SCH6} \PYG{n}{will} \PYG{o+ow}{not} \PYG{n}{be} \PYG{n}{created}
\PYG{n}{WaveHelper} \PYG{n}{helper} \PYG{o}{=} \PYG{n}{WaveHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{uint32\PYGZus{}t} \PYG{n}{channels}\PYG{p}{[}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{n}{CCH}\PYG{p}{,} \PYG{n}{SCH1}\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\PYG{n}{std}\PYG{p}{:}\PYG{p}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{uint32\PYGZus{}t}\PYG{o}{\PYGZgt{}} \PYG{n}{channelsVector} \PYG{p}{(}\PYG{n}{channels}\PYG{p}{,} \PYG{n}{channels} \PYG{o}{+} \PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{o}{.}\PYG{n}{CreateMacForChannel} \PYG{p}{(}\PYG{n}{channelsVector}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

If users can create other channel access assignment mechanism, e.g.
in the context of more PHY entities, which may be called
“ns3::AnotherScheduler”, they can use this helper to create WAVE devices
with new assignment mechanisms.  Usage is as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WaveHelper} \PYG{n}{helper} \PYG{o}{=} \PYG{n}{WaveHelper}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{helper}\PYG{o}{.}\PYG{n}{helper}\PYG{o}{.}\PYG{n}{CreateMacForChannel} \PYG{p}{(}\PYG{n}{ChannelManager}\PYG{p}{:}\PYG{p}{:}\PYG{n}{GetWaveChannels} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}    \PYG{o}{/}\PYG{o}{/} \PYG{n}{create} \PYG{n+nb}{all} \PYG{l+m+mi}{7} \PYG{n}{MAC} \PYG{n}{entities} \PYG{k}{for} \PYG{n}{WAVE}
\PYG{n}{helper}\PYG{o}{.}\PYG{n}{CreatePhys} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}        \PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{or} \PYG{n}{other} \PYG{n}{number} \PYG{n}{which} \PYG{n}{should} \PYG{n}{be} \PYG{n}{less} \PYG{n}{than} \PYG{l+m+mi}{7}
\PYG{n}{helper}\PYG{o}{.}\PYG{n}{SetChannelScheduler} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ns3::AnotherScheduler}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}    \PYG{o}{/}\PYG{o}{/} \PYG{n}{The} \PYG{n}{AnotherScheduler} \PYG{n}{should} \PYG{n}{be} \PYG{n}{implemented} \PYG{n}{by} \PYG{n}{users}\PYG{o}{.}
\PYG{n}{helper}\PYG{o}{.}\PYG{n}{SetRemoteStationManager} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ns3::ConstantRateWifiManager}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}    \PYG{o}{/}\PYG{o}{/} \PYG{o+ow}{or} \PYG{n}{other}  \PYG{n}{rate} \PYG{n}{control} \PYG{n}{algorithms}
\end{sphinxVerbatim}


\subsection{Examples}
\label{\detokenize{wave:examples}}
A basic example exists called \sphinxcode{\sphinxupquote{wave\sphinxhyphen{}simple\sphinxhyphen{}80211p.cc}}.
This example shows basic construction of an 802.11p node.  Two nodes
are constructed with 802.11p devices, and by default, one node sends a single
packet to another node (the number of packets and interval between
them can be configured by command\sphinxhyphen{}line arguments).  The example shows
typical usage of the helper classes for this mode of WiFi.

Another example exists called \sphinxcode{\sphinxupquote{wave\sphinxhyphen{}simple\sphinxhyphen{}device.cc}}. This
example shows how to create WAVE devices by helpers and the routing service
for different packets.
After WAVE devices are configured and created by helpers, these packets are
transmitted in different approaches.

Another example exists called \sphinxcode{\sphinxupquote{vanet\sphinxhyphen{}routing\sphinxhyphen{}compare.cc}}. This
example shows how to create mobility nodes in a VANET scenario and
send Basic Safety Message (BSM) packets are regular intervals and/or
additional data traffic to be routed between nodes.  BSMs are transmitted
assuming the WAVE Short Message Protocol (WSMP), whereas non\sphinxhyphen{}BSM data
packets are relayed by using one of several different IP\sphinxhyphen{}based routing
protocols (e.g., AODV, OLSR, DSDV, or DSR).


\subsection{Troubleshooting}
\label{\detokenize{wave:troubleshooting}}
To be defined.


\section{Validation}
\label{\detokenize{wave:validation}}
A test suite named \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}80211p\sphinxhyphen{}ocb}} is defined.  This test
case consists of a stationary node and a mobile node.  The mobile
node moves towards the stationary mode, and time points are checked
at which time the physical layer starts to receive packets (and
whether the MAC becomes associated, if applicable).  The same physical
experiment is repeated for normal WiFi NetDevices in AP/STA mode, in
Adhoc mode, and the new OCB mode.

Another test suite named \sphinxcode{\sphinxupquote{wave\sphinxhyphen{}mac\sphinxhyphen{}extension}} is defined. This test suite
has four test cases, including \sphinxcode{\sphinxupquote{channel\sphinxhyphen{}coordination}}, \sphinxcode{\sphinxupquote{channel\sphinxhyphen{}routing}},
\sphinxcode{\sphinxupquote{channel\sphinxhyphen{}access}} and \sphinxcode{\sphinxupquote{annex\sphinxhyphen{}c}}. The first case is to test channel
coordination
feature. The second case is to test channel routing for three types of packets.
The third case is to test four channel access assignments. And the fourth case
is to test the implemented feature described in the Annex C of the standard.
It is worth noting that the  \sphinxcode{\sphinxupquote{channel\sphinxhyphen{}routing}} and \sphinxcode{\sphinxupquote{channel\sphinxhyphen{}access}} test
cases are both in the context of single\sphinxhyphen{}PHY device, which depends on the
default channel
access assignment mechanism \sphinxcode{\sphinxupquote{ns3:DefaultChannelScheduler}}, thus they may not
be suitable for testing when other channel access assignment mechanisms are
used.  Although they are test cases, they are also good examples to show
usage.

The \sphinxcode{\sphinxupquote{ns3::VanetRoutingExample}} example was studied using mobility trace
files in the Raleigh, NC USA area generated using Simulation for Urban
Mobility (SUMO).  Three environments were studied:  a) an open highway
scenario, b) a residential neighborhood scenario, and c) and urban downtown
scenario.  For each environment, a constant number of 50\sphinxhyphen{}750 vehicles was
maintained for 2000 simulation seconds (\textgreater{} 30 minutes).  The mobility trace
file were played back using \sphinxcode{\sphinxupquote{ns3::Ns2MobilityHelper}}.  All vehicular nodes
transmitted a 200\sphinxhyphen{}byte BSM at 10 Hz and the PDR was determined for
transmission ranges of 50\sphinxhyphen{}1500m.  No additional non\sphinxhyphen{}BSM data was injected /
routed through the network.  The default propagation loss model used
was Two\sphinxhyphen{}Ray Ground.  Different fading / shadowing models were evaluated,
including a) no fading, b) stochastic Nakagami\sphinxhyphen{}m fading, and c) an
obstacle shadowing model (to be contributed to \sphinxstyleemphasis{ns\sphinxhyphen{}3}).  30 trials of each
scenario were run in the North Carolina State University (NCSU) High
Performance Computing (HPC) center, with each trial requiring from
8 hours to 6 days of CPU time to complete.  Preliminary results were
presented at the PhD Forum, 22nd IEEE International Conference on
Network Protocols (ICNP), October 24, 2014, Research Triangle Park, NC.
See:  \sphinxurl{http://www4.ncsu.edu/~scarpen/Research\_files/Final-PHD\_Forum\_SE\_Carpenter\_2014.pdf}


\chapter{Wi\sphinxhyphen{}Fi Module}
\label{\detokenize{wifi:wi-fi-module}}\label{\detokenize{wifi::doc}}

\section{Design Documentation}
\label{\detokenize{wifi-design:design-documentation}}\label{\detokenize{wifi-design::doc}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} nodes can contain a collection of NetDevice objects, much like an actual
computer contains separate interface cards for Ethernet, Wifi, Bluetooth, etc.
This chapter describes the \sphinxstyleemphasis{ns\sphinxhyphen{}3} WifiNetDevice and related models. By adding
WifiNetDevice objects to \sphinxstyleemphasis{ns\sphinxhyphen{}3} nodes, one can create models of 802.11\sphinxhyphen{}based
infrastructure and ad hoc networks.


\subsection{Overview of the model}
\label{\detokenize{wifi-design:overview-of-the-model}}
The WifiNetDevice models a wireless network interface controller based
on the IEEE 802.11 standard \sphinxcite{wifi-references:ieee80211}. We will go into more detail below but in brief,
\sphinxstyleemphasis{ns\sphinxhyphen{}3} provides models for these aspects of 802.11:
\begin{itemize}
\item {} 
basic 802.11 DCF with \sphinxstylestrong{infrastructure} and \sphinxstylestrong{adhoc} modes

\item {} 
\sphinxstylestrong{802.11a}, \sphinxstylestrong{802.11b}, \sphinxstylestrong{802.11g}, \sphinxstylestrong{802.11n} (both 2.4 and 5 GHz bands), \sphinxstylestrong{802.11ac} and \sphinxstylestrong{802.11ax} (both 2.4 and 5 GHz bands) physical layers

\item {} 
\sphinxstylestrong{MSDU aggregation} and \sphinxstylestrong{MPDU aggregation} extensions of 802.11n, and both can be combined together (two\sphinxhyphen{}level aggregation)

\item {} 
QoS\sphinxhyphen{}based EDCA and queueing extensions of \sphinxstylestrong{802.11e}

\item {} 
the ability to use different propagation loss models and propagation delay models,
please see the chapter on {\hyperref[\detokenize{propagation:propagation}]{\sphinxcrossref{\DUrole{std,std-ref}{Propagation}}}} for more detail

\item {} 
various rate control algorithms including \sphinxstylestrong{Aarf, Arf, Cara, Onoe, Rraa,
ConstantRate, and Minstrel}

\item {} 
802.11s (mesh), described in another chapter

\item {} 
802.11p and WAVE (vehicular), described in another chapter

\end{itemize}

The set of 802.11 models provided in \sphinxstyleemphasis{ns\sphinxhyphen{}3} attempts to provide an accurate
MAC\sphinxhyphen{}level implementation of the 802.11 specification and to provide a
packet\sphinxhyphen{}level abstraction of the PHY\sphinxhyphen{}level for different PHYs, corresponding to
802.11a/b/e/g/n/ac/ax specifications.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, nodes can have multiple WifiNetDevices on separate channels, and the
WifiNetDevice can coexist with other device types.
With the use of the \sphinxstylestrong{SpectrumWifiPhy} framework, one can also build scenarios
involving cross\sphinxhyphen{}channel interference or multiple wireless technologies on
a single channel.

The source code for the WifiNetDevice and its models lives in the directory
\sphinxcode{\sphinxupquote{src/wifi}}.

The implementation is modular and provides roughly three sublayers of models:
\begin{itemize}
\item {} 
the \sphinxstylestrong{PHY layer models}

\item {} 
the so\sphinxhyphen{}called \sphinxstylestrong{MAC low models}: they model functions such as medium
access (DCF and EDCA), RTS/CTS and ACK.  In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the lower\sphinxhyphen{}level MAC
is further subdivided into a \sphinxstylestrong{MAC low} and \sphinxstylestrong{MAC middle} sublayering,
with channel access grouped into the \sphinxstylestrong{MAC middle}.

\item {} 
the so\sphinxhyphen{}called \sphinxstylestrong{MAC high models}: they implement non\sphinxhyphen{}time\sphinxhyphen{}critical processes
in Wifi such as the MAC\sphinxhyphen{}level beacon generation, probing, and association
state machines, and a set of \sphinxstylestrong{Rate control algorithms}.  In the literature,
this sublayer is sometimes called the \sphinxstylestrong{upper MAC} and consists of more
software\sphinxhyphen{}oriented implementations vs. time\sphinxhyphen{}critical hardware implementations.

\end{itemize}

Next, we provide an design overview of each layer, shown in
Figure {\hyperref[\detokenize{wifi-design:wifi-architecture}]{\sphinxcrossref{\DUrole{std,std-ref}{WifiNetDevice architecture.}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{WifiArchitecture}.pdf}
\caption{WifiNetDevice architecture.}\label{\detokenize{wifi-design:id31}}\label{\detokenize{wifi-design:wifi-architecture}}\end{figure}


\subsubsection{MAC high models}
\label{\detokenize{wifi-design:mac-high-models}}
There are presently three \sphinxstylestrong{MAC high models} that provide for the three
(non\sphinxhyphen{}mesh; the mesh equivalent, which is a sibling of these with common
parent \sphinxcode{\sphinxupquote{ns3::RegularWifiMac}}, is not discussed here) Wi\sphinxhyphen{}Fi topological
elements \sphinxhyphen{} Access Point (AP) (\sphinxcode{\sphinxupquote{ns3::ApWifiMac}}),
non\sphinxhyphen{}AP Station (STA) (\sphinxcode{\sphinxupquote{ns3::StaWifiMac}}), and STA in an Independent
Basic Service Set (IBSS) \sphinxhyphen{} also commonly referred to as an ad hoc
network (\sphinxcode{\sphinxupquote{ns3::AdhocWifiMac}}).

The simplest of these is \sphinxcode{\sphinxupquote{ns3::AdhocWifiMac}}, which implements a
Wi\sphinxhyphen{}Fi MAC that does not perform any kind of beacon generation,
probing, or association. The \sphinxcode{\sphinxupquote{ns3::StaWifiMac}} class implements
an active probing and association state machine that handles automatic
re\sphinxhyphen{}association whenever too many beacons are missed. Finally,
\sphinxcode{\sphinxupquote{ns3::ApWifiMac}} implements an AP that generates periodic
beacons, and that accepts every attempt to associate.

These three MAC high models share a common parent in
\sphinxcode{\sphinxupquote{ns3::RegularWifiMac}}, which exposes, among other MAC
configuration, an attribute \sphinxcode{\sphinxupquote{QosSupported}} that allows
configuration of 802.11e/WMM\sphinxhyphen{}style QoS support, an attribute
\sphinxcode{\sphinxupquote{HtSupported}} that allows configuration of 802.11n High Throughput
style support, an attribute \sphinxcode{\sphinxupquote{VhtSupported}} that allows configuration
of 802.11ac Very High Throughput style support and an attribute \sphinxcode{\sphinxupquote{HeSupported}}
that allows configuration of 802.11ax High Efficiency style support.

There are also several \sphinxstylestrong{rate control algorithms} that can be used by the
MAC low layer.  A complete list of available rate control algorithms is
provided in a separate section.


\subsubsection{MAC low layer}
\label{\detokenize{wifi-design:mac-low-layer}}
The \sphinxstylestrong{MAC low layer} is split into three main components:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxcode{\sphinxupquote{ns3::MacLow}} which takes care of RTS/CTS/DATA/ACK transactions and also
performs MPDU aggregation.

\item {} 
\sphinxcode{\sphinxupquote{ns3::ChannelAccessManager}} and \sphinxcode{\sphinxupquote{ns3::DcfState}} which implements the DCF and EDCAF
functions.

\item {} 
\sphinxcode{\sphinxupquote{ns3::Txop}} and \sphinxcode{\sphinxupquote{ns3::QosTxop}} which handle the packet queue,
packet fragmentation, and packet retransmissions if they are needed.
The \sphinxcode{\sphinxupquote{ns3::Txop}} object is used by high MACs that are not QoS\sphinxhyphen{}enabled,
and for transmission of frames (e.g., of type Management)
that the standard says should access the medium using the DCF.
\sphinxcode{\sphinxupquote{ns3::QosTxop}} is is used by QoS\sphinxhyphen{}enabled high MACs and also
performs MSDU aggregation.

\end{enumerate}


\subsubsection{PHY layer models}
\label{\detokenize{wifi-design:phy-layer-models}}
In short, the physical layer models are mainly responsible for modeling
the reception of packets and for tracking energy consumption.  There
are typically three main components to packet reception:
\begin{itemize}
\item {} 
each packet received is probabilistically evaluated for successful or
failed reception.  The probability depends on the modulation, on
the signal to noise (and interference) ratio for the packet, and on
the state of the physical layer (e.g. reception is not possible while
transmission or sleeping is taking place);

\item {} 
an object exists to track (bookkeeping) all received signals so that
the correct interference power for each packet can be computed when
a reception decision has to be made; and

\item {} 
one or more error models corresponding to the modulation and standard
are used to look up probability of successful reception.

\end{itemize}

\sphinxstyleemphasis{ns\sphinxhyphen{}3} offers users a choice between two physical layer models, with a
base interface defined in the \sphinxcode{\sphinxupquote{ns3::WifiPhy}} class.  The YansWifiPhy
class has been the only physical layer model until recently; the model
implemented there is described in a paper entitled
\sphinxhref{https://dl.acm.org/doi/pdf/10.1145/1190455.1190467?download=true}{Yet Another Network Simulator}
The acronym \sphinxstyleemphasis{Yans} derives from this paper title.  The SpectrumWifiPhy
class is an alternative implementation based on the Spectrum framework
used for other \sphinxstyleemphasis{ns\sphinxhyphen{}3} wireless models.  Spectrum allows a fine\sphinxhyphen{}grained
frequency decomposition of the signal, and permits scenarios to
include multiple technologies coexisting on the same channel.


\subsection{Scope and Limitations}
\label{\detokenize{wifi-design:scope-and-limitations}}
The IEEE 802.11 standard \sphinxcite{wifi-references:ieee80211} is a large specification,
and not all aspects are covered by \sphinxstyleemphasis{ns\sphinxhyphen{}3}; the documentation of \sphinxstyleemphasis{ns\sphinxhyphen{}3}’s
conformance by itself would lead to a very long document.  This section
attempts to summarize compliance with the standard and with behavior
found in practice.

The physical layer and channel models operate on a per\sphinxhyphen{}packet basis, with
no frequency\sphinxhyphen{}selective propagation or interference effects when using
the default YansWifiPhy model.  Directional antennas are also not
supported at this time.  For additive white Gaussian noise (AWGN)
scenarios, or wideband interference scenarios, performance is governed
by the application of analytical models (based on modulation and factors
such as channel width) to the received signal\sphinxhyphen{}to\sphinxhyphen{}noise ratio, where noise
combines the effect of thermal noise and of interference from other Wi\sphinxhyphen{}Fi
packets.  Moreover, interference from other technologies is not modeled.
The following details pertain to the physical layer and channel models:
\begin{itemize}
\item {} 
802.11ax MU\sphinxhyphen{}OFDMA is not supported

\item {} 
802.11ax only supports SU PPDU format

\item {} 
802.11ac/ax MU\sphinxhyphen{}MIMO is not supported, and no more than 4 antennas can be configured

\item {} 
802.11n/ac/ax beamforming is not supported

\item {} 
802.11 HCF/HCCA are not implemented

\item {} 
802.11 PCF implementation currently assumes a DTIM interval equal to the beacon interval

\item {} 
Authentication and encryption are missing

\item {} 
Processing delays are not modeled

\item {} 
PHY\_RXSTART is not supported

\item {} 
The current implementation assumes that secondary channels are always higher than primary channels

\item {} 
Cases where RTS/CTS and ACK are transmitted using HT/VHT/HE formats are not supported

\item {} 
Energy consumption model does not consider MIMO

\end{itemize}

At the MAC layer, most of the main functions found in deployed Wi\sphinxhyphen{}Fi
equipment for 802.11a/b/e/g/n/ac/ax are implemented, but there are scattered instances
where some limitations in the models exist. Support for 802.11n, ac and ax is evolving.

Some implementation choices that are not imposed by the standard are listed below:
\begin{itemize}
\item {} 
BSSBasicRateSet for 802.11b has been assumed to be 1\sphinxhyphen{}2 Mbit/s

\item {} 
BSSBasicRateSet for 802.11a/g has been assumed to be 6\sphinxhyphen{}12\sphinxhyphen{}24 Mbit/s

\item {} 
The wifi manager always selects the lowest basic rate for management frames.

\end{itemize}


\subsection{Design Details}
\label{\detokenize{wifi-design:design-details}}
The remainder of this section is devoted to more in\sphinxhyphen{}depth design descriptions
of some of the Wi\sphinxhyphen{}Fi models.  Users interested in skipping to the section
on usage of the wifi module (User Documentation) may do so at this point.
We organize these more detailed sections from the bottom\sphinxhyphen{}up, in terms of
layering, by describing the channel and PHY models first, followed by
the MAC models.

We focus first on the choice between physical layer frameworks.  \sphinxstyleemphasis{ns\sphinxhyphen{}3}
contains support for a Wi\sphinxhyphen{}Fi\sphinxhyphen{}only physical layer model called YansWifiPhy
that offers no frequency\sphinxhyphen{}level decomposition of the signal.  For simulations
that involve only Wi\sphinxhyphen{}Fi signals on the Wi\sphinxhyphen{}Fi channel, and that do not
involve frequency\sphinxhyphen{}dependent propagation loss or fading models, the default
YansWifiPhy framework is a suitable choice.  For simulations involving
mixed technologies on the same channel, or frequency dependent effects,
the SpectrumWifiPhy is more appropriate.  The two frameworks are very
similarly configured.

The SpectrumWifiPhy framework uses the \sphinxcode{\sphinxupquote{Spectrum}} channel
framework, which is not documented herein but in the Spectrum module
documentation.

The YansWifiChannel is the only concrete channel model class in
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} wifi module.  The
\sphinxcode{\sphinxupquote{ns3::YansWifiChannel}} implementation uses the propagation loss and
delay models provided within the \sphinxstyleemphasis{ns\sphinxhyphen{}3} {\hyperref[\detokenize{propagation:propagation}]{\sphinxcrossref{\DUrole{std,std-ref}{Propagation}}}} module.
In particular, a number of propagation models can be added (chained together,
if multiple loss models are added) to the channel object, and a propagation
delay model also added. Packets sent from a \sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} object
onto the channel with a particular signal power, are copied to all of the
other \sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} objects after the signal power is reduced due
to the propagation loss model(s), and after a delay corresponding to
transmission (serialization) delay and propagation delay due to
any channel propagation delay model (typically due to speed\sphinxhyphen{}of\sphinxhyphen{}light
delay between the positions of the devices).

Only objects of \sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} may be attached to a
\sphinxcode{\sphinxupquote{ns3::YansWifiChannel}}; therefore, objects modeling other
(interfering) technologies such as LTE are not allowed.    Furthermore,
packets from different channels do not interact; if a channel is logically
configured for e.g. channels 5 and 6, the packets do not cause
adjacent channel interference (even if their channel numbers overlap).


\subsubsection{WifiPhy and related models}
\label{\detokenize{wifi-design:wifiphy-and-related-models}}
The \sphinxcode{\sphinxupquote{ns3::WifiPhy}} is an abstract base class representing the 802.11
physical layer functions.  Packets passed to this object (via a
\sphinxcode{\sphinxupquote{SendPacket()}} method) are sent over a channel object, and
upon reception, the receiving PHY object decides (based on signal power
and interference) whether the packet was successful or not.  This class
also provides a number of callbacks for notifications of physical layer
events, exposes a notion of a state machine that can be monitored for
MAC\sphinxhyphen{}level processes such as carrier sense, and handles sleep/wake models
and energy consumption.  The \sphinxcode{\sphinxupquote{ns3::WifiPhy}} hooks to the \sphinxcode{\sphinxupquote{ns3::MacLow}}
object in the WifiNetDevice.

There are currently two implementations of the \sphinxcode{\sphinxupquote{WifiPhy}}: the
\sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} and the \sphinxcode{\sphinxupquote{ns3::SpectrumWifiPhy}}.  They each work in
conjunction with three other objects:
\begin{itemize}
\item {} 
\sphinxstylestrong{WifiPhyStateHelper}:  Maintains the PHY state machine

\item {} 
\sphinxstylestrong{InterferenceHelper}:  Tracks all packets observed on the channel

\item {} 
\sphinxstylestrong{ErrorModel}:  Computes a probability of error for a given SNR

\end{itemize}


\paragraph{YansWifiPhy and WifiPhyStateHelper}
\label{\detokenize{wifi-design:yanswifiphy-and-wifiphystatehelper}}
Class \sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} is responsible for taking packets passed to
it from the MAC (the \sphinxcode{\sphinxupquote{ns3::MacLow}} object) and sending them onto the
\sphinxcode{\sphinxupquote{ns3::YansWifiChannel}} to which it is attached.  It is also responsible
to receive packets from that channel, and, if reception is deemed to have
been successful, to pass them up to the MAC.

The energy of the signal intended to be received is
calculated from the transmission power and adjusted based on the Tx gain
of the transmitter, Rx gain of the receiver, and any path loss propagation
model in effect.

Class \sphinxcode{\sphinxupquote{ns3::WifiPhyStateHelper}} manages the state machine of the PHY
layer, and allows other objects to hook as \sphinxstyleemphasis{listeners} to monitor PHY
state.  The main use of listeners is for the MAC layer to know when
the PHY is busy or not (for transmission and collision avoidance).

The PHY layer can be in one of six states:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
TX: the PHY is currently transmitting a signal on behalf of its associated
MAC

\item {} 
RX: the PHY is synchronized on a signal and is waiting until it has received
its last bit to forward it to the MAC.

\item {} 
IDLE: the PHY is not in the TX, RX, or CCA BUSY states.

\item {} 
CCA Busy: the PHY is not in TX or RX state but the measured energy is higher than the energy detection threshold.

\item {} 
SWITCHING: the PHY is switching channels.

\item {} 
SLEEP: the PHY is in a power save mode and cannot send nor receive frames.

\end{enumerate}

Packet reception works as follows.  For \sphinxcode{\sphinxupquote{YansWifiPhy}}, most of the logic
is implemented in the \sphinxcode{\sphinxupquote{WifiPhy}} base class.  The \sphinxcode{\sphinxupquote{YansWifiChannel}} calls
\sphinxcode{\sphinxupquote{WifiPhy::StartReceivePreamble ()}} to start packet reception, but first
there is a check of the packet’s notional signal power level against a
threshold value stored in the attribute \sphinxcode{\sphinxupquote{WifiPhy::RxSensitivity}}.  Any
packet with a power lower than RxSensitivity will be dropped with no
further processing.  The default value is \sphinxhyphen{}101 dBm, which is the thermal
noise floor for 20 MHz signal at room temperature.  The purpose of this
attribute is two\sphinxhyphen{}fold:  1) very weak signals that will not affect the
outcome will otherwise consume simulation memory and event processing, so
they are discarded, and 2) this value can be adjusted upwards to function as
a basic carrier sense threshold limitation for experiments involving
spatial reuse considerations.  Users are cautioned about the behavior of
raising this threshold; namely, that all packets with power below this
threshold will be discarded upon reception.

In \sphinxcode{\sphinxupquote{StartReceivePreamble ()}}, the packet is immediately added
to the interference helper for signal\sphinxhyphen{}to\sphinxhyphen{}noise
tracking, and then further reception steps are decided upon the state of
the PHY.  In the case that the PHY is transmitting, for instance, the
packet will be dropped.  If the PHY is IDLE, or if the PHY is receiving and
an optional FrameCaptureModel is being used (and the packet is within
the capture window), then \sphinxcode{\sphinxupquote{WifiPhy::StartRx ()}} is called next.

The \sphinxcode{\sphinxupquote{WifiPhy::StartRx ()}} will typically schedule an event,
\sphinxcode{\sphinxupquote{WifiPhy::StartReceiveHeader ()}}, to occur at
the notional end of the first OFDM symbol, to check whether the preamble
has been detected.  As of revisions to the model in ns\sphinxhyphen{}3.30, any state
machine transitions from IDLE state are suppressed until after the preamble
detection event.

The \sphinxcode{\sphinxupquote{StartReceiveHeader ()}} method will check, with a preamble detection
model, whether the signal is strong enough to be received, and if so,
an event \sphinxcode{\sphinxupquote{WifiPhy::EndReceive ()}} is scheduled for the end of reception,
and the PHY is put into the RX state.  Currently, there is only a
simple threshold\sphinxhyphen{}based preamble detection model in ns\sphinxhyphen{}3,
called \sphinxcode{\sphinxupquote{ThresholdPreambleDetectionModel}}.  If there is no preamble detection
model, the preamble is assumed to have been detected.
It is important to note that, starting with the ns\sphinxhyphen{}3.30 release, the default
in the WifiPhyHelper is to add the \sphinxcode{\sphinxupquote{ThresholdPreambleDetectionModel}} with
a threshold RSSI of \sphinxhyphen{}82 dBm, and a threshold SNR of 4 dB.  Both the RSSI
and SNR must be above these respective values for the preamble to be
successfully detected.  The default sensitivity has been reduced in ns\sphinxhyphen{}3.30
compared with that of previous releases, so some packet receptions that were
previously successful will now fail on this check.  More details on the
modeling behind this change are provided in \sphinxcite{wifi-references:lanante2019}.

In a real system, the \sphinxcode{\sphinxupquote{EndReceive ()}} time would
not be determined until later when the PHY headers are successfully decoded,
but this ns\sphinxhyphen{}3 model has the available information at the start of the
packet to schedule this.  The second event to schedule is
\sphinxcode{\sphinxupquote{StartReceivePayload ()}} for the time at which the PHY headers
have been received and the payload is about to start.

The next event at \sphinxcode{\sphinxupquote{StartReceivePayload ()}} checks, using the interference
helper and error model, whether the header was successfully decoded, and if so,
a \sphinxcode{\sphinxupquote{PhyRxPayloadBegin}} callback (equivalent to the PHY\sphinxhyphen{}RXSTART primitive)
is triggered.
The PHY header is often transmitted
at a lower modulation rate than is the payload.  The portion of the packet
corresponding to the PHY header is evaluated for probability of error
based on the observed SNR.  The InterferenceHelper object returns a value
for “probability of error (PER)” for this header based on the SNR that has
been tracked by the InterferenceHelper.  The \sphinxcode{\sphinxupquote{YansWifiPhy}} then draws
a random number from a uniform distribution and compares it against the
PER and decides success or failure.  The process is again repeated after
the payload has been received (possibly with a different error model
applied for the different modulation).  If both the header and payload
are successfully received, the packet is passed up to the \sphinxcode{\sphinxupquote{MacLow}} object.

If the header is determined to have errors, then a “PlcpSuccess” flag is
set for future reference, but the \sphinxcode{\sphinxupquote{EndReceive ()}} is not cancelled and
the PHY stays in RX state; upon the \sphinxcode{\sphinxupquote{EndReceive ()}} event, the packet
will be considered errored in this case regardless of the payload reception,
based on the PlcpSuccess flag.

Even if packet objects received by the PHY are not part of the reception
process, they are tracked by the InterferenceHelper object for purposes
of SINR computation and making clear channel assessment decisions.
If, in the course of reception, a packet is errored or dropped due to
the PHY being in a state in which it cannot receive a packet, the packet
is added to the interference helper, and the aggregate of the energy of
all such signals is compared against an energy detection threshold to
determine whether the PHY should enter a CCA\_BUSY state.
The \sphinxcode{\sphinxupquote{WifiPhy::CcaEdThreshold}} attribute
corresponds to what the standard calls the “ED threshold” for CCA Mode 1.
In section 16.4.8.5 in the 802.11\sphinxhyphen{}2012 standard: “CCA Mode 1: Energy above
threshold. CCA shall report a busy medium upon detection of any energy above
the ED threshold.” By default, this value is set to the \sphinxhyphen{}62 dBm level specified
in the standard for 20 MHz channels. When using \sphinxcode{\sphinxupquote{YansWifiPhy}}, there are no
non\sphinxhyphen{}Wi\sphinxhyphen{}Fi signals, so it is unlikely that this attribute would play much of a
role in Yans wifi models if left at the default value, but if there is a strong
Wi\sphinxhyphen{}Fi signal that is not otherwise being received by the model, it has
the possibility to raise the CCA\_BUSY while the overall energy exceeds
this threshold.

The above describes the case in which the packet is a single MPDU.  For
more recent Wi\sphinxhyphen{}Fi standards using MPDU aggregation, each individual MPDU
in the aggregate is sent as a single \sphinxcode{\sphinxupquote{ns3::Packet}}, and the logic in
the \sphinxcode{\sphinxupquote{WifiPhy}} is a bit different than the above for handling such
MPDUs (MPDUs after the first arrive without a preamble and header).


\paragraph{InterferenceHelper}
\label{\detokenize{wifi-design:interferencehelper}}
The InterferenceHelper is an object that tracks all incoming packets and
calculates probability of error values for packets being received, and
also evaluates whether energy on the channel rises above the CCA
threshold.

The basic operation of probability of error calculations is shown in Figure
{\hyperref[\detokenize{wifi-design:snir}]{\sphinxcrossref{\DUrole{std,std-ref}{SNIR function over time.}}}}.  Packets are represented as bits (not symbols) in the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
model, and the InterferenceHelper breaks the packet into one or more
“chunks”, each with a different signal to noise (and interference) ratio
(SNIR).  Each chunk is separately evaluated by asking for the probability
of error for a given number of bits from the error model in use.  The
InterferenceHelper builds an aggregate “probability of error” value
based on these chunks and their duration, and returns this back to
the \sphinxcode{\sphinxupquote{YansWifiPhy}} for a reception decision.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{snir}.pdf}
\caption{\sphinxstyleemphasis{SNIR function over time.}}\label{\detokenize{wifi-design:id32}}\label{\detokenize{wifi-design:snir}}\end{figure}

From the SNIR function we can derive the Bit Error Rate (BER) and Packet
Error Rate (PER) for
the modulation and coding scheme being used for the transmission.


\paragraph{ErrorModel}
\label{\detokenize{wifi-design:errormodel}}
The error models are described in more detail in outside references.  Please refer to \sphinxcite{wifi-references:pei80211ofdm}, \sphinxcite{wifi-references:pei80211b}, \sphinxcite{wifi-references:lacage2006yans}, \sphinxcite{wifi-references:haccoun} and \sphinxcite{wifi-references:frenger} for a detailed description of the available BER/PER models.

The current \sphinxstyleemphasis{ns\sphinxhyphen{}3} error rate models are for additive white gaussian
noise channels (AWGN) only; any potential fast fading effects are not modeled.

The original error rate model was called the \sphinxcode{\sphinxupquote{ns3::YansErrorRateModel}} and
was based on analytical results.  For 802.11b modulations, the 1 Mbps mode
is based on DBPSK. BER is from equation 5.2\sphinxhyphen{}69 from \sphinxcite{wifi-references:proakis2001}.
The 2 Mbps model is based on DQPSK. Equation 8 of \sphinxcite{wifi-references:ferrari2004}.
More details are provided in \sphinxcite{wifi-references:lacage2006yans}.

The \sphinxcode{\sphinxupquote{ns3::NistErrorRateModel}} was later added and became the \sphinxstyleemphasis{ns\sphinxhyphen{}3} default.
The model was largely aligned with the previous \sphinxcode{\sphinxupquote{ns3::YansErrorRateModel}}
for DSSS modulations 1 Mbps and 2 Mbps, but the 5.5 Mbps and 11 Mbps models
were re\sphinxhyphen{}based on equations (17) and (18) from \sphinxcite{wifi-references:pursley2009}.
For OFDM modulations, newer results were
obtained based on work previously done at NIST \sphinxcite{wifi-references:miller2003}.  The results
were also compared against the CMU wireless network emulator, and details
of the validation are provided in \sphinxcite{wifi-references:pei80211ofdm}.  Since OFDM modes use
hard\sphinxhyphen{}decision of punctured codes, the coded BER is calculated using
Chernoff bounds.

The 802.11b model was split from the OFDM model when the NIST error rate
model was added, into a new model called DsssErrorRateModel.

Furthermore, the 5.5 Mbps and 11 Mbps models for 802.11b rely on library
methods implemented in the GNU Scientific Library (GSL).  The Waf build
system tries to detect whether the host platform has GSL installed; if so,
it compiles in the newer models from \sphinxcite{wifi-references:pursley2009} for 5.5 Mbps and 11 Mbps;
if not, it uses a backup model derived from Matlab simulations.

As a result, there are three error models:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxcode{\sphinxupquote{ns3::DsssErrorRateModel}}:  contains models for 802.11b modes.  The
802.11b 1 Mbps and 2 Mbps error models are based on classical modulation
analysis.  If GSL is installed, the 5.5 Mbps and 11 Mbps from
\sphinxcite{wifi-references:pursley2009} are used; otherwise, a backup Matlab model is used.

\item {} 
\sphinxcode{\sphinxupquote{ns3::NistErrorRateModel}}: is the default for OFDM modes and reuses
\sphinxcode{\sphinxupquote{ns3::DsssErrorRateModel}} for 802.11b modes.

\item {} 
\sphinxcode{\sphinxupquote{ns3::YansErrorRateModel}}: is the legacy for OFDM modes and reuses
\sphinxcode{\sphinxupquote{ns3::DsssErrorRateModel}} for 802.11b modes.

\end{enumerate}

Users should select either Nist or Yans models for OFDM (Nist is default),
and Dsss will be used in either case for 802.11b.


\paragraph{SpectrumWifiPhy}
\label{\detokenize{wifi-design:spectrumwifiphy}}
This section describes the implementation of the \sphinxcode{\sphinxupquote{SpectrumWifiPhy}}
class that can be found in \sphinxcode{\sphinxupquote{src/wifi/model/spectrum\sphinxhyphen{}wifi\sphinxhyphen{}phy.\{cc,h\}}}.

The implementation also makes use of additional classes found in the
same directory:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}spectrum\sphinxhyphen{}phy\sphinxhyphen{}interface.\{cc,h\}}}

\item {} 
\sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}spectrum\sphinxhyphen{}signal\sphinxhyphen{}parameters.\{cc,h\}}}

\end{itemize}

and classes found in the spectrum module:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}spectrum\sphinxhyphen{}value\sphinxhyphen{}helper.\{cc,h\}}}

\end{itemize}

The current \sphinxcode{\sphinxupquote{SpectrumWifiPhy}} class
reuses the existing interference manager and error rate models originally
built for YansWifiPhy, but allows, as a first step, foreign (non Wi\sphinxhyphen{}Fi)
signals to be treated as additive noise.

Two main changes were needed to adapt the Spectrum framework to Wi\sphinxhyphen{}Fi.
First, the physical layer must send signals compatible with the
Spectrum channel framework, and in particular, the
\sphinxcode{\sphinxupquote{MultiModelSpectrumChannel}} that allows signals from different
technologies to coexist.  Second, the InterferenceHelper must be
extended to support the insertion of non\sphinxhyphen{}Wi\sphinxhyphen{}Fi signals and to
add their received power to the noise, in the same way that
unintended Wi\sphinxhyphen{}Fi signals (perhaps from a different SSID or arriving
late from a hidden node) are added to the noise.

Unlike YansWifiPhy, where there are no foreign signals, CCA BUSY state
will be raised for foreign signals that are higher than CcaEdThreshold
(see section 16.4.8.5 in the 802.11\sphinxhyphen{}2012 standard for definition of
CCA Mode 1).  The attribute \sphinxcode{\sphinxupquote{WifiPhy::CcaEdThreshold}} therefore
potentially plays a larger role in this model than in the \sphinxcode{\sphinxupquote{YansWifiPhy}}
model.

To support the Spectrum channel, the \sphinxcode{\sphinxupquote{YansWifiPhy}} transmit and receive methods
were adapted to use the Spectrum channel API.  This required developing
a few \sphinxcode{\sphinxupquote{SpectrumModel}}\sphinxhyphen{}related classes.  The class
\sphinxcode{\sphinxupquote{WifiSpectrumValueHelper}} is used to create Wi\sphinxhyphen{}Fi signals with the
spectrum framework and spread their energy across the bands. The
spectrum is sub\sphinxhyphen{}divided into sub\sphinxhyphen{}bands (the width of an OFDM
subcarrier, which depends on the technology). The power allocated to a particular channel
is spread across the sub\sphinxhyphen{}bands roughly according to how power would
be allocated to sub\sphinxhyphen{}carriers. Adjacent channels are models by the use of
OFDM transmit spectrum masks as defined in the standards.

To support an easier user configuration experience, the existing
YansWifi helper classes (in \sphinxcode{\sphinxupquote{src/wifi/helper}}) were copied and
adapted to provide equivalent SpectrumWifi helper classes.

Finally, for reasons related to avoiding C++ multiple inheritance
issues, a small forwarding class called \sphinxcode{\sphinxupquote{WifiSpectrumPhyInterface}}
was inserted as a shim between the \sphinxcode{\sphinxupquote{SpectrumWifiPhy}} and the
Spectrum channel.  The \sphinxcode{\sphinxupquote{WifiSpectrumPhyInterface}} calls a different
\sphinxcode{\sphinxupquote{SpectrumWifiPhy::StartRx ()}} method to start the reception process.
This method performs the check of the signal power against the
\sphinxcode{\sphinxupquote{WifiPhy::RxSensitivity}} attribute and discards weak signals, and
also checks if the signal is a Wi\sphinxhyphen{}Fi signal; non\sphinxhyphen{}Wi\sphinxhyphen{}Fi signals are added
to the InterferenceHelper and can raise CCA\_BUSY but are not further processed
in the reception chain.   After this point, valid Wi\sphinxhyphen{}Fi signals cause
\sphinxcode{\sphinxupquote{WifiPhy::StartReceivePreamble}} to be called, and the processing continues
as described above.


\subsubsection{The MAC model}
\label{\detokenize{wifi-design:the-mac-model}}

\paragraph{Infrastructure association}
\label{\detokenize{wifi-design:infrastructure-association}}
Association in infrastructure mode is a high\sphinxhyphen{}level MAC function.
Either active probing or passive scanning is used (default is passive scan).
At the start of the simulation, Wi\sphinxhyphen{}Fi network devices configured as
STA will attempt to scan the channel. Depends on whether passive or active
scanning is selected, STA will attempt to gather beacons, or send a probe
request and gather probe responses until the respective timeout occurs. The
end result will be a list of candidate AP to associate to. STA will then try
to associate to the best AP (i.e., best SNR).

If association is rejected by the AP for some reason, the STA will try to
associate to the next best AP until the candidate list is exhausted which
then sends STA to ‘REFUSED’ state. If this occurs, the simulation user will
need to force reassociation retry in some way, perhaps by changing
configuration (i.e. the STA will not persistently try to associate upon a
refusal).

When associated, if the configuration is changed by the simulation user,
the STA will try to reassociate with the existing AP.

If the number of missed beacons exceeds the threshold, the STA will notify
the rest of the device that the link is down (association is lost) and
restart the scanning process. Note that this can also happen when an
association request fails without explicit refusal (i.e., the AP fails to
respond to association request).


\paragraph{Roaming}
\label{\detokenize{wifi-design:roaming}}
Roaming at layer\sphinxhyphen{}2 (i.e. a STA migrates its association from one AP to
another) is not presently supported. Because of that, the Min/Max channel
dwelling time implementation as described by the IEEE 802.11 standard
\sphinxcite{wifi-references:ieee80211} is also omitted, since it is only meaningful on the context
of channel roaming.


\paragraph{Channel access}
\label{\detokenize{wifi-design:channel-access}}
The 802.11 Distributed Coordination Function is used to calculate when to grant
access to the transmission medium. While implementing the DCF would have been
particularly easy if we had used a recurring timer that expired every slot, we
chose to use the method described in \sphinxcite{wifi-references:ji2004sslswn}
where the backoff timer duration is lazily calculated whenever needed since it
is claimed to have much better performance than the simpler recurring timer
solution.

The DCF basic access is described in section 10.3.4.2 of \sphinxcite{wifi-references:ieee80211-2016}.
\begin{itemize}
\item {} 
“A STA may transmit an MPDU when it is operating under the DCF access method
{[}..{]} when the STA determines that the medium is idle when a frame is queued
for transmission, and remains idle for a period of a DIFS, or an EIFS
(10.3.2.3.7) from the end of the immediately preceding medium\sphinxhyphen{}busy event,
whichever is the greater, and the backoff timer is zero. Otherwise the random
backoff procedure described in 10.3.4.3 shall be followed.”

\end{itemize}

Thus, a station is allowed not to invoke the backoff procedure if all of the
following conditions are met:
\begin{itemize}
\item {} 
the medium is idle when a frame is queued for transmission

\item {} 
the medium remains idle until the most recent of these two events: a DIFS
from the time when the frame is queued for transmission; an EIFS from the
end of the immediately preceding medium\sphinxhyphen{}busy event (associated with the
reception of an erroneous frame)

\item {} 
the backoff timer is zero

\end{itemize}

The backoff procedure of DCF is described in section 10.3.4.3 of \sphinxcite{wifi-references:ieee80211-2016}.
\begin{itemize}
\item {} 
“A STA shall invoke the backoff procedure to transfer a frame
when finding the medium busy as indicated by either the physical or
virtual CS mechanism.”

\item {} 
“A backoff procedure shall be performed immediately after the end of
every transmission with the More Fragments bit set to 0 of an MPDU of
type Data, Management, or Control with subtype PS\sphinxhyphen{}Poll, even if no
additional transmissions are currently queued.”

\end{itemize}

The EDCA backoff procedure is slightly different than the DCF backoff procedure
and is described in section 10.22.2.2 of \sphinxcite{wifi-references:ieee80211-2016}. The backoff procedure
shall be invoked by an EDCAF when any of the following events occur:
\begin{itemize}
\item {} 
a frame is “queued for transmission such that one of the transmit queues
associated with that AC has now become non\sphinxhyphen{}empty and any other transmit queues
associated with that AC are empty; the medium is busy on the primary channel”

\item {} 
“The transmission of the MPDU in the final PPDU transmitted by the TXOP holder
during the TXOP for that AC has completed and the TXNAV timer has expired, and
the AC was a primary AC”

\item {} 
“The transmission of an MPDU in the initial PPDU of a TXOP fails {[}..{]} and the
AC was a primary AC”

\item {} 
“The transmission attempt collides internally with another EDCAF of an AC that
has higher priority”

\item {} 
(optionally) “The transmission by the TXOP holder of an MPDU in a non\sphinxhyphen{}initial
PPDU of a TXOP fails”

\end{itemize}

Additionally, section 10.22.2.4 of \sphinxcite{wifi-references:ieee80211-2016} introduces the notion of
slot boundary, which basically occurs following SIFS + AIFSN * slotTime of idle
medium after the last busy medium that was the result of a reception of a frame
with a correct FCS or following EIFS \sphinxhyphen{} DIFS + AIFSN * slotTime + SIFS of idle
medium after the last indicated busy medium that was the result of a frame reception
that has resulted in FCS error, or following a slotTime of idle medium occurring
immediately after any of these conditions.

On these specific slot boundaries, each EDCAF shall make a determination to perform
one and only one of the following functions:
\begin{itemize}
\item {} 
Decrement the backoff timer.

\item {} 
Initiate the transmission of a frame exchange sequence.

\item {} 
Invoke the backoff procedure due to an internal collision.

\item {} 
Do nothing.

\end{itemize}

Thus, if an EDCAF decrements its backoff timer on a given slot boundary and, as
a result, the backoff timer has a zero value, the EDCAF cannot immediately
transmit, but it has to wait for another slotTime of idle medium before transmission
can start.

The higher\sphinxhyphen{}level MAC functions are implemented in a set of other C++ classes and
deal with:
\begin{itemize}
\item {} 
packet fragmentation and defragmentation,

\item {} 
use of the RTS/CTS protocol,

\item {} 
rate control algorithm,

\item {} 
connection and disconnection to and from an Access Point,

\item {} 
the MAC transmission queue,

\item {} 
beacon generation,

\item {} 
MSDU aggregation,

\item {} 
etc.

\end{itemize}


\paragraph{Rate control algorithms}
\label{\detokenize{wifi-design:rate-control-algorithms}}
Multiple rate control algorithms are available in \sphinxstyleemphasis{ns\sphinxhyphen{}3}.
Some rate control algorithms are modeled after real algorithms used in real devices;
others are found in literature.
The following rate control algorithms can be used by the MAC low layer:

Algorithms found in real devices:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{ArfWifiManager}} (default for \sphinxcode{\sphinxupquote{WifiHelper}})

\item {} 
\sphinxcode{\sphinxupquote{OnoeWifiManager}}

\item {} 
\sphinxcode{\sphinxupquote{ConstantRateWifiManager}}

\item {} 
\sphinxcode{\sphinxupquote{MinstrelWifiManager}}

\end{itemize}

Algorithms in literature:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{IdealWifiManager}}

\item {} 
\sphinxcode{\sphinxupquote{AarfWifiManager}} \sphinxcite{wifi-references:lacage2004aarfamrr}

\item {} 
\sphinxcode{\sphinxupquote{AmrrWifiManager}} \sphinxcite{wifi-references:lacage2004aarfamrr}

\item {} 
\sphinxcode{\sphinxupquote{CaraWifiManager}} \sphinxcite{wifi-references:kim2006cara}

\item {} 
\sphinxcode{\sphinxupquote{RraaWifiManager}} \sphinxcite{wifi-references:wong2006rraa}

\item {} 
\sphinxcode{\sphinxupquote{AarfcdWifiManager}} \sphinxcite{wifi-references:maguolo2008aarfcd}

\item {} 
\sphinxcode{\sphinxupquote{ParfWifiManager}} \sphinxcite{wifi-references:akella2007parf}

\item {} 
\sphinxcode{\sphinxupquote{AparfWifiManager}} \sphinxcite{wifi-references:chevillat2005aparf}

\end{itemize}


\paragraph{ConstantRateWifiManager}
\label{\detokenize{wifi-design:constantratewifimanager}}
The constant rate control algorithm always uses the same
transmission mode for every packet. Users can set a desired
‘DataMode’ for all ‘unicast’ packets and ‘ControlMode’ for all
‘request’ control packets (e.g. RTS).

To specify different data mode for non\sphinxhyphen{}unicast packets, users
must set the ‘NonUnicastMode’ attribute of the
WifiRemoteStationManager.  Otherwise, WifiRemoteStationManager
will use a mode with the lowest rate for non\sphinxhyphen{}unicast packets.

The 802.11 standard is quite clear on the rules for selection
of transmission parameters for control response frames (e.g.
CTS and ACK).  \sphinxstyleemphasis{ns\sphinxhyphen{}3} follows the standard and selects the rate
of control response frames from the set of basic rates or
mandatory rates. This means that control response frames may
be sent using different rate even though the ConstantRateWifiManager
is used.  The ControlMode attribute of the ConstantRateWifiManager
is used for RTS frames only.  The rate of CTS and ACK frames are
selected according to the 802.11 standard.  However, users can still
manually add WifiMode to the basic rate set that will allow control
response frames to be sent at other rates.  Please consult the
\sphinxhref{https://www.nsnam.org/wiki/HOWTO\_add\_basic\_rates\_to\_802.11}{project wiki} on how to do this.

Available attributes:
\begin{itemize}
\item {} 
DataMode (default WifiMode::OfdmRate6Mbps): specify a mode for
all non\sphinxhyphen{}unicast packets

\item {} 
ControlMode (default WifiMode::OfdmRate6Mbps): specify a mode for
all ‘request’ control packets

\end{itemize}


\paragraph{IdealWifiManager}
\label{\detokenize{wifi-design:idealwifimanager}}
The ideal rate control algorithm selects the best
mode according to the SNR of the previous packet sent.
Consider node \sphinxstyleemphasis{A} sending a unicast packet to node \sphinxstyleemphasis{B}.
When \sphinxstyleemphasis{B} successfully receives the packet sent from \sphinxstyleemphasis{A},
\sphinxstyleemphasis{B} records the SNR of the received packet into a \sphinxcode{\sphinxupquote{ns3::SnrTag}}
and adds the tag to an ACK back to \sphinxstyleemphasis{A}.
By doing this, \sphinxstyleemphasis{A} is able to learn the SNR of the packet sent to \sphinxstyleemphasis{B}
using an out\sphinxhyphen{}of\sphinxhyphen{}band mechanism (thus the name ‘ideal’).
\sphinxstyleemphasis{A} then uses the SNR to select a transmission mode based
on a set of SNR thresholds, which was built from a target BER and
mode\sphinxhyphen{}specific SNR/BER curves.

Available attribute:
\begin{itemize}
\item {} 
BerThreshold (default 10e\sphinxhyphen{}6): The maximum Bit Error Rate
that is used to calculate the SNR threshold for each mode.

\end{itemize}


\paragraph{MinstrelWifiManager}
\label{\detokenize{wifi-design:minstrelwifimanager}}
The minstrel rate control algorithm is a rate control algorithm originated from
madwifi project.  It is currently the default rate control algorithm of the Linux kernel.

Minstrel keeps track of the probability of successfully sending a frame of each available rate.
Minstrel then calculates the expected throughput by multiplying the probability with the rate.
This approach is chosen to make sure that lower rates are not selected in favor of the higher
rates (since lower rates are more likely to have higher probability).

In minstrel, roughly 10 percent of transmissions are sent at the so\sphinxhyphen{}called lookaround rate.
The goal of the lookaround rate is to force minstrel to try higher rate than the currently used rate.

For a more detailed information about minstrel, see \sphinxcite{wifi-references:linuxminstrel}.


\paragraph{Ack policy selection}
\label{\detokenize{wifi-design:ack-policy-selection}}
Since the introduction of the IEEE 802.11e amendment, multiple acknowledgment policies
are available, which are coded in the Ack Policy subfield in the QoS Control field of
QoS Data frames (see Section 9.2.4.5.4 of the IEEE 802.11\sphinxhyphen{}2016 standard). For instance,
an A\sphinxhyphen{}MPDU can be sent with the \sphinxstyleemphasis{Normal Ack or Implicit Block Ack Request} policy, in which
case the receiver replies with a Normal Ack or a Block Ack depending on whether the A\sphinxhyphen{}MPDU
contains a single MPDU or multiple MPDUs, or with the \sphinxstyleemphasis{Block Ack} policy, in which case
the receiver waits to receive a Block Ack Request in the future to which it replies with
a Block Ack.

\sphinxcode{\sphinxupquote{WifiAckPolicySelector}} is the abstract base class introduced to provide an interface
for multiple ack policy selectors. Currently, the default ack policy selector is
the \sphinxcode{\sphinxupquote{ConstantWifiAckPolicySelector}}.


\paragraph{ConstantWifiAckPolicySelector}
\label{\detokenize{wifi-design:constantwifiackpolicyselector}}
The \sphinxcode{\sphinxupquote{ConstantWifiAckPolicySelector}} allows to determine which acknowledgment policy
to use depending on the value of its attributes:
\begin{itemize}
\item {} 
UseExplicitBar: used to determine the ack policy to use when a response is needed from
the recipient and the current transmission includes multiple frames (A\sphinxhyphen{}MPDU) or there are
frames transmitted previously for which an acknowledgment is needed. If this attribute is
true, the \sphinxstyleemphasis{Block Ack} policy is used. Otherwise, the \sphinxstyleemphasis{Implicit Block Ack Request} policy is used.

\item {} 
BaThreshold: used to determine when the originator of a Block Ack agreement needs to
request a response from the recipient. A value of zero means that a response is requested
at every frame transmission. Otherwise, a non\sphinxhyphen{}zero value (less than or equal to 1) means
that a response is requested upon transmission of a frame whose sequence number is distant
at least BaThreshold multiplied by the transmit window size from the starting sequence
number of the transmit window.

\end{itemize}


\paragraph{802.11ax OBSS PD spatial reuse}
\label{\detokenize{wifi-design:ax-obss-pd-spatial-reuse}}
802.11ax mode supports OBSS PD spatial reuse feature.
OBSS PD stands for Overlapping Basic Service Set Preamble\sphinxhyphen{}Detection.
OBSS PD is an 802.11ax specific feature that allows a STA, under specific conditions,
to ignore an inter\sphinxhyphen{}BSS PPDU.


\paragraph{OBSS PD Algorithm}
\label{\detokenize{wifi-design:obss-pd-algorithm}}
\sphinxcode{\sphinxupquote{ObssPdAlgorithm}} is the base class of OBSS PD algorithms.
It implements the common functionalities. First, it makes sure the necessary callbacks are setup.
Second, when a PHY reset is requested by the algorithm, it performs the computation to determine the TX power
restrictions and informs the PHY object.

The PHY keeps tracks of incoming requests from the MAC to get access to the channel.
If a request is received and if PHY reset(s) indicating TX power limitations occured
before a packet was transmitted, the next packet to be transmitted will be sent with
a reduced power. Otherwise, no TX power restrictions will be applied.


\paragraph{Constant OBSS PD Algorithm}
\label{\detokenize{wifi-design:constant-obss-pd-algorithm}}
Constant OBSS PD algorithm is a simple OBSS PD algorithm implemented in the \sphinxcode{\sphinxupquote{ConstantObssPdAlgorithm}} class.

Once a HE preamble and its header have been received by the PHY, \sphinxcode{\sphinxupquote{ConstantObssPdAlgorithm::
ReceiveHeSig}} is triggered.
The algorithm then checks whether this is an OBSS frame by comparing its own BSS color with the BSS color of the received preamble.
If this is an OBSS frame, it compares the received RSSI with its configured OBSS PD level value. The PHY then gets reset to IDLE
state in case the received RSSI is lower than that constant OBSS PD level value, and is informed about a TX power restrictions.

Note: since our model is based on a single threshold, the PHY only supports one restricted power level.


\paragraph{Modifying Wifi model}
\label{\detokenize{wifi-design:modifying-wifi-model}}
Modifying the default wifi model is one of the common tasks when performing research.
We provide an overview of how to make changes to the default wifi model in this section.
Depending on your goal, the common tasks are (in no particular order):
\begin{itemize}
\item {} 
Creating or modifying the default Wi\sphinxhyphen{}Fi frames/headers by making changes to \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}mac\sphinxhyphen{}header.*}}.

\item {} 
MAC low modification. For example, handling new/modified control frames (think RTS/CTS/ACK/Block ACK),
making changes to two\sphinxhyphen{}way transaction/four\sphinxhyphen{}way transaction.  Users usually make changes to
\sphinxcode{\sphinxupquote{mac\sphinxhyphen{}low.*}} to accomplish this.  Handling of control frames is performed in
\sphinxcode{\sphinxupquote{MacLow::ReceiveOk}}.

\item {} 
MAC high modification. For example, handling new management frames (think beacon/probe),
beacon/probe generation.  Users usually make changes to \sphinxcode{\sphinxupquote{regular\sphinxhyphen{}wifi\sphinxhyphen{}mac.*}},
\sphinxcode{\sphinxupquote{infrastructure\sphinxhyphen{}wifi\sphinxhyphen{}mac.*}},\textasciigrave{}\textasciigrave{}sta\sphinxhyphen{}wifi\sphinxhyphen{}mac.*\textasciigrave{}\textasciigrave{}, \sphinxcode{\sphinxupquote{ap\sphinxhyphen{}wifi\sphinxhyphen{}mac.*}}, or \sphinxcode{\sphinxupquote{adhoc\sphinxhyphen{}wifi\sphinxhyphen{}mac.*}} to accomplish this.

\item {} 
Wi\sphinxhyphen{}Fi queue management.  The files \sphinxcode{\sphinxupquote{txop.*}} and \sphinxcode{\sphinxupquote{qos\sphinxhyphen{}txop.*}} are of interest for this task.

\item {} 
Channel access management.  Users should modify the files \sphinxcode{\sphinxupquote{channel\sphinxhyphen{}access\sphinxhyphen{}manager.*}}, which grant access to
\sphinxcode{\sphinxupquote{Txop}} and \sphinxcode{\sphinxupquote{QosTxop}}.

\item {} 
Fragmentation and RTS threholds are handled by Wi\sphinxhyphen{}Fi remote station manager.  Note that Wi\sphinxhyphen{}Fi remote
station manager simply indicates if fragmentation and RTS are needed.  Fragmentation is handled by
\sphinxcode{\sphinxupquote{Txop}} or \sphinxcode{\sphinxupquote{QosTxop}} while RTS/CTS transaction is handled by \sphinxcode{\sphinxupquote{MacLow}}.

\item {} 
Modifying or creating new rate control algorithms can be done by creating a new child class of Wi\sphinxhyphen{}Fi remote
station manager or modifying the existing ones.

\end{itemize}


\section{User Documentation}
\label{\detokenize{wifi-user:user-documentation}}\label{\detokenize{wifi-user::doc}}

\subsection{Using the WifiNetDevice}
\label{\detokenize{wifi-user:using-the-wifinetdevice}}
The modularity provided by the implementation makes low\sphinxhyphen{}level configuration of
the WifiNetDevice powerful but complex. For this reason, we provide some helper
classes to perform common operations in a simple matter, and leverage the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
attribute system to allow users to control the parameterization of the underlying
models.

Users who use the low\sphinxhyphen{}level \sphinxstyleemphasis{ns\sphinxhyphen{}3} API and who wish to add a WifiNetDevice to
their node must create an instance of a WifiNetDevice, plus a number of
constituent objects, and bind them together appropriately (the WifiNetDevice is
very modular in this regard, for future extensibility). At the low\sphinxhyphen{}level API,
this can be done with about 20 lines of code (see \sphinxcode{\sphinxupquote{ns3::WifiHelper::Install}},
and \sphinxcode{\sphinxupquote{ns3::YansWifiPhyHelper::Create}}). They also must create, at some point, a
Channel, which also contains a number of constituent objects (see
\sphinxcode{\sphinxupquote{ns3::YansWifiChannelHelper::Create}}).

However, a few helpers are available for users to add these devices and channels
with only a few lines of code, if they are willing to use defaults, and the
helpers provide additional API to allow the passing of attribute values to
change default values.  Commonly used attribute values are listed in the
Attributes section.  The scripts in \sphinxcode{\sphinxupquote{examples/wireless}} can be browsed to
see how this is done.  Next, we describe the common steps to create a WifiNetDevice
from the bottom layer (Channel) up to the device layer (WifiNetDevice).

To create a WifiNetDevice, users need to follow these steps:
\begin{itemize}
\item {} 
Decide on which physical layer framework, the \sphinxcode{\sphinxupquote{SpectrumWifiPhy}} or
\sphinxcode{\sphinxupquote{YansWifiPhy}}, to use.  This will affect which Channel and Phy type to use.

\item {} 
Configure the Channel: Channel takes care of getting signal
from one device to other devices on the same Wi\sphinxhyphen{}Fi channel.
The main configurations of WifiChannel are propagation loss model and propagation delay model.

\item {} 
Configure the WifiPhy: WifiPhy takes care of actually sending and receiving wireless
signal from Channel.  Here, WifiPhy decides whether each frame will be successfully
decoded or not depending on the received signal strength and noise.  Thus, the main
configuration of WifiPhy is the error rate model, which is the one that actually
calculates the probability of successfully decoding the frame based on the signal.

\item {} 
Configure WifiMac: this step is more related to the architecture and device level.
The users configure the wifi architecture (i.e. ad\sphinxhyphen{}hoc or ap\sphinxhyphen{}sta) and whether QoS (802.11e),
HT (802.11n) and/or VHT (802.11ac) and/or HE (802.11ax) features are supported or not.

\item {} 
Create WifiDevice: at this step, users configure the desired wifi standard
(e.g. \sphinxstylestrong{802.11b}, \sphinxstylestrong{802.11g}, \sphinxstylestrong{802.11a}, \sphinxstylestrong{802.11n}, \sphinxstylestrong{802.11ac} or \sphinxstylestrong{802.11ax}) and rate control algorithm.

\item {} 
Configure mobility: finally, mobility model is (usually) required before WifiNetDevice
can be used.

\end{itemize}

The following sample code illustrates a typical configuration using mostly
default values in the simulator, and infrastructure mode:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NodeContainer} \PYG{n}{wifiStaNode}\PYG{p}{;}
\PYG{n}{wifiStaNode}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// Create 10 station node objects}
\PYG{n}{NodeContainer} \PYG{n}{wifiApNode}\PYG{p}{;}
\PYG{n}{wifiApNode}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// Create 1 access point node object}

\PYG{c+c1}{// Create a channel helper and phy helper, and then create the channel}
\PYG{n}{YansWifiChannelHelper} \PYG{n}{channel} \PYG{o}{=} \PYG{n}{YansWifiChannelHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{YansWifiPhyHelper} \PYG{n}{phy} \PYG{o}{=} \PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{phy}\PYG{p}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{channel}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Create a WifiMacHelper, which is reused across STA and AP configurations}
\PYG{n}{WifiMacHelper} \PYG{n}{mac}\PYG{p}{;}

\PYG{c+c1}{// Create a WifiHelper, which will use the above helpers to create}
\PYG{c+c1}{// and install Wifi devices.  Configure a Wifi standard to use, which}
\PYG{c+c1}{// will align various parameters in the Phy and Mac to standard defaults.}
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}5GHZ}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// Declare NetDeviceContainers to hold the container returned by the helper}
\PYG{n}{NetDeviceContainer} \PYG{n}{wifiStaDevices}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{wifiApDevice}\PYG{p}{;}

\PYG{c+c1}{// Perform the installation}
\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiStaDevices} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiStaNodes}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiApDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiApNode}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

At this point, the 11 nodes have Wi\sphinxhyphen{}Fi devices configured, attached to a
common channel.  The rest of this section describes how additional
configuration may be performed.


\subsubsection{YansWifiChannelHelper}
\label{\detokenize{wifi-user:yanswifichannelhelper}}
The YansWifiChannelHelper has an unusual name. Readers may wonder why it is
named this way. The reference is to the \sphinxhref{https://dl.acm.org/doi/pdf/10.1145/1190455.1190467?download=true}{yans simulator} from which this model is taken. The
helper can be used to create a YansWifiChannel with a default PropagationLoss and
PropagationDelay model.

Users will typically type code such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{YansWifiChannelHelper} \PYG{n}{wifiChannelHelper} \PYG{o}{=} \PYG{n}{YansWifiChannelHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{Channel}\PYG{o}{\PYGZgt{}} \PYG{n}{wifiChannel} \PYG{o}{=} \PYG{n}{wifiChannelHelper}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

to get the defaults.  Specifically, the default is a channel model with a
propagation delay equal to a constant, the speed of light (\sphinxcode{\sphinxupquote{ns3::ConstantSpeedPropagationDelayModel}}),
and a propagation loss based on a default log distance model (\sphinxcode{\sphinxupquote{ns3::LogDistancePropagationLossModel}}), using a default exponent of 3.
Please note that the default log distance model is configured with a reference
loss of 46.6777 dB at reference distance of 1m.  The reference loss of 46.6777 dB
was calculated using Friis propagation loss model at 5.15 GHz.  The reference loss
must be changed if \sphinxstylestrong{802.11b}, \sphinxstylestrong{802.11g}, \sphinxstylestrong{802.11n} (at 2.4 GHz) or \sphinxstylestrong{802.11ax} (at 2.4 GHz) are used since they operate at 2.4 Ghz.

Note the distinction above in creating a helper object vs. an actual simulation
object.  In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, helper objects (used at the helper API only) are created on
the stack (they could also be created with operator new and later deleted).
However, the actual \sphinxstyleemphasis{ns\sphinxhyphen{}3} objects typically inherit from \sphinxcode{\sphinxupquote{class ns3::Object}}
and are assigned to a smart pointer.  See the chapter in the \sphinxstyleemphasis{ns\sphinxhyphen{}3} manual for
a discussion of the \sphinxstyleemphasis{ns\sphinxhyphen{}3} object model, if you are not familiar with it.

The following two methods are useful when configuring YansWifiChannelHelper:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{YansWifiChannelHelper::AddPropagationLoss}} adds a PropagationLossModel
to a chain of PropagationLossModel

\item {} 
\sphinxcode{\sphinxupquote{YansWifiChannelHelper::SetPropagationDelay}} sets a PropagationDelayModel

\end{itemize}


\subsubsection{YansWifiPhyHelper}
\label{\detokenize{wifi-user:yanswifiphyhelper}}
Physical devices (base class \sphinxcode{\sphinxupquote{ns3::WifiPhy}}) connect to \sphinxcode{\sphinxupquote{ns3::YansWifiChannel}} models in
\sphinxstyleemphasis{ns\sphinxhyphen{}3}.  We need to create WifiPhy objects appropriate for the YansWifiChannel; here
the \sphinxcode{\sphinxupquote{YansWifiPhyHelper}} will do the work.

The YansWifiPhyHelper class configures an object factory to create instances of
a \sphinxcode{\sphinxupquote{YansWifiPhy}} and adds some other objects to it, including possibly a
supplemental ErrorRateModel and a pointer to a MobilityModel. The user code is
typically:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{YansWifiPhyHelper} \PYG{n}{wifiPhyHelper} \PYG{o}{=} \PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{wifiChannel}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The default YansWifiPhyHelper is configured with NistErrorRateModel
(\sphinxcode{\sphinxupquote{ns3::NistErrorRateModel}}). You can change the error rate model by
calling the \sphinxcode{\sphinxupquote{YansWifiPhyHelper::SetErrorRateModel}} method.

Optionally, if pcap tracing is needed, a user may use the following
command to enable pcap tracing:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetPcapDataLinkType} \PYG{p}{(}\PYG{k}{enum} \PYG{n}{SupportedPcapDataLinkTypes} \PYG{n}{dlt}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstyleemphasis{ns\sphinxhyphen{}3} supports RadioTap and Prism tracing extensions for 802.11.

Note that we haven’t actually created any WifiPhy objects yet; we’ve just
prepared the YansWifiPhyHelper by telling it which channel it is connected to.
The Phy objects are created in the next step.

In order to enable 802.11n/ac/ax MIMO, the number of antennas as well as the number of supported spatial streams need to be configured.
For example, this code enables MIMO with 2 antennas and 2 spatial streams:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Antennas}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSupportedTxSpatialStreams}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSupportedRxSpatialStreams}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is also possible to configure less streams than the number of antennas in order to benefit from diversity gain, and to define different MIMO capabilities for downlink and uplink.
For example, this code configures a node with 3 antennas that supports 2 spatial streams in downstream and 1 spatial stream in upstream:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Antennas}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSupportedTxSpatialStreams}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MaxSupportedRxSpatialStreams}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

802.11n PHY layer can support both 20 (default) or 40 MHz channel width, and 802.11ac/ax PHY layer can use either 20, 40, 80 (default) or 160 MHz channel width.  See below for further documentation on setting the frequency, channel width, and channel number.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211ac}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetRemoteStationManager} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantRateWifiManager}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VhtMcs9}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ControlMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VhtMcs0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{//Install PHY and MAC}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3\PYGZhy{}wifi}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{WifiMacHelper} \PYG{n}{mac}\PYG{p}{;}

\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NetDeviceContainer} \PYG{n}{staDevice}\PYG{p}{;}
\PYG{n}{staDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiStaNode}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NetDeviceContainer} \PYG{n}{apDevice}\PYG{p}{;}
\PYG{n}{apDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiApNode}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{Channel, frequency, and channel width configuration}
\label{\detokenize{wifi-user:channel-frequency-and-channel-width-configuration}}
There are a few \sphinxcode{\sphinxupquote{ns3::WifiPhy}} parameters that are related, and cannot
be set completely independently, concerning the frequency and channel width
that the device is tuned to.  These are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{WifiPhyStandard}}:  For example, 802.11b, 802.11n, etc.

\item {} 
\sphinxcode{\sphinxupquote{Frequency}}

\item {} 
\sphinxcode{\sphinxupquote{ChannelWidth}}

\item {} 
\sphinxcode{\sphinxupquote{ChannelNumber}}

\end{itemize}

It is possible to set the above to incompatible combinations (e.g. channel
number 1 with 40 MHz channel width on frequency 4915 MHz).  In addition,
the latter three values above are attributes; it is possible to set them
in a number of ways:
\begin{itemize}
\item {} 
by setting global configuration default; e.g.

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SetDefault} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::WifiPhy::ChannelNumber}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
by setting an attribute value in the helper; e.g.

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{YansWifiPhyHelper} \PYG{n}{wifiPhyHelper} \PYG{o}{=} \PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhyHelper}\PYG{p}{.}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ChannelNumber}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
by setting the WifiHelper::SetStandard (enum WifiPhyStandard) method; and

\item {} 
by performing post\sphinxhyphen{}installation configuration of the option, either
via a Ptr to the WifiPhy object, or through the Config namespace; e.g.:

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/0/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Phy/\PYGZdl{}ns3::WifiPhy/ChannelNumber}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
             \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This section provides guidance on how to configure these settings in
a coherent manner, and what happens if non\sphinxhyphen{}standard values are chosen.


\paragraph{WifiHelper::SetStandard()}
\label{\detokenize{wifi-user:wifihelper-setstandard}}
\sphinxcode{\sphinxupquote{WifiHelper::SetStandard ()}} is a method to set various parameters
in the Mac and Phy to standard values and some reasonable defaults.
For example, \sphinxcode{\sphinxupquote{SetStandard (WIFI\_PHY\_STANDARD\_80211a)}} will set the
WifiPhy to Channel 36 in the 5 GHz band, among other settings appropriate
for 802.11a.

The following values for WifiPhyStandard are defined in
\sphinxcode{\sphinxupquote{src/wifi/model/wifi\sphinxhyphen{}phy\sphinxhyphen{}standard.h}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cm}{/** OFDM PHY for the 5 GHz band (Clause 17) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211a}\PYG{p}{,}
\PYG{c+cm}{/** DSSS PHY (Clause 15) and HR/DSSS PHY (Clause 18) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211b}\PYG{p}{,}
\PYG{c+cm}{/** ERP\PYGZhy{}OFDM PHY (Clause 19, Section 19.5) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211g}\PYG{p}{,}
\PYG{c+cm}{/** OFDM PHY for the 5 GHz band (Clause 17 with 10 MHz channel bandwidth) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211\PYGZus{}10MHZ}\PYG{p}{,}
\PYG{c+cm}{/** OFDM PHY for the 5 GHz band (Clause 17 with 5 MHz channel bandwidth) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211\PYGZus{}5MHZ}\PYG{p}{,}
\PYG{c+cm}{/** This is intended to be the configuration used in this paper:}
\PYG{c+cm}{ *  Gavin Holland, Nitin Vaidya and Paramvir Bahl, \PYGZdq{}A Rate\PYGZhy{}Adaptive}
\PYG{c+cm}{ *  MAC Protocol for Multi\PYGZhy{}Hop Wireless Networks\PYGZdq{}, in Proc. of}
\PYG{c+cm}{ *  ACM MOBICOM, 2001.}
\PYG{c+cm}{ */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}holland}\PYG{p}{,}
\PYG{c+cm}{/** HT OFDM PHY for the 2.4 GHz band (clause 20) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}2\PYGZus{}4GHZ}\PYG{p}{,}
\PYG{c+cm}{/** HT OFDM PHY for the 5 GHz band (clause 20) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}5GHZ}\PYG{p}{,}
\PYG{c+cm}{/** VHT OFDM PHY (clause 22) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211ac}\PYG{p}{,}
\PYG{c+cm}{/** HE PHY for the 2.4 GHz band (clause 26) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211ax\PYGZus{}2\PYGZus{}4GHZ}\PYG{p}{,}
\PYG{c+cm}{/** HE PHY for the 5 GHz band (clause 26) */}
\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211ax\PYGZus{}5GHZ}
\end{sphinxVerbatim}

In addition, a value WIFI\_PHY\_STANDARD\_UNSPECIFIED is defined to indicate
that the user has not set a standard.

By default, the WifiPhy will be initialized to WIFI\_PHY\_STANDARD\_UNSPECIFIED,
when it is created directly by \sphinxcode{\sphinxupquote{CreateObject}} (i.e. not by WifiHelper).
However, the WifiHelper (the typical use case for WifiPhy creation) will
configure the WIFI\_PHY\_STANDARD\_80211a standard by default.  Other values
for standards should be passed explicitly to the WifiHelper object.

If user has not already separately configured Frequency or ChannelNumber
when SetStandard is called, the user obtains default values, in addition
(e.g. channel 1 for 802.11b/g, or channel 36 for a/n), in addition to
an appropriate ChannelWidth value for the standard (typically, 20 MHz, but
80 MHz for 802.11ac/ax).


\paragraph{WifiPhy attribute interactions}
\label{\detokenize{wifi-user:wifiphy-attribute-interactions}}
Users should keep in mind that the two attributes that matter most
within the model code are \sphinxcode{\sphinxupquote{WifiPhy::Frequency}} and
\sphinxcode{\sphinxupquote{WifiPhy::ChannelWidth}}; these are the ones directly used to set
transmission parameters.  \sphinxcode{\sphinxupquote{WifiPhy::ChannelNumber}} and
\sphinxcode{\sphinxupquote{WifiHelper::SetStandard ()}} are convenience shorthands for setting
frequency and channel width.  The \sphinxcode{\sphinxupquote{ns3::WifiPhy}} contains code to
keep these values aligned and to generate runtime errors in some cases
if users set these attributes to incompatible values.

The pair (WifiPhyStandard, ChannelNumber) is an alias for a pair of
(Frequency/ChannelWidth) items.  Valid combinations are stored in
a map within WifiPhy that is populated with well\sphinxhyphen{}known values but that
can be dynamically extended at runtime.


\paragraph{WifiPhy::Frequency}
\label{\detokenize{wifi-user:wifiphy-frequency}}
The WifiPhy channel center frequency is set by the attribute \sphinxcode{\sphinxupquote{Frequency}}
in the class \sphinxcode{\sphinxupquote{WifiPhy}}.  It is expressed in units of MHz.  By default,
this attribute is set to the value 0 to indicate that no value is configured.

Note that this is a change in definition from ns\sphinxhyphen{}3.25 and earlier releases,
where this attribute referred to the start of the overall frequency band
on which the channel resides, not the specific channel center frequency.


\paragraph{WifiPhy::ChannelWidth}
\label{\detokenize{wifi-user:wifiphy-channelwidth}}
The WifiPhy channel width is set by the attribute \sphinxcode{\sphinxupquote{ChannelWidth}}
in the class \sphinxcode{\sphinxupquote{WifiPhy}}.  It is expressed in units of MHz.  By default,
this attribute is set to the value 20.  Allowable values are 5, 10, 20,
22, 40, 80, or 160 (MHz).


\paragraph{WifiPhy::ChannelNumber}
\label{\detokenize{wifi-user:wifiphy-channelnumber}}
Several channel numbers are defined and well\sphinxhyphen{}known in practice.  However,
valid channel numbers vary by geographical region around the world, and
there is some overlap between the different standards.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, the class \sphinxcode{\sphinxupquote{WifiPhy}} contains an attribute \sphinxcode{\sphinxupquote{ChannelNumber}} that
is, by default, set to the value 0.  The value 0 indicates that no
channel number has been set by the user.

In \sphinxstyleemphasis{ns\sphinxhyphen{}3}, a ChannelNumber may be defined or unknown.  These terms
are not found in the code; they are just used to describe behavior herein.

If a ChannelNumber is defined, it means that WifiPhy has stored a
map of ChannelNumber to the center frequency and channel width commonly
known for that channel in practice.  For example:
\begin{itemize}
\item {} 
Channel 1, when IEEE 802.11b is configured, corresponds to a channel
width of 22 MHz and a center frequency of 2412 MHz.

\item {} 
Channel 36, when IEEE 802.11n is configured at 5GHz, corresponds to
a channel width of 20 MHz and a center frequency of 5180 MHz.

\end{itemize}

The following channel numbers are well\sphinxhyphen{}defined for 2.4 GHz standards:
\begin{itemize}
\item {} 
channels 1\sphinxhyphen{}14 with ChannelWidth of 22 MHz for 802.11b

\item {} 
channels 1\sphinxhyphen{}14 with ChannelWidth of 20 MHz for 802.11n\sphinxhyphen{}2.4GHz and 802.11g

\end{itemize}

The following channel numbers are well\sphinxhyphen{}defined for 5 GHz standards:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxcode{\sphinxupquote{ChannelWidth}}
&
\sphinxcode{\sphinxupquote{ChannelNumber}}
\\
\hline
20 MHz
&
36, 40, 44, 48, 52, 56, 60, 64, 100,
104, 108, 112, 116, 120, 124,
128, 132, 136, 140, 144,
149, 153, 161, 165, 169
\\
\hline
40 MHz
&
38, 46, 54, 62, 102, 110, 118, 126,
134, 142, 151, 159
\\
\hline
80 MHz
&
42, 58, 106, 122, 138, 155
\\
\hline
160 MHz
&
50, 114
\\
\hline
10 MHz (802.11p)
&
172, 174, 176, 178, 180, 182, 184
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The channel number may be set either before or after creation of the
WifiPhy object.

If an unknown channel number (other than zero) is configured, the
simulator will exit with an error; for instance, such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiPhy}\PYG{o}{\PYGZgt{}} \PYG{n}{wifiPhy} \PYG{o}{=} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ChannelNumber}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{1321}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The known channel numbers are defined in the implementation file
\sphinxcode{\sphinxupquote{src/wifi/model/wifi\sphinxhyphen{}phy.cc}}.  Of course, this file may be edited
by users to extend to additional channel numbers.  Below, we describe
how new channel numbers may be defined dynamically at run\sphinxhyphen{}time.

If a known channel number is configured against an incorrect value
of the WifiPhyStandard, the simulator will exit with an error; for instance,
such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}5GHZ}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiPhy}\PYG{o}{\PYGZgt{}} \PYG{n}{wifiPhy} \PYG{o}{=} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetAttribute} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ChannelNumber}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{14}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In the above, while channel number 14 is well\sphinxhyphen{}defined in practice for 802.11b
only, it is for 2.4 GHz band, not 5 GHz band.


\paragraph{Defining a new channel number}
\label{\detokenize{wifi-user:defining-a-new-channel-number}}
Users may define their own channel number so that they can later refer to
the channel by number.

The method is \sphinxcode{\sphinxupquote{WifiPhy::DefineChannelNumber ()}} and it takes the following
arguments:
\begin{itemize}
\item {} 
uint16\_t channelNumber

\item {} 
enum WifiPhyStandard standard

\item {} 
uint32\_t frequency

\item {} 
uint32\_t channelWidth

\end{itemize}

The pair of (channelNumber, standard) are used as an index to a map that
returns a Frequency and ChannelWidth.  By calling this method, one can
dynamically add members to the map.  For instance, let’s suppose that you
previously configured WIFI\_PHY\_STANDARD\_80211a, and wanted to define a new
channel number ‘34’ of width 20 MHz and at center frequency 5160 MHz.

If you try to simply configure ChannelNumber to the value 34, it will fail,
since 34 is undefined.  However, you can use DefineChannelNumber as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiPhy}\PYG{o}{\PYGZgt{}} \PYG{n}{wifiPhy} \PYG{o}{=} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{DefineChannelNumber} \PYG{p}{(}\PYG{l+m+mi}{34}\PYG{p}{,} \PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211a}\PYG{p}{,} \PYG{l+m+mi}{5160}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and then later you can refer to channel number 34 in your program, which
will configure a center operating frequency of 5160 MHz and a width of
20 MHz.

The steps can be repeated to explicitly configure the same channel for
multiple standards:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{DefineChannelNumber} \PYG{p}{(}\PYG{l+m+mi}{34}\PYG{p}{,} \PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211a}\PYG{p}{,} \PYG{l+m+mi}{5160}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{DefineChannelNumber} \PYG{p}{(}\PYG{l+m+mi}{34}\PYG{p}{,} \PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}5GHZ}\PYG{p}{,} \PYG{l+m+mi}{5160}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

or for a wildcard, unspecified standard:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{wifiPhy}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{DefineChannelNumber} \PYG{p}{(}\PYG{l+m+mi}{34}\PYG{p}{,} \PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}UNSPECIFIED}\PYG{p}{,} \PYG{l+m+mi}{5160}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\paragraph{Order of operation issues}
\label{\detokenize{wifi-user:order-of-operation-issues}}
Depending on the default values used and the order of operation in setting
the values for the standard, channel width, frequency, and channel number,
different configurations can be obtained.   Below are some common use cases.
\begin{itemize}
\item {} 
\sphinxstylestrong{(accepting the standard defaults):}  If a user has not already
separately configured frequency or channel number when
\sphinxcode{\sphinxupquote{WifiHelper::SetStandard ()}} is called, the user gets default values
(e.g. channel 1 for 802.11b/g or channel 36 for a/n, with 20 MHz
channel widths)

\item {} 
\sphinxstylestrong{(overwriting the standard channel):}  If the user has previously
configured (e.g. via SetDefault) either frequency or channel number when
SetStandard is called, and the frequency or channel number are appropriate
for the standard being configured, they are not overwritten

\item {} 
\sphinxstylestrong{(changing the standard channel after Install):}  The user may also call
\sphinxcode{\sphinxupquote{WifiHelper::SetStandard ()}} after \sphinxcode{\sphinxupquote{Install ()}} and either configure
the frequency to something different, or configure the channel number
to something different.  Note that if the channel number is undefined
for the standard that was previously set, an error will occur.

\item {} 
\sphinxstylestrong{(changing to non\sphinxhyphen{}standard frequency):}  If the user configures a
frequency outside the standardized frequency range for the current
WifiPhyStandard, this is OK.  This allows users to experiment with
wifi on e.g. whitespace frequencies but still use SetStandard to set
all of the other configuration details.

\item {} 
\sphinxstylestrong{(interaction between channel number and frequency):}  If the user
sets Frequency to a different value than the currently configured
ChannelNumber (or if ChannelNumber is zero), then the ChannelNumber is
set to a new channel number if known, or to zero if unknown.
\begin{itemize}
\item {} 
\sphinxstyleemphasis{example:}  ChannelNumber previously set to 36, user sets Frequency to 5200, then ChannelNumber gets automatically set to 40

\item {} 
\sphinxstyleemphasis{example:}  ChannelNumber set to 36, user later sets Frequency to 5185, ChannelNumber gets reset to 0

\end{itemize}

\end{itemize}

In summary, ChannelNumber and Frequency follow each other.  ChannelNumber
sets both Frequency and ChannelWidth if the channel number has been defined
for the standard.  Setting ChannelWidth has no effect on Frequency or
ChannelNumber.  Setting Frequency will set ChannelNumber to either the
defined value for that Wi\sphinxhyphen{}Fi standard, or to the value 0 if undefined.


\subsubsection{SpectrumWifiPhyHelper}
\label{\detokenize{wifi-user:spectrumwifiphyhelper}}
The API for this helper closely tracks the API of the YansWifiPhyHelper,
with the exception that a channel of type \sphinxcode{\sphinxupquote{ns3::SpectrumChannel}} instead
of type \sphinxcode{\sphinxupquote{ns3::YansWifiChannel}} must be used with it.


\subsubsection{WifiMacHelper}
\label{\detokenize{wifi-user:wifimachelper}}
The next step is to configure the MAC model. We use WifiMacHelper to accomplish this.
WifiMacHelper takes care of both the MAC low model and MAC high model, and configures an object factory to create instances of a \sphinxcode{\sphinxupquote{ns3::WifiMac}}.
It is used to configure MAC parameters like type of MAC, and to select whether 802.11/WMM\sphinxhyphen{}style QoS and/or 802.11n\sphinxhyphen{}style High Throughput (HT)
and/or 802.11ac\sphinxhyphen{}style Very High Throughput (VHT) support and/or 802.11ax\sphinxhyphen{}style High Efficiency (HE) support are/is required.

By default, it creates an ad\sphinxhyphen{}hoc MAC instance that does not have 802.11e/WMM\sphinxhyphen{}style QoS nor 802.11n\sphinxhyphen{}style High Throughput (HT)
nor 802.11ac\sphinxhyphen{}style Very High Throughput (VHT) nor 802.11ax\sphinxhyphen{}style High Efficiency (HE) support enabled.

For example the following user code configures a non\sphinxhyphen{}QoS and non\sphinxhyphen{}HT/non\sphinxhyphen{}VHT/non\sphinxhyphen{}HE MAC that
will be a non\sphinxhyphen{}AP STA in an infrastructure network where the AP has SSID \sphinxcode{\sphinxupquote{ns\sphinxhyphen{}3\sphinxhyphen{}ssid}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns\PYGZhy{}3\PYGZhy{}ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The following code shows how to create an AP with QoS enabled:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{QosSupported}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BeaconGeneration}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BeaconInterval}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{Seconds} \PYG{p}{(}\PYG{l+m+mf}{2.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

To create ad\sphinxhyphen{}hoc MAC instances, simply use \sphinxcode{\sphinxupquote{ns3::AdhocWifiMac}} instead of \sphinxcode{\sphinxupquote{ns3::StaWifiMac}} or \sphinxcode{\sphinxupquote{ns3::ApWifiMac}}.

In infrastructure mode without QoS enabled, it is also possible to enable PCF support.
The following code shows how to create a CF\sphinxhyphen{}pollable station:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{PcfSupported}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

PCF also supports an option to change the maximum duration of the contention\sphinxhyphen{}free period (which must be a multiple of 1024 microseconds).
The following code shows how to create an AP with a custom PCF configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{PcfSupported}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{,}
                       \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{CfpMaxDuration}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{l+m+mi}{20480}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

With QoS\sphinxhyphen{}enabled MAC models it is possible to work with traffic belonging to
four different Access Categories (ACs): \sphinxstylestrong{AC\_VO} for voice traffic,
\sphinxstylestrong{AC\_VI} for video traffic, \sphinxstylestrong{AC\_BE} for best\sphinxhyphen{}effort
traffic and \sphinxstylestrong{AC\_BK} for background traffic.

When selecting \sphinxstylestrong{802.11n} as the desired wifi standard, both 802.11e/WMM\sphinxhyphen{}style QoS and 802.11n\sphinxhyphen{}style High Throughput (HT) support gets enabled.
Similarly when selecting \sphinxstylestrong{802.11ac} as the desired wifi standard, 802.11e/WMM\sphinxhyphen{}style QoS, 802.11n\sphinxhyphen{}style High Throughput (HT) and 802.11ac\sphinxhyphen{}style Very High Throughput (VHT)
support gets enabled. And when selecting \sphinxstylestrong{802.11ax} as the desired wifi standard, 802.11e/WMM\sphinxhyphen{}style QoS, 802.11n\sphinxhyphen{}style High Throughput (HT),
802.11ac\sphinxhyphen{}style Very High Throughput (VHT) and 802.11ax\sphinxhyphen{}style High Efficiency (HE) support gets enabled.

For MAC instances that have QoS support enabled, the \sphinxcode{\sphinxupquote{ns3::WifiMacHelper}} can be also used to set:
\begin{itemize}
\item {} 
block ack threshold (number of packets for which block ack mechanism should be used);

\item {} 
block ack inactivity timeout.

\end{itemize}

For example the following user code configures a MAC that will be a non\sphinxhyphen{}AP STA with QoS enabled and a block ack threshold for AC\_BE set to 2 packets,
in an infrastructure network where the AP has SSID \sphinxcode{\sphinxupquote{ns\sphinxhyphen{}3\sphinxhyphen{}ssid}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns\PYGZhy{}3\PYGZhy{}ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{QosSupported}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BE\PYGZus{}BlockAckThreshold}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For MAC instances that have 802.11n\sphinxhyphen{}style High Throughput (HT) and/or 802.11ac\sphinxhyphen{}style Very High Throughput (VHT) and/or 802.11ax\sphinxhyphen{}style High Efficiency (HE) support enabled,
the \sphinxcode{\sphinxupquote{ns3::WifiMacHelper}} can be also used to set:
\begin{itemize}
\item {} 
MSDU aggregation parameters for a particular Access Category (AC) in order to use 802.11n/ac A\sphinxhyphen{}MSDU feature;

\item {} 
MPDU aggregation parameters for a particular Access Category (AC) in order to use 802.11n/ac A\sphinxhyphen{}MPDU feature.

\end{itemize}

By default, MSDU aggregation feature is disabled for all ACs and MPDU aggregation is enabled for AC\_VI and AC\_BE, with a maximum aggregation size of 65535 bytes.

For example the following user code configures a MAC that will be a non\sphinxhyphen{}AP STA with HT and QoS enabled, MPDU aggregation enabled for AC\_VO with a maximum aggregation size of 65535 bytes, and MSDU aggregation enabled for AC\_BE with a maximum aggregation size of 7935 bytes,
in an infrastructure network where the AP has SSID \sphinxcode{\sphinxupquote{ns\sphinxhyphen{}3\sphinxhyphen{}ssid}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}5GHZ}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{WifiMacHelper} \PYG{n}{wifiMacHelper}\PYG{p}{;}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns\PYGZhy{}3\PYGZhy{}ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiMacHelper}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VO\PYGZus{}MaxAmpduSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{65535}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BE\PYGZus{}MaxAmsduSize}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{UintegerValue} \PYG{p}{(}\PYG{l+m+mi}{7935}\PYG{p}{)}\PYG{p}{,}
                      \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\paragraph{Selection of the Access Category (AC)}
\label{\detokenize{wifi-user:selection-of-the-access-category-ac}}
Since ns\sphinxhyphen{}3.26, the QosTag is no longer used to assign a user priority to an MSDU.
Instead, the selection of the Access Category (AC) for an MSDU is based on the
value of the DS field in the IP header of the packet (ToS field in case of IPv4,
Traffic Class field in case of IPv6). Details on how to set the ToS field of IPv4
packets are given in the {\hyperref[\detokenize{sockets-api:type-of-service}]{\sphinxcrossref{\DUrole{std,std-ref}{ToS (Type of Service)}}}} section of the documentation. In
summary, users can create an address of type \sphinxcode{\sphinxupquote{ns3::InetSocketAddress}}
with the desired type of service value and pass it to the application helpers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{InetSocketAddress} \PYG{n+nf}{destAddress} \PYG{p}{(}\PYG{n}{ipv4Address}\PYG{p}{,} \PYG{n}{udpPort}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{destAddress}\PYG{p}{.}\PYG{n}{SetTos} \PYG{p}{(}\PYG{n}{tos}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{OnOffHelper} \PYG{n+nf}{onoff} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::UdpSocketFactory}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{destAddress}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Mapping the values of the DS field onto user priorities is performed similarly to the
Linux mac80211 subsystem. Basically, the \sphinxcode{\sphinxupquote{ns3::WifiNetDevice::SelectQueue()}}
method sets the user priority (UP) of an MSDU to the three most significant
bits of the DS field. The Access Category is then determined based on the user priority
according to the following table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
UP
&\sphinxstyletheadfamily 
Access Category
\\
\hline
7
&
AC\_VO
\\
\hline
6
&
AC\_VO
\\
\hline
5
&
AC\_VI
\\
\hline
4
&
AC\_VI
\\
\hline
3
&
AC\_BE
\\
\hline
0
&
AC\_BE
\\
\hline
2
&
AC\_BK
\\
\hline
1
&
AC\_BK
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

TOS and DSCP values map onto user priorities and access categories according
to the following table.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
DiffServ PHB
&\sphinxstyletheadfamily 
TOS (binary)
&\sphinxstyletheadfamily 
UP
&\sphinxstyletheadfamily 
Access Category
\\
\hline
EF
&
101110xx
&
5
&
AC\_VI
\\
\hline
AF11
&
001010xx
&
1
&
AC\_BK
\\
\hline
AF21
&
010010xx
&
2
&
AC\_BK
\\
\hline
AF31
&
011010xx
&
3
&
AC\_BE
\\
\hline
AF41
&
100010xx
&
4
&
AC\_VI
\\
\hline
AF12
&
001100xx
&
1
&
AC\_BK
\\
\hline
AF22
&
010100xx
&
2
&
AC\_BK
\\
\hline
AF32
&
011100xx
&
3
&
AC\_BE
\\
\hline
AF42
&
100100xx
&
4
&
AC\_VI
\\
\hline
AF13
&
001110xx
&
1
&
AC\_BK
\\
\hline
AF23
&
010110xx
&
2
&
AC\_BK
\\
\hline
AF33
&
011110xx
&
3
&
AC\_BE
\\
\hline
AF43
&
100110xx
&
4
&
AC\_VI
\\
\hline
CS0
&
000000xx
&
0
&
AC\_BE
\\
\hline
CS1
&
001000xx
&
1
&
AC\_BK
\\
\hline
CS2
&
010000xx
&
2
&
AC\_BK
\\
\hline
CS3
&
011000xx
&
3
&
AC\_BE
\\
\hline
CS4
&
100000xx
&
4
&
AC\_VI
\\
\hline
CS5
&
101000xx
&
5
&
AC\_VI
\\
\hline
CS6
&
110000xx
&
6
&
AC\_VO
\\
\hline
CS7
&
111000xx
&
7
&
AC\_VO
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

So, for example,:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{destAddress}\PYG{p}{.}\PYG{n}{SetTos} \PYG{p}{(}\PYG{l+m+mh}{0xc0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

will map to CS6, User Priority 6, and Access Category AC\_VO.
Also, the ns3\sphinxhyphen{}wifi\sphinxhyphen{}ac\sphinxhyphen{}mapping test suite (defined in
src/test/ns3wifi/wifi\sphinxhyphen{}ac\sphinxhyphen{}mapping\sphinxhyphen{}test\sphinxhyphen{}suite.cc) can provide additional
useful information.

Note that \sphinxcode{\sphinxupquote{ns3::WifiNetDevice::SelectQueue()}} also sets the packet
priority to the user priority, thus overwriting the value determined by the
socket priority (users can read {\hyperref[\detokenize{sockets-api:socket-options}]{\sphinxcrossref{\DUrole{std,std-ref}{Socket options}}}} for details on how to
set the packet priority). Also, given that the Traffic Control layer calls
\sphinxcode{\sphinxupquote{ns3::WifiNetDevice::SelectQueue()}} before enqueuing the packet
into a queue disc, it turns out that queuing disciplines (such as
PfifoFastQueueDisc) that classifies packets based on their priority will
use the user priority instead of the socket priority.


\subsubsection{WifiHelper}
\label{\detokenize{wifi-user:wifihelper}}
We’re now ready to create WifiNetDevices. First, let’s create
a WifiHelper with default settings:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifiHelper}\PYG{p}{;}
\end{sphinxVerbatim}

What does this do?  It sets the default wifi standard to \sphinxstylestrong{802.11a} and sets the RemoteStationManager to
\sphinxcode{\sphinxupquote{ns3::ArfWifiManager}}.  You can change the RemoteStationManager by calling the
\sphinxcode{\sphinxupquote{WifiHelper::SetRemoteStationManager}} method. To change the wifi standard, call the
\sphinxcode{\sphinxupquote{WifiHelper::SetStandard}} method with the desired standard.

Now, let’s use the wifiPhyHelper and wifiMacHelper created above to install WifiNetDevices
on a set of nodes in a NodeContainer “c”:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NetDeviceContainer} \PYG{n}{wifiContainer} \PYG{o}{=} \PYG{n}{WifiHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiPhyHelper}\PYG{p}{,} \PYG{n}{wifiMacHelper}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This creates the WifiNetDevice which includes also a WifiRemoteStationManager, a
WifiMac, and a WifiPhy (connected to the matching Channel).

The \sphinxcode{\sphinxupquote{WifiHelper::SetStandard}} method sets various default timing parameters as defined in the selected standard version, overwriting values that may exist or have been previously configured.
In order to change parameters that are overwritten by \sphinxcode{\sphinxupquote{WifiHelper::SetStandard}}, this should be done post\sphinxhyphen{}install using \sphinxcode{\sphinxupquote{Config::Set}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211n\PYGZus{}2\PYGZus{}4GHZ}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetRemoteStationManager} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantRateWifiManager}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{HtMcs7}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ControlMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{StringValue}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{HtMcs0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{//Install PHY and MAC}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3\PYGZhy{}wifi}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{WifiMacHelper} \PYG{n}{mac}\PYG{p}{;}
\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NetDeviceContainer} \PYG{n}{staDevice}\PYG{p}{;}
\PYG{n}{staDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiStaNode}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{mac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NetDeviceContainer} \PYG{n}{apDevice}\PYG{p}{;}
\PYG{n}{apDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{phy}\PYG{p}{,} \PYG{n}{mac}\PYG{p}{,} \PYG{n}{wifiApNode}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{//Once install is done, we overwrite the standard timing values}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/Slot}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{slot}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/Sifs}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{sifs}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/AckTimeout}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{ackTimeout}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/CtsTimeout}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{ctsTimeout}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/Rifs}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{rifs}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/BasicBlockAckTimeout}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{basicBlockAckTimeout}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Config}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Set} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/NodeList/*/DeviceList/*/\PYGZdl{}ns3::WifiNetDevice/Mac/CompressedBlockAckTimeout}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{TimeValue} \PYG{p}{(}\PYG{n}{MicroSeconds} \PYG{p}{(}\PYG{n}{compressedBlockAckTimeout}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The WifiHelper can be used to set the attributes of the default ack policy selector
(\sphinxcode{\sphinxupquote{ConstantWifiAckPolicySelector}}) or to select a different (user provided) ack
policy selector, for each of the available Access Categories. As an example, the
following code can be used to set the BaThreshold attribute of the default ack
policy selector associated with BE AC to 0.5:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetAckPolicySelectorForAc} \PYG{p}{(}\PYG{n}{AC\PYGZus{}BE}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantWifiAckPolicySelector}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BaThreshold}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The WifiHelper is also used to configure OBSS PD spatial reuse for 802.11ax.
The following lines configure a WifiHelper to support OBSS PD spatial reuse
using the \sphinxcode{\sphinxupquote{ConstantObssPdAlgorithm}} with a threshold set to \sphinxhyphen{}72 dBm:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetObssPdAlgorithm} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantObssPdAlgorithm}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                         \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ObssPdLevel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{72.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

There are many other \sphinxstyleemphasis{ns\sphinxhyphen{}3} attributes that can be set on the above helpers to
deviate from the default behavior; the example scripts show how to do some of
this reconfiguration.


\subsubsection{HT configuration}
\label{\detokenize{wifi-user:ht-configuration}}
HT is an acronym for High Throughput, a term synonymous with the IEEE 802.11n
standard.  Once the \sphinxcode{\sphinxupquote{ns3::WifiHelper::Install}} has been called and the
user sets the standard to a variant that supports HT capabilities (802.11n,
802.11ac, or 802.11ax), an HT configuration object will automatically be
created for the device.  The configuration object is used to store and
manage HT\sphinxhyphen{}specific attributes.

802.11n/ac PHY layer can use either long (800 ns) or short (400 ns) OFDM guard intervals. To configure this parameter for a given device, the following lines of code could be used (in this example, it enables the support of a short guard interval for the first station):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{nd} \PYG{o}{=} \PYG{n}{wifiStaDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{wnd} \PYG{o}{=} \PYG{n}{nd}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{HtConfiguration}\PYG{o}{\PYGZgt{}} \PYG{n}{htConfiguration} \PYG{o}{=} \PYG{n}{wnd}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetHtConfiguration} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{htConfiguration}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetShortGuardIntervalSupported} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is also possible to configure HT\sphinxhyphen{}specific attributes using \sphinxcode{\sphinxupquote{Config::Set}}.
The following line of code enables the support of a short guard interval for all stations:
\begin{quote}

Config::Set (“/NodeList/\sphinxstyleemphasis{/DeviceList/}/\$ns3::WifiNetDevice/HtConfiguration/ShortGuardIntervalSupported”, BooleanValue (true));
\end{quote}

Furthermore, 802.11n provides an optional mode (Greenfield mode) to reduce preamble durations and which is only compatible with 802.11n devices. This mode is enabled as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{htConfiguration}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetGreenfieldSupported} \PYG{p}{(}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsubsection{VHT configuration}
\label{\detokenize{wifi-user:vht-configuration}}
IEEE 802.11ac devices are also known as supporting Very High Throughput (VHT).  Once the \sphinxcode{\sphinxupquote{ns3::WifiHelper::Install}} has been called and either the 802.11ac
or 802.11ax 5 GHz standards are configured, a VHT configuration object will be
automatically created to manage VHT\sphinxhyphen{}specific attributes.

As of ns\sphinxhyphen{}3.29, however, there are no VHT\sphinxhyphen{}specific configuration items to
manage; therefore, this object is a placeholder for future growth.


\subsubsection{HE configuration}
\label{\detokenize{wifi-user:he-configuration}}
IEEE 802.11ax is also known as High Efficiency (HE).  Once the \sphinxcode{\sphinxupquote{ns3::WifiHelper::Install}} has been called and IEEE 802.11ax configured as the standard, an
HE configuration object will automatically be created to manage HE\sphinxhyphen{}specific
attributes for 802.11ax devices.

802.11ax PHY layer can use either 3200 ns, 1600 ns or 800 ns OFDM guard intervals. To configure this parameter, the following lines of code could be used (in this example, it enables the support of 1600 ns guard interval), such as in this example code snippet:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{NetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{nd} \PYG{o}{=} \PYG{n}{wifiStaDevices}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{wnd} \PYG{o}{=} \PYG{n}{nd}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetObject}\PYG{o}{\PYGZlt{}}\PYG{n}{WifiNetDevice}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{HeConfiguration}\PYG{o}{\PYGZgt{}} \PYG{n}{heConfiguration} \PYG{o}{=} \PYG{n}{wnd}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetHeConfiguration} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{heConfiguration}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetGuardInterval} \PYG{p}{(}\PYG{n}{NanoSeconds} \PYG{p}{(}\PYG{l+m+mi}{1600}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{l+m+mf}{802.11}\PYG{n}{ax} \PYG{n}{allows} \PYG{n}{extended} \PYG{n}{compressed} \PYG{n}{Block} \PYG{n}{ACKs} \PYG{n}{containing} \PYG{n}{a} \PYG{l+m+mi}{256}\PYG{o}{\PYGZhy{}}\PYG{n}{bits} \PYG{n}{bitmap}\PYG{p}{,} \PYG{n}{making} \PYG{n}{possible} \PYG{n}{transmissions} \PYG{n}{of} \PYG{n}{A}\PYG{o}{\PYGZhy{}}\PYG{n}{MPDUs} \PYG{n}{containing} \PYG{n}{up} \PYG{n}{to} \PYG{l+m+mi}{256} \PYG{n}{MPDUs}\PYG{p}{,}
\PYG{n}{depending} \PYG{n}{on} \PYG{n}{the} \PYG{n}{negotiated} \PYG{n}{buffer} \PYG{n}{size}\PYG{p}{.} \PYG{n}{In} \PYG{n}{order} \PYG{n}{to} \PYG{n}{configure} \PYG{n}{the} \PYG{n}{buffer} \PYG{n}{size} \PYG{n}{of} \PYG{n}{an} \PYG{l+m+mf}{802.11}\PYG{n}{ax} \PYG{n}{device}\PYG{p}{,} \PYG{n}{the} \PYG{n}{following} \PYG{n}{line} \PYG{n}{of} \PYG{n}{code} \PYG{n}{could} \PYG{n}{be} \PYG{n}{used}\PYG{o}{:}\PYG{o}{:}

\PYG{n}{heConfiguration}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetMpduBufferSize} \PYG{p}{(}\PYG{l+m+mi}{256}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{For} \PYG{n}{transmitting} \PYG{n}{large} \PYG{n}{MPDUs}\PYG{p}{,} \PYG{n}{it} \PYG{n}{might} \PYG{n}{also} \PYG{n}{be} \PYG{n}{needed} \PYG{n}{to} \PYG{n}{increase} \PYG{n}{the} \PYG{n}{maximum} \PYG{n}{aggregation} \PYG{n}{size} \PYG{p}{(}\PYG{n}{see} \PYG{n}{above}\PYG{p}{)}\PYG{p}{.}
\end{sphinxVerbatim}


\subsubsection{Mobility configuration}
\label{\detokenize{wifi-user:mobility-configuration}}
Finally, a mobility model must be configured on each node with Wi\sphinxhyphen{}Fi device.
Mobility model is used for calculating propagation loss and propagation delay.
Two examples are provided in the next section.
Users are referred to the chapter on {\hyperref[\detokenize{mobility:mobility}]{\sphinxcrossref{\DUrole{std,std-ref}{Mobility}}}} module for detailed information.


\subsubsection{Example configuration}
\label{\detokenize{wifi-user:example-configuration}}
We provide two typical examples of how a user might configure a Wi\sphinxhyphen{}Fi network \textendash{}
one example with an ad\sphinxhyphen{}hoc network and one example with an infrastructure network.
The two examples were modified from the two examples in the \sphinxcode{\sphinxupquote{examples/wireless}} folder
(\sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}simple\sphinxhyphen{}adhoc.cc}} and \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}simple\sphinxhyphen{}infra.cc}}).
Users are encouraged to see examples in the \sphinxcode{\sphinxupquote{examples/wireless}} folder.


\paragraph{AdHoc WifiNetDevice configuration}
\label{\detokenize{wifi-user:adhoc-wifinetdevice-configuration}}
In this example, we create two ad\sphinxhyphen{}hoc nodes equipped with 802.11a Wi\sphinxhyphen{}Fi devices.
We use the \sphinxcode{\sphinxupquote{ns3::ConstantSpeedPropagationDelayModel}} as the propagation delay model and
\sphinxcode{\sphinxupquote{ns3::LogDistancePropagationLossModel}} with the exponent of 3.0 as the propagation loss model.
Both devices are configured with \sphinxcode{\sphinxupquote{ConstantRateWifiManager}} at the fixed rate of 12Mbps.
Finally, we manually place them by using the \sphinxcode{\sphinxupquote{ns3::ListPositionAllocator}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{phyMode} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{OfdmRate12Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NodeContainer} \PYG{n}{c}\PYG{p}{;}
\PYG{n}{c}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211a}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{YansWifiPhyHelper} \PYG{n}{wifiPhy} \PYG{o}{=}  \PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// ns\PYGZhy{}3 supports RadioTap and Prism tracing extensions for 802.11}
\PYG{n}{wifiPhy}\PYG{p}{.}\PYG{n}{SetPcapDataLinkType} \PYG{p}{(}\PYG{n}{WifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DLT\PYGZus{}IEEE802\PYGZus{}11\PYGZus{}RADIO}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{YansWifiChannelHelper} \PYG{n}{wifiChannel}\PYG{p}{;}
\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{SetPropagationDelay} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantSpeedPropagationDelayModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{AddPropagationLoss} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LogDistancePropagationLossModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Exponent}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{3.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{p}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Add a non\PYGZhy{}QoS upper mac, and disable rate control (i.e. ConstantRateWifiManager)}
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMac}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetRemoteStationManager} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantRateWifiManager}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{phyMode}\PYG{p}{)}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ControlMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{phyMode}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// Set it to adhoc mode}
\PYG{n}{wifiMac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::AdhocWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiPhy}\PYG{p}{,} \PYG{n}{wifiMac}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Configure mobility}
\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{ListPositionAllocator}\PYG{o}{\PYGZgt{}} \PYG{n}{positionAlloc} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{ListPositionAllocator}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{positionAlloc}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{positionAlloc}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetPositionAllocator} \PYG{p}{(}\PYG{n}{positionAlloc}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetMobilityModel} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantPositionMobilityModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{c}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// other set up (e.g. InternetStack, Application)}
\end{sphinxVerbatim}


\paragraph{Infrastructure (access point and clients) WifiNetDevice configuration}
\label{\detokenize{wifi-user:infrastructure-access-point-and-clients-wifinetdevice-configuration}}
This is a typical example of how a user might configure an access point and a set of clients.
In this example, we create one access point and two clients.
Each node is equipped with 802.11b Wi\sphinxhyphen{}Fi device:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{phyMode} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DsssRate1Mbps}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{NodeContainer} \PYG{n}{ap}\PYG{p}{;}
\PYG{n}{ap}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n}{sta}\PYG{p}{;}
\PYG{n}{sta}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{WifiHelper} \PYG{n}{wifi}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetStandard} \PYG{p}{(}\PYG{n}{WIFI\PYGZus{}PHY\PYGZus{}STANDARD\PYGZus{}80211b}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{YansWifiPhyHelper} \PYG{n}{wifiPhy} \PYG{o}{=}  \PYG{n}{YansWifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Default} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// ns\PYGZhy{}3 supports RadioTap and Prism tracing extensions for 802.11}
\PYG{n}{wifiPhy}\PYG{p}{.}\PYG{n}{SetPcapDataLinkType} \PYG{p}{(}\PYG{n}{WifiPhyHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DLT\PYGZus{}IEEE802\PYGZus{}11\PYGZus{}RADIO}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{YansWifiChannelHelper} \PYG{n}{wifiChannel}\PYG{p}{;}
\PYG{c+c1}{// reference loss must be changed since 802.11b is operating at 2.4GHz}
\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{SetPropagationDelay} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantSpeedPropagationDelayModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{AddPropagationLoss} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::LogDistancePropagationLossModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Exponent}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{3.0}\PYG{p}{)}\PYG{p}{,}
                                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ReferenceLoss}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{DoubleValue} \PYG{p}{(}\PYG{l+m+mf}{40.0459}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wifiPhy}\PYG{p}{.}\PYG{n}{SetChannel} \PYG{p}{(}\PYG{n}{wifiChannel}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Add a non\PYGZhy{}QoS upper mac, and disable rate control}
\PYG{n}{WifiMacHelper} \PYG{n}{wifiMac}\PYG{p}{;}
\PYG{n}{wifi}\PYG{p}{.}\PYG{n}{SetRemoteStationManager} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantRateWifiManager}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DataMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{phyMode}\PYG{p}{)}\PYG{p}{,}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ControlMode}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{StringValue} \PYG{p}{(}\PYG{n}{phyMode}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Setup the rest of the upper mac}
\PYG{n}{Ssid} \PYG{n}{ssid} \PYG{o}{=} \PYG{n}{Ssid} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{wifi\PYGZhy{}default}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// setup ap.}
\PYG{n}{wifiMac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ApWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{apDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiPhy}\PYG{p}{,} \PYG{n}{wifiMac}\PYG{p}{,} \PYG{n}{ap}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{devices} \PYG{o}{=} \PYG{n}{apDevice}\PYG{p}{;}

\PYG{c+c1}{// setup sta.}
\PYG{n}{wifiMac}\PYG{p}{.}\PYG{n}{SetType} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::StaWifiMac}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Ssid}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{SsidValue} \PYG{p}{(}\PYG{n}{ssid}\PYG{p}{)}\PYG{p}{,}
                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ActiveProbing}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BooleanValue} \PYG{p}{(}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{NetDeviceContainer} \PYG{n}{staDevice} \PYG{o}{=} \PYG{n}{wifi}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{wifiPhy}\PYG{p}{,} \PYG{n}{wifiMac}\PYG{p}{,} \PYG{n}{sta}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{devices}\PYG{p}{.}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{staDevice}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Configure mobility}
\PYG{n}{MobilityHelper} \PYG{n}{mobility}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{ListPositionAllocator}\PYG{o}{\PYGZgt{}} \PYG{n}{positionAlloc} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{ListPositionAllocator}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{positionAlloc}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{positionAlloc}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{positionAlloc}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Add} \PYG{p}{(}\PYG{n}{Vector} \PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{5.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetPositionAllocator} \PYG{p}{(}\PYG{n}{positionAlloc}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{SetMobilityModel} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ns3::ConstantPositionMobilityModel}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ap}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mobility}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{sta}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// other set up (e.g. InternetStack, Application)}
\end{sphinxVerbatim}


\section{Testing Documentation}
\label{\detokenize{wifi-testing:testing-documentation}}\label{\detokenize{wifi-testing::doc}}
At present, most of the available documentation about testing and validation
exists in publications, some of which are referenced below.


\subsection{Error model}
\label{\detokenize{wifi-testing:error-model}}
Validation results for the 802.11b error model are available in this
\sphinxhref{http://www.nsnam.org/~pei/80211b.pdf}{technical report}

Two clarifications on the results should be noted.  First, Figure 1\sphinxhyphen{}4
of the above reference
corresponds to the \sphinxstyleemphasis{ns\sphinxhyphen{}3} NIST BER model.   In the program in the
Appendix of the paper (80211b.c), there are two constants used to generate
the data.  The first, packet size, is set to 1024 bytes.  The second,
“noise”, is set to a value of 7 dB; this was empirically picked to align
the curves the best with the reported data from the CMU testbed.  Although
a value of 1.55 dB would correspond to the reported \sphinxhyphen{}99 dBm noise floor
from the CMU paper, a noise figure of 7 dB results in the best fit with the
CMU experimental data.  This default of 7 dB is the RxNoiseFigure in the
\sphinxcode{\sphinxupquote{ns3::YansWifiPhy}} model.  Other values for noise figure will shift the
curves leftward or rightward but not change the slope.

The curves can be reproduced by running the \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}clear\sphinxhyphen{}channel\sphinxhyphen{}cmu.cc}}
example program in the \sphinxcode{\sphinxupquote{examples/wireless}} directory, and the figure produced
(when GNU Scientific Library (GSL) is enabled) is reproduced below in
Figure {\hyperref[\detokenize{wifi-testing:fig-clear-channel-80211b}]{\sphinxcrossref{\DUrole{std,std-ref}{Clear channel (AWGN) error model for 802.11b}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{clear-channel}.pdf}
\caption{Clear channel (AWGN) error model for 802.11b}\label{\detokenize{wifi-testing:id2}}\label{\detokenize{wifi-testing:fig-clear-channel-80211b}}\end{figure}

Validation results for the 802.11a/g OFDM error model are available in this
\sphinxhref{https://www.nsnam.org/~pei/80211ofdm.pdf}{technical report}.  The curves
can be reproduced by running the \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}ofdm\sphinxhyphen{}validation.cc}} example program
in the \sphinxcode{\sphinxupquote{examples/wireless}} directory, and the figure is reproduced below
in Figure {\hyperref[\detokenize{wifi-testing:fig-nist-frame-success-rate}]{\sphinxcrossref{\DUrole{std,std-ref}{Frame error rate (NIST model) for 802.11a/g (OFDM) Wi\sphinxhyphen{}Fi}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nist-frame-success-rate}.pdf}
\caption{Frame error rate (NIST model) for 802.11a/g (OFDM) Wi\sphinxhyphen{}Fi}\label{\detokenize{wifi-testing:id3}}\label{\detokenize{wifi-testing:fig-nist-frame-success-rate}}\end{figure}

Similar curves for 802.11n/ac/ax can be obtained by running the \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}ofdm\sphinxhyphen{}ht\sphinxhyphen{}validation.cc}},
\sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}ofdm\sphinxhyphen{}vht\sphinxhyphen{}validation.cc}} and \sphinxcode{\sphinxupquote{wifi\sphinxhyphen{}ofdm\sphinxhyphen{}he\sphinxhyphen{}validation.cc}} example programs
in the \sphinxcode{\sphinxupquote{examples/wireless}} directory, and the figures are reproduced below
in Figure {\hyperref[\detokenize{wifi-testing:fig-nist-frame-success-rate-n}]{\sphinxcrossref{\DUrole{std,std-ref}{Frame error rate (NIST model) for 802.11n (HT OFDM) Wi\sphinxhyphen{}Fi}}}}, Figure {\hyperref[\detokenize{wifi-testing:fig-nist-frame-success-rate-ac}]{\sphinxcrossref{\DUrole{std,std-ref}{Frame error rate (NIST model) for 802.11ac (VHT OFDM) Wi\sphinxhyphen{}Fi}}}}
and Figure {\hyperref[\detokenize{wifi-testing:fig-nist-frame-success-rate-ax}]{\sphinxcrossref{\DUrole{std,std-ref}{Frame error rate (NIST model) for 802.11ax (HE OFDM) Wi\sphinxhyphen{}Fi}}}}, respectively.
There is no validation for those curves yet.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nist-frame-success-rate-n}.pdf}
\caption{Frame error rate (NIST model) for 802.11n (HT OFDM) Wi\sphinxhyphen{}Fi}\label{\detokenize{wifi-testing:id4}}\label{\detokenize{wifi-testing:fig-nist-frame-success-rate-n}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nist-frame-success-rate-ac}.pdf}
\caption{Frame error rate (NIST model) for 802.11ac (VHT OFDM) Wi\sphinxhyphen{}Fi}\label{\detokenize{wifi-testing:id5}}\label{\detokenize{wifi-testing:fig-nist-frame-success-rate-ac}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nist-frame-success-rate-ax}.pdf}
\caption{Frame error rate (NIST model) for 802.11ax (HE OFDM) Wi\sphinxhyphen{}Fi}\label{\detokenize{wifi-testing:id6}}\label{\detokenize{wifi-testing:fig-nist-frame-success-rate-ax}}\end{figure}


\subsection{MAC validation}
\label{\detokenize{wifi-testing:mac-validation}}
Validation of the 802.11 DCF MAC layer has been performed in \sphinxcite{wifi-references:baldo2010}.

802.11 PCF operation has been verified by running ‘wifi\sphinxhyphen{}pcf’ example with PCAP files generation enabled, and observing the frame exchange using Wireshark.


\subsection{SpectrumWiFiPhy}
\label{\detokenize{wifi-testing:spectrumwifiphy}}
The SpectrumWifiPhy implementation has been verified to produce equivalent
results to the legacy YansWifiPhy by using the saturation and packet
error rate programs (described below) and toggling the implementation
between the two physical layers.

A basic unit test is provided using injection of hand\sphinxhyphen{}crafted packets to
a receiving Phy object, controlling the timing and receive power of
each packet arrival and checking the reception results.  However, most of
the testing of this Phy implementation has been performed using example
programs described below, and during the course of a (separate) LTE/Wi\sphinxhyphen{}Fi
coexistence study not documented herein.


\subsubsection{Saturation performance}
\label{\detokenize{wifi-testing:saturation-performance}}
The program \sphinxcode{\sphinxupquote{examples/wireless/wifi\sphinxhyphen{}spectrum\sphinxhyphen{}saturation\sphinxhyphen{}example.cc}}
allows user to select either the \sphinxtitleref{SpectrumWifiPhy} or \sphinxtitleref{YansWifiPhy} for
saturation tests.  The wifiType can be toggled by the argument
\sphinxcode{\sphinxupquote{\textquotesingle{}\sphinxhyphen{}\sphinxhyphen{}wifiType=ns3::YansWifiPhy\textquotesingle{}}} or \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}wifiType=ns3::SpectrumWifiPhy\textquotesingle{}}}

There isn’t any difference in the output, which is to be expected because
this test is more of a test of the DCF than the physical layer.

By default, the program will use the \sphinxtitleref{SpectrumWifiPhy} and will run
for 10 seconds of saturating UDP data, with 802.11n features enabled.
It produces this output for the main 802.11n rates (with short and long guard
intervals):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
wifiType: ns3::SpectrumWifiPhy distance: 1m
index   MCS   width Rate \PYG{o}{(}Mb/s\PYG{o}{)} Tput \PYG{o}{(}Mb/s\PYG{o}{)} Received
    \PYG{l+m}{0}     \PYG{l+m}{0}      \PYG{l+m}{20}       \PYG{l+m}{6}.5     \PYG{l+m}{5}.81381    \PYG{l+m}{4937}
    \PYG{l+m}{1}     \PYG{l+m}{1}      \PYG{l+m}{20}        \PYG{l+m}{13}     \PYG{l+m}{11}.8266   \PYG{l+m}{10043}
    \PYG{l+m}{2}     \PYG{l+m}{2}      \PYG{l+m}{20}      \PYG{l+m}{19}.5     \PYG{l+m}{17}.7935   \PYG{l+m}{15110}
    \PYG{l+m}{3}     \PYG{l+m}{3}      \PYG{l+m}{20}        \PYG{l+m}{26}     \PYG{l+m}{23}.7958   \PYG{l+m}{20207}
    \PYG{l+m}{4}     \PYG{l+m}{4}      \PYG{l+m}{20}        \PYG{l+m}{39}     \PYG{l+m}{35}.7331   \PYG{l+m}{30344}
    \PYG{l+m}{5}     \PYG{l+m}{5}      \PYG{l+m}{20}        \PYG{l+m}{52}     \PYG{l+m}{47}.6174   \PYG{l+m}{40436}
    \PYG{l+m}{6}     \PYG{l+m}{6}      \PYG{l+m}{20}      \PYG{l+m}{58}.5     \PYG{l+m}{53}.6102   \PYG{l+m}{45525}
    \PYG{l+m}{7}     \PYG{l+m}{7}      \PYG{l+m}{20}        \PYG{l+m}{65}     \PYG{l+m}{59}.5501   \PYG{l+m}{50569}
  ...
   \PYG{l+m}{63}    \PYG{l+m}{15}      \PYG{l+m}{40}       \PYG{l+m}{300}     \PYG{l+m}{254}.902  \PYG{l+m}{216459}
\end{sphinxVerbatim}

The above output shows the first 8 (of 32) modes, and last mode, that will be
output from the program.  The first 8 modes correspond
to short guard interval disabled and channel bonding disabled.  The
subsequent 24 modes run by this program are variations with short guard
interval enabled (cases 9\sphinxhyphen{}16), and then with channel bonding enabled and
short guard first disabled then enabled (cases 17\sphinxhyphen{}32).  Cases 33\sphinxhyphen{}64 repeat
the same configurations but for two spatial streams (MIMO abstraction).

When run with the legacy YansWifiPhy, as in \sphinxcode{\sphinxupquote{./waf \sphinxhyphen{}\sphinxhyphen{}run "wifi\sphinxhyphen{}spectrum\sphinxhyphen{}saturation\sphinxhyphen{}example \sphinxhyphen{}\sphinxhyphen{}wifiType=ns3::YansWifiPhy"}}, the same output is observed:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
wifiType: ns3::YansWifiPhy distance: 1m
index   MCS   width Rate \PYG{o}{(}Mb/s\PYG{o}{)} Tput \PYG{o}{(}Mb/s\PYG{o}{)} Received
    \PYG{l+m}{0}     \PYG{l+m}{0}      \PYG{l+m}{20}       \PYG{l+m}{6}.5     \PYG{l+m}{5}.81381    \PYG{l+m}{4937}
    \PYG{l+m}{1}     \PYG{l+m}{1}      \PYG{l+m}{20}        \PYG{l+m}{13}     \PYG{l+m}{11}.8266   \PYG{l+m}{10043}
    \PYG{l+m}{2}     \PYG{l+m}{2}      \PYG{l+m}{20}      \PYG{l+m}{19}.5     \PYG{l+m}{17}.7935   \PYG{l+m}{15110}
    \PYG{l+m}{3}     \PYG{l+m}{3}      \PYG{l+m}{20}        \PYG{l+m}{26}     \PYG{l+m}{23}.7958   \PYG{l+m}{20207}
  ...
\end{sphinxVerbatim}

This is to be expected since YansWifiPhy and SpectrumWifiPhy use the
same error rate model in this case.


\subsubsection{Packet error rate performance}
\label{\detokenize{wifi-testing:packet-error-rate-performance}}
The program \sphinxcode{\sphinxupquote{examples/wireless/wifi\sphinxhyphen{}spectrum\sphinxhyphen{}per\sphinxhyphen{}example.cc}} allows users
to select either \sphinxtitleref{SpectrumWifiPhy} or \sphinxtitleref{YansWifiPhy}, as above, and select
the distance between the nodes, and to log the reception statistics and
received SNR (as observed by the WifiPhy::MonitorSnifferRx trace source), using a
Friis propagation loss model.  The transmit power is lowered from the default
of 40 mW (16 dBm) to 1 dBm to lower the baseline SNR; the distance between
the nodes can be changed to further change the SNR.  By default, it steps
through the same index values as in the saturation example (0 through 31)
for a 50m distance, for 10 seconds of simulation time, producing output such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
wifiType: ns3::SpectrumWifiPhy distance: 50m\PYG{p}{;} time: \PYG{l+m}{10}\PYG{p}{;} TxPower: \PYG{l+m}{1} dBm \PYG{o}{(}\PYG{l+m}{1}.3 mW\PYG{o}{)}
index   MCS  Rate \PYG{o}{(}Mb/s\PYG{o}{)} Tput \PYG{o}{(}Mb/s\PYG{o}{)} Received Signal \PYG{o}{(}dBm\PYG{o}{)} Noise \PYG{o}{(}dBm\PYG{o}{)} SNR \PYG{o}{(}dB\PYG{o}{)}
    \PYG{l+m}{0}     \PYG{l+m}{0}      \PYG{l+m}{6}.50        \PYG{l+m}{5}.77    \PYG{l+m}{7414}      \PYGZhy{}79.71      \PYGZhy{}93.97       \PYG{l+m}{14}.25
    \PYG{l+m}{1}     \PYG{l+m}{1}     \PYG{l+m}{13}.00       \PYG{l+m}{11}.58   \PYG{l+m}{14892}      \PYGZhy{}79.71      \PYGZhy{}93.97       \PYG{l+m}{14}.25
    \PYG{l+m}{2}     \PYG{l+m}{2}     \PYG{l+m}{19}.50       \PYG{l+m}{17}.39   \PYG{l+m}{22358}      \PYGZhy{}79.71      \PYGZhy{}93.97       \PYG{l+m}{14}.25
    \PYG{l+m}{3}     \PYG{l+m}{3}     \PYG{l+m}{26}.00       \PYG{l+m}{22}.96   \PYG{l+m}{29521}      \PYGZhy{}79.71      \PYGZhy{}93.97       \PYG{l+m}{14}.25
    \PYG{l+m}{4}     \PYG{l+m}{4}     \PYG{l+m}{39}.00        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
    \PYG{l+m}{5}     \PYG{l+m}{5}     \PYG{l+m}{52}.00        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
    \PYG{l+m}{6}     \PYG{l+m}{6}     \PYG{l+m}{58}.50        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
    \PYG{l+m}{7}     \PYG{l+m}{7}     \PYG{l+m}{65}.00        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
\end{sphinxVerbatim}

As in the above saturation example, running this program with YansWifiPhy
will yield identical output.


\subsubsection{Interference performance}
\label{\detokenize{wifi-testing:interference-performance}}
The program \sphinxcode{\sphinxupquote{examples/wireless/wifi\sphinxhyphen{}spectrum\sphinxhyphen{}per\sphinxhyphen{}interference.cc}} is based
on the previous packet error rate example, but copies over the
WaveformGenerator from the unlicensed LTE interferer test, to allow
users to inject a non\sphinxhyphen{}Wi\sphinxhyphen{}Fi signal (using the \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}waveformPower}} argument)
from the command line.  Another difference with respect to the packet
error rate example program is that the transmit power is set back to the
default of 40 mW (16 dBm).  By default, the interference generator is off,
and the program should behave similarly to the other packet error rate example,
but by adding small
amounts of power (e.g. \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}waveformPower=0.001}}), one will start to observe
SNR degradation and frame loss.

Some sample output with default arguments (no interference) is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}wifi\PYGZhy{}spectrum\PYGZhy{}per\PYGZhy{}interference\PYGZdq{}}

wifiType: ns3::SpectrumWifiPhy distance: 50m\PYG{p}{;} time: \PYG{l+m}{10}\PYG{p}{;} TxPower: \PYG{l+m}{16} dBm \PYG{o}{(}\PYG{l+m}{40} mW\PYG{o}{)}
index   MCS  Rate \PYG{o}{(}Mb/s\PYG{o}{)} Tput \PYG{o}{(}Mb/s\PYG{o}{)} Received Signal \PYG{o}{(}dBm\PYG{o}{)}Noi+Inf\PYG{o}{(}dBm\PYG{o}{)} SNR \PYG{o}{(}dB\PYG{o}{)}
    \PYG{l+m}{0}     \PYG{l+m}{0}      \PYG{l+m}{6}.50        \PYG{l+m}{5}.77    \PYG{l+m}{7414}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{1}     \PYG{l+m}{1}     \PYG{l+m}{13}.00       \PYG{l+m}{11}.58   \PYG{l+m}{14892}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{2}     \PYG{l+m}{2}     \PYG{l+m}{19}.50       \PYG{l+m}{17}.39   \PYG{l+m}{22358}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{3}     \PYG{l+m}{3}     \PYG{l+m}{26}.00       \PYG{l+m}{23}.23   \PYG{l+m}{29875}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{4}     \PYG{l+m}{4}     \PYG{l+m}{39}.00       \PYG{l+m}{34}.90   \PYG{l+m}{44877}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{5}     \PYG{l+m}{5}     \PYG{l+m}{52}.00       \PYG{l+m}{46}.51   \PYG{l+m}{59813}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{6}     \PYG{l+m}{6}     \PYG{l+m}{58}.50       \PYG{l+m}{52}.39   \PYG{l+m}{67374}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
    \PYG{l+m}{7}     \PYG{l+m}{7}     \PYG{l+m}{65}.00       \PYG{l+m}{58}.18   \PYG{l+m}{74819}      \PYGZhy{}64.69      \PYGZhy{}93.97       \PYG{l+m}{29}.27
  ...
\end{sphinxVerbatim}

while a small amount of waveform power will cause frame losses to occur at
higher order modulations, due to lower SNR:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./waf \PYGZhy{}\PYGZhy{}run \PYG{l+s+s2}{\PYGZdq{}wifi\PYGZhy{}spectrum\PYGZhy{}per\PYGZhy{}interference \PYGZhy{}\PYGZhy{}waveformPower=0.001\PYGZdq{}}

wifiType: ns3::SpectrumWifiPhy distance: 50m\PYG{p}{;} sent: \PYG{l+m}{1000} TxPower: \PYG{l+m}{16} dBm \PYG{o}{(}\PYG{l+m}{40} mW\PYG{o}{)}
index   MCS Rate \PYG{o}{(}Mb/s\PYG{o}{)} Tput \PYG{o}{(}Mb/s\PYG{o}{)} Received Signal \PYG{o}{(}dBm\PYG{o}{)}Noi+Inf\PYG{o}{(}dBm\PYG{o}{)}  SNR \PYG{o}{(}dB\PYG{o}{)}
    \PYG{l+m}{0}     \PYG{l+m}{0}      \PYG{l+m}{6}.50        \PYG{l+m}{5}.77    \PYG{l+m}{7414}      \PYGZhy{}64.69      \PYGZhy{}80.08       \PYG{l+m}{15}.38
    \PYG{l+m}{1}     \PYG{l+m}{1}     \PYG{l+m}{13}.00       \PYG{l+m}{11}.58   \PYG{l+m}{14892}      \PYGZhy{}64.69      \PYGZhy{}80.08       \PYG{l+m}{15}.38
    \PYG{l+m}{2}     \PYG{l+m}{2}     \PYG{l+m}{19}.50       \PYG{l+m}{17}.39   \PYG{l+m}{22358}      \PYGZhy{}64.69      \PYGZhy{}80.08       \PYG{l+m}{15}.38
    \PYG{l+m}{3}     \PYG{l+m}{3}     \PYG{l+m}{26}.00       \PYG{l+m}{23}.23   \PYG{l+m}{29873}      \PYGZhy{}64.69      \PYGZhy{}80.08       \PYG{l+m}{15}.38
    \PYG{l+m}{4}     \PYG{l+m}{4}     \PYG{l+m}{39}.00        \PYG{l+m}{0}.41     \PYG{l+m}{531}      \PYGZhy{}64.69      \PYGZhy{}80.08       \PYG{l+m}{15}.38
    \PYG{l+m}{5}     \PYG{l+m}{5}     \PYG{l+m}{52}.00        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
    \PYG{l+m}{6}     \PYG{l+m}{6}     \PYG{l+m}{58}.50        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
    \PYG{l+m}{7}     \PYG{l+m}{7}     \PYG{l+m}{65}.00        \PYG{l+m}{0}.00       \PYG{l+m}{0}         N/A         N/A         N/A
  ...
\end{sphinxVerbatim}

If ns3::YansWifiPhy is selected as the wifiType, the waveform generator will
not be enabled because only transmitters of type YansWifiPhy may be connected
to a YansWifiChannel.

The interference signal as received by the sending node is typically below
the default \sphinxhyphen{}62 dBm CCA Mode 1 threshold in this example.  If it raises
above, the sending node will suppress all transmissions.


\section{References}
\label{\detokenize{wifi-references:references}}\label{\detokenize{wifi-references::doc}}

\chapter{Wimax NetDevice}
\label{\detokenize{wimax:wimax-netdevice}}\label{\detokenize{wimax::doc}}
This chapter describes the \sphinxstyleemphasis{ns\sphinxhyphen{}3} WimaxNetDevice and related models. By
adding WimaxNetDevice objects to \sphinxstyleemphasis{ns\sphinxhyphen{}3} nodes, one can create models of
802.16\sphinxhyphen{}based networks. Below, we list some more details about what
the \sphinxstyleemphasis{ns\sphinxhyphen{}3} WiMAX models cover but, in summary, the most important features
of the \sphinxstyleemphasis{ns\sphinxhyphen{}3} model are:
\begin{itemize}
\item {} 
a scalable and realistic physical layer and channel model

\item {} 
a packet classifier for the IP convergence sublayer

\item {} 
efficient uplink and downlink schedulers

\item {} 
support for Multicast and Broadcast Service (MBS), and

\item {} 
packet tracing functionality

\end{itemize}

The source code for the WiMAX models lives in the directory
\sphinxcode{\sphinxupquote{src/wimax}}.

There have been two academic papers published on this model:
\begin{itemize}
\item {} 
M.A. Ismail, G. Piro, L.A. Grieco, and T. Turletti, “An Improved IEEE 802.16
WiMAX Module for the NS\sphinxhyphen{}3 Simulator”, SIMUTools 2010 Conference, March 2010.

\item {} 
J. Farooq and T. Turletti, “An IEEE 802.16 WiMAX module for the NS\sphinxhyphen{}3
Simulator,” SIMUTools 2009 Conference, March 2009.

\end{itemize}


\section{Scope of the model}
\label{\detokenize{wimax:scope-of-the-model}}
From a MAC perspective, there are two basic modes of operation, that of a
Subscriber Station (SS) or a Base Station (BS). These are implemented as two
subclasses of the base class \sphinxcode{\sphinxupquote{ns3::NetDevice}}, class
\sphinxcode{\sphinxupquote{SubscriberStationNetDevice}} and class
\sphinxcode{\sphinxupquote{BaseStationNetDevice}}. As is typical in \sphinxstyleemphasis{ns\sphinxhyphen{}3}, there is also a
physical layer class \sphinxcode{\sphinxupquote{WimaxPhy}} and a channel class
\sphinxcode{\sphinxupquote{WimaxChannel}} which serves to hold the references to all of the
attached Phy devices. The main physical layer class is the
\sphinxcode{\sphinxupquote{SimpleOfdmWimaxChannel}} class.

Another important aspect of WiMAX is the uplink and downlink scheduler, and
there are three primary scheduler types implemented:
\begin{itemize}
\item {} 
SIMPLE:  a simple priority based FCFS scheduler

\item {} 
RTPS:  a real\sphinxhyphen{}time polling service (rtPS) scheduler

\item {} 
MBQOS:  a migration\sphinxhyphen{}based uplink scheduler

\end{itemize}

The following additional aspects of the 802.16 specifications, as well as
physical layer and channel models, are modelled:
\begin{itemize}
\item {} 
leverages existing \sphinxstyleemphasis{ns\sphinxhyphen{}3} wireless propagation loss and delay models, as well
as \sphinxstyleemphasis{ns\sphinxhyphen{}3} mobility models

\item {} 
Point\sphinxhyphen{}to\sphinxhyphen{}Multipoint (PMP) mode and the WirelessMAN\sphinxhyphen{}OFDM PHY layer

\item {} 
Initial Ranging

\item {} 
Service Flow Initialization

\item {} 
Management Connection

\item {} 
Transport Initialization

\item {} 
UGS, rtPS, nrtPS, and BE connections

\end{itemize}

The following aspects are not presently modelled but would be good topics for
future extensions:
\begin{itemize}
\item {} 
OFDMA PHY layer

\item {} 
Link adaptation

\item {} 
Mesh topologies

\item {} 
ARQ

\item {} 
ertPS connection

\item {} 
packet header suppression

\end{itemize}


\section{Using the Wimax models}
\label{\detokenize{wimax:using-the-wimax-models}}
The main way that users who write simulation scripts will typically interact
with the Wimax models is through the helper API and through the publicly visible
attributes of the model.

The helper API is defined in \sphinxcode{\sphinxupquote{src/wimax/helper/wimax\sphinxhyphen{}helper.\{cc,h\}}}.

The example \sphinxcode{\sphinxupquote{src/wimax/examples/wimax\sphinxhyphen{}simple.cc}} contains some basic code that
shows how to set up the model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{switch} \PYG{p}{(}\PYG{n}{schedType}\PYG{p}{)}
  \PYG{p}{\PYGZob{}}
  \PYG{k}{case} \PYG{l+m+mi}{0}\PYG{o}{:}
    \PYG{n}{scheduler} \PYG{o}{=} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SCHED\PYGZus{}TYPE\PYGZus{}SIMPLE}\PYG{p}{;}
    \PYG{k}{break}\PYG{p}{;}
  \PYG{k}{case} \PYG{l+m+mi}{1}\PYG{o}{:}
    \PYG{n}{scheduler} \PYG{o}{=} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SCHED\PYGZus{}TYPE\PYGZus{}MBQOS}\PYG{p}{;}
    \PYG{k}{break}\PYG{p}{;}
  \PYG{k}{case} \PYG{l+m+mi}{2}\PYG{o}{:}
    \PYG{n}{scheduler} \PYG{o}{=} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SCHED\PYGZus{}TYPE\PYGZus{}RTPS}\PYG{p}{;}
    \PYG{k}{break}\PYG{p}{;}
  \PYG{k}{default}\PYG{o}{:}
    \PYG{n}{scheduler} \PYG{o}{=} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SCHED\PYGZus{}TYPE\PYGZus{}SIMPLE}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}

\PYG{n}{NodeContainer} \PYG{n}{ssNodes}\PYG{p}{;}
\PYG{n}{NodeContainer} \PYG{n}{bsNodes}\PYG{p}{;}

\PYG{n}{ssNodes}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{bsNodes}\PYG{p}{.}\PYG{n}{Create} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{WimaxHelper} \PYG{n}{wimax}\PYG{p}{;}

\PYG{n}{NetDeviceContainer} \PYG{n}{ssDevs}\PYG{p}{,} \PYG{n}{bsDevs}\PYG{p}{;}

\PYG{n}{ssDevs} \PYG{o}{=} \PYG{n}{wimax}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ssNodes}\PYG{p}{,}
                        \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DEVICE\PYGZus{}TYPE\PYGZus{}SUBSCRIBER\PYGZus{}STATION}\PYG{p}{,}
                        \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SIMPLE\PYGZus{}PHY\PYGZus{}TYPE\PYGZus{}OFDM}\PYG{p}{,}
                        \PYG{n}{scheduler}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{bsDevs} \PYG{o}{=} \PYG{n}{wimax}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{bsNodes}\PYG{p}{,} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DEVICE\PYGZus{}TYPE\PYGZus{}BASE\PYGZus{}STATION}\PYG{p}{,} \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SIMPLE\PYGZus{}PHY\PYGZus{}TYPE\PYGZus{}OFDM}\PYG{p}{,} \PYG{n}{scheduler}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This example shows that there are two subscriber stations and one base station
created. The helper method \sphinxcode{\sphinxupquote{Install}} allows the user to specify the scheduler
type, the physical layer type, and the device type.

Different variants of \sphinxcode{\sphinxupquote{Install}} are available; for instance, the example
\sphinxcode{\sphinxupquote{src/wimax/examples/wimax\sphinxhyphen{}multicast.cc}} shows how to specify a non\sphinxhyphen{}default channel
or propagation model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{channel} \PYG{o}{=} \PYG{n}{CreateObject}\PYG{o}{\PYGZlt{}}\PYG{n}{SimpleOfdmWimaxChannel}\PYG{o}{\PYGZgt{}} \PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{channel}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{SetPropagationModel} \PYG{p}{(}\PYG{n}{SimpleOfdmWimaxChannel}\PYG{o}{:}\PYG{o}{:}\PYG{n}{COST231\PYGZus{}PROPAGATION}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ssDevs} \PYG{o}{=} \PYG{n}{wimax}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{ssNodes}\PYG{p}{,}
                        \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DEVICE\PYGZus{}TYPE\PYGZus{}SUBSCRIBER\PYGZus{}STATION}\PYG{p}{,}
                        \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SIMPLE\PYGZus{}PHY\PYGZus{}TYPE\PYGZus{}OFDM}\PYG{p}{,}
                        \PYG{n}{channel}\PYG{p}{,}
                        \PYG{n}{scheduler}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Ptr}\PYG{o}{\PYGZlt{}}\PYG{n}{WimaxNetDevice}\PYG{o}{\PYGZgt{}} \PYG{n}{dev} \PYG{o}{=} \PYG{n}{wimax}\PYG{p}{.}\PYG{n}{Install} \PYG{p}{(}\PYG{n}{bsNodes}\PYG{p}{.}\PYG{n}{Get} \PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,}
                                         \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{DEVICE\PYGZus{}TYPE\PYGZus{}BASE\PYGZus{}STATION}\PYG{p}{,}
                                         \PYG{n}{WimaxHelper}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SIMPLE\PYGZus{}PHY\PYGZus{}TYPE\PYGZus{}OFDM}\PYG{p}{,}
                                         \PYG{n}{channel}\PYG{p}{,}
                                         \PYG{n}{scheduler}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Mobility is also supported in the same way as in Wifi models; see the
\sphinxcode{\sphinxupquote{src/wimax/examples/wimax\sphinxhyphen{}multicast.cc}}.

Another important concept in WiMAX is that of a service flow. This is a
unidirectional flow of packets with a set of QoS parameters such as traffic
priority, rate, scheduling type, etc. The base station is responsible for
issuing service flow identifiers and mapping them to WiMAX connections. The
following code from \sphinxcode{\sphinxupquote{src/wimax/examples/wimax\sphinxhyphen{}multicast.cc}} shows how this is
configured from a helper level:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ServiceFlow} \PYG{n}{MulticastServiceFlow} \PYG{o}{=} \PYG{n}{wimax}\PYG{p}{.}\PYG{n}{CreateServiceFlow} \PYG{p}{(}\PYG{n}{ServiceFlow}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SF\PYGZus{}DIRECTION\PYGZus{}DOWN}\PYG{p}{,}
                                                            \PYG{n}{ServiceFlow}\PYG{o}{:}\PYG{o}{:}\PYG{n}{SF\PYGZus{}TYPE\PYGZus{}UGS}\PYG{p}{,}
                                                            \PYG{n}{MulticastClassifier}\PYG{p}{)}\PYG{p}{;}

 \PYG{n}{bs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{GetServiceFlowManager} \PYG{p}{(}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{AddMulticastServiceFlow} \PYG{p}{(}\PYG{n}{MulticastServiceFlow}\PYG{p}{,} \PYG{n}{WimaxPhy}\PYG{o}{:}\PYG{o}{:}\PYG{n}{MODULATION\PYGZus{}TYPE\PYGZus{}QPSK\PYGZus{}12}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\section{Wimax Attributes}
\label{\detokenize{wimax:wimax-attributes}}
The WimaxNetDevice makes heavy use of the \sphinxstyleemphasis{ns\sphinxhyphen{}3} attributes subsystem for
configuration and default value management.  Presently, approximately 60 values
are stored in this system.

For instance, class \sphinxcode{\sphinxupquote{ns\sphinxhyphen{}3::SimpleOfdmWimaxPhy}} exports these
attributes:
\begin{itemize}
\item {} 
NoiseFigure:  Loss (dB) in the Signal\sphinxhyphen{}to\sphinxhyphen{}Noise\sphinxhyphen{}Ratio due to non\sphinxhyphen{}idealities in the receiver.

\item {} 
TxPower:  Transmission power (dB)

\item {} 
G:  The ratio of CP time to useful time

\item {} 
txGain:  Transmission gain (dB)

\item {} 
RxGain:  Reception gain (dB)

\item {} 
Nfft:  FFT size

\item {} 
TraceFilePath:  Path to the directory containing SNR to block error rate files

\end{itemize}

For a full list of attributes in these models, consult the Doxygen page that
lists all attributes for \sphinxstyleemphasis{ns\sphinxhyphen{}3}.


\section{Wimax Tracing}
\label{\detokenize{wimax:wimax-tracing}}
\sphinxstyleemphasis{ns\sphinxhyphen{}3} has a sophisticated tracing infrastructure that allows users to hook into
existing trace sources, or to define and export new ones.

Many \sphinxstyleemphasis{ns\sphinxhyphen{}3} users use the built\sphinxhyphen{}in Pcap or Ascii tracing, and the
WimaxHelper has similar APIs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{AsciiTraceHelper} \PYG{n}{ascii}\PYG{p}{;}
\PYG{n}{WimaxHelper} \PYG{n}{wimax}\PYG{p}{;}
\PYG{n}{wimax}\PYG{p}{.}\PYG{n}{EnablePcap} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{wimax\PYGZhy{}program}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{wimax}\PYG{p}{.}\PYG{n}{EnableAsciiAll} \PYG{p}{(}\PYG{n}{ascii}\PYG{p}{.}\PYG{n}{CreateFileStream} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{wimax\PYGZhy{}program.tr}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Unlike other helpers, there is also a special \sphinxcode{\sphinxupquote{EnableAsciiForConnection()}}
method that limits the ascii tracing to a specific device and connection.

These helpers access the low level trace sources that exist in the WiMAX
physical layer, net device, and queue models. Like other \sphinxstyleemphasis{ns\sphinxhyphen{}3} trace sources,
users may hook their own functions to these trace sources if they want to do
customized things based on the packet events. See the Doxygen List of trace
sources for a complete list of these sources.


\section{Wimax MAC model}
\label{\detokenize{wimax:wimax-mac-model}}
The 802.16 model provided in \sphinxstyleemphasis{ns\sphinxhyphen{}3} attempts to provide an accurate MAC and PHY
level implementation of the 802.16 specification with the Point\sphinxhyphen{}to\sphinxhyphen{}Multipoint
(PMP) mode and the WirelessMAN\sphinxhyphen{}OFDM PHY layer. The model is mainly composed of
three layers:
\begin{itemize}
\item {} 
The convergence sublayer (CS)

\item {} 
The MAC CP Common Part Sublayer (MAC\sphinxhyphen{}CPS)

\item {} 
Physical (PHY) layer

\end{itemize}

The following figure {\hyperref[\detokenize{wimax:wimax-architecture}]{\sphinxcrossref{\DUrole{std,std-ref}{WiMAX architecture}}}} shows the relationships of these
models.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{WimaxArchitecture}.pdf}
\caption{WiMAX architecture}\label{\detokenize{wimax:id1}}\label{\detokenize{wimax:wimax-architecture}}\end{figure}


\subsection{Convergence Sublayer}
\label{\detokenize{wimax:convergence-sublayer}}
The Convergence sublayer (CS) provided with this module implements the Packet
CS, designed to work with the packet\sphinxhyphen{}based protocols at higher layers. The CS is
responsible of receiving packet from the higher layer and from peer stations,
classifying packets to appropriate connections (or service flows) and processing
packets. It keeps a mapping of transport connections to service flows. This
enables the MAC CPS identifying the Quality of Service (QoS) parameters
associated to a transport connection and ensuring the QoS requirements. The CS
currently employs an IP classifier.


\subsection{IP Packet Classifier}
\label{\detokenize{wimax:ip-packet-classifier}}
An IP packet classifier is used to map incoming packets to appropriate
connections based on a set of criteria. The classifier maintains a list of
mapping rules which associate an IP flow (src IP address and mask, dst IP
address and mask, src port range, dst port range and protocol) to one of the
service flows.  By analyzing the IP and the TCP/UDP headers the classifier will
append the incoming packet (from the upper layer) to the queue of the
appropriate WiMAX connection. Class \sphinxcode{\sphinxupquote{IpcsClassifier}} and class
\sphinxcode{\sphinxupquote{IpcsClassifierRecord}} implement the classifier module for both SS
and BS


\subsection{MAC Common Part Sublayer}
\label{\detokenize{wimax:mac-common-part-sublayer}}
The MAC Common Part Sublayer (CPS) is the main sublayer of the IEEE 802.16 MAC
and performs the fundamental functions of the MAC. The module implements the
Point\sphinxhyphen{}Multi\sphinxhyphen{}Point (PMP) mode. In PMP mode BS is responsible of managing
communication among multiple SSs. The key functionalities of the MAC CPS include
framing and addressing, generation of MAC management messages, SS initialization
and registration, service flow management, bandwidth management and scheduling
services.  Class \sphinxcode{\sphinxupquote{WimaxNetDevice}} represents the MAC layer of a WiMAX
network device. This class extends the class \sphinxcode{\sphinxupquote{NetDevice}} of the \sphinxstyleemphasis{ns\sphinxhyphen{}3}
API that provides abstraction of a network device. Class
\sphinxcode{\sphinxupquote{WimaxNetDevice}} is further extended by class
\sphinxcode{\sphinxupquote{BaseStationNetDevice}} and class
\sphinxcode{\sphinxupquote{SubscriberStationNetDevice}}, defining MAC layers of BS and SS,
respectively.  Besides these main classes, the key functions of MAC are
distributed to several other classes.


\subsection{Framing and Management Messages}
\label{\detokenize{wimax:framing-and-management-messages}}
The module implements a frame as a fixed duration of time, i.e., frame
boundaries are defined with respect to time. Each frame is further subdivided
into downlink (DL) and uplink (UL) subframes. The module implements the Time
Division Duplex (TDD) mode where DL and UL operate on same frequency but are
separated in time. A number of DL and UL bursts are then allocated in DL and UL
subframes, respectively. Since the standard allows sending and receiving bursts
of packets in a given DL or UL burst, the unit of transmission at the MAC layer
is a packet burst. The module implements a special PacketBurst data structure
for this purpose. A packet burst is essentially a list of packets. The BS
downlink and uplink schedulers, implemented by class \sphinxcode{\sphinxupquote{BSScheduler}}
and class \sphinxcode{\sphinxupquote{UplinkScheduler}}, are responsible of generating DL and UL
subframes, respectively. In the case of DL, the subframe is simulated by
transmitting consecutive bursts (instances PacketBurst). In case of UL, the
subframe is divided, with respect to time, into a number of slots. The bursts
transmitted by the SSs in these slots are then aligned to slot boundaries. The
frame is divided into integer number of symbols and Physical Slots (PS) which
helps in managing bandwidth more effectively. The number of symbols per frame
depends on the  underlying implementation of the PHY layer. The size of a DL or
UL burst is specified in units of symbols.


\subsection{Network Entry and Initialization}
\label{\detokenize{wimax:network-entry-and-initialization}}
The network entry and initialization phase is basically divided into two
sub\sphinxhyphen{}phases, (1) scanning and synchronization and (2) initial ranging. The entire
phase is performed by the LinkManager component of SS and BS. Once an SS wants
to join the network, it first scans the downlink frequencies to search for a
suitable channel. The search is complete as soon as it detects a PHY frame. The
next step is to establish synchronization with the BS. Once SS receives a
Downlink\sphinxhyphen{}MAP (DL\sphinxhyphen{}MAP) message the synchronization phase is complete and it
remains synchronized as long as it keeps receiving DL\sphinxhyphen{}MAP and  Downlink Channel
Descriptor (DCD) messages. After the synchronization is established, SS waits
for a Uplink Channel Descriptor (UCD) message to acquire uplink channel
parameters. Once acquired, the first sub\sphinxhyphen{}phase of the network entry and
initialization is complete. Once synchronization is achieved, the SS waits for a
UL\sphinxhyphen{}MAP message to locate a special grant, called initial ranging interval, in
the UL subframe. This grant is allocated by the BS Uplink Scheduler at regular
intervals. Currently this interval is set to 0.5 ms, however the user is enabled
to modify its value from the simulation script.


\subsection{Connections and Addressing}
\label{\detokenize{wimax:connections-and-addressing}}
All communication at the MAC layer is carried in terms of connections. The
standard defines a connection as a unidirectional mapping between the SS and
BS’s MAC entities for the transmission of traffic. The standard defines two
types of connections: management connections for transmitting control messages
and transport connections for data transmission. A connection is identified by a
16\sphinxhyphen{}bit Connection Identifier (CID).  Class \sphinxcode{\sphinxupquote{WimaxConnection}} and
class \sphinxcode{\sphinxupquote{Cid}} implement the connection and CID, respectively. Note that
each connection maintains its own transmission queue where packets to transmit
on that connection are queued. The ConnectionManager component of BS is
responsible of creating and managing connections for all SSs.

The two key management connections defined by the standard, namely the Basic and
Primary management connections, are created and allocated to the SS during the
ranging process. Basic connection plays an important role throughout the
operation of SS also because all (unicast) DL and UL grants are directed towards
SS’s Basic CID. In addition to management connections, an SS may have one or
more transport connections to send data packets. The Connection Manager
component of SS manages the connections associated to SS. As defined by the
standard, a management connection is bidirectional, i.e., a pair of downlink and
uplink connections is represented by the same CID. This feature is implemented
in a way that one connection (in DL direction) is created by the BS and upon
receiving the CID the SS then creates an identical connection (in UL direction)
with the same CID.


\subsection{Scheduling Services}
\label{\detokenize{wimax:scheduling-services}}
The module supports the four scheduling services defined by the 802.16\sphinxhyphen{}2004
standard:
\begin{itemize}
\item {} 
Unsolicited Grant Service (UGS)

\item {} 
Real\sphinxhyphen{}Time Polling Services (rtPS)

\item {} 
Non Real\sphinxhyphen{}Time Polling Services (nrtPS)

\item {} 
Best Effort (BE)

\end{itemize}

These scheduling services behave differently with respect to how they request
bandwidth as well as how the it is granted. Each service flow is associated to
exactly one scheduling service, and the QoS parameter set associated to a
service flow actually defines the scheduling service it belongs to. When a
service flow is created the UplinkScheduler calculates necessary parameters such
as grant size and grant interval based on QoS parameters associated to it.


\subsection{WiMAX Uplink Scheduler Model}
\label{\detokenize{wimax:wimax-uplink-scheduler-model}}
Uplink Scheduler at the BS decides which of the SSs will be assigned uplink
allocations based on the QoS parameters associated to a service flow (or
scheduling service) and bandwidth requests from the SSs. Uplink scheduler
together with Bandwidth Manager implements the complete scheduling service
functionality. The standard defines up to four scheduling services (BE, UGS,
rtPS, nrtPS) for applications with different types of QoS requirements. The
service flows of these scheduling services behave differently with respect to
how they request for bandwidth as well as how the bandwidth is granted. The
module supports all four scheduling services. Each service flow is associated to
exactly one transport connection and one scheduling service. The QoS parameters
associated to a service flow actually define the scheduling service it belongs
to. Standard QoS parameters for UGS, rtPS, nrtPS and BE services, as specified
in Tables 111a to 111d of the 802.16e amendment, are supported. When a service
flow is created the uplink scheduler calculates necessary parameters such as
grant size and allocation interval based on QoS parameters associated to it.
The current WiMAX module provides three different versions of schedulers.
\begin{itemize}
\item {} 
The first one is a simple priority\sphinxhyphen{}based First Come First Serve (FCFS).  For
the real\sphinxhyphen{}time services (UGS and rtPS) the BS then allocates grants/polls on
regular basis based on the calculated interval. For the non real\sphinxhyphen{}time services
(nrtPS and BE) only minimum reserved bandwidth is guaranteed if available
after servicing real\sphinxhyphen{}time flows. Note that not all of these parameters are
utilized by the uplink scheduler. Also note that currently only service flow
with fixed\sphinxhyphen{}size packet size are supported, as currently set up in simulation
scenario with OnOff application of fixed packet size. This scheduler is
implemented by class \sphinxcode{\sphinxupquote{BSSchedulerSimple}} and class
\sphinxcode{\sphinxupquote{UplinkSchedulerSimple}}.

\item {} 
The second one is similar to first scheduler except by rtPS service flow. All
rtPS Connections are able to transmit all packet in the queue according to the
available bandwidth. The bandwidth saturation control has been implemented to
redistribute the effective available bandwidth to all rtPS that have at least
one packet to transmit. The remaining bandwidth is allocated to nrtPS and BE
Connections. This scheduler is implemented by class
\sphinxcode{\sphinxupquote{BSSchedulerRtps}} and class
\sphinxcode{\sphinxupquote{UplinkSchedulerRtps}}.

\item {} 
The third one is a Migration\sphinxhyphen{}based Quality of Service uplink scheduler This
uplink scheduler uses three queues, the low priority queue, the intermediate
queue and the high priority queue. The scheduler serves the requests in
strict priority order from the high priority queue to the low priority queue.
The low priority queue stores the bandwidth requests of the BE service flow.
The intermediate queue holds bandwidth requests sent by rtPS and by nrtPS
connections. rtPS and nrtPS requests can migrate to the high priority queue to
guarantee that their QoS requirements are met. Besides the requests migrated
from the intermediate queue, the high priority queue stores periodic grants
and unicast request opportunities that must be scheduled in the following
frame. To guarantee the maximum delay requirement, the BS assigns a deadline
to each rtPS bandwidth request in the intermediate queue. The minimum
bandwidth requirement of both rtPS and nrtPS connections is guaranteed over a
window of duration T. This scheduler is implemented by class
\sphinxcode{\sphinxupquote{UplinkSchedulerMBQoS}}.

\end{itemize}


\subsection{WiMAX Outbound Schedulers Model}
\label{\detokenize{wimax:wimax-outbound-schedulers-model}}
Besides the uplink scheduler these are the outbound schedulers at BS and SS side
(BSScheduler and SSScheduler). The outbound schedulers decide which of the
packets from the outbound queues will be transmitted in a given allocation. The
outbound scheduler at the BS schedules the downlink traffic, i.e., packets to be
transmitted to the SSs in the downlink subframe. Similarly the outbound
scheduler at a SS schedules the packet to be transmitted in the uplink
allocation assigned to that SS in the uplink subframe. All three schedulers have
been implemented to work as FCFS scheduler, as they allocate grants starting
from highest priority scheduling service to the lower priority one (UGS\textgreater{} rtPS\textgreater{}
nrtPS\textgreater{} BE). The standard does not suggest any scheduling algorithm and instead
leaves this decision up to the manufacturers. Of course more sophisticated
algorithms can be added later if required.


\section{WimaxChannel and WimaxPhy models}
\label{\detokenize{wimax:wimaxchannel-and-wimaxphy-models}}
The module implements the Wireless MAN OFDM PHY specifications as the more
relevant for implementation as it is the schema chosen by the WiMAX Forum. This
specification is designed for non\sphinxhyphen{}light\sphinxhyphen{}of\sphinxhyphen{}sight (NLOS) including fixed and
mobile broadband wireless access. The proposed model uses a 256 FFT processor,
with 192 data subcarriers. It supports all the seven modulation and coding
schemes specified by Wireless MAN\sphinxhyphen{}OFDM. It is composed of two parts: the channel
model and the physical model.


\section{Channel model}
\label{\detokenize{wimax:channel-model}}
The channel model we propose is implemented by the class
\sphinxcode{\sphinxupquote{SimpleOFDMWimaxChannel}} which extends the class
\sphinxcode{\sphinxupquote{wimaxchannel}}. The channel entity has a private structure named
m\_phyList which handles all the physical devices connected to it. When a
physical device sends a packet (FEC Block) to the channel, the channel handles
the packet, and then for each physical device connected to it, it calculates the
propagation delay, the path loss according to a given propagation model and
eventually forwards the packet to the receiver device.  The channel class uses
the method \sphinxtitleref{GetDistanceFrom()} to calculate the distance between two physical
entities according to their 3D coordinates. The delay is
computed as \sphinxtitleref{delay = distance/C}, where \sphinxtitleref{C} is the speed of the light.


\section{Physical model}
\label{\detokenize{wimax:physical-model}}
The physical layer performs two main operations: (i) It receives a burst from a
channel and forwards it to the MAC layer, (ii) it receives a burst from the MAC
layer and transmits it on the channel. In order to reduce the simulation
complexity of the WiMAX physical layer, we have chosen to model offline part of
the physical layer. More specifically we have developed an OFDM simulator to
generate trace files used by the reception process to evaluate if a FEC block
can be correctly decoded or not.

Transmission Process: A burst is a set of WiMAX MAC PDUs. At the sending
process, a burst is converted into bit\sphinxhyphen{}streams and then split into smaller
FEC blocks which are then sent to the channel with a power equal P\_tx.

Reception Process: The reception process includes the following operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Receive a FEC block from the channel.

\item {} 
Calculate the noise level.

\item {} 
Estimate the signal to noise ratio (SNR) with the following formula.

\item {} 
Determine if a FEC block can be correctly decoded.

\item {} 
Concatenate received FEC blocks to reconstruct the original burst.

\item {} 
Forward the burst to the upper layer.

\end{enumerate}

The developed process to evaluate if a FEC block can be correctly received or
not uses pre\sphinxhyphen{}generated traces.  The trace files are generated by an external
OFDM simulator (described later). A class named SNRToBlockErrorRateManager
handles a repository containing seven trace files (one for each modulation and
coding scheme). A repository is specific for a particular channel model.

A trace file is made of 6 columns. The first column provides the SNR value (1),
whereas the other columns give respectively the bit error rate BER (2), the
block error rate BlcER(3), the standard deviation on BlcER, and the confidence
interval (4 and 5).  These trace files are loaded into memory by the
SNRToBlockErrorRateManager entity at the beginning of the simulation.

Currently, The first process uses the first and third columns to determine if a
FEC block is correctly received. When the physical layer receives a packet with
an SNR equal to SNR\_rx, it asks the SNRToBlockErrorRateManager to return the
corresponding block error rate BlcER. A random number RAND between 0 and 1 is
then generated. If RAND is greater than BlcER, then the block is correctly
received, otherwise the block is considered erroneous and is ignored.

The module provides defaults SNR to block error rate traces in default\sphinxhyphen{}traces.h.
The traces have been generated by an External WiMAX OFDM simulator. The
simulator is based on an external mathematics and signal processing library IT++
and includes : a random block generator, a Reed Solomon (RS) coder, a
convolutional coder, an interleaver, a 256 FFT\sphinxhyphen{}based OFDM modulator, a
multi\sphinxhyphen{}path channel simulator and an equalizer. The multipath channel is
simulated using the TDL\_channel class of the IT++ library.

Users can configure the module to use their own traces generated by another OFDM
simulator or ideally by performing experiments in real environment. For this
purpose, a path to a repository containing trace files should be provided.  If
no repository is provided the traces form default\sphinxhyphen{}traces.h will be loaded. A
valid repository should contain 7 files, one for each modulation and coding
scheme.

The names of the files should respect the following format: modulation0.txt for
modulation 0, modulation1.txt for modulation 1 and so on…  The file format
should be as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
SNR\PYGZus{}value1   BER  Blc\PYGZus{}ER  STANDARD\PYGZus{}DEVIATION  CONFIDENCE\PYGZus{}INTERVAL1  CONFIDENCE\PYGZus{}INTERVAL2
SNR\PYGZus{}value2   BER  Blc\PYGZus{}ER  STANDARD\PYGZus{}DEVIATION  CONFIDENCE\PYGZus{}INTERVAL1  CONFIDENCE\PYGZus{}INTERVAL2
 ...          ...  ...     ...                 ...                   ...
 ...          ...  ...     ...                 ...                   ...
\end{sphinxVerbatim}

\begin{sphinxthebibliography}{magrin20}
\bibitem[Balanis]{antenna-design:balanis}
C.A. Balanis, “Antenna Theory \sphinxhyphen{} Analysis and Design”,  Wiley, 2nd Ed.
\bibitem[Chunjian]{antenna-design:chunjian}
Li Chunjian, “Efficient Antenna Patterns for
Three\sphinxhyphen{}Sector WCDMA Systems”, Master of Science Thesis, Chalmers
University of Technology, Göteborg, Sweden, 2003
\bibitem[Calcev]{antenna-design:calcev}
George Calcev and Matt Dillon, “Antenna Tilt Control in
CDMA Networks”, in Proc. of the 2nd Annual International Wireless
Internet Conference (WICON), 2006
\bibitem[R4\sphinxhyphen{}092042a]{antenna-design:r4-092042a}
3GPP TSG RAN WG4 (Radio) Meeting \#51, R4\sphinxhyphen{}092042, Simulation
assumptions and parameters for FDD HeNB RF requirements.
\bibitem[Mailloux]{antenna-design:mailloux}
Robert J. Mailloux, “Phased Array Antenna Handbook”, Artech House, 2nd Ed.
\bibitem[turkmani]{buildings-references:turkmani}
Turkmani A.M.D., J.D. Parson and D.G. Lewis, “Radio propagation into buildings at 441, 900 and 1400 MHz”,
in Proc. of 4th Int. Conference on Land Mobile Radio, 1987.
\bibitem[FlowMonitor]{flow-monitor:flowmonitor}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{6}
\item {} 
Carneiro, P. Fortuna, and M. Ricardo. 2009. FlowMonitor: a network monitoring framework for the network simulator 3 (NS\sphinxhyphen{}3). In Proceedings of the Fourth International ICST Conference on Performance Evaluation Methodologies and Tools (VALUETOOLS ‘09). \sphinxurl{http://dx.doi.org/10.4108/ICST.VALUETOOLS2009.7493} (Full text: \sphinxurl{https://dl.acm.org/doi/abs/10.4108/ICST.VALUETOOLS2009.7493})

\end{enumerate}
\bibitem[magrin2017performance]{lorawan:magrin2017performance}
D. Magrin, M. Centenaro and L. Vangelista,
\sphinxstyleemphasis{Performance Evaluation of LoRa Networks in a Smart
City Scenario}, in Proc. of the IEEE International
Conference on Communications, May 2017.
\bibitem[magrin2017thesis]{lorawan:magrin2017thesis}
D. Magrin, \sphinxstyleemphasis{Network level performances of a LoRa system},
December 2016. Available:
\sphinxurl{http://tesi.cab.unipd.it/53740/}
\bibitem[sx1301]{lorawan:sx1301}
Semtech, SX1301 Datasheet.
\bibitem[goursaud2015dedicated]{lorawan:goursaud2015dedicated}
C. Goursaud, J. M. Gorce, \sphinxstyleemphasis{Dedicated networks for
IoT: PHY/MAC state of the art and challenges}, EAI
endorsed transactions on Internet of Things, 2015.
\bibitem[semtech2015modulation]{lorawan:semtech2015modulation}
Semtech Corporation, \sphinxstyleemphasis{AN1200.22 LoRa Modulation
Basics}, May 2015, Online. Available:
\sphinxurl{http://www.semtech.com/images/datasheet/an1200.22.pdf}
\bibitem[knight2016reversing]{lorawan:knight2016reversing}
M. Knight, \sphinxstyleemphasis{Reversing LoRa}, Online. Available:
\sphinxurl{https://github.com/matt-knight/research}
\bibitem[lorawanstandard]{lorawan:lorawanstandard}
N. Sornin, M. Luis, T. Eirich, T. Kramp, and O. Hersent,
\sphinxstyleemphasis{LoRaWAN Specifications}, LoRa Alliance, Tech. Rep., 2015.
\bibitem[TS25814]{lte-references:ts25814}
3GPP TS 25.814 “Physical layer aspect for evolved Universal Terrestrial Radio Access”
\bibitem[TS29274]{lte-references:ts29274}
3GPP TS 29.274 “GPRS Tunnelling Protocol for Control plane (GTPv2\sphinxhyphen{}C)”
\bibitem[TS36101]{lte-references:ts36101}
3GPP TS 36.101 “E\sphinxhyphen{}UTRA User Equipment (UE) radio transmission and reception”
\bibitem[TS36104]{lte-references:ts36104}
3GPP TS 36.104 “E\sphinxhyphen{}UTRA Base Station (BS) radio transmission and reception”
\bibitem[TS36133]{lte-references:ts36133}
3GPP TS 36.133 “E\sphinxhyphen{}UTRA Requirements for support of radio resource management”
\bibitem[TS36211]{lte-references:ts36211}
3GPP TS 36.211 “E\sphinxhyphen{}UTRA Physical Channels and Modulation”
\bibitem[TS36212]{lte-references:ts36212}
3GPP TS 36.212 “E\sphinxhyphen{}UTRA Multiplexing and channel coding”
\bibitem[TS36213]{lte-references:ts36213}
3GPP TS 36.213 “E\sphinxhyphen{}UTRA Physical layer procedures”
\bibitem[TS36214]{lte-references:ts36214}
3GPP TS 36.214 “E\sphinxhyphen{}UTRA Physical layer \textendash{} Measurements”
\bibitem[TS36300]{lte-references:ts36300}
3GPP TS 36.300 “E\sphinxhyphen{}UTRA and E\sphinxhyphen{}UTRAN; Overall description; Stage 2”
\bibitem[TS36304]{lte-references:ts36304}
3GPP TS 36.304 “E\sphinxhyphen{}UTRA User Equipment (UE) procedures in idle mode”
\bibitem[TS36321]{lte-references:ts36321}
3GPP TS 36.321 “E\sphinxhyphen{}UTRA Medium Access Control (MAC) protocol specification”
\bibitem[TS36322]{lte-references:ts36322}
3GPP TS 36.322 “E\sphinxhyphen{}UTRA Radio Link Control (RLC) protocol specification”
\bibitem[TS36323]{lte-references:ts36323}
3GPP TS 36.323 “E\sphinxhyphen{}UTRA Packet Data Convergence Protocol (PDCP) specification”
\bibitem[TS36331]{lte-references:ts36331}
3GPP TS 36.331 “E\sphinxhyphen{}UTRA Radio Resource Control (RRC) protocol specification”
\bibitem[TS36413]{lte-references:ts36413}
3GPP TS 36.413 “E\sphinxhyphen{}UTRAN S1 application protocol (S1AP)”
\bibitem[TS36420]{lte-references:ts36420}
3GPP TS 36.420 “E\sphinxhyphen{}UTRAN X2 general aspects and principles”
\bibitem[TS36423]{lte-references:ts36423}
3GPP TS 36.423 “E\sphinxhyphen{}UTRAN X2 application protocol (X2AP)”
\bibitem[TR36814]{lte-references:tr36814}
3GPP TR 36.814 “E\sphinxhyphen{}UTRA Further advancements for E\sphinxhyphen{}UTRA physical layer aspects”
\bibitem[R1\sphinxhyphen{}081483]{lte-references:r1-081483}
3GPP R1\sphinxhyphen{}081483 \sphinxhref{http://www.3gpp.org/ftp/tsg\_ran/WG1\_RL1/TSGR1\_52b/Docs/R1-081483.zip}{“Conveying MCS and TB size via PDCCH”}
\bibitem[R4\sphinxhyphen{}092042]{lte-references:r4-092042}
3GPP R4\sphinxhyphen{}092042 \sphinxhref{http://www.3gpp.org/ftp/tsg\_ran/wg4\_radio/TSGR4\_51/Documents/R4-092042.zip}{“Simulation assumptions and parameters for FDD HeNB RF requirements”}
\bibitem[FFAPI]{lte-references:ffapi}
FemtoForum \sphinxhref{http://www.smallcellforum.org/smallcellforum\_resources/pdfsend05.php?file=LTE\%20MAC\%20Scheduler\%20Interface\%20Specification.pdf}{“LTE MAC Scheduler Interface Specification v1.11”}
\bibitem[ns3tutorial]{lte-references:ns3tutorial}
\sphinxhref{http://www.nsnam.org/docs/tutorial/singlehtml/index.html}{“The ns\sphinxhyphen{}3 Tutorial”}
\bibitem[ns3manual]{lte-references:ns3manual}
\sphinxhref{http://www.nsnam.org/docs/manual/singlehtml/index.html}{“The ns\sphinxhyphen{}3 Manual”}
\bibitem[Sesia2009]{lte-references:sesia2009}
S. Sesia, I. Toufik and M. Baker,
“LTE \sphinxhyphen{} The UMTS Long Term Evolution \sphinxhyphen{} from theory to practice”,
Wiley, 2009
\bibitem[Baldo2009]{lte-references:baldo2009}
N. Baldo and M. Miozzo, “Spectrum\sphinxhyphen{}aware Channel and PHY layer modeling for ns3”,
Proceedings of ICST NSTools 2009, Pisa, Italy
\bibitem[Piro2010]{lte-references:piro2010}
Giuseppe Piro, Luigi Alfredo Grieco, Gennaro Boggia, and Pietro Camarda,
“A Two\sphinxhyphen{}level Scheduling Algorithm for QoS Support in the Downlink of LTE Cellular Networks”,
Proc. of European Wireless, EW2010, Lucca, Italy, Apr., 2010
\bibitem[Holtzman2000]{lte-references:holtzman2000}
J.M. Holtzman, “CDMA forward link waterfilling power control”,
in Proc. of IEEE VTC Spring, 2000.
\bibitem[Piro2011]{lte-references:piro2011}
G. Piro, N. Baldo. M. Miozzo, “An LTE module for the ns\sphinxhyphen{}3 network simulator”,
in Proc. of Wns3 2011 (in conjunction with SimuTOOLS 2011), March 2011, Barcelona (Spain)
\bibitem[Seo2004]{lte-references:seo2004}
H. Seo, B. G. Lee. “A proportional\sphinxhyphen{}fair power allocation scheme for fair and efficient multiuser OFDM systems”,
in Proc. of IEEE GLOBECOM, December 2004. Dallas (USA)
\bibitem[Ofcom2600MHz]{lte-references:ofcom2600mhz}
Ofcom, “Consultation on assessment of future mobile
competition and proposals for the award of 800 MHz and 2.6 GHz
spectrum and related issues”, March 2011
\bibitem[RealWireless]{lte-references:realwireless}
RealWireless, “Low\sphinxhyphen{}power shared access to spectrum
for mobile broadband”,  Final Report, Ofcom Project MC/073, 18th
March 2011
\bibitem[PaduaPEM]{lte-references:paduapem}
\sphinxhref{http://mailman.isi.edu/pipermail/ns-developers/2011-November/009559.html}{“Ns\sphinxhyphen{}developers \sphinxhyphen{} LTE error model contribution”}
\bibitem[ViennaLteSim]{lte-references:viennaltesim}
\sphinxhref{http://www.nt.tuwien.ac.at/about-us/staff/josep-colom-ikuno/lte-simulators/}{“The Vienna LTE Simulators”}
\bibitem[LozanoCost]{lte-references:lozanocost}
Joan Olmos, Silvia Ruiz, Mario García\sphinxhyphen{}Lozano and David Martín\sphinxhyphen{}Sacristán,
“Link Abstraction Models Based on Mutual Information for LTE Downlink”,
COST 2100 TD(10)11052 Report
\bibitem[wimaxEmd]{lte-references:wimaxemd}
WiMAX Forum White Paper, “WiMAX System Evaluation Methodology”, July 2008.
\bibitem[mathworks]{lte-references:mathworks}
Matlab R2011b Documentation Communications System Toolbox,
\sphinxhref{http://www.mathworks.es/help/toolbox/comm/ug/a1069449399.html\#bq5zk36}{“Methodology for Simulating Multipath Fading Channels”}
\bibitem[CatreuxMIMO]{lte-references:catreuxmimo}
S. Catreux, L.J. Greenstein, V. Erceg,
“Some results and insights on the performance gains of MIMO systems,”
Selected Areas in Communications, IEEE Journal on , vol.21, no.5, pp. 839\sphinxhyphen{} 847, June 2003
\bibitem[Ikuno2010]{lte-references:ikuno2010}
J.C. Ikuno, M. Wrulich, M. Rupp, “System Level Simulation of LTE Networks,”
Vehicular Technology Conference (VTC 2010\sphinxhyphen{}Spring), 2010 IEEE 71st , vol., no., pp.1\sphinxhyphen{}5, 16\sphinxhyphen{}19 May 2010
\bibitem[Milos2012]{lte-references:milos2012}
J. Milos, “Performance Analysis Of PCFICH LTE Control Channel”,
Proceedings of the 19th Conference STUDENT EEICT 2012, Brno, CZ, 2012.
\bibitem[FujitsuWhitePaper]{lte-references:fujitsuwhitepaper}
“Enhancing LTE Cell\sphinxhyphen{}Edge Performance via PDCCH ICIC”.
\bibitem[Bharucha2011]{lte-references:bharucha2011}
Z. Bharucha, G. Auer, T. Abe, N. Miki,
“Femto\sphinxhyphen{}to\sphinxhyphen{}Macro Control Channel Interference Mitigation via Cell ID Manipulation in LTE,”
Vehicular Technology Conference (VTC Fall), 2011 IEEE , vol., no., pp.1\sphinxhyphen{}6, 5\sphinxhyphen{}8 Sept. 2011
\bibitem[R4\sphinxhyphen{}081920]{lte-references:r4-081920}
3GPP R4\sphinxhyphen{}081920 \sphinxhref{http://www.3gpp.org/ftp/tsg\_ran/wg4\_radio/TSGR4\_48/Documents/R4-081920.zip}{“LTE PDCCH/PCFICH Demodulation Performance Results with Implementation Margin”}
\bibitem[FCapo2012]{lte-references:fcapo2012}
F.Capozzi, G.Piro, L.A. Grieco, G.Boggia, P.Camarda,
“Downlink Packet Scheduling in LTE Cellular Networks: Key Design Issues and a Survey”,
IEEE Comm. Surveys and Tutorials, vol.2012, no.99, pp.1\sphinxhyphen{}23, Jun. 2012
\bibitem[FABokhari2009]{lte-references:fabokhari2009}
F.A. Bokhari, H. Yanikomeroglu, W.K. Wong, M. Rahman,
“Cross\sphinxhyphen{}Layer Resource Scheduling for Video Traffic in the Downlink of OFDMA\sphinxhyphen{}Based Wireless 4G Networks”,
EURASIP J. Wirel. Commun. Netw., vol.2009, no.3, pp. 1\sphinxhyphen{}10, Jan. 2009.
\bibitem[WKWong2004]{lte-references:wkwong2004}
W.K. Wong, H.Y. Tang, V.C.M, Leung,
“Token bank fair queuing: a new scheduling algorithm for wireless multimedia services”,
Int. J. Commun. Syst., vol.17, no.6, pp.591\sphinxhyphen{}614, Aug.2004.
\bibitem[GMonghal2008]{lte-references:gmonghal2008}
G. Mongha, K.I. Pedersen, I.Z. Kovacs, P.E. Mogensen,
“QoS Oriented Time and Frequency Domain Packet Schedulers for The UTRAN Long Term Evolution”,
In Proc. IEEE VTC, 2008.
\bibitem[Dimou2009]{lte-references:dimou2009}
K. Dimou, M. Wang, Y. Yang, M. Kazmi, A. Larmo, J. Pettersson, W. Muller, Y. Timner,
“Handover within 3GPP LTE: Design Principles and Performance”,
Vehicular Technology Conference Fall (VTC 2009\sphinxhyphen{}Fall), 2009 IEEE 70th, pp.1\sphinxhyphen{}5, 20\sphinxhyphen{}23 Sept. 2009
\bibitem[Lee2010]{lte-references:lee2010}
Y.J. Lee, B.J. Shin, J.C. Lim, D.H. Hong,
“Effects of time\sphinxhyphen{}to\sphinxhyphen{}trigger parameter on handover performance in SON\sphinxhyphen{}based LTE systems”,
Communications (APCC), 2010 16th Asia\sphinxhyphen{}Pacific Conference on, pp.492\sphinxhyphen{}496, Oct. 31 2010\textendash{}Nov. 3 2010
\bibitem[Bbojovic2014]{lte-references:bbojovic2014}
B. Bojovic, N. Baldo, \sphinxhref{http://www.cttc.es/publication/a-new-channel-and-qos-aware-scheduler-to-enhance-the-capacity-of-voice-over-lte-systems/}{“A new Channel and QoS Aware
Scheduler to enhance the capacity of Voice over LTE systems”},
in Proceedings of 11th International Multi\sphinxhyphen{}Conference on Systems,
Signals \& Devices (SSD’14), Castelldefels, 11\sphinxhyphen{}14 February 2014,
Castelldefels (Spain).
\bibitem[Baldo2014]{lte-references:baldo2014}
N. Baldo, R. Martínez, P. Dini, R. Vilalta, M. Miozzo,
R. Casellas, R. Muñoz, \sphinxhref{http://www.cttc.es/publication/a-testbed-for-fixed-mobile-convergence-experimentation-adrenaline-lena-integration/}{“A Testbed for Fixed Mobile Convergence
Experimentation: ADRENALINE\sphinxhyphen{}LENA Integration”},
in Proceedings of European Wireless 2014, 14\sphinxhyphen{}16 May 2014, Barcelona
(Spain).
\bibitem[ASHamza2013]{lte-references:ashamza2013}
Abdelbaset S. Hamza, Shady S. Khalifa, Haitham S. Hamza, and Khaled Elsayed, “A Survey on Inter\sphinxhyphen{}Cell Interference Coordination Techniques in OFDMA\sphinxhyphen{}based Cellular Networks”, IEEE Communications Surveys \& Tutorials, March 19, 2013
\bibitem[ZXie2009]{lte-references:zxie2009}
Zheng Xie, Bernhard Walke, “Enhanced Fractional Frequency Reuse to Increase Capacity of OFDMA Systems”, Proceedings of the 3rd international conference on New technologies, mobility and security, NTMS 2009
\bibitem[DKimura2012]{lte-references:dkimura2012}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
Kimura, H. Seki, “Inter\sphinxhyphen{}Cell Interference Coordination (ICIC) Technology”, FUJITSU Sci. Tech. J., Vol. 48, No. 1 (January 2012)

\end{enumerate}
\bibitem[And09]{mesh-references:and09}
K. Andreev, \sphinxhref{http://www.nsnam.org/wiki/Wns3-2009}{Realization of IEEE802.11s draft standard in NS\sphinxhyphen{}3}.
\bibitem[And10]{mesh-references:and10}
K. Andreev and P. Boyko, \sphinxhref{http://www.nsnam.org/workshops/wns3-2010/dot11s.pdf}{IEEE 802.11s Mesh Networking NS\sphinxhyphen{}3 Model}.
\bibitem[Hep15]{mesh-references:hep15}
C. Hepner and A. Witt and R. Muenzner, \sphinxhref{https://www.nsnam.org/wp-content/uploads/2015/05/WNS3\_2015\_submission\_33.pdf}{Validation of the ns\sphinxhyphen{}3 802.11s model and proposed changes compliant to IEEE 802.11\sphinxhyphen{}2012}, Poster at 2015 Workshop on ns\sphinxhyphen{}3, May 2015.
\bibitem[Hep16]{mesh-references:hep16}
C. Hepner and S. Moll and R. Muenzner, \sphinxhref{http://dl.acm.org/citation.cfm?id=3021439}{Influence of Processing Delays on the VoIP Performance for IEEE 802.11s Multihop Wireless Mesh Networks:  Comparison of ns\sphinxhyphen{}3 Network Simulations with Hardware Measurements}, Proceedings of SIMUTOOLS 16, August, 2016.
\bibitem[ieee80211s]{mesh-references:ieee80211s}
IEEE Standard for Information Technology, Telecommunications and information exchange between systems, Local and metropolitan area networks, Specific requirements,  Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) specifications, Amendment 10: Mesh Networking, 10 September 2011.
\bibitem[rfc3626]{olsr:rfc3626}
\index{RFC@\spxentry{RFC}!RFC 3626@\spxentry{RFC 3626}}\sphinxhref{https://tools.ietf.org/html/rfc3626.html}{\sphinxstylestrong{RFC 3626}} \sphinxstyleemphasis{Optimized Link State Routing}
\bibitem[rfc7181]{olsr:rfc7181}
\index{RFC@\spxentry{RFC}!RFC 7181@\spxentry{RFC 7181}}\sphinxhref{https://tools.ietf.org/html/rfc7181.html}{\sphinxstylestrong{RFC 7181}} \sphinxstyleemphasis{The Optimized Link State Routing Protocol Version 2}
\bibitem[friis]{propagation:friis}
Friis, H.T., “A Note on a Simple Transmission Formula,” Proceedings of the IRE , vol.34, no.5, pp.254,256, May 1946
\bibitem[hata]{propagation:hata}
M.Hata, “Empirical formula for propagation loss in land mobile radio
services”, IEEE Trans. on Vehicular Technology, vol. 29, pp. 317\sphinxhyphen{}325, 1980
\bibitem[cost231]{propagation:cost231}
“Digital Mobile Radio: COST 231 View on the Evolution Towards 3rd Generation Systems”, Commission of the European Communities, L\sphinxhyphen{}2920, Luxembourg, 1989
\bibitem[walfisch]{propagation:walfisch}
J.Walfisch and H.L. Bertoni, “A Theoretical model of UHF propagation in urban environments,” in IEEE Trans. Antennas Propagat., vol.36, 1988, pp.1788\sphinxhyphen{} 1796
\bibitem[ikegami]{propagation:ikegami}
F.Ikegami, T.Takeuchi, and S.Yoshida, “Theoretical prediction of mean field strength for Urban Mobile Radio”, in IEEE Trans. Antennas Propagat., Vol.39, No.3, 1991
\bibitem[kun2600mhz]{propagation:kun2600mhz}
Sun Kun, Wang Ping, Li Yingze, “Path loss models for suburban scenario at 2.3GHz, 2.6GHz and 3.5GHz”,
in Proc. of the 8th International Symposium on Antennas, Propagation and EM Theory (ISAPE),  Kunming,  China, Nov 2008.
\bibitem[Baldo2009Spectrum]{spectrum:baldo2009spectrum}
N. Baldo and M. Miozzo, “Spectrum\sphinxhyphen{}aware Channel and PHY layer modeling for ns3”,
Proceedings of ICST NSTools 2009, Pisa, Italy
\bibitem[Baron8VSB]{spectrum:baron8vsb}
Baron, Stanley. “First\sphinxhyphen{}Hand:Digital Television: The Digital
Terrestrial Television Broadcasting (DTTB) Standard.” IEEE Global History
Network. \textless{}http://www.ieeeghn.org/wiki/index.php/First\sphinxhyphen{}Hand:Digital\_Television:\_The\_Digital\_Terrestrial\_Television\_Broadcasting\_(DTTB)\_Standard\textgreater{}.
\bibitem[KoppCOFDM]{spectrum:koppcofdm}
Kopp, Carlo. “High Definition Television.” High Definition
Television. Air Power Australia. \textless{}\sphinxurl{http://www.ausairpower.net/AC-1100.html}\textgreater{}.
\bibitem[MatlabGeo]{spectrum:matlabgeo}
“Geodetic2ecef.” Convert Geodetic to Geocentric (ECEF)
Coordinates. The MathWorks, Inc.
\textless{}\sphinxurl{http://www.mathworks.com/help/map/ref/geodetic2ecef.html}\textgreater{}.
\bibitem[QualcommAnalog]{spectrum:qualcommanalog}
Stephen Shellhammer, Ahmed Sadek, and Wenyi Zhang.
“Technical Challenges for Cognitive Radio in the TV White Space Spectrum.”
Qualcomm Incorporated.
\bibitem[TR38901]{spectrum:tr38901}
3GPP. 2018. TR 38.901. Study on channel for frequencies from 0.5 to
100 GHz. V.15.0.0. (2018\sphinxhyphen{}06).
\bibitem[Zhang]{spectrum:zhang}
Menglei Zhang, Michele Polese, Marco Mezzavilla, Sundeep Rangan,
Michele Zorzi. “ns\sphinxhyphen{}3 Implementation of the 3GPP MIMO Channel Model for
Frequency Spectrum above 6 GHz”. In Proceedings of the Workshop on ns\sphinxhyphen{}3
(WNS3 ‘17). 2017.
\bibitem[Zugno]{spectrum:zugno}
Tommaso Zugno, Michele Polese, Natale Patriciello, Biljana Bojovic,
Sandra Lagen, Michele Zorzi. “Implementation of a Spatial Channel Model for
ns\sphinxhyphen{}3”. Submitted to the Workshop on ns\sphinxhyphen{}3 (WNS3 ‘20). 2020.
Available: \sphinxurl{https://arxiv.org/abs/2002.09341}
\bibitem[RFC4944]{sixlowpan:rfc4944}
\index{RFC@\spxentry{RFC}!RFC 4944@\spxentry{RFC 4944}}\sphinxhref{https://tools.ietf.org/html/rfc4944.html}{\sphinxstylestrong{RFC 4944}}, “Transmission of IPv6 Packets over IEEE 802.15.4 Networks”
\bibitem[RFC6282]{sixlowpan:rfc6282}
\index{RFC@\spxentry{RFC}!RFC 6282@\spxentry{RFC 6282}}\sphinxhref{https://tools.ietf.org/html/rfc6282.html}{\sphinxstylestrong{RFC 6282}}, “Compression Format for IPv6 Datagrams over IEEE 802.15.4\sphinxhyphen{}Based Networks”
\bibitem[RFC6775]{sixlowpan:rfc6775}
\index{RFC@\spxentry{RFC}!RFC 6775@\spxentry{RFC 6775}}\sphinxhref{https://tools.ietf.org/html/rfc6775.html}{\sphinxstylestrong{RFC 6775}}, “Neighbor Discovery Optimization for IPv6 over Low\sphinxhyphen{}Power Wireless Personal Area Networks (6LoWPANs)”
\bibitem[IANA802]{sixlowpan:iana802}
IANA, assigned IEEE 802 numbers: \sphinxurl{http://www.iana.org/assignments/ieee-802-numbers/ieee-802-numbers.xml}
\bibitem[Ethertype]{sixlowpan:ethertype}
IEEE Ethertype numbers: \sphinxurl{http://standards.ieee.org/develop/regauth/ethertype/eth.txt}
\bibitem[Shelby]{sixlowpan:shelby}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{25}
\item {} 
Shelby and C. Bormann, 6LoWPAN: The Wireless Embedded Internet. Wiley, 2011. {[}Online{]}. Available: \sphinxurl{https://books.google.it/books?id=3Nm7ZCxscMQC}

\end{enumerate}
\bibitem[Ref1]{tbf:ref1}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\item {} 
Kuznetsov and D. Torokhov; Linux Cross Reference Source Code; Available online at \sphinxurl{http://lxr.free-electrons.com/source/net/sched/sch\_tbf.c}.

\end{enumerate}
\bibitem[Ref2]{tbf:ref2}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{9}
\item {} 
Vehent; Journey to the Center of the Linux Kernel: Traffic Control, Shaping and QoS; Available online at \sphinxurl{http://wiki.linuxwall.info/doku.php/en:resources:dossiers:networking:traffic\_control\#tbf\_-\_token\_bucket\_filter}.

\end{enumerate}
\bibitem[Ref3]{tbf:ref3}
Practical IP Network QoS: TBF queuing discipline; Available online at \sphinxurl{http://web.opalsoft.net/qos/default.php?p=ds-24}.
\bibitem[Nic12]{codel:nic12}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{10}
\item {} 
Nichols and V. Jacobson, Controlling Queue Delay, ACM Queue, Vol. 10 No. 5, May 2012.  Available online at \sphinxurl{http://queue.acm.org/detail.cfm?id=2209336}.

\end{enumerate}
\bibitem[Nic14]{codel:nic14}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{10}
\item {} 
Nichols and V. Jacobson, Internet\sphinxhyphen{}Draft:  Controlled Delay Active Queue Management, March 2014.  Available online at \sphinxurl{http://tools.ietf.org/html/draft-nichols-tsvwg-codel-02}.

\end{enumerate}
\bibitem[Buf14]{codel:buf14}
Bufferbloat.net.  Available online at \sphinxurl{http://www.bufferbloat.net/}.
\bibitem[Hoe16]{fq-codel:hoe16}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{19}
\item {} 
Hoeiland\sphinxhyphen{}Joergensen, P. McKenney, D. Taht, J. Gettys and E. Dumazet, The FlowQueue\sphinxhyphen{}CoDel Packet Scheduler and Active Queue Management Algorithm, IETF draft.  Available online at \sphinxurl{https://tools.ietf.org/html/draft-ietf-aqm-fq-codel}

\end{enumerate}
\bibitem[Buf16]{fq-codel:buf16}
Bufferbloat.net.  Available online at \sphinxurl{http://www.bufferbloat.net/}.
\bibitem[Pan13]{pie:pan13}
Pan, R., Natarajan, P., Piglione, C., Prabhu, M. S., Subramanian, V., Baker, F., \& VerSteeg, B. (2013, July). PIE: A lightweight control scheme to address the bufferbloat problem. In High Performance Switching and Routing (HPSR), 2013 IEEE 14th International Conference on (pp. 148\sphinxhyphen{}155). IEEE.  Available online at \sphinxurl{https://www.ietf.org/mail-archive/web/iccrg/current/pdfB57AZSheOH.pdf}.
\bibitem[Pan16]{pie:pan16}\begin{enumerate}
\sphinxsetlistlabels{\Alph}{enumi}{enumii}{}{.}%
\setcounter{enumi}{17}
\item {} 
Pan, P. Natarajan, F. Baker, G. White, B. VerSteeg, M.S. Prabhu, C. Piglione, V. Subramanian, Internet\sphinxhyphen{}Draft: PIE: A lightweight control scheme to address the bufferbloat problem, April 2016.  Available online at \sphinxurl{https://tools.ietf.org/html/draft-ietf-aqm-pie-07}.

\end{enumerate}
\bibitem[ieee80211p]{wave:ieee80211p}
IEEE Std 802.11p\sphinxhyphen{}2010 “IEEE Standard for Information technology\textendash{} Local and metropolitan area networks\textendash{} Specific requirements\textendash{} Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications Amendment 6: Wireless Access in Vehicular Environments”
\bibitem[ieee1609dot1]{wave:ieee1609dot1}
IEEE Std 1609.1\sphinxhyphen{}2010 “IEEE Standard for Wireless Access in Vehicular Environments (WAVE) \sphinxhyphen{} Resource Manager, 2010”
\bibitem[ieee1609dot2]{wave:ieee1609dot2}
IEEE Std 1609.2\sphinxhyphen{}2010 “IEEE Standard for Wireless Access in Vehicular Environments (WAVE) \sphinxhyphen{} Security Services for Applications and Management Messages, 2010”
\bibitem[ieee1609dot3]{wave:ieee1609dot3}
IEEE Std 1609.3\sphinxhyphen{}2010 “IEEE Standard for Wireless Access in Vehicular Environments (WAVE) \sphinxhyphen{} Networking Services, 2010”
\bibitem[ieee1609dot4]{wave:ieee1609dot4}
IEEE Std 1609.4\sphinxhyphen{}2010 “IEEE Standard for Wireless Access in Vehicular Environments (WAVE) \sphinxhyphen{} Multi\sphinxhyphen{}Channel Operation, 2010”
\bibitem[saej2735]{wave:saej2735}
SAE Std J2735 “J2735 dedicated short range communications (DSRC) message set dictionary. 2009”
\bibitem[ieee80211]{wifi-references:ieee80211}
IEEE Std 802.11\sphinxhyphen{}2012, \sphinxstyleemphasis{Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications}
\bibitem[ieee80211\sphinxhyphen{}2016]{wifi-references:ieee80211-2016}
IEEE Std 802.11\sphinxhyphen{}2016, \sphinxstyleemphasis{Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications}
\bibitem[pei80211b]{wifi-references:pei80211b}
G. Pei and Tom Henderson, \sphinxhref{http://www.nsnam.org/~pei/80211b.pdf}{Validation of ns\sphinxhyphen{}3 802.11b PHY model}
\bibitem[pei80211ofdm]{wifi-references:pei80211ofdm}
G. Pei and Tom Henderson, \sphinxhref{http://www.nsnam.org/~pei/80211ofdm.pdf}{Validation of OFDM error rate model in ns\sphinxhyphen{}3}
\bibitem[lacage2006yans]{wifi-references:lacage2006yans}
M. Lacage and T. Henderson, \sphinxhref{https://dl.acm.org/doi/pdf/10.1145/1190455.1190467?download=true}{Yet another Network Simulator}
\bibitem[Haccoun]{wifi-references:haccoun}
D. Haccoun and G. Begin, \sphinxstyleemphasis{High\sphinxhyphen{}Rate Punctured Convolutional Codes for Viterbi Sequential Decoding}, IEEE Transactions on Communications, Vol. 32, Issue 3, pp.315\sphinxhyphen{}319.
\bibitem[Frenger]{wifi-references:frenger}
Pâl Frenger et al., “Multi\sphinxhyphen{}rate Convolutional Codes”.
\bibitem[ji2004sslswn]{wifi-references:ji2004sslswn}
Z. Ji, J. Zhou, M. Takai and R. Bagrodia, \sphinxstyleemphasis{Scalable simulation of large\sphinxhyphen{}scale wireless networks with bounded inaccuracies}, in Proc. of the Seventh ACM Symposium on Modeling, Analysis and Simulation of Wireless and Mobile Systems, October 2004.
\bibitem[linuxminstrel]{wifi-references:linuxminstrel}
\sphinxhref{https://wireless.wiki.kernel.org/en/developers/documentation/mac80211/ratecontrol/minstrel}{minstrel linux wireless}
\bibitem[lacage2004aarfamrr]{wifi-references:lacage2004aarfamrr}
M. Lacage, H. Manshaei, and T. Turletti, \sphinxstyleemphasis{IEEE 802.11 rate adaptation: a practical approach}, in Proc. 7th ACM International Symposium on Modeling, Analysis and Simulation of Wireless and Mobile Systems, 2004.
\bibitem[kim2006cara]{wifi-references:kim2006cara}
J. Kim, S. Kim, S. Choi, and D. Qiao, \sphinxstyleemphasis{CARA: Collision\sphinxhyphen{}Aware Rate Adaptation for IEEE 802.11 WLANs}, in Proc. 25th IEEE International Conference on Computer Communications, 2006
\bibitem[wong2006rraa]{wifi-references:wong2006rraa}
S. Wong, H. Yang, S. Lu, and V. Bharghavan, \sphinxstyleemphasis{Robust Rate Adaptation for 802.11 Wireless Networks}, in Proc. 12th Annual International Conference on Mobile Computing and Networking, 2006
\bibitem[maguolo2008aarfcd]{wifi-references:maguolo2008aarfcd}
F. Maguolo, M. Lacage, and T. Turletti, \sphinxstyleemphasis{Efficient collision detection for auto rate fallback algorithm}, in IEEE Symposium on Computers and Communications, 2008
\bibitem[proakis2001]{wifi-references:proakis2001}
J. Proakis, Digital Communications, Wiley, 2001.
\bibitem[miller2003]{wifi-references:miller2003}
 L. E. Miller, “Validation of 802.11a/UWB Coexistence Simulation.” Technical Report, October 2003.  Available \sphinxhref{https://doi.org/10.6028/NIST.WCTG.10-17-2003}{online}
\bibitem[ferrari2004]{wifi-references:ferrari2004}
G. Ferrari and G. Corazza, “Tight bounds and accurate approximations for DQPSK transmission bit error rate”, Electronics Letters, 40(20):1284\sphinxhyphen{}85, September 2004.
\bibitem[pursley2009]{wifi-references:pursley2009}
M. Pursley and T. Royster, “Properties and performance of the IEEE 802.11b complementary code key signal sets,” IEEE Transactions on Communications, 57(2);440\sphinxhyphen{}449, February 2009.
\bibitem[akella2007parf]{wifi-references:akella2007parf}
A. Akella, G. Judd, S. Seshan, and P. Steenkiste, ‘Self\sphinxhyphen{}management in chaotic wireless deployments’, in Wireless Networks, Kluwer Academic Publishers, 2007, 13, 737\sphinxhyphen{}755.  \sphinxurl{http://www.cs.odu.edu/~nadeem/classes/cs795-WNS-S13/papers/enter-006.pdf}
\bibitem[chevillat2005aparf]{wifi-references:chevillat2005aparf}
 Chevillat, P.; Jelitto, J., and Truong, H. L., ‘Dynamic data rate and transmit power adjustment in IEEE 802.11 wireless LANs’, in International Journal of Wireless Information Networks, Springer, 2005, 12, 123\sphinxhyphen{}145.  \sphinxurl{http://www.cs.mun.ca/~yzchen/papers/papers/rate\_adaptation/80211\_dynamic\_rate\_power\_adjustment\_chevillat\_j2005.pdf}
\bibitem[hepner2015]{wifi-references:hepner2015}
C. Hepner, A. Witt, and R. Muenzner, “In depth analysis of the ns\sphinxhyphen{}3 physical layer abstraction for WLAN systems and evaluation of its influences on network simulation results”, BW\sphinxhyphen{}CAR Symposium on Information and Communication Systems (SInCom) 2015.  \sphinxurl{https://core.ac.uk/download/pdf/75487102.pdf\#page=50}
\bibitem[baldo2010]{wifi-references:baldo2010}
N. Baldo et al., “Validation of the ns\sphinxhyphen{}3 IEEE 802.11 model using the EXTREME testbed”, Proceedings of SIMUTools Conference, March 2010.
\bibitem[lanante2019]{wifi-references:lanante2019}
L. Lanante Jr. et al., “Improved Abstraction for Clear Channel Assessment in ns\sphinxhyphen{}3 802.11 WLAN Model”, Proceedings of the 2019 Workshop on ns\sphinxhyphen{}3, June 2019.
\end{sphinxthebibliography}



\renewcommand{\indexname}{Index}
\printindex
\end{document}